accuracy defined loss function mean square error mean absolute percentage error model use output activation linear compiled loss mean squared error output looks like mean mean squared error scalar percentage val acc mean squared error mean percentage error another function definition mse wikipedia always non negative values closer zero better mean value val acc better val acc edit examples output accuracy metric train accuracy increase train loss function mse decrease accuracy defined mse defined keras least two separate issues question first one clear now commentssnoopy answer accuracy meaningless regression problem see also comment patyork keras thread good bad fact keras will protect user putting meaningful requests code even warning attempting something make sense requesting accuracy regression setting clarified issue since keras indeed return accuracy even regression setting exactly calculated light letrevert public dataset since provide details data namely boston house price dataset saved locally run simple experiment follows case model fitting history shown shows decreasing loss accuracy roughly increasing letevaluate now model performance training set using appropriate keras built function exact contents score array depend exactly requested model compilation case first element loss mse second one accuracy point letlook definition keras binary accuracy keras generated predictionspred first rounds checks see many equal true labelstrue getting mean letreplicate operation using plain python numpy code case true labelsbingo actually value returned score since erroneously request metrics accuracy model compilation keras will best satisfy will return accuracy indeed calculated shown despite completely meaningless setting quite settings keras hood performs rather meaningless operations without giving hint warning user two happened encounter giving meaningless results multi class setting one happens request loss binary crossentropy instead categorical crossentropy metrics accuracy see answers keras binary crossentropycategorical crossentropy performance binary crossentropy accurate categorical crossentropy multiclass classification keras disabling completely dropout extreme case one requests dropout rate see answer dropout behavior keras rate dropping input units expected loss function mean square error case used indicate far predictions deviate target values training phase weights updated based quantity dealing classification problem quite common define additional metric called accuracy monitors many cases correct class predicted expressed percentage value consequently value means correct decision correct decisons network training loss decreasing usually accuracy increases note contrast loss accuracy usally used update parameters network helps monitor learning progress current performane network desertnaut said clearly consider following two pieces code compile code binary accuracy code labels integer keras roundtrue get high categorical variables must use one hot encoding want use classifier classification can pass data classifier without encoding trying following feature selection read train file change type categorical features category use one hot encoding problempart often get stuck although using strong machine thus without one hot encoding canfeature selection determining importance features recommend approach can use pandas example following will transform given column one hot use prefix multiple dummies approach use scikit learn using onehotencoder advantage able fit training data transform data using instance also handle unknown control encoder unseen data given dataset three features four samples let encoder find maximum value per feature transform data binary one hot encoding link examplelooking options can use scikit learn basic one hot encoding pandas pass data frame get dummies function example dataframe called imdb movies returns new dataframe column every level rating exists along either specifying presence rating given observation usually want part original dataframe case attach new dummy coded frame onto original frame using column binding can column bind using pandas concat function can now run analysis full dataframe simple utility function recommend making utility function quickly usage result also per pmalbu comment like function remove original feature encode use version can encode multiple features time follows can return value indices one hotclasses data now reshape make sure right labels format might also one hot encoding pandas easy edit another way one hot using sklearnlabelbinarizer firstly easiest way one hot encode use sklearn donthink using pandas one hot encode simple unconfirmed though creating dummy variables pandas python lastly necessary one hot encode one hot encoding exponentially increases number features drastically increasing run time classifier anything else going run especially categorical feature many levels instead can dummy coding using dummy encoding usually works much less run time complexity wise prof told lesscode custom encoding function want edit comparison clearer one hot encoding convertlevelscolumns can see will explode memory many different types levels categorical feature keep mind just one column dummy coding convert numerical representations instead greatly saves feature space cost bit accuracy can use get dummies get one hot encoding particular columnone line code one hot encoding solution using dictvectorizer pandas records method one hot encoding requires bit converting values indicator variables typicallyprocess requires apply coding several times validation test data sets applying model construct real time observed data store mapping transform used construct model good solution use dictvectorizer labelencoder followed get dummies function can use works pandas dataframe column dataframe creates returns mapping back call like test data call made passing dictionary returned back training equivalent method use dictvectorizer related post blog mention since provides reasoning behind approach simply using get dummies post disclosure blog can pass data catboost classifier without encoding catboost handles categorical variables performing one hot target expanding mean encoding can following note donuse changing color group knowlate party simplest way hot encode dataframe automated way use function works output used acoustic model probably helpsmodel function one hot encoding without using numpy pandas packages takes list integers booleans strings perhaps types example know already lot answers question noticed two things first answers use packages like numpy pandas good thing writing production code probably using robust fast algorithms like provided numpy pandas packages sake education think someone provide answer transparent algorithm just implementation someone elsealgorithm second noticed many answers provide robust implementation one hot encoding meet one requirements requirements see useful accurate robust one hot encoding function one hot encoding function must tested many answers question fail one requirements tryresulting dataframetrain encoded original categorical features now replaced one hot encoded versions information category encoders add questions let provide python function using numpy linevalueshard coded use good number neurons case use mini batches example demo project tutorial function used usage expanding martin thomaanswer assume variables categorical variables data frame named cname cname cname following code will automatically create one hot encoded variable new dataframe simple example using vectorize numpy apply example pandas tried approach pandas dataframe wish divide separate sets know using train test split one can divide data two sets train test however couldnfind solution splitting data three sets preferablylike indices original data know workaround use train test split two times somehow adjust indices standard built way split data sets instead numpy solution will shuffle whole dataset first frac random state split data set following parts int lenint lenindices sections array small demo usage letsplit elements array following parts however one approach dividing dataset train testuse train test split method twice function written handle seeding randomized set creation rely set splitting doesnrandomize sets python function splits pandas dataframe train validation test dataframes stratified sampling performs split calling scikit learnfunction train test split twice complete working example consider dataset label upon want perform stratification label distribution original dataset say foo bar baz now letsplit dataset train validation test subsets using ratio split retains distribution labels see illustration example dataset now letcall split stratified train val test function get train validation test dataframes following ratio three dataframestrainvaltest contain original rows sizes will follow ratio three splits will distribution label namely foo bar baz case supervised learning may want splityinputground truth output just pay attention shuffley way splitting eithery dataframe shuffle separate apply split just like chosen answery two different dataframes shufflereorderway shuffledapply split convenient use train test split without performing reindexing dividing several sets writing additional code best answer mention separating two times using train test split changing partition sizes wongive initially intended partition portion validation test setsremain change counted occasion initial partitions saved split data times sklearntrain test split consideringoriginal dataframe first split data train test split train set train validation slice original dataframe according indices generated steps result going like note soluctions uses workaround mentioned question split dataset training testing set answers using fit model can add validation split parameter need create validation set advance example validation set meant serve representative run testing set training training set taken entirely training setfold cross validation recommended validation split need create validation set separately still split dataset three sets asking answer amount sub sets work size percentage case percentage train percentage val percentage test percentage easiest way think mapping split fractions array index follows data data question appear programming within scope defined help center closed years agoaware gradient descent back propagation algorithm donget using bias important use example mapping function use two inputs one output give correct weights however use three inputs one bias gives correct weights think biases almost always helpful effect bias value allows shift activation function left right may critical successful learning might help look simple example consider input output network bias output network computed multiplying inputweightpassing result kind activation function function network computes various valueschanging weightessentially changes steepness sigmoiduseful wanted network outputjust changing steepness sigmoid wonreally work want able shift entire curve rightexactly bias allows add bias network likexoutput network looks like various valuesweightshifts curve right allowsnetwork outputssimpler way understand bias somehow similar constantlinear functionaxallows move line fit prediction data better withoutline always goes origin may get poorer fit illustrations showing result simple layer feed forward neural network without bias units two variable regression problem weights initialized randomly standard relu activation used answers concluded without bias relu network able deviate zero two different kinds parameters can adjusted training ann weights value activation functions impractical easier one parameters adjusted cope problem bias neuron invented bias neuron lies one layer connected neurons next layer none previous layer always emits since bias neuron emits weights connected bias neuron added directly combined sum weights equation just likevalue activation functions reasonimpracticalsimultaneously adjusting weight value change weight can neutralize change value useful previous data source single perceptron can used represent many boolean functions example assume boolean values true false one way use two input perceptron implement function set weightswperceptron can made represent function instead altering thresholdfact can viewed special casesn functions functions leastn inputs perceptron must true function correspondsfunctionnn function easily represented using perceptron setting input weights value setting thresholdaccordingly perceptrons can represent primitive boolean functions nand machine learning tom mitchell threshold biasweight associated bias threshold neuron biastermgeneric algebra term considermc straight line equation nowbias line will always pass origin depends one parameter slope less things playbias takes number activity shift graph hence able represent complex situations logistic regression expected value target transformed link function restrict value unit interval way model predictions can viewed primary outcome probabilities shown sigmoid function wikipedia final activation layermap turns neuron also bias role play shifts curve flexibly helpmap model layer neural network without bias nothing multiplication input vector matrix output vector might passed sigmoid function normalisation use multi layered ann afterwardsimportant meansusing linear function thus input zeros will always mapped output zeros might reasonable solution systems general restrictive using biaseffectively adding another dimension input space always takes value oneavoiding input vector zeros donlose generality trained weight matrix needs surjective still can map values previously possibleann ann mapping two dimensions one dimension reproducing xor functions can think neuronal network followingplane mark positions input vectors boolean valueswant mark ann now drawing straight lineplane separating positive output negative output values without bias straight linezero whereas biasfree put anywheresee without biasfacing problem function since canput negative side allowed line problem equal function bias howevereasy draw line note xor function situation cansolved even bias use anns rarely know internals systems want learn things learned without bias look following data basically function mapsone layered network linear mapping find solution however biastrivial ideal setting bias also map points mean target points let hidden neurons model differences point modification neuron weights alone serves manipulate shape curvature transfer function equilibrium zero crossing point introduction bias neurons allows shift transfer function curve horizontally left right along input axis leaving shape curvature unaltered will allow network produce arbitrary outputs different defaults hence can customize shift input output mapping suit particular needs see graphical explanation found bias might important first layerespecially fully connected layers end seems play big role might highly dependent network architecture datasetworking images might actually prefer use bias theory way network will independent data magnitude whether picture dark bright vivid net going learnjob studying relativity inside data lots modern neural networks utilize data biases might critical depends type datadealing information magnitude invariant inputting lead result inputting might better without bias bias determines much angle weight will rotate two dimensional chart weight bias can helpfind decision boundary outputs say need build function inputoutputpairtttt now need find decision boundary ideal boundary seeperpendicular boundary thus saydecided direction boundary however hard find correctfirst time mostly choose originalvalue randomly thus first boundary may now boundary parallelaxis want rotate boundary changinguse learning rule functionwwp equivalentwb therefore changing valuebias can decide anglew learning rule ann also read neural network design martinhagan howarddemuth markbeale chapter perceptron learning rule simpler terms biases allow variations weights learnt side note sometimes given threshold anyway variations mean biases add richer representation input space modellearnt stored weights better weights can enhance neural netguessing power example learning models hypothesis guess desirably boundedy given input maybe classificationycondition hypothesis outcome threshold talked note examples setup inputsx double valued vector instead natesingle valuedinputs collectionignore bias many inputs may end represented lot weights model limited poorer quantities good weights instead many many good weights better learn bias poorly learnt weights lead poorer guesses decrease neural netguessing power optimal model learns close origin also many places possible inside threshold decision boundary bias can enable degrees freedom close origin limited originimmediate region neural networks absence bias neuron may activated considering weighted sum input layer neuron activated information neuron passed rest neural network value bias learnable effectively bias threshold can think bias easy get neuron output really big biaseasy neuron output bias negativedifficult summary bias helps controlling value activation function will trigger follow video details useful links geeksforgeeks towardsdatascience expanding zfyexplanation equation one input one neuron one output lookvalue input node value bias nodecan directly output passed function often sigmoid function also note bias constant make everything simpler always pick probablycommon zfy without showing explaining network trying learn coefficientsadapt data can see adding elementallows fit better data now can change slope intercept one input equation will look like note equation still describes one neuron one output network neurons just add one dimension coefficient matrix multiplex inputs nodes sum back node contribution can write vectorized format inputs bias another desired solution dot product two vectors need transposeshape correct wrotex transposed end can also see bias just one input represent part output actually independent input think simple waywy outputweight imagine conditionyx equals want update weight compute much change delw targettarget target output case delw will change sincecomputed suppose can add extra value will helpww bias weight can adjusted get correct bias consider example terms line slope intercept specific form linear equationsmxcheck image imagewant increase will changing valuebiasbooks studiedalways defined connectivity index two neurons means higher connectivity two neurons stronger signals will transmitted firing neuron target neuronwresult maintain biological character neurons need keepreal regressionwill endcontradicts neurons working result proposecos theta cos thetaxxbb cos thetainteger bias acts anchorwaykind baseline dongo terms graph think likemxs likeintercept function output input times weight value added bias value apply activation function term bias used adjust final output matrixintercept instance classic equationmxc line will always pass adding bias term provides flexibility better generalisation neural network model bias helps get better equation imagine input output like functionaxneed put right line inputoutputminimise global error point line keep equation likeax will one parameter adaptation even find best minimising global error will kind far wanted value can say bias makes equation flexible adapt best valuesgivenarray indices want one hot encodearray create zeroed arrayenough columns row setcolumn case using keras built utility pretty much yxdanswer see source code find useful num classes stands number classes vector shape function transformsnote zero indexed will give exactly wanted believesource sequence models number classes vector containing labels can use example output amongst things may initialize output transform sparse hot encoding example enjoy coding can use following code converting one hot vector letnormal class vector single column classes number class remove function convertsvectorone hot array example usage think short answer generic casedimensions came wondering better solution donlike create lists last two lines anyway measurements timeit seems numpy based indices arange iterative versions perform just elaborate excellent answerrnc generic version also quick dirty benchmark method method currently accepted answer yxd slightly changed offer api except latter worksndarrays latter method faster macbook pro former general using tensorflow one hot recently ran problem kind found said solution turned satisfying numberswithin certain formation example want one hot encode following listahead posted solutions already mentioned considering data methods mentioned will likely end one hot columns answers include something likefound generic solution worked wanted share hope someone encountered restrictions solutions might come handy type encoding usually part numpy array using numpy array like simple way convert hot encodingclean easy solution find easiest solution combines adding completion simple function using numpy operators takes input probability matrix will returndimensionality independent standalone solution will convertdimensional array arr nonnegative integers one hotdimensional array one hot one hotc means arrc can recover input via one hot use following code works best founds donneedlink link documentationfollowing googleofficial tensorflow guide trying build simple neural network using keras comes training model use entire dataset entries instead uses entries training possible fix outputoriginal google colab notebookworking number batches according documentation unspecified batch size will default happens fit default batch size since specified anything different total number batches data train samples number steps samples fit method argument batch size default value implementation correct train batch size will see number steps will instead since just use batch size want entire data samples lot methods written like logits just generic tensor input named logits secondly difference following two methods know example really helpful softmax logits simply means function operates unscaled output earlier layers relative scale understand units linear means particular sum inputs may equal values probabilities might input internally first applies softmax unscaled output computes cross entropy valuesdefined labels squishes inputs sum input mapping interpreting inputs log probabilities logits converting back raw probabilities shape output softmax input see answer softmax used extensively dnns together mathematically careful waysimilar result cross entropy summary metric sums across elements output tensor shape first dimension treated batch want optimization minimize cross entropysoftmaxing last layer use covers numerically unstable corner cases mathematically right way otherwiseend hacking adding little epsilons edited single class labels object can belong one class might now consider usingconvert labels dense one hot array function added release short version suppose two tensorshat contains computed scores class examplewbtrue contains one hot encoded true labels interpret scoreshat unnormalized log probabilities logits additionally total cross entropy loss computed manner essentially equivalent total cross entropy loss computed function softmax cross entropy logits long version output layer neural network will probably compute array contains class scores training instances computationhatxserve examplecreatedhatarray rows correspond training instances columns correspond classes training instances classes note values normalizedadd order normalize can apply softmax function interprets input unnormalized log probabilities aka logits outputs normalized linear probabilitiesimportant fully understand softmax output sayingshown table clearly represents output can seen example probability training instance class class probabilities training instance normalized sum row now class probabilities training instance can take argmax row generate final classification may generate training instance belongs class training instance belongs class classifications correct need measure true labels training set will need one hot encodedtrue array rows training instances columns classescreated exampletrue one hot array true label training instance class true label training instance class probability distributionhat softmax close probability distributiontrue can use cross entropy loss measure error can compute cross entropy loss row wise basis see results can see training instance loss training instance higher loss result makes sense examplehat softmax showed training instancehighest probability class matches training instancetrue however prediction training instance showed highest probability class match true class class really want total loss training instances can compute using softmax cross entropy logits can instead compute total cross entropy loss using function shown note total loss total loss produce essentially equivalent results small differences final digits however might use second approach takes one less line code accumulates less numerical error softmax done inside softmax cross entropy logits values output softmax normalization applied wish constrain output model architecture outputs unconstrained values can add normalisation layer enforce common choice sigmoid function binary classification typically logistic function multi class tasks multinomial logistic function want interpret outputs new final layer probabilities implication unconstrained inputs sigmoid must inverse sigmoid probabilities logistic case equivalent log odds probability arguments softmax called logits tensorflow assumption softmax final layer model outputinterpreted probability inputlayer interpretable logit machine learning propensity generalise terminology borrowed maths stats computer science hence tensorflow logit analogy used synonym input many normalisation functions answers enough description asked question adding tensorflow optimised operation applying activation function calculating cost using activation followed cost functions hence good practice use can find prominent difference resource intensive model tensorflow compatible answer explanations dga stackoverflowuser detailed logits related functions functions used tensorflowwill work fine migrate codeetcetc using functions result error hence specifying compatible calls functions discussed migratex benefit community functionsrespective functions migratedx information migrationx please refer migration guide one thing definitely like highlight logit just raw output generally output last layer can negative value usecross entropy evaluation mentioned work logdefined usingsoftmax activation will overcome problem understanding please correct wrong logits unnormalized outputs neural network softmax normalization function squashes outputs neural network sum softmax cross entropy logits loss function takes outputs neural network squashed softmax true labels outputs returns loss valuetrying train cnn categorize text topic use binary cross entropy get accuracy categorical cross entropy get accuracy donunderstandmulticlass problem doesnmean use categorical cross entropy results binary cross entropy meaningless compile either like using categorical crossentropy loss function intuitively makes sensewant use categorical cross entropy donunderstand get good results binary poor results categorical reason apparent performance discrepancy categorical binary cross entropy user xtof already reported answer accuracy computed keras method evaluate just plain wrong using binary crossentropy labels like elaborate demonstrate actual underlying issue explain offer remedy behavior bug underlying reason rather subtle undocumented issue keras actually guesses accuracy use depending loss function selected include simply metrics accuracy model compilation words first compilation option valid second one will produce expect reason use binary cross entropy least principle absolutely valid loss function check metrics source code keras define single accuracy metric several different ones among binary accuracy categorical accuracy happens hood since selected binary cross entropy loss function specified particular accuracy metric keras infers interested binary accuracy returns fact interested categorical accuracy letverify case using mnist cnn example keras following modification remedy said nothing wrong least principle still getting categorical accuracy required problem hand ask explicitly categorical accuracy model compilation follows mnist example training scoring predicting test set show two metrics now system setup update post discovered issue already identified answer depends type classification problem dealing three main categories first case binary cross entropy used targets encoded one hot vectors second case categorical cross entropy used targets encoded one hot vectors last case binary cross entropy used targets encoded one hot vectors output neuron unit considered separate random binary variable loss entire vector outputs product loss single binary variables therefore product binary cross entropy single output unit binary cross entropy defined categorical cross entropy definedindex running number classescame across inverted issue getting good results categorical crossentropy classes poor binary crossentropy seems problem wrong activation function correct settingsreally interesting case actually setup following statement true means constant multiplication factor losses equivalent weird behaviour observing training phase might example following phenomenonconstant factor might help case binary crossentropy many epochs learning rate value greater categorical crossentropy case usually restart training learning phase times notice behaviour adjusting class weights using following pattern makes loss less frequent classes balancing influence dominant class loss beginning training part optimization process edit actually checked even though case maths hold case kerastrue keras automatically normalizing outputs sum actual reason behind weird behaviour case multiclassification normalization harms training commenting marcin answer carefully checked one students code found weird behavior even epochs marcinexplanation likely case found answer actually simple accuracy computed keras method evaluate just plain wrong using binary crossentropy labels can check recomputing accuracy first call keras method predict compute number correct answers returned predict get true accuracy much lower keras evaluate one simple example multi class setting illustrate suppose classes onehot encoded just one prediction true label predicted label using categorical crossentropy accuracy just cares get concerned class right however using binary crossentropy accuracy calculated classes prediction final result will mean individual accuracies cases recommended use categorical crossentropy multi class classes mutually exclusive problem binary crossentropy multi label problem multi class problem use categorical crossentropy binary cross entropy will produce bogus results likely will evaluate first two classes multi class problem can quite good depending number classesclassesminimum performance can get outputting random class passing target array shapedimdim using loss categorical crossentropy categorical crossentropy expects targets binary matricess shape samples classes targets integer classes can convert expected format via alternatively can use loss function sparse categorical crossentropy instead expect integer targets using categorical crossentropy loss targets categorical format target sample dimensional vector zeros except index corresponding class sample take look equation can find binary cross entropy punish label predicted also label predicted however categorical cross entropy punish label predictedmake assumption one label positive main point answered satisfactorily brilliant piece sleuthing desernaut however occasions bce binary cross entropy throw different results cce categorical cross entropy may preferred choice thumb rules shared loss select work fine cases like add new dimensions discussionsoftmax activation throws probability distribution predicted value multi class problem preferred loss categoricalessentially boilsppredicted probability lone positive class sample means negative predictions role play calculatingintention rare occasion may needed makevoices count can done treating sample series binary predictions expected predicted broken now proceed compute different cross entropies one expected predicted combo sumdifferent scale continues measure difference expected predicted values difference schemevalues also penalized rewarded alongvalues case problem going use output probabilitiesves instead using max predict justlabel may want consider versionmulti label situation expected conventional approach use one sigmoid per output neuron instead overall softmax ensures output probabilities independent get something like definitionmeasures difference probability distributions two lists probability distributions probability distributions always add conventional solution use loss approach break expected predicted values individual probability distributions proceed calculate cross entropies sum challenge happens number classes may high say may couple present sample expected something like predicted something likecasecan seeclasses beginning create nuisance value calculating loss voicesamples may care getting drowned canuse categoricalversionsamples considered calculation forced break probability distributions multiple binary probability distributions otherwise probability distribution first place break multiple binary probability distributions choice use binarycourse gives weightageclasses one option drown voiceclasses multiplier multiplylosses value gamma gamma say case gamma can now loss comes nuisance value come years back facebook much paper came also multipliedlossespowerp probability outputx constant penalizedlosses even especially ones model pretty confidentclose combined effect punishing negative class losses combined harsher punishment easily classified cases accounted majoritycases worked beautifully facebook called focal loss responses question whether binarymakes sense case answer depends cases conventional thumb rules work occasions rules bent even broken suit problem hand depth treatment can refertargetpredict doesnneed apply binary classification problem source code binary crossentropy labels target logits output tensorflow actually used documentation says measures probability error discrete classification tasks class independent mutually exclusive instance one perform multilabel classification picture can contain elephant dog decision paths trained tree decision tree textual list something like believe answer correct answers prints valid python functionexample output tree trying return input number stumbling blocks see answers created function extract rules decision trees created sklearn function first starts nodes identified child arrays recursively finds parents call nodelineage along way grab values need create else sas logic sets tuples contain everything need create sas else statements like using blocks sas create logic describing nodeentire path single integer tuples terminal node path preceding tuples combine create node scikit learn introduced delicious new method called export text version may extract rules tree documentationlonger necessary create custom functionfit model just need two lines code first import export text second create object will contain rules make rules look readable use feature names argument pass list feature names example model called model features named dataframe calledtrain create object called tree rules just print save tree rules output will look like modified code submitted zelazny print pseudocode call get codeexample will obtain new decisiontreeclassifier method decision path release developers provide extensive documented walkthrough first section code walkthrough prints tree structure seemshowever modified code second section interrogate one sample changes denoted edit changes marked code since updated walkthrough link errors pointed pull requestsmuch easier follow along now change sample see decision paths samples havenasked developers changes just seemed intuitive working example can see digraph treebuilding open source automl python package many times mljar users want see exact rules treeimplemented function based paulkernfeld answer rules sorted number training samples assigned rule rule information predicted class name probability prediction classification tasks regression task information predicted value printed printed rulessummarized ways extract rules decision tree article extract rules decision tree ways scikit learn python code need modified top liked code indent jupyter notebook python correctly just everyone helpfuljust add modification zelazny danielebeautiful solutions one python tabs make readablegoing needed rules written format adapted answer paulkernfeld thanks can customize need now can use export text complete example sklearn codes approach anaconda python plus package name pydotmaking pdf file decision rules hope helpful tree graphy show way translate whole tree single necessarily human readable python expression using skompiler library builds paulkernfeldanswer dataframefeatures target dataframeresonses want get ideavalue ended node also ant plot accordingly can following elegant version printing rules scikit learn decision tree python offsets conditional blocks make structure readable can also make informative distinguishing class belongs even mentioning output value approach extract decision rules form can used directly sql data can grouped node based approaches previous posters result will subsequent case clauses can copied sql statementselect coalesce case conditions nodea case conditions nodeb nodename table view modified zelaznycode fetch sql decision tree apparently long time ago somebody already decided try add following function official scikittree export functions basically supports export graphviz full commit copy content paste thank wonderful solution paulkerfeld top solution want serialized version trees just usesplits hence feature names children placeholder noticefunction generates python code decision tree converting output export text sample usage sample output example generated namesstrj range num features one handy feature can generate smaller file size reduced spacing just set spacing answer get readable efficient representationfeatures relatively new machine learning python ubuntu set images jpg format half contain feature want caffe learn half donm trouble finding way convert required lmdb format necessary text input files question can anyone provide step step guide use convert thanks first thing must build caffe caffetools convert imageset one tools installing caffe makeing make sure ran make tools verify binary file convert imageset created caffe root build tools images put images foldercall path jpegs labels create text file path labels line per input image example img img img flags might useful can check caffe root examples imagenet convert example use convert output happend documentation says note input layer rank greater flattened prior initial dot product kernel output reshaped currently contrary stated documentation dense layer applied last axis input tensor contrary documentation donactually flattenapplied last axis independently words dense layerunits applied input tensor shapedimdimdimk output shapedimdimside note makes timedistributed dense dense equivalent another side note aware effect shared weights example consider toy network model summary can see dense layer parameters unit dense layer connected elements row input weights therefore bias params per unit update visual illustration example question appear programming within scope defined help center closed years agodeveloping internal website portfolio management tool lot text data company names etcreally impressed search engines ability quickly respond queries mean xxxx need able intelligently take user query respond raw search results also mean response highly likely alternative answer etcdevelopingdonhold updatecan mimic without millions unpaid usersexplanation directly source almost min worth watching basically according douglas merrill former cto google like write misspelled word google donfind wanted donclick results realize misspelled word rewrite word search box find want click first links pattern multiplied millions times shows common misspells common corrections way google can almost instantaneously offer spell correction every language also means overnight everyone start spell night nigth google suggest word instead edit thomasrutter douglas describe statistical machine learning know correct query know query comes user using cookies users perform query users click result goes back type another query corrected word time clicks result know found correction can also know related queries two different information links show furthermore now including context spell check can even suggest different word depending context see demo google waves shows context taken account automatically correct spelling explained natural language processing works finally awesome demo can done adding automatic machine translationmmixadded anchors minute seconds videos skip directly content donwork try reloading page scrolling hand mark found article time ago write spelling corrector written peter norvig director research google incinteresting read spelling correction topic examples pythonclear simple understand think algorithm can easily translated languages follows short description algorithm algorithm consists two steps preparation word checking step preparation setting word database best can use actual search words occurence donlarge set text can used instead count occurrence popularity word step word checking finding words similar one checked similar means edit distance low typically edit distance minimum number inserts deletes changes swaps needed transform one word another choose popular word previous step suggest correction word theory mean algorithm can refer chapter introduction information retrieval available online free section page exactly answers question specifically answer update need dictionary words nothing else including millions users internet serious nlp natural language processing example much data entire internet can count number times three word sequence occurs known trigram see sentence like pink frugr concert see hits find likely pink concert corpus apparently just variation davide gualano saying though definitely read link google course use web pages knows corpus makes algorithm particularly effective guess use combination levenshtein distance algorithm masses data collect regarding searches run pull set searches shortest levenshtein distance entered search string pick one results normally production spelling corrector utilizes several methodologies provide spelling suggestion decide way determine whether spelling correction required may include insufficient results results specific accurate enough according measure etc use large body text dictionary known correctly spelled easily found online places lingpipe determine best suggestion look word closest match based several measures intuitive one similar characters shown research experimentation two three character sequence matches work better bigrams trigrams improve results weigh higher score upon match beginning end word performance reasons index words trigrams bigrams performing lookup convertgram lookup via hashtable trie use heuristics related potential keyboard mistakes based character location hwllo hellocloseuse phonetic key soundex metaphone index words lookup possible corrections practice normally returns worse results usinggram indexing described case must select best correction list may distance metric levenshtein keyboard metric etc multi word phrase one word may misspelled case can use remaining words context determining best match use levenshtein distance create metric tree slim tree index words run nearest neighbour query got result google apparently suggests queries best results spelled correctly case probably spell corrector feasible course store value every query based metric good results returns need dictionary english based data generate word trellis calculate probabilities transitions using dictionary add decoder calculate minimum error distance using trellis course take care insertions deletions calculating distances fun thing qwerty keyboard maximizes distance hit keys close cae turn car cay turn cat return word minimum distance compare query database check better results close matches best answer found spelling corrector implemented described googledirector research peter norvig want read theory behind can read book chapter idea algorithm based statistical machine learning saw something years back may changed since apparently started analysing logs users submitting similar queries short space time used machine learning based users corrected something else identifying fingerprints restoring broken data spelling corrections davide mentioned already simple tons data statistics every possible term based often queried variations usually yield results users see typed frequent misspelling search termahead propose usual answer actually misspelling effect frequent searched term algorythm will take right one regarding question mimic behavior without tons data use tons data collected google download google sarch results misspelled word search mean html guesscalled mashup nowadays apart answers case want implement something quickly suggestion can find implementation detailed documentation algorithm github mean say spell checker spell checker rather whole phrasegot link spell checking algorithm developed python check link meanwhile also working project includes searching databases using text guess solve problem old questionsurprised nobody suggestedusing apache solr apache solr full text search engine besides many functionality also provides spellchecking query suggestions documentation default lucene spell checkers sort suggestions first score string distance calculation second frequency available suggestion index specific data structure ternary search tree naturally supports partial matches near neighbor matches easiest way figure google dynamic programmingalgorithmborrowed information retrieval used heavily modern day bioinformatics see similiar two gene sequences optimal solution uses dynamic programming recursion solved problem lots solutions just google around find open source code learning neural networks built simple one keras iris dataset classification uci machine learning repository used one hidden layer network hidden nodes adam optimizer used learning rate run epochs softmax used output loss catogorical crossentropy getting following learning curves can see learning curve accuracy lot flat regions donunderstand error seems decreasing constantly accuracy doesnseem increasing manner flat regions accuracy learning curve imply accuracy increasing regions even though error seems decreasing normal training likely something wrong little understanding actual meanings mechanics loss accuracy will much help refer also answer mine although will reuse parts sake simplicity will limit discussion case binary classification idea generally applicable equation logistic loss now letsuppose true labelk early point training make rather poor predictionk plugging numbers loss equation suppose now next training step getting better indeed getk now hopefully start getting idea letsee one later snapshot get sayk can see classifier indeed got better particular sample improvement still shown accuracy cares correct classifications accuracy viewpoint doesnmatter get better estimatesk long estimates remain threshold momentk exceeds threshold loss continues decrease smoothly far now jump accuracy contribution samplen total number samples similarly can confirmk exceeded hence giving correct classification now contributing positively accuracy improvementsgetting closer still continue decrease loss impact accuracy similar arguments hold cases true labelm corresponding estimatesm start somewhere threshold evenm initial estimates hence providing correct classifications already contributing positively accuracy convergence towards will decrease loss without improving accuracy putting pieces together hopefully can now convince smoothly decreasing loss stepwise increasing accuracy incompatible make perfect sense indeed general level strict perspective mathematical optimization thing called accuracy loss accuracy gets discussion business perspective different business logic might even call threshold different default quoting linked answer loss accuracy different things roughly speaking accuracy actually interested business perspective loss objective function learning algorithms optimizers trying minimize mathematical perspective even roughly speaking can think loss translation business objective accuracy mathematical domain translation necessary classification problems regression ones usually loss business objective least can principle tried following libraries like keras fcn ahundt used custom loss functions none seems work target output codetruepred respectively used writing method coefficient metric second writing wrapper function format things way keras needsactually quite bit cleaner use keras backend instead tensorflow directly simple custom loss functions like diceexample coefficient implemented way now tricky part keras loss functions must taketruepred parameters need separate function returns another function finally can use follows keras compile according documentation can use custom loss function like callable signature lossy truepred returns array losses one sample input batch can passed compile loss note sample weighting automatically supported loss simple example complete example addition can extend existing loss function inheriting example masking binarycrossentropy good starting point custom log guide custom losseshaving running get incorrect tags quick brown lazy sentence testing online tool gives result quick brown fox adjectives nouns short nltk perfect fact model perfect note nltk version default pos tag function longer old maxent english pickle now perceptron tagger honnibalimplementation seebetter perfect point someone wantsdr solutions see try using tagger see using default maxent pos tagger nltk using stanford pos tagger using hunpos note default encoding iso utf using senna make surelatest version nltk changes made api try building better pos tagger complains pos tag accuracy stackoverflow include issues nltk hunpos include issues nltk stanford pos tagger include solutions changing stanford senna hunpos tagger will definitely yield results much simpler way experiment different taggers also included within nltk default pos tagger ntlk right now averaged perceptron taggerfunction will opt use maxent treebank tagger instead found averaged perceptron pre trained tagger nltk biased treating adjectives nouns example treebank tagger gotten adjectives correctevaluating tools productionbased applications one options spark mllib questions serve model trained example azuretrained model exposed web service can consumed applicationsimilar case amazonserve deploymodels apache spark one hand machine learning model built spark canserved way serve azureamazontraditional manner databricks claims able deploy models usingnotebook havenactually tried yet hand can use model three ways three possible ways course can think architecture restful service behind can build using spark jobserver per example train deploy needs developmentbox solution might also use projects like oryx create full lambda architecture train deploy serve model unfortunately describing mentioned solution quite broad doesnfit scope one option use mleap serve spark pipelinemodel online dependencies spark sparkcontext use sparkcontext important will drop scoring time single recordsingle digit microseconds order use mleap integrated pipeline stages available spark mllib exception lda time writing however things might get bit complicated using custom estimators transformers take look mleap faq info custom transformers estimators performances integration comparing two rather different things apache spark computation engine mentioned amazon microsoft solutions offering services services might spark mllib behind scene save trouble building web service pay extra number companies like domino data lab cloudera ibm offer products can deploy spark cluster easily build service around models various degrees flexibility naturally build service various open source tools specifically depends user interact model sortjest rest api need change parameters model model jobs batch real time nature can naturally build one solutiongoing huge effort personal recommendation take advantage can one available services amazon google microsoft whatever need premises deployment check domino data lab product mature allows easy working models building till deployment cloudera focused cluster computing including spark will take something mature editrecommend look apache predictionio open source machine learning server amazing project lotpotential able just get work caveats python using sparkapi mllib sure work way basically follow example provided msftazureml github word warning code will provision error example run method end also completely agree mleap assessment answer can make process run way faster thought answer question specificallyi developinglstm model want add attention layer getting add current code model model summary can possible custom solution custom layer computes attention positional temporal dimensionbuild receivetensors outputtensors return sequences truetensors return sequences false dummy example return sequences true return sequences false can integrate networks easily running notebook case someone using tensorflow keras externally waynew neural networks machine learning genetic algorithms first implementation writing network learns play snake example case havenplayed questions donfully understand questions just want make sure understand general idea correctly population snakes randomly generated dna dna weights used neural network time snake moves uses neural net decideusing bias population dies select parents maybe highest fitness crossover dna slight mutation chance given whole board input spots enough hidden layers idea many maybe enough time learn box good inputs ideas given input method good starting place hidden layer sizes course plan tweaking just donknow good starting place finally fitness snake besides time get applelengthlifetime anything else factored order get snake learn block anything else add fitness help thank post will advise general opinion idea can seetrying believe game idea using randomly generated identities adversaries control behavior way randomly alters wayusing artificial intelligence behave intelligently lot potential mapping navigational instructions action sequences neural network processing game board involves dense opposed sparse data find convolutional neural network cnn useful however need translate map action sequence sequence optimized neural networks recurrent neural networks will likely useful find studies use neural networks map navigational instructions action sequences construct game map move character game many types inputs general opinion will help sounds likemissing basic understanding neural networks work primary recommendation study underlying mechanics behind neural networks generalimportant keep mind neural network type machine learning model doesnreally make sense just construct neural network random parameters neural network machine learning model trained sample data trained can evaluated test data root machine learning largely influenced bayesian statistics might benefit getting textbook bayesian statistics gain deeper understanding machine based classification works general will also valuable learn differences different types neural networks long short term memory lstm convolutional neural networks cnns want tinker neural networks can used classification tasks try learn math professional opinion learning underlying math neural networks importantintimidating give testimony able learn prefer learning classroom environment recommend try great resource textbook learning mechanics mathematics neural networks tutorials neural network libraries recommend try working tutorials neural network library saw similar application inputs usually snake coordinates apple coordinates sensory data wall next snake head case using genetic algorithm good idea case parametric learning finding set weights structure will based estimationcan also used structure learning finding topology ann usingwill computational hard professor floreano something similar usefinding weights neural network controller robot robot labyrinth perform task neural network hidden layer one neuron recurrent joints inputs one lateral connection two outputs outputs connected input layer hidden layer mentioned one neuron floreano something interesting say donborn determined synapses synapses change lifetime usefinding rules change synapses rules based hebbian learning perform node encoding weights connected neuron will apply rule beginning initialized weights small random values finding rules instead numerical value synapse leads better results one florenoarticles experience last semester schoolmate get task finding rules synapsespiking neural network snn controller kinematic model mobile robot task lead robot chosen point obtained results expected can see results recommend use ordinary ann instead snn snn brings new phenomensusing linearperfect problem evaluate predicted results using accuracy score metric true data predicted data code error message despite plethora wrong answers attempt circumvent error numerically manipulating predictions root cause error theoretical computational issue trying use classification metric accuracy regression model linearregression meaningless just like majority performance metrics accuracy compares apples applestrue labels predictions ask function compare binary true labels apples continuous predictions oranges get expected error message tells exactly problem computational point view despite message doesntell directly trying compute metric invalid problem shouldnactually expectfar certainly good thing scikit learn least gives direct explicit warning attempting something wrong necessarily case frameworks see example behavior keras similar situation get warning one just ends complaining low accuracy regression including accepted highly upvoted one effectively suggesting manipulate predictions order simply get rid errortrue end set numbers can certainly start mingling various ways rounding thresholding etc order make code behave course mean numeric manipulations meaningful specific contextproblem trying solve wrap problem applying metric accuracy inappropriate model linearregression classification setting change model regression setting change metric check list metrics available scikit learn can confirm accuracy used classification compare also situation recent questiontrying get accuracy list models first models workrest commented ones give error now able convince commented models regression classification ones hence justified error last important note may sound legitimate someone claimwant use linear regression just round threshold outputs effectively treating predictions probabilities thus converting model classifier actually already suggested several answers implicitly invalid approach fact negative predictions already alerted interpreted probabilities andrewpopular machine learning course coursera explains bad idea see lecture logistic regression classification youtube explanation starts section linear regression classification highly recommended freely available textbook introduction statistical learning hastie tibshirani use regression problem can see available regression metrics docs problem truebinary zeros ones predictions probably generated probabilities predictions hence result try instead generate class membership worktruepred method definespredpredarray like label indicator array sparse matrix predicted labels returned classifier meanspred arrays predicated labels probabilities predicated labelss predicted probabilites can generated using linearregression modelmethods predict predict proba respectively generate predicted labels outputpreds can now used accuracy score method accuracy scoretruepred generate probabilities labels metrics precision recall curvetrue probas pred require probabilities can generated follows output resolve problem use round preditions facing error difference datatypespredtruetrue might dataframepred arraylist convert arrays issue will get resolved just use accuracy score classification metric use regression problem use way save trained naive bayes classifier disk use predict data following sample program scikit learn website classifiers just objects can pickled dumped like continue example edit using sklearn pipeline custom transformers serialized pickle joblib using neuraxlecustompipeline saving solution can define custom step savers per step basis savers called step defined upon saving otherwise joblib used default steps without saver can also use edit pythonnow possible use pickle efficient pickling object large numerical arrays attributes use pickle protocol default looking called model persistence sklearn words documented introduction model persistence sections initialized classifier trained long time two options using pickle using joblib one time helpful read mentioned links many cases particularly text classification enough just store classifierneed store vectorizer can vectorize input future future use case dumping vectorizer one can delete stop words property vectorizer make dumping efficient also classifier parameters sparse text classification examples can convert parameters dense sparse will make huge difference terms memory consumption loading dumping sparsify model will automatically work sgdclassifier case know model sparse lots zeros can manually convert can store efficiently sklearn estimators implement methods make easy save relevant trained properties estimator estimators implement getstate methods others like gmm just use base implementation simply saves objects inner dictionary recommended method save model disc use pickle module however save additional data can retrain model future suffer dire consequences locked old version sklearn documentation order rebuild similar model future versions scikit learn additional metadata saved along pickled model training data isolationforest since creates coupling implementation guaranteed stable versions sklearn seen backwards incompatible changes past models become large loading becomes nuisance can also use efficient joblib documentation specific case scikit may interesting use joblibreplacement pickle efficient objects carry large numpy arrays internally often case fitted scikit learn estimators can pickle disk string usr local lib python site packages sklearn externals joblib futurewarning removed please import functionality directly joblib can installed pip install joblib warning raised loading pickled models may needserialize models scikit learn msg category futurewarning therefore need install joblib finally write model disk now order read dumped file need run caffe layer type python instance layer type can used loss layer occasions used input layer layer type can layer used prunebharatanswers gives overall purpose python layer general purpose layer implemented python ratherintend answer serve tutorial using python layer please see excellent answers prune bharat order use python layer need compile caffe flag set python layer implemented python class derived methods def setup self bottom top method called caffe builds net function check number inputs len bottom number outputs len top expected also allocate internal parameters net see thread information method access self bottom top method called whenever caffe reshapes net function allocate outputs top blobs outputs shape usually related bottoms shape def forward self bottom top implementing forward pass bottom top def backward self top propagate bottom method implements backpropagation propagates gradients top bottom propagate boolean vector len bottom indicating bottoms gradient propagated information bottom top inputs can find post examples can see examples simplified python layers example moving average output layer can found trainable parameters python layer can trainable parameters like conv innerproduct etc can find information adding trainable parameters thread onealso simplified example caffe git see bharatanswer details need add following prototxtsimple invoking python code caffe nothing need worry caffe uses boost api call python code compiledneed make sure python module implementing layer pythonpath caffe imports can found instance module python testing forward function entirely layer different functionality testing backward method easy method implements gradient forward can numerically tested automatically check test gradient python layer testing utility worth noting python code runs cpu thus plan python layer middle net will see significant degradation performance plan using gpu happens caffe needs copy blobs gpu cpu calling python layer copy back gpu proceed forward backward pass degradation far less significant python layer either input layer topmost loss layer update seppr merged masterexposes gpu pointers blobs via python interface may access blob gpu data ptr blob gpu diff ptr directly python risk simplylayer provide implementation code rather using one pre defined types backed efficient functions want define custom loss functionahead write create layer type python non standard input needs perhaps data specific pre processing problem write create layer type python python layers differentlayers need compiled parameters need added proto file finally need register layer layer factory write python layer donneed worry things layer parameters can defined string accessible string python example parameter layer can access using param str defined prototxt file like layers need define class following functions prototxt example name layer rpn data bottom top input output details layer respectively python param defines parameters python layer module specifies file name layer file called anchor target located inside folder called rpn parameter layer parameter name class case anchortargetlayer param str parameter layer contains value key feat stride unlikecuda layers python layers work multi gpu setting caffe now disadvantage usingdeep learning class softmaxsimply exponential divided sum exponential wholevectory softmax functione exponentialcolumns input vectorve tried following returns suggested solution produces output first implementation even though first implementation explicitly takes difference column max divides sum can someone show mathematically one correct one wrong implementation similar terms code time complexity efficientcorrect preferred point view numerical stability start using factcc answer says replace maxvariable cancel question start two solutions equivalent happen equivalent special casescore arrays discovered tried alsoscore array udacity quiz provided example results wise actual difference two solutions axis argument see case lettry solution softmax one difference axis argument saidscore array results indeed identical nevertheless resultsscore array given udacity quiz test example results different second one indeed identical one expected udacity quiz columns indeed sum case first wrong result fuss actually implementation detail axis argument according default axis none will sum elements input array want sum row wise hence axisarray sum row sum elements happen identical hence identical results implementation actually better suggested solution fact recommended way implementing softmax function see justification numeric stability also pointed answers really comment desertnautanswer cancomment yet due reputation pointed version correct input consists single sample input consists several samples wrong however desertnautsolution also wrong problem takes dimensional input takes dimensional input let show take desertnauts example output can see desernauts version fail situation input just one dimensional like now use samples since reason use dimensional input followingone desernauts example input consists batch samples sample one three essentially now expect rows softmax activations first third also activationhope can see case solution additionally results tensorflows softmax implementation result say correct mathematically implementation wise first one better computing softmax intermediate values may become large dividing two large numbers can numerically unstable notes stanford mention normalization trick essentially sklearn also offers implementation softmax mathematical point view sides equal can easily prove letm maxnow function softmax returns vector whosecoordinate equal notice workseven complex numbersm computational complexity point view also equivalent runn timesize vector numerical stability point view first solution preferredx grows fast even pretty small valueswill overflow subtracting maximum value allows get rid overflow practically experience stuff talking try feedfunctions one will return correct probability second will overflow nan solution works vectors udacity quiz wants calculate matrices order fix need use sum axis edit version scipy includes softmax special function subtracting max users described good practice wrote detailed post can find used maxwriting code computing softmax function practice intermediate terms may large due exponentials dividing large numbers can numerically unstable important use normalization trick curious see performance difference using increasing values insideget consistently better results original numpy version just one test get said version numerically stable large numbers small numbers way around concise version offer alternative solution consider cases arguments extremely large magnitude expunderflow negative case overflow positive case want remain log space long possible exponentiating end can trust result will behaved needed something compatible output dense layer tensorflow solution desertnaut work case batches data therefore came another solution work cases results ref tensorflow softmax suggest will work stochastic batch detail see ravish analysis softmax functiondorder maintain numerical stability maxsubtracted following code softmax function def softmaxalready answered much detail answers max subtracted avoid overflow adding one implementation python everybody seems post solutionpost mine get exact results imported sklearn based responsesn notes allow summarise usage output softmax function activation function turns numbers probabilities sum one softmax function outputs vector represents probability distributions list outcomes also core element used deep learning classification tasks softmax function used multiple classes useful finding class max probability softmax function ideally used output layer actually trying attain probabilities define class input ranges softmax function turns logits probabilities probabilities sum logits raw scores output last layer neural network activation takes place understand softmax function must look outputth layer softmax function fact arg max function means return largest value input position largest values example softmax softmax code also works find giving right answer arrayhigher dimensions give suggestions follow result will get correct answer vectorization since related college homework post exact code like give suggestions donunderstand goal achieve similar results using numpy tensorflow change original answer axis parameter axis however provide intended results dimensionsmodified approach axis lenalways sum last dimension provides similar results tensorflowsoftmax function generalized solution using numpy comparision correctness tensorflow ans scipy data preparation output softmax using tensorflow output softmax using scipy output softmax using numpy output purpose softmax function preserve ratio vectors opposed squashing end points sigmoid values saturate tanh logistical preserves information rate change end points thus applicable neural netsoutput encodingtell one biggest smallest got squished also makes total output sum clear winner will closer numbers close will sump number output neurons similar values purpose subtracting max value vectory exponents may get high value clips float max value leading tie case example becomes big problem subtract max value make negative number negative exponent rapidly shrinks values altering ratio occurred posterquestion yielded incorrect answer answer supplied udacity horribly inefficient first thing need calculateyvector components keep values sum divide udacity messed calculateytwice correct answer generalizes assumes normalizing trailing dimension used three simple lines possible specify distance function using scikit learnmeans clusteringsmall kmeans uses odd distances user function comments welcome one user far enough particulardimmetric notes added mar cosine distance first normalize data vectorsfast bit vectors keep norms separately vectors instead expanding floats although programs may expand sparse vectors sayxtake timen spacen donknow programs scikit learn clustering gives excellent overviewmeans mini batchmeans code works always check cluster sizesmeansexpecting roughly equal sized clusters come sound head scratching unfortunately scikit learn current implementationmeans uses euclidean distances trivial extendmeans distances denis answer correct way implementmeans metrics just use nltk instead can however definitionmeans clustering algorithm relies eucldiean distance mean cluster use different metric even though still calculating mean use something like mahalnobis distance pyclustering pythonfast specify custom metric function actually haventested code cobbled together ticket example codemeans spectral python allows usemanhattan distance sklearn kmeans uses euclidean distance metric parameter saidclustering time series can use tslearn python package can specify metric dtw softdtw euclidean affinity propagation algorithm sklearn library allows pass similarity matrix instead samples can use metric compute similarity matrix dissimilarity matrix pass function setting affinity term precomputed termsmean think also possible tried however answers stated finding mean using different metric will issue instead can use pammedoids algorthim calculates change total deviationthus rely distance metric fasterpam yes current stable version sklearn scikit learn can easily use distance metric create class inherits domain machine learning math beginning ask fundamental questions can someone please clarify questions currently study problems classification nearest neighbor searching music information retrieval may interested approximate nearest neighbor ann algorithms idea allow algorithm return sufficiently near neighbors perhaps nearest neighbor reduce complexity mentionedtree one example saidtree works poorly high dimensions fact current indexing techniques based space partitioning degrade linear search sufficiently high dimensions among ann algorithms proposed recently perhaps popular locality sensitive hashing lsh maps set points high dimensional space set bins hash table unlike traditional hashes locality sensitive hash places nearby points bin lsh huge advantages first simple just compute hash points database make hash table query just compute hash query point retrieve points bin hash table second rigorous theory supports performance can shown query time sublinear size database faster linear search much faster depends upon much approximation can tolerate finally lsh compatiblenormtherefore answer first question can use lsh euclidean distance metric can use manhattandistance metric also variants hamming distance cosine similarity decent overview written malcolm slaney michael casey ieee signal processing magazine lsh applied seemingly everywhere may want give try datar indyk immorlica mirrokni locality sensitive hashing scheme basedstable distributions weber schek blott quantitative analysis performance study similarity search methods high dimensional spaces gionis indyk motwani similarity search high dimensions via hashing slaney casey locality sensitive hashing finding nearest neighbors distance metric first number features columns data set factor selecting distance metric use knn quite published studies directed precisely question usual bases comparison underlying statistical distribution data relationship among features comprise data covariance matrix look like coordinate space data obtained prior knowledge distributiondata sampled least one documented thorough study concludes euclidean distance best choice yeuclidean metric used mega scale web recommendation engines current academic research distances calculated euclidean intuitive meaning computation euclidean distance calculated way whether two points two dimension twenty two dimension space failed times cases euclidean distance failed underlying cartesian coordinate system poor choiceusually recognize instance path lengths distances longer metric space chessboard manhattan distance better euclidean likewise metric space earth distances trans continental flights distance metric suitable polar coordinate system good idea london vienna hours viennapetersburg another hrs less direction yet londonpetersburg isnhours instead little hrs apart cases data belongs non cartesian coordinate system choice distance metric usually material see blog poststudent comparing several distance metrics examining effect knn classifier chi square give best results differences large comprehensive study academic paper comparative study distance functions nearest neighbors mahalanobis essentially euclidean normalized account dimension covariance best study one important proviso distance metric calculations meaningful mustscale data rarely possible build knn model generate accurate predictions without instance building knn model predict athletic performance expectation variables heightweightbodyfat resting pulse beats per minute typical data point might look something like clearly distance calculation will dominated height contribution bodyfat will almost negligible put another way instead data reported differently bodyweight grams rather kilograms original value large effect results exactly donwant probably common scaling technique subtracting mean dividing standard deviation meanrefer calculated separately column feature data setrefers individual entry cell within data rowdata structure concerned performancetree structure voronoi tessellation conceptually simple container will drastically improve performance scales bettertrees common way persist knn training data though applicationpurpose consequent performance advantages documented see practical significance provided using mainstream language tiobe index find library performknow pythonmultiple options language voronoi packageavailable cran usingknn works like data randomly selectpoints voronoi centers voronoi cell encapsulates neighboring points nearest center imagine assign different color voronoi centers point assigned given center painted color long sufficient density will nicely show boundaries voronoi center boundary separates two colors select voronoi centers use two orthogonal guidelines random selectingpoints calculatetraining data next check number data points assigned voronoi center values given uniform point density across data space two dimensions causetilesfirst rulesecond selectiteration run knn algorithmvariable parameter measure performance time required return prediction queryingimagine one million datatree perform average couple million distance calculations new data points whose response variable wish predict course calculations performed single data sett nearest neighbor search performed two steps one two different populations data first voronoi centers nearest center found points inside cell corresponding center searched find actual nearest neighbor successive distance calculations combined two look ups much faster single brute force lookeasy seedata points suppose select voronoi centers tesselate data space average voronoi cell will data points instead performing average distance calculations brute force perform far lesss average just iii calculating result predicted response variable two steps calculating predicted value set knn training data first identifyingnumber nearest neighbors use calculation second weight contribution predicted valuerfirst component can determine best valuesolving optimization problem similar least squares optimizationtheory practice people just useeventsimple run knn algorithm set test instances calculate predicted valuesnetc plot error functionjust want plausible valueget started just usesecond component weight contribution neighbors assumingsimplest weighting technique just multiplying neighbor weighting coefficient just distinverse distance neighbor test instance often multiplied empirically derived constantfan technique often weights closest neighbors concomitantly weights distant ones significance given prediction can almost entirely dependent single neighbor turn increases algorithmsensitivity noise must better weighting function substantially avoids limitation gaussian function python looks like calculate predicted value using knn code identifynearest neighbors data point whose response variable wish predict test instance call weight gauss functionneighbors passing distance neighbor test used neighborcoefficient weighted average calculation facing known curse dimensionality sometimes useful run algorithm like pca ica make sure really need dimensions possibly find linear transformation allow use less approximately result quality update encountered book called biomedical signal processing rangayyan hope remember correctly ica trivial technique developed researchers finland think matlab code publicly available download pca widely used technique believe able findsoftware implementation pca performed solving linear equations iterativelydone long ago remember idea break signals independent eigenvectors discrete eigenfunctions really eigenvalues case eigenvalue shows amount contribution eigenfunction provides measurements eigenvalue tiny can closely represent signals without using corresponding eigenfunctionget rid dimension top answers good oldlike add answer said high dimensional space curse dimensionality lurks around corner making traditional approaches populard tree slow brute force approach result turn interest approximate nearest neighbor search anns favor accuracy speedups process get good approximation exactgood propability hot topics might worthy can also check relevant answers answer questions one one nice paper get started right direction nearest neighbour meaningful beyerwork text data dimensionswant text related advice might able help cosine similarity common way compare high dimension vectors note sincesimilarity distancewant maximize minimize can also use domain specific way compare data example data dna sequences use sequence similarity takes account probabilities mutations etc number nearest neighbors use varies depending type data much noise etc general rules just find works best specific data problem trying values within range people intuitive understanding data fewer neighbors need hypothetical situation possible data need look single nearest neighbor classifynearest neighbor method known computationally expensiveone main reasons people turn algorithms like support vector machinestrees indeed wonwork high dimensional data pruning step longer helps lot closest edge dimensional deviation will almost always smaller full dimensional deviation known nearest neighbors furthermoretrees worknorms know distance concentration effect makes distance based algorithms degrade increasing dimensionality information may want read curse dimensionality various variants one sideconvinced lot use just blindly approximating euclidean nearest neighbors lot depends want know nearest neighbors might look mean shift algorithmtime proven heuristic used many search engines like lucene euclidean distance experience shows bad results text like data selecting different weightsexamples can done training data brute force parameter selection idistance probably best exact knn retrieval high dimensional data can view approximate voronoi tessalationexperienced problem can say following euclidean distance good distance metric howevercomputationally expensive manhattan distance sometimes yields slightly poorer results thuschoose later valuecan found empirically can try different values check resulting roc curves precision recall measure order find acceptable value euclidean manhattan distances respect triangle inequality thus can use metric trees indeedtrees performance severely degraded data dimensionsexperienced problem foundtrees better optiontrees work fine dimensions quit early looking say points flann speedups match dim sift vectors unfortunately flann euclidean metric fast solidmetrics may may adequate data course speed accuracy tradeoff describe ndata nquery data distribution might help people try similar data added april run times ckdtree cutoff old mac ppc give rough idea feasibility tryorder curveeasy dimension similar question back fast approximate nearest neighbor search can use annoy library spotify optimizedprovide different distance measurements distance measurement want apply depends highly individual problem also consider prescaling meaning weighting certain dimensions importance first dimension feature importance weights might calculated something like entropy loss supervised learning problem gini impurity gain mean average loss check much worse machine learning model performs scramble dimensions values often direction vector importantabsolute value example semantic analysis text documents want document vectors close semantics similar lengths thus can either normalize vectors unit length use angular distance distance measurement hope helpful euclidean distance good metric finding nearest neighbors first place options suggest soft subspace clustering pretty common approach nowadays feature weights calculated find relevant dimensions can use weights using euclidean distance example see curse dimensionality common problems also article can enlighten somehowmeans type clustering algorithm subspace clustering mixed numeric categorical datasetsthe classifiers machine learning packages like liblinear nltk offer method show informative features really helpful debugging features question something similar implemented classifiers scikit learn searched documentation couldnfind anything like function yet somebody know workaround get values classifiers record feature names just see numeric arrays however extracted features using vectorizer countvectorizer tfidfvectorizer dictvectorizer using linear model can apply trick document classification example uses example untested may contain bug two multiclass classification binary case think use may sort class labels help larsmans code came code binary case add update randomforestclassifier now supports feature importances attribute attribute tells much observed variance explained feature obviously sum values must find attribute useful performing feature engineering thanks scikit learn team contributors implementing edit works randomforest gradientboosting randomforestclassifier randomforestregressor gradientboostingclassifier gradientboostingregressor supportrecently released library allows handles variuos classifiers scikit learn binary multiclass cases allows highlight text according feature values integrates ipython etc actually find feature importance naivebayes classifier although used functions able get feature importance based classes went scikit learndocumentation tweaked functions bit find working problem hope helps note classifier casenaivebayes must attribute feature count work can also something like create graph importance features order randomforestclassifier yet coef attrubute will release think however see randomforestclassifierwithcoef class recursive feature elimination random forest using scikit learn may give ideas work around limitation exactly looking quick way get largest magnitude coefficients assuming pandas dataframe columns feature names trained model like get largest negative coefficient values change reverse true largest positive like first make list give list name label extracting features name column name add label list use naive bayes model naive bayes model feature log prob give probability understand sometimes example input values non numerical certain transformation must performed numerical input numbers must certain interval will happen data normalizedexplained input variables combined linearly mlp multilayer perceptron rarely strictly necessary standardize inputs least theory reason rescaling input vector can effectively undone changing corresponding weights biases leaving exact outputs however variety practical reasons standardizing inputs can make training faster reduce chances getting stuck local optima also weight decay bayesian estimation can done conveniently standardized inputs neural networks good idea just normalize data also scale intended faster approaching global minima error surface see following pictures pictures taken coursera course neural networks author course geoffrey hinton inputsmight naturally defined range values example average value might slowly continuously increasing time example number records database case feeding raw value network will work will teach network values lower part range actual inputs will higher part range quite possibly range network learned work normalize value example tell network much value changed since previous input increment usually can defined high probability specific range makes good input network reasons normalize input features feeding neural network reason feature dataset big scale compared others big scaled feature becomes dominating result predictions neural network will accurate example case employee data consider age salary age will two digit number salary can digit million etc case salary will dominate prediction neural network normalize features values features will lie range reason front propagation neural networks involves dot product weights input features values high image non image data calculation output takes lot computation time memory case back propagation consequently model converges slowly inputs normalized example perform image classification size image will huge value pixel ranges normalization case important mentioned instances normalization important use unnormalized input features loss function likely elongated valleys optimizing gradient descent becomes issue gradient will steep respect parameters leads large oscillations search space bouncing steep slopes compensate stabilize optimization small learning rates consider featuresx range million respectively turns ratios corresponding parameters sayw will also large normalizing tends make loss function symmetrical spherical easier optimize gradients tend point towards global minimum can take larger steps looking neural network outside just function takes arguments produces result functions domain normalize values want pass neural net order make sure domain functions arguments domain result guaranteed appropriate exact behavior neural net arguments outside domain depends implementation neural net overall result useless arguments within domain believe answer dependent scenario considerneural network operatorf input output case relation linearinput output might choose either leave input output unnormalised raw forms normalise eliminate obviously linearity assumption violated classification tasks nearly task outputs probabilityinput output practice normalisation allows non fittable networks fittable crucial experimenters programmers nevertheless precise impact normalisation will depend network architecture algorithm also statistical prior input outputnn often implemented solve difficult problems black box fashion means underlying problem may poor statistical formulation making hard evaluate impact normalisation causing technical advantage becoming fittable dominate impact statistics statistical sense normalisation removes variation believed non causal predicting output preventlearning variation predictorsee variation hence use reason normalization needed look adaptive step proceeds one place domain function just simply transport problem equivalent step translated large value direction domain get different results boils question adapting linear piece data point much piece move without turning much turn response one training point makes sense changed adaptation procedure different parts domain normalization required reduce difference training result havengot written can just look math simple linear function trained one training point two different places problem may corrected places familiar alns problem corrected can send paper write wwarmstrong observe normalization standardization mostly used will notice anytime use magnitude difference model building process becomes necessary standardize inputs ensure important inputs small magnitude donloose significance midway model building process contributes hardly thing result hence input corresponding values considered futile model consider following distance measure clustering cost function nns use magnitude difference way hence standardization ensures magnitude difference doesncommand important input parameters algorithm works expected hidden layers used accordance complexity data input data linearly separable need use hidden layer number nodes taken layer depends upon degree cross validation outputnoticed frequent occurrence training nans introduced often times seems introduced weights inner product fully connected convolution layers blowing occurring gradient computation blowing weight initialization weight initialization effect likely caused nature input data overarching question simply common reason nans occurring training secondly methods combatting work came across phenomenon several times observations reason large gradients throw learning process track expect looking runtime log look loss values per iterationnotice loss starts grow significantly iteration iteration eventually loss will large represented floating point variable will become nan can decrease baseorder magnitude least several loss layers inspect log see layer responsible gradient blow decrease loss weight train specific layer instead general basereason caffe fails compute valid learning rate gets inf nan instead invalid rate multiplies updates thus invalidating parameters expect looking runtime log see learning rate becomes nan example can fix parameters affecting learning rate file instance usepolicy poly forget define max iter parameterendinformation learning rate caffe see thread reason sometimes computations loss loss layers causes nans appear example feeding infogainloss layer non normalized values using custom loss layer bugs etc expect looking runtime log probably wonnotice anything unusual loss decreasing gradually sudden nan appears can see can reproduce error add printout loss layer debug error example used loss normalized penalty frequency label occurrence batch just happened one training labels appear batch loss computed produced nans case working large enough batches respect number labels set enough avoid error reason input nan expect learning process hits faulty input output becomes nan looking runtime log probably wonnotice anything unusual loss decreasing gradually sudden nan appears canbuild input datasets lmdb leveldn make sure bad image files training validation set debug can build simple net read input layer dummy loss top runs inputs one faulty dummy net also produce nan reason choosing stride kernel size pooling may results nans example results nansreported settings batchnorm layer may output nans due numerical instabilities issue raised bvlc caffeattempting fix recently became aware debug info flag setting debug info true will make caffe print log debug information including gradient magnitudes activation values training information can help spotting gradient blowups problems training process case setting bias convolution deconvolution layers cause solution add following convolution layer parameters answer cause nans rather proposes way help debug can python layer adding layer train learning rate high decreased accuracy rnn code nan select low value learning rate fixes trying build sparse autoencoder several layers induce sparsity running net encountered nanremoving layers case actually remove found nandisappeared guess much sparsity may lead nancomputations may invoked one solution anyone stuck like just receiving nan inf losses network setup float dtype across layers input data else failed occurred switch back float nan losses solved bottom line switched dtype float change back float set dataframes one columns contains categorical variablelike convert several dummy variables casenormally use get dummies happens get dummies looks data available dataframe find many categories thus create appropriate number dummy variables however problemworking right now actually know advance possible categories looking dataframe individually categories necessarily appear question way pass get dummies equivalent function names categories categories donappear given dataframejust create columnsomething make becomedr way pass get dummies equivalent function names categories categories donappear given dataframejust create columnyes pandas special type series just categorical data one attributes series possible categories get dummies takes accountexample get dummies will exactly want bunch ways create categorical series dataframe just one find convenient can read pandas documentation edit havenfollowed exact versioning bug pandas treats sparse matrices least version corrected version released may version try sparse true option dataframe column zeros missing dummy variable will column nan will converted dense looks like pandas added categoricaldtype creating categoricals explicitly include categories original answer deprecatedquite sure using transpose reindex try ask pandas github turns really easy get around define column categorical define possible categories get dummies will rest expected donthink get dummies provides box allows creating extra column highlights nan values add missing columns use vertically stack dataframes dummy columns plus dataframe automatically create missing columns use fillna replace missing values use groupby separate various dataframe adding missing category test set notice code also remove column resulting category test dataset present training dataset suggested others converting categorical features category data type resolve unseen label issue using get dummies shorter better result notesshorter shorter version changed index values result bonus track imagine categories previous dummy one hot using training data can save original encoding columns apply production time result know categories can first apply suggested add missing category columns afterwards will create example missing catnow simply add missing category columns union operation suggested recently looking solve issue working multi column dataframe two datasets train set test set machine learning task test dataframe categorical columns train dataframe columns missing categories present train dataframe want manually define possible categories every column instead combined train test dataframes one called get dummies split back two working classifying simple data using knn euclidean distance seen example like done matlab knnsearch function shown code takes new point finds closest values new point can anyone please show matlab algorithm detailed explanation knnsearch function way basisnearest neighbour knn algorithm data matrix consistsrowscolumnsnumber data pointsdimensionality data point example placed cartesianordinates inside data matrix usuallyxx matrix data matrix provide query point search closestpoints within data matrix closest query point usually use euclidean distance query rest points data matrix calculate distances however distances likecity block manhattan distance also used operation willeuclidean manhattan distances symbolize distances query corresponding point data set find simply searchnearest points query sorting distances ascending order retrievingpoints smallest distance data set query supposing data matrix storednewpoint sample pointcolumns general procedure follow point form letstep slowly one way someone may perhaps loop like wanted implement manhattan distance simply distselement vector contains distances data pointnewpoint element element subtraction newpoint data pointsquare differences sum together sum square rooted completes euclidean distance manhattan distance perform element element subtraction take absolute values sum components together probably simplest implementations understand possibly element element subtraction matrix summing columns row square root therefore can something like manhattan distance repmat takes matrix vector repeats certain amount times given direction case want take newpoint vector stacktimes top createxmatrix rowelements long subtract two matrices together square component sum columns row finally take square root result manhattan distance subtraction take absolute value sum however efficient way opinion use bsxfun essentially replication talked hood single function call therefore code simply looks much cleaner point manhattan distance now distances simply sort can use sort sort distancescontain distances sorted ascending order ind tells value unsorted array appears sorted result need use ind extract firstelements vector use ind indexdata matrix return points closest newpoint final step now returndata points closest newpoint can simply ind closest contain indices original data matrixclosest newpoint specifically ind closest contains rows need sampleobtain closest points newpointclosest will contain actual data points copying pasting pleasure code looks like running example letsee code action inspecting ind closestclosest get ran knnsearch will see variablematches ind closest however variablereturns distances newpoint pointactual data points want actual distances simply following code wrote note answer uses one query point batchexamples frequently knn used multiple examples simultaneously supposingquery points want test knn resultxxmatrix example slice returnclosest points dimensionalityalternatively can return idsclosest points thus resultingxmatrix letcompute naive way apply code loop loop every example something like work allocatexmatrix apply bsxfun based approach set row output matrixclosest points dataset will use fisher iris dataset just likealso keep dimensionality previous exampleuse four examplesm though nice can even better way efficiently compute squared euclidean distance two sets vectorsleave exercise want manhattan consulting blog givenxmatrix row point dimensionalityq pointsqm matrix row also point dimensionalityq points can efficiently compute distance matrixj element row columndenotes distance row rowb using following matrix formulation therefore let matrix query pointsdataset consisting original data can determineclosest points sorting row individually determininglocations row smallest can also additionally use retrieve actual points therefore see used logic computing distance matrix variables changed suit example also sort row independently using two input version sort ind will contain ids per rowwill contain corresponding distances figure indices closest query point simply truncating matrixcolumns use permute reshape determine associated closest points first use closest indices create point matrix stacks ids top getkm matrix using reshape permute allowscreatematrix becomesxxmatrix like specified wanted get actual distances can indexgrab need will need use sub ind obtain linear indices can indexone shot values ind closest already givecolumns need access rows need access simplytimestimes etck number points wanted return run code query points indices points distances get compare knnsearch instead specify matrix points second parameter row query point will see indices sorted distances match implementation knnsearch hope helps good lucklike choose best algorithm future found solutions didnunderstandsquared value correct divided data two test training printed two differentsquared values firstsquared result secondsquared result didnunderstand value correct arguably real challenge cases sure compare apples apples case seems donbest friend always relevant documentation combined simple experimentslinearregression fitted default fit intercept true docs case statsmodels olsr squared quoting docs intercept included default added user see letrun simple experiments dummy data practical purposes two valuessquared produced scikit learn statsmodels identical letgo step try scikit learn model without intercept use artificially intercepted dataalready built use statsmodelssquared identical previous values happens accidentally forget account fact statsmodels ols fitted without intercept letseesquared indeed far one returned model intercept arguably exactly happened case far good easily finish answer indeed point harmonious world breaks letsee happens fit models without intercept initial dataartificially added interception already fitted ols model gotsquared similar model scikit learn heck seems scikit earn computesscore always assumes intercept either explicitly model fit intercept true implicitly data way producedx using statsmodels add constant digging little online reveals github thread closed without remedy confirmed situation indeed like update dec detailed depth investigation explanation two scores different particular case see great answer flavia let clarify discrepancy described nothing issue case real issue actually comparing apples model intercept oranges model without intercept scikit learn fails admittedly edge case even fact emerges github issue actually treated indifference notice also scikit learn core developer replies thread casually admitssuper familiar stats answer goes little beyond coding issues ones mainly may worth elaborating little arguably reason wholesquared concept comes fact directly world statistics emphasis interpretative models little use machine learning contexts emphasis clearly predictive models least afaik beyond introductory courses never mean seen predictive modeling problemsquared used kind performance assessment neitheraccident popular machine learning introductions andrews machine learning coursera even bother mention noted github thread emphasis added particular using test setbit unclearmeans certainly concur edge case discussed include intercept term suspect sound really irrelevant modern deep learning practitioners equivalent intercept bias parameters always included default neural network highly upvoted answer cross validated question difference statsmodel ols scikit linear regression detailed discussion along last lines discussion linkssquared useless triggered relevant negative remarks great statistician cosma shalizi also enlightening highly recommended seem using model can arbitrarily worse wikipedia article documentation leads points valuesoutside range can occur model fits data worse horizontal hyperplane occur wrong model chosen nonsensical constraints applied mistake reason fact negativescore probably far significant relatively good greatstatistic computed way first score indicates model choice poor second statistic likely just artifact overfitting note wikipedia article notes multiple definitionssquaredsquared however common ones property range usually positive clear squared part name exceptions general rule see wikipedia article firstsquared result even positive thus reallysquared use secondsquared result correct range trying build model predict house prices featuresbathrooms etc targetranging around used sklearnstandard scaler standardizefitting model keras model trouble trying interpret results mse mean inverse transform number square root results getting error rate dollars apologise sounding silly starting apologise sounding silly starting subtle issue great importance usually regrettably omitted tutorials introductory expositions unfortunately simple taking square root inverse transformed mse complicated either essentially order get performance indicator model will meaningful business context problem letsee quick example toy data omitting model irrelevant fact can regression model keras one now letsay fit keras model shown using scaled setstraintrain get predictions training set mse reported keras actually scaled mse steps described simply case initialus dollars actual error units dollars dollars notice naive approach inverse transforming scaled mse give different incorrect result mse mean square error formula basically mean square different expected output prediction making square root will give difference error output useful training currently build model want train model use function want prediction output use following code can find details principally modes run rnn right ones picture image source andrej karpathy now wonder minimalistic code snippet look like keras something like tasks maybe little bit explanation one one use dense layer processing sequences one many option supported chaining models easy keras following version easiest one many one actually code snippet almost example approach many many easiest snippet length input output matches number recurrent steps many many number steps differ input output length freaky hard keras easy code snippets code editone recent applications implemented something might similar many manyimage case want network following architecture input longer output achieve following mannernumber last steps want cover imagepoint getting simple artificial padding sequence lengthusing order adjust appropriate size great answer marcinejko add followingmany many different length vanilla lstmencoder decoder lstmperhaps general question can anyone explain cause convolutional neural network diverge specifics using tensorflowiris training model data keep getting error tensorflow model diverged loss nan nan loss training traceback originated linetried adjusting optimizer using zero learning rate using optimizer insights network layers data size etc appreciated lots things seen make model diverge high learning rate can often tell case loss begins increase diverges infinity familiar dnnclassifier guessing uses categorical cross entropy cost function involves taking log prediction diverges prediction approaches zero people usually add small epsilon value prediction prevent divergence guessing dnnclassifier probably uses tensorflow opp probably issue numerical stability issues can exist division zero adding epsilon can help another less obvious one square root whose derivative can diverge properly simplified dealing finite precision numbers yet doubt issue case dnnclassifier may issue input data try calling assertinput data make sure introducing nan also make sure target values valid finally make sure data properly normalized probably want pixels range labels must domain loss function using logarithmic based loss function labels must non negative noted evancommentstraining cross entropy want add small number likeoutput probability log negative infinity model trained enough output distribution will skewed instance sayclass output beginning probability looks like toward end probability will probably look like take cross entropy distribution everything will explode fix artifitially add small number terms prevent case got nan setting distant integer labelsuse distant label edit can see effect following simple code result shows nans adding label using integers targets makes sure arensymmetrical donuse classes use insteadlike gather information error error occurs first iterations suggest run experiment cpu mode gpus error message will much specific source relu possible intermediate layergenerating negative value relu convert gradually stops training observed leakyrelu able solve problems regularization can help classifier good case activity regularization whether binary multi class classifier regressor kernel regularization might appropriate reason nan inf inf often comes fact division tensorflow doesnresult division zero exception result nan inf inf value training data might thus loss function happen perform division output following tensor adding small eplisonoften trick additionally since tensorflow opterationlike plug shallow reasons experienced follows hope helps found interesting thing battling whit problem addition answers data labels arranged like applying shuffle data may help problem labels enjoyment ratings read answers didnmake much sense problem facing changed labels worked donknow happened tensorflow uses labels positions tensor contextsnegative numbers non integers etc can instead cause loss nan reason also using small values liketry replacing manually changed considering example code like know apply gradient clipping network rnn possibility exploding gradients example used introduce def rnn doesnmake sense tensorinput grad clipped define optimizer simpler option gradient clipping needs happen computing gradients applying update modelparameters example things handled method order clip gradientsneed explicitly compute clip apply described section tensorflowapi documentation specificallyneed substitute call minimize method something like following despite seems popular probably want clip whole gradient global norm clipping gradient matrix individually changes relative scale also possible tensorflow tape computes gradients optimizers come keras donneed store updateruns automatically without passing sessioneasy optimizer will clip gradients values see docs actually properly explained documentation calling minimize takes care computing gradients applying variables want process gradients applying can instead use optimizer three steps example provide use steps mycapper function caps gradient list useful functions like understand idea gradient clipping norm whenever gradient norm greater particular threshold clip gradient norm stays within threshold threshold sometimes set let gradientmax norm thresholdnowjjg implementation doneestimator decorator way define run every gradients calculation documentation range per condition clipped value grad range range var grad var grads vars grads vars pairs gradients calculate via variables will applied clipping simply apply value using optimizer clipped value training model using custom training loop one update step will look like also simply just replace first line code second method will also work using via initialize weights single layer use function alternatively can modify parameters writing example applies biases pass initialization functionappliesrecursively every submodule returned children self typical use includes initializing parameters model see also torchinit example follow principle occamrazor might think setting weights best solution case every weight neurons layer producing output makes hard decide weights adjust uniform distribution equal probability picking number set numbers letsee neural network trains using uniform weight initialization low highsee another way besides net class code initialize weights network define weights outside model definition can general rule setting weights neural network set close zero without small good practice start weights rangeysqrtn number inputs given neuron compare performanceweights initialized uniform distribution versus one whose weight initialized using general rule normal distribution mean standard deviationsqrtn number inputsshow performance twoone initialized using uniform distribution using normal distribution initialize layers typically donneed anything pytorch will think makes lot sense initialize layers pytorch can following latest trends instance linear layerinit method will kaiming initialization similarly holds layers types convcheck note advantage proper initialization faster training speed problem requires special initialization can still afterwards want extra flexibility can also set weights manually say input ones want make dense layer bias can visualize set weights anything else weights weights now pass data remember neuron receives inputs weight value bias sums sorry late hope answer will help initialise weights normal distribution use use constant distribution write use uniform distribution can check methods initialise tensors use apply instance model implement sequential directly can trylen check appropriately initialized better way just pass whole model cuz havenenough reputation far canadd comment answer posted prosti jun wanna point actually know assumptions paper kaiming delving deep rectifiers surpassing human level performance imagenet classification appropriate though looks like deliberately designed initialization method makes hit practice within subsection backward propagation case assumel deltal independent known take score map deltal instance oftensoftmaxlsoftmaxll use typical cross entropy loss function objective think true underlying reasoninitialization works remains unravel cuz everyone witnessed power boosting deep learning training see deprecation warningbio perezallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago noticed lsh seems good way find similar items high dimension properties reading paperstill confused formulas anyone know blog article explains easy way best tutorial seen lsh book mining massive datasets check chapter finding similar items ullman mmds evandurme papers example slide helps lot understanding hashing cosine similarity borrow two slides benjamin van durme ashwin lall acl try explain intuitions lsh families cosine distance bit sample code just lines python using cosine similarity mvogiatzispresentation stanford explains made big difference part two lsh part one covers picture overview much slides near neighbor search high dimensional data part tried thoroughly explain lsh cases minhashing jaccard similarity measure simhashing cosine distance measure hope find useful cube chair intuition lsh similar take shadows objects like take shadowcube getsquare like piece papersphere will get circle like shadow piece paper eventually many three dimensions search problem word text one dimension shadow analogy still useful now can efficiently compare strings bits software fixed length bit string kinda less like line single dimension lsh project shadows objects eventually points single fixed length line bit string whole trick take shadows still make sense lower dimension looks like square present object light will determine get good recognizable shadow think good lsh one will turn objects front light shadow best recognizable representing object recap think things index lsh physical objects like cube table chair project shadowseventually along line bit string good lsh function present objects front light get approximately distinguishable shapeflatland later bit string finally want search object similar objects indexed take shadows query object using way present object front light eventually ending bit string now can compare similar bit string indexed bit strings proxy searching whole objects found good recognizable way present objects light short tldr answer example locality sensitive hashing first set planes randomly rotation offset space inputs hash drop points hash space plane measure point answer hash points similar space will similar hash measured cosine distance read example using scikit learn matlab correct think code bit complicated needs structure otherwiselost equations operations end regression boils four operations case guess confusedndenotes number examples training set number features letlook variation code first create small random dataset look like can see also added generated regression line formula calculated excel need take care intuition regression using gradient descent complete batch pass dataneed reducelosses every example single weight update case average sum gradients thus divisionnext thing need take care track convergence adjust learning rate matter always track cost every iteration maybe even plot run example theta returned will look like actually quite close equation calculated excelx note passed bias first column first theta value denotes bias weight can find implementation gradient descent linear regression problem first calculate gradient liketwn update current theta gradient simultaneously python code answers missing explanation linear regression code little convoluted imo thing datasetsamples sample calledn dimensional vector vector outcomesm dimensional vector can construct following matrices now goal findn dimensional vector describes line linear regressionconstant termcoefficients dimension feature input sample essence want findxclosepossiblejust account constant term additionjust matrix get stacking outcome rowmmatrix construct python numpy code gradient descent actually straight forward voila returns vectordescription prediction line work code finding gradient vector cost function squared differences case going flow find minimum cost given bestactual formula used line full maths explanation code including creation matrices see post implement gradient descent python edit illustration code estimates line can use make predictions image shows example learned gradient descent line red original data samples blue scatter fish market dataset kaggle know question already answer made updatefunction function reduce alpha iteration making function converge faster see estimating linear regression gradient descent steepest descent exampleapply logic python following thomas jungblut implementation python octave find something wrong please let know will fix update data comes txt file following rows think rough sample features number bedrooms mts last column rent price want predict octave implementation creating sequential model keras understand provide input shape first layer input shape make implicit input layer example model explicitly specifies dense layers actually model layers consisting one input layer implied input shape one hidden dense layer neurons one output layer possible outputs actually implicit input layer indeed good old neural net three layers input hidden output explicitly visible keras functional api check example docs model written actually implicit input layer reason include input shape argument first explicit layer model sequential api subsequent layers input shape inferred output previous ones see comments source code may also find documentation rewriting code line recent keras tutorial examples probably use keras least input layer really keras layerplace store tensor may tensor keras layer transformation outputs tensor possibly different size shape input identifiable tensors input outputs two layers transformations involved corresponding keras layers hand graphically might represent network graphical layers nodes two sets lines connecting layers nodes graphicallylayer network layers graphical notation bunches circles sit page nothing whereas layers keras transform tensors actual work personally get used keras perspective note finally fun simplicity substituted input dim input shape avoid syntax python uses confuse newcomers createtuple valuebinary classification problem labels know prediction floating point numberprobability belonging class following cross entropy loss function howevernecessarily keras calculate accuracy will keras automatically round predictions example following code accuracy targets predictions floating point numbers necessarily little confused speak accuracy showing formula loss equation show indeed cross entropy loss formula binary classification simply logistic losslabels indeed eitherpredictions usually interpreted probabilities real numbers without rounding now one term sum will survive first term vanishessimilarly second term vanishesletsee examples supposepredictedsecond term sum vanishes sincefirst one becomes log contribution sample prediction overall loss due sign front sum suppose now true label next sample made rather poor predictionsecond term vanishes contribution prediction overall loss now log indeed greater first good prediction expect intuitively final example letsupposemade perfectly good predictionhence first term vanishes second term becomes intuitively expected since made perfectly good prediction logistic loss formula simply computes errors individual predictions sums divides numbernevertheless loss snippet accuracy loss accuracy different things roughly speaking accuracy actually interested business perspective loss objective function learning algorithms optimizers trying minimize mathematical perspective even roughly speaking can think loss translation business objective accuracy mathematical domain translation necessary classification problems regression ones usually loss business objective least can principle will keras automatically round predictions actually yes compute accuracy implicitly set threshold predicted probabilities usually binary classification may differ case highly imbalanced data keras actually converts predictionsotherwise accuracy computed simply counting casestruepred correct predictions dividing total number samples give number summarize following tensorflow function must feed activation artificial neurons final layer understand donunderstand called logits isnmathematical function logits overloaded term can mean many different things math logit function maps probabilitiesinf inf probability corresponds logit negative logit correspond probabilities less positivecan vector raw non normalized predictions classification model generates ordinarily passed normalization function model solving multi class classification problem logits typically become input softmax function softmax function generates vector normalized probabilities one value possible class logits also sometimes refer element wise inverse sigmoid function just adding clarification anyone scrolls much can least gets right since many wrong answers upvoted dianshenganswer jakejanswer get right new answer posted shital shah even better complete answer yes logit mathematical function statistics logit used context neural networks different statistical logit doesneven make sense couldnfind formal definition anywhere logit basically means raw predictions come last layer neural network tensor apply argmax function get predicted class tensor feed softmax function get probabilities predicted classes also tutorial official tensorflow website final layer neural network logits layer will return raw values predictions create dense layer neurons one target class linear activation default still confused situation like predicted class index raw predicted class index prob will equal another name raw predictions code logit edit see answer historical motivations behind term although want can apply statistical logit probabilities come softmax function probability certain classlog odds classlogitalso probability class can recoveredsigmoidusing sigmoid function useful calculate log odds though summary context deep learning logits layer means layer feeds softmax normalization output softmax probabilities classification task input logits layer logits layer typically produces values infinity infinity softmax layer transforms values historical context term comess several people trying adapt linear regression problem predicting probabilities however linear regression produces output infinity infinity probabilities desired output one way somehow mapping probabilities infinity infinity use linear regression usual one mapping cumulative normal distribution used chester ittner bliss called probit model short probability unit however function computationally expensive lacking desirable properties multi class classification joseph berkson used function logp mapping called logit short logistic unit term logistic regression derived confusion unfortunately term logits abused deep learning pure mathematical perspective logit function performs mapping deep learning people started calling layer logits layer feeds logit function people started calling output values layer logit creating confusion logit function tensorflow code unfortunately tensorflow code adds confusion names like just means input function supposed output last neuron layer described logits suffix redundant confusing pointless functions named without regards specific contexts simply mathematical operations can performed values derived many domains fact tensorflow another similar function sparse softmax cross entropy fortunately forgot add logits suffix creating inconsistency adding confusion pytorch hand simply names function without kind suffixes reference logit probit lecture slides one best resource understand logit also updated wikipedia article information logit function maps probabilities inf inf softmax function maps inf inf similar sigmoid softmax also normalizes sum values output vector tensorflow logit means applying softmax function logit numbers normalize input vector logit normalized can scale inf inf normalization used multiclass classification problems multilabel classification problems sigmoid normalization used tensorflow domain logits values used input softmax came understanding based tensorflow tutorial especially statistics donthinklogit looking book deep learning ian goodfellow mentioned functioncalled logit statistics term rarely used machine learningstands inverse function logistic sigmoid function tensorflow frequently seen name last layer chapter book hands machine learning scikit learn tensorflow aur lienron came across paragraph stated logits layer clearly note logits output neural network going softmax activation function optimization reasons will handle softmax computation later say although use softmax activation function last layer design ease computation take logits separately efficient calculate softmax cross entropy loss together remember cross entropy cost function used forward propagation fomosapiens check math logit function converts real space interval infinity inf inf sigmoid softmax will exactly opposite thing will convert inf inf real space real space machine learning may use logit sigmoid softmax function since match may call anything machine learning goes front sigmoid softmax function logithinton video using term concise answer future readers tensorflowlogit defined output neuron without applying activation functioninputweightbiasfollowing irrelevant question historical lectures read answers hats tensorflowcreatively confusing naming convention pytorch one crossentropyloss acceptsactivated outputs convolutions matrix multiplications activations level operations design much modular less confusing one reasons switched tensorflow pytorch vector raw non normalized predictions classification model generates ordinarily passed normalization function model solving multi class classification problem logits typically become input softmax function softmax function generates vector normalized probabilities one value possible class addition logits sometimes refer element wise inverse sigmoid function information seesquashed apply number classes interested check researchers use train shallow neural net based deep network learnedkind like learning subject detail will learn great many minor points teaching student will try compress simplest case student now tried teachquite difficult able describe just enough use language logitdloh jit function inverse sigmoidal logistic function logistic transform used mathematics especially statistics functionvariable represents probabilitylogit function gives log odds logarithm oddsp seecreated model two layers tried merge returns error first layer sequential model must get input shape batch input shape argument line merged modelgetting error result defined sequential just container model defined input giventrying build set result take third inputhowever preferred way building model type input structure use functional api implementation requirements get started answer question comments concatenation works likerows just joined adding accepted answer helps using tensorflow result can experiment notice concatenateconcatenate layer size can view notebook detail decision tree classifier random forest classifier data following code result much better random forest classifier runs randomly sampling data training test random forest estimators one estimator isnjust decision tree done something wrong misunderstood concept random forest estimators one estimator isnjust decision tree good question answer turns random forest algorithm simple bag individually grown decision trees apart randomness induced ensembling many trees random forestalgorithm also incorporates randomness building individual trees two distinct ways none present simple decision treealgorithm first number features consider looking best split tree nodeconsiders featuresconsiders random subset size equal parameter max features see docs secondconsiders whole training set singletree considers bootstrapped sub sample docs sub sample size always original input sample size samples drawn replacement bootstrap true defaultalgorihm essentially combination two independent ideas bagging random selection features see wikipedia entry nice overview bagging essentially second point applied ensemble random selection features first point seems independently proposed tin kambreimanrf see wikipedia entryalready suggested random feature selection alone improves performance exactly done still use bootstrap sampling idea bagging easily replicates idea setting bootstrap false randomforestclassifier arguments fact given research difference performance use bootstrap false max features none arguments performance roughly equal single decision nans loss converge etc sometimes useful look verbose training log setting debug info true file training log looks something like mean first glance can see log section divided two forward backward recall neural network training done via forward backward propagation training example batch fed net forward pass outputs current prediction based prediction loss computed loss derived gradient estimated propagated backward using chain rule caffe blob data structure just quickcap caffe uses blob data structure store data weights parameters etc discussion important note blob two parts data diff values blob stored data part diff part used store element wise gradients backpropagation step forward pass will see layers bottom top listed part log layersee layer conv convolution layer param blobs filters bias consequently log three lines filter blob param blob data currentnorm convolution filter weights current bias param blob meaning currently bias set last least conv layer output top named convnorm output notevalues forward pass reported data part blobs question loss gradient end forward pass comes loss layer example batch loss gradient loss rest layers listed part top bottom can seemagnitudes reported now diff part blobs params layers inputs finally last log line iteration reports totall magnitudes data gradients look nans loss see point data diff turns nan layer iteration look gradient magnitude reasonable starting see valuesdata gradients starting blow decrease learning rate see diffs zero zero diffs mean gradients updates learning started random weights consider generating random weights higher variance look activations rather gradients going zero using relu means inputs weights lead regions relu gates active leading dead neurons consider normalizing inputs zero mean add batchnorm layers setting negative slope reluusing python confusion matrixeslike calculate precisions recallsmeasure confusion matrixes multiclass classification result logs doncontaintruepred just contain confusion matrix tell get scores confusion matrix multiclass classification letconsider case mnist data classification classes test set samples get following confusion matrixnumpy array order get precision recall per class need computefpper class donneedwill compute will helpsanity check true positives simply diagonal elements false positives sum respective column minus diagonal element similarly false negatives sum respective row minus diagonal element now true negatives little trickier letfirst think exactly true negative means respect say class means samples correctly identified essentially remove corresponding row column confusion matrix sum remaining elements letmake sanity check class sumfptn must equal size test set letconfirm indeed case result calculated quantities now straightforward get precision recall per class example similarly can compute related quantities like specificity recall sensitivity thing recall results example now able compute quantities virtually size confusion matrix confusion matrix form following simple function can made testing output function can also extended produce scores formulae mentioned disarray four classes can use disarray calculate matrices gives question appear programming within scope defined help center closed years ago rule thumb best divide data training validation sets even split advisable clear advantages training data relative validation data vice versa choice pretty much application dependent mostly using training validation data respectively chose division without principled reason can someone experienced machine learning advise two competing concerns less training data parameter estimates greater variance less testing data performance statistic will greater variance broadly speaking concerned dividing data neither variance high absolute number instances category rather percentage total instancesprobably stuck cross validation single split going give satisfactory variance estimates instances doesnreally matter whether choose split split indeed may choose use less training data method particularly computationally intensive assuming enough data proper held test data rather cross validation following instructive way get handle variancessurprised find quite commonly occurring ratio often referred pareto principleusually safe bet use ratio however depending training validation methodology employ ratio may change example use fold cross validation end validation set fold research proper ratio training set validation set fraction patterns reserved validation set inversely proportional square root number free adjustable parameters conclusion specify formula validation settraining setsize ratiot scales likenmaxnumber families recognizersmax largest complexity families mean complexity family recognizer characterized complexity may may relateddimension description length number adjustable parameters measures complexity taking first rule thumb can conclude adjustable parameters square root fractiont roughly reserved validation training last year took prof andrews online machine learning course recommendation training cross validation testing think one thing really big dataset like examples split may unnecessary examples may just much just saying model works fine maybe enough examples can represent variance data can easily tell model works good based examples test dev donuse justheardok think purpose test set perhaps reasonable choice reason total sample sizewanted randomly sample replacement statistical bootstrapcases initialprobability individual case selectedsample approximately providedsmall explained probability individual case selectedsample digits sampleprobability depends data hand considerable amount data good choice mentioned cross validation split might help lot prevent creating model fitting training data suppose less data suggest try test giving better result case chances test get poor accuracy following tutorial available part part unfortunately author didntime final section involved using cosine similarity actually find distance two documents followed examples article help following link stackoverflow included code mentioned link just make life easier result code following matrix sure use output order calculate cosine similarity know implement cosine similarity respect two vectors similar length sure identify two vectors first want extract count features applyidf normalization row wise euclidean normalization can one operation tfidfvectorizer now find cosine distances one document others just need compute dot products first vector others tfidf vectors already row normalized explained chris clark comments cosine similarity take account magnitude vectors row normalised magnitude linear kernel sufficient calculate similarity values scipy sparse matrix api bit weird flexible densedimensional numpy arrays get first vector need slice matrix row wise get submatrix single row scikit learn already provides pairwise metrics work dense sparse representations vector collections case need dot product also known linear kernel hence find top related documents can use argsort negative array slicing related documents highest cosine similarity values hence end sorted indices array first result sanity check find query document similar document cosine similarity score following text second similar document reply quotes original message hence many common words help excraycomment manage figure answer need actually write simple loop iterate two arrays represent train data test data first implement simple lambda function hold formula cosine calculation just write simple loop iterate vector logic every vector trainvectorizerarray find cosine similarity vector testvectorizerarray output know old post tried doc doc documents want rank help cosine similarity can use code also tutorials provided question useful parts part partpart iii output will follows represents query matched three scores matching query respective documents let give another tutorial written answers question also makes explanation things also tried make concise list documents just array strings another document just string need find document list documents similar document letcombine together documents list documents document letstart dependencies will become clear use one approaches can uses bag words approach treat word document independent others just throw together big bag one point view looses lot information like words connected another point view makes model simple english human language lot useless words like common possess lot meaning called stop words good idea remove another thing one can notice words like analyze analyzer analysis really similar common root can converted just one word process called stemming exist different stemmers differ speed aggressiveness transform documents list stems words without stop words also discard punctuation will bag words helpimagine bagscbd can convert vectors basiscend vectors similar thing documents vectors will way longer now see removed lot words stemmed also decrease dimensions vectors just interesting observation longer documents will way positive elements shorternice normalize vector called term frequencypeople also used additional information often word used documents inverse document frequency idf together metricidf couple flavors can achieved one line sklearn actually vectorizer allows lot things like removing stop words lowercasing done separate step sklearn non english stopwords nltk vectors calculated last step find one similar last one various ways achieve one euclidean distance great reason discussed another approach cosine similarity iterate documents calculating cosine similarity document last one now minimum will information best document score help output will function compares test data training dataidf transformer fitted training data advantage can quickly pivot group findclosest elements calculations matrix wise currently usingo classification problem dataset testingorandomforestestimator python environment noticed results predict method giving values assuming probability data set target attribute numeric still getting result modified code convert target column factor using asfactor methodoframe still wasnchange result changed values target attribute true false respectively getting expected resultoutput classification rather probability principle theory hard soft classification probabilities respectively different approaches one merits downsides consider example following paper hard soft classification large margin unified machines margin based classifiers popular machine learning statistics classification problems among numerous classifiers hard classifiers soft ones soft classifiers explicitly estimate class conditional probabilities perform classification based estimated probabilities contrast hard classifiers directly target classification decision boundary without producing probability estimation two types classifiers based different philosophies merits said practice classifiers used today including random forest exception can think svm family fact soft classifiers actually produce underneath probability like measure subsequently combined implicit threshold usually default binary case gives hard class membership like true false right way get classified prediction result starters always possibleprobabilities hard classes opposite true generally speaking given fact classifier fact soft one getting just end hard classifications true false gives black box flavor process principle undesirable handling directly produced probabilities important controlling explicitly decision threshold preferable way according experience subtleties often lost new practitioners consider example following cross validated thread reduce classification probability threshold statistical component exercise ends output probability class new sample choosing threshold beyond classify new observationpart statistics part decision component apart soft arguments pun unintended like cases need handle directly underlying probabilities thresholds notably classes imbalanced see answer high auc bad predictions imbalanced data links therein concrete example case honest rather surprised behavioro report havenuse personally case indeed may issue bad design compare example random forest classifier scikit learn includes two different methods predict predict proba get hard classifications underlying probabilities respectively checking docs apparent output predict based probability estimates computed already probabilities outcomes numerical target values handle case multiclass classification nothing new principle apart fact simple threshold longer meaningful random forest predict docs scikit learn predicted class one highest mean probability estimate classes get estimatepelements summing one per rules probability predicted class one highest probability case reproducible example class iris datasetgbm algorithmrationale adding desertnautanswer since tagged question python handle last part question probabilities outcomes numerical target values handle case multiclass classification will convert num examplesclasses array probability values num examples array predicted understand supposed allow evaluate model turn back training example training code using eval kind switch specific layers parts model behave differently training inference evaluating time example dropouts layers batchnorm layers etc need turn model evaluation eval will addition common practice evaluating validation using pair turn gradients computation donforget turn back training mode eval step can turn evaluation mode running use running model inference engine validating predicting though practically will make difference model include differently behaving layers sets module evaluation mode effect certain modules see documentations particular modules details behaviors training evaluation mode affected batchnorm etc equivalent false opposite method recently started working pytorch lightning wraps much boilerplate training validation testing pipelines among things makes near redundant allowing train step validation step callbacks wrap eval train never forgetd convolutions convolutional neural networks deep learning use examples want explain pictured nutshell convolutional direction output shape importantconvolutions basicconvolutions basicconvolutions basicconvolutionsinput lenet vgg bonusconv cnn googlenetconvolutionsinputconvolutionsinput following answer runhani adding details make explanation bit clear will try explain bit course exmaplestf one main additional bitsincludingmightconvolution usingtf specific data following shapesway less worktf need session variable initializer example letunderstand using signal smoothing example left got original right got output convolutionoutput channels multiple channels basically multiple feature representations input example three representations obtained three different filters first channel equally weighted smoothing filter second filter weights middle filter boundaries final filter opposite second can see different filters bring different effectsconvolution successful used sentence classification taskconvolution deep learning person chances havencome acrossconvolution zero used cnns image classification object detection etc nlp problems involve images lettry example got convolution kernel following filters specific data following shapes can see output produced code first image original going clock wise outputsfilterfilter filter contextconvolution much easier understand multiple channels mean say face recognition can think unrealistic simplification gets point across filter represents eye mouth nose etc feature map binary representation whether feature image provided donthink need stress face recognition model valuable features information article illustrationtrying articulateconvolution prevalent realm deep learning cnns convolution neural networks useconvolution operation almost computer vision tasks object detection video classification now becomes increasingly difficult illustrategoing number dimensions increase good understandingd convolution worksstraight forward generalize understandingconvolution goes specific data following shapesconvolution used developing machine learning applications involving lidar light detection ranging data dimensional nature alrightnearly hold letsee stride padding quite intuitive think stride across corridor get faster fewer steps also means observed lesser surrounding walked across room letnow reinforce understanding pretty picture letunderstand viaconvolution use need set vector elementsreason get intimidated just contain strides following orderconvolution batch stride height stride width stride channel stride batch stride channel stride just set oneimplementing deep learning models years never set anything except one leaves strides setconvolution batch stride height stride width stride depth stride channel stride worry height width depth strides now notice matter small stride unavoidable dimension reduction happening convolution undesirable especially building deep convolution neural networks padding comes rescue two commonly used padding types can see difference final word curious might wondering just dropped bomb whole automatic dimension reduction now talking different strides best thing stride control dimensions get reduced summarycnn kernel moves direction input output datacnn dimensional mostly used time series datacnn kernel moves directions input output datacnn dimensional mostly used image datacnn kernel moves directions input output datacnn dimensional mostly usedimage data mriscans can find details xzz convconvconvccnndrefers convolution direction rather input filter dimension channel input cnnequals cnnkernel length input length conv direction question appear programming within scope defined help center closed years ago trying build neural network scratch acrossliterature consensus weights initialized random numbers order network converge faster neural networks initial weights initialized random numbers read somewhere done break symmetry makes neural network learn faster breaking symmetry make learn faster wouldninitializing weights better idea way weights able find values whether positive negative faster underlying philosophy behind randomizing weights apart hoping near optimum values initialized breaking symmetry essential reason performance imagine first layers multilayer perceptron input hidden layers forward propagation unit hidden layer gets signal hidden unit gets sum inputs multiplied corresponding weight now imagine initialize weights value case hidden unit will get exactly signal unit gets signal equal sum inputs outputs sigmoid sum inputs weights zeros even worse every hidden unit will get zero signal matter input weights units hidden layer will main issue symmetry reason initialize weights randomly least different values note issue affects architectures use connections analogy imagine someone dropped helicopter unknown mountain toptrapped fog everywhere know get sea level somehow direction take get lowest possible point couldnreach sea level helicopter take drop mountain top take directionsinitializing starting positions however time helicopter drops somewhere randomly mountain take different directions steps better chance reaching lowest possible point meant breaking symmetry initialization asymmetric different can find different solutions problem analogy land weight different weightsbetter chance reaching lowest lower point also increases entropy system system can create information help find lower points local global minimums answer pretty simple basic training algorithms greedy nature find global optimum rather nearest local solution result starting fixed initialization biases solution towards one particular set weights randomly possibly many times much less probable will get stuck weird part error surface argument applies algorithms able find global optimummeansetc apply global optimization techniques like smo algorithm svm mentioned key point breaking symmetry initialize weights zero hidden neurons units neural network will exact calculations something desire want different hidden units compute different functions however possible initialize value wouldninitializing weights better idea way weights able find values whether positive negative faster breaking symmetry make learn faster initialize weights zero neurons layers performs calculation giving output making whole deep net useless weights zero complexity whole deep net single neuron predictions nothing better random nodes side side hidden layer connected inputs must different weights learning algorithm update weights making weights non zero close like etc algorithm will learn weights next iterations wonstuck way breaking symmetry happens stochastic optimization algorithms stochastic gradient descent use randomness selecting starting point search progression search progression search learning neural network known convergence discovering sub optimal solution local optima result premature convergence instead relying one local optima run algorithm multiple times different random weights best possibility finding global optima without getting stuck local optima post due advancements machine learning researchal initialization introduced replace random initialization weights still random differ range depending size previous layer neurons summary non zero random weights helplet mathematical fact reason answer found bit lacking answers assume layers look back propagation algorithm computationymt letignoresorry sorrywdzz problem see bold computingrequired computew never got chance change weights anything beyond never will essentially neural network learn anything think worse logistic regression single unit case logistic regression learn iterations since get different input thankscase layers always giving output donlearn addition initialization random values initial weights start large values often use tanh sigmoid functions hidden layers output layers look graphs two functions forward propagation first iteration results higher values values correspond places sigmoid tanh functions converge derivative zero leads cold start learning process increase learning time result start weights random can avoid problems multiplying values values learned one thing initialize weight zerosobvious activation units layer will meansvalues backbrop will find rows gradientalso hence rows weight matrixgradient descent updates general initializing weights zero results network failing break symmetry means every neuron layer will learn thing might training neural networkll every layer network powerful linear classifier logistic regression andrewcourse first algorithms converge even zero initial weightings simple example linear perceptron network course many learning networks require random initial weighting although guarantee getting fastest best answer neural networks use back propagation learn update weights problem method weights converge local optimal local minimum cost loss global optimal random weighting helps network take chances direction available space gradually improve arrive better answer limited one direction answer image shows one dimensional example convergence given initial location local optimization achieved global optimization higher dimensions random weighting can increase chances right place starting better resulting converging weights better values kalhor classification regression nns lecture simplest case new weight follows cost function gradient added previous weight get new weight previous weights next step weights may equal result case geometric point view neural network inclined one direction weights weights different possible update weights different amounts depending impact factor weight result affects cost updates weights even small error initial random weighting can solved simple example shows effect random weighting initialization learning enables neural networkdifferent spaces instead going one side result process learningbest spacesi keras installed tensorflow backend cudalike sometimes demand force keras use cpu can done without say installing separate cpu tensorflow virtual environment backend theano flags set heard tensorflow flags accessible via keras want force keras use cpu keras tensorflow imported run script see also worked win place import keras rather separable way use booleans gpu cpu indicate whether like run code gpu cpu rigidly defining number gpus cpus tensorflow session allowed access variables num gpu num cpu define value num cores sets number cpu cores available usage via intraparallelism threads interparallelism threads intraparallelism threads variable dictates number threads parallel operation single node computation graph allowed use intra inter ops parallelism threads variable defines number threads accessible parallel operations across nodes computation graph inter allow soft placement allows operations run cpu following criterion met gpu implementation operation gpu devices known registered needlocate inputs cpu executed constructor class operations completely separable model code use note requires tensorflow gpu cuda cudnn installed option given use gpu refs options configproto like allow soft placement log device placement mean meaning interparallelism threads intraparallelism threads just import tensortflow use keraseasy per keras tutorial can simply use just spent time figure thomaanswer complete say program want use gpu run program keep gpus free write cuda visible devices pythondevices device people working pycharm forcing cpu can add following line run debug configuration environment variables disable running gpu tensor flow use gpu empty list argument say will gpus visible run early codegone official dochard time understanding function used works can someone explain laymanterms unfold imagines tensor longer tensor repeated columns rows values folded top unfolded unfolding step patch size across dim fold roughly opposite operation overlapping values summed output unfold fold used facilitate sliding window operations like convolutions suppose want apply function foo everywindow feature map image now windows size batch num windows can apply foo windows now need fold processed back original sizeneed take care padding kernel size may affect ability fold back processed sizemoreover fold sums overlapping elements might want divide output fold patch size please note since answerstensors acceptstensor will explain assuming input tensor shape batch size channels height width taken example batch size channels height width kernel size nothingkernelthis might beginner question seen lot people using labelencoder replace categorical variables ordinality lot people using feature passing multiple columns time however doubt wrong ordinality features will effecting model example input output can see ordinal values mapped correctly since labelencoder cares order column array high med low vice versa drastically wrong mapping can effect models easy way ordinalencoder map values properlydr using labelencoder encode ordinal kind features bad idea fact clearly stated docs mentioned name suggests encoding method aimed encoding label transformer used encode target values inputrightly point question mapping inherent ordinality ordinal feature wrong scale will negative impact performance model proportional relevance feature applies categorical feature just original feature ordinality intuitive way think way decision tree sets boundaries training decision tree will learn optimal features set node optimal threshold whereby unseen samples will follow branch another depending values encode ordinal feature using simple labelencoder lead feature say represent warm maybe translate hot representing boiling case result will end tree unnecessarily high amount splits hence much higher complexity simpler model instead right approach use ordinalencoder define appropriate mapping schemes ordinal features case categorical feature looking onehotencoder various encoders available category encoders though actually seeing bad idea will intuitive just words letuse simple example illustrate consisting two ordinal features containing range amount hours spend student preparing exam average grade previous assignments target variable indicating whether exam pastdefined dataframecolumns advantage defining categorical column pandas categorical get establish order among categories mentioned earlier allows much faster sorting based established order rather lexical sorting can also used simple way get codes different categories according order dataframeusing looks follows corresponding category codes can obtained now letfit decisiontreeclassifier see tree defined splits can visualise tree structure using plot tree yesactually set features way simple obvious relation hours dedication feature whether exam passed making clear problem easy model now lettry directly encoding features encoding scheme obtained instance labelencoder disregarding actual ordinality features just assigning value random expected tree structure way complex necessary simple problemtrying model order tree correctly predict training samples expanded depth single node suffice will imply classifier likely overfit sincedrastically increasing complexity pruning tree tuning necessary parameters prevent overfitting solving problem either sinceadded much noise wrongly encoding features summarize preserving ordinality features encoding crucial otherwise made clear examplelose predictable power just add noise model image size rgb uint want classify pixel set colors transformed using rgb lab rgb lab space removedlayer now double consistingnow want classify colors trained another image calculated respectiverepresentations now order classify label pixel cluster currently following pseudo code however terribly slow seconds image resolution manually loopy built functions can use performs job must summarize need classification method classifies pixel images already defined set clustersx sized points pixels array can avoid permute suggested solution luis slow things bit kind permute unrolled version also letbsxfun work towardsarray insteadarray must better performance thus assuming clusters orderedx sized array may try bsxfun based approach can try another approach leverages fast matrix multiplication matlab based smart solution letconsider two matriceswant calculate distance matrix sake easier explanation follows next letconsiderbsized arrays thus indicating workingy pointsxmsized arraysypoints now manually calculate first element square distance matrix look like now according proposed matrix multiplication check output extext loop earlier code ends look like following perform matrix multiplication ext transposeext first element product sum elementwise multiplication first rows extext result identical result obtained equation earlier continue elements elementscolumn thus end complete squared distance matrixvectorized variations matrix multiplication based distance matrix calculations possible though werenbig performance improvements seen two variations listed next variation variation considered experimental versions use pdist statistics toolbox compute distances vectorized manner donstatistics toolbox can replace third line gives squared distance instead distance purposes minimizing doesnsteps parameter indicating number steps run data yet see practical usage also execute fit functionepochs difference running steps epoch running steps epoch one better practice logic changes consecutive epochs data shuffling training step one gradient update one step batch size examples processed epoch consists one full cycle training data usually many steps example images use batch size epoch consists choose training image randomly independently step normally call epoch answer differs previous one also see comment epoch usually means one iteration training data instance images batch size epoch contain steps however usually just set fixed number steps like per epoch even though much larger data set end epoch check average cost improved save checkpoint difference steps one epoch another just treat checkpoints people often shuffle around data set epochs prefer use samples pool training data currently experimenting donknow yet usage steps epochs parameters consistent throughout tensorflow therefore just relating specifically now training steps defined num epochs steps explicitly defined comment set num epochs training input doc entry numpy inputtells num epochs integer number epochs iterate data none will run forever num epochs example training runs exactlycase stepstrain size batch size training steps defined num epochs steps explicitly defined higher number steps implicitly defined num epochs comment num epochs case mean stepsbatch size exactly number steps inputtrain input steps training steps defined steps comment although set num epochs calling numpy input fnthe training stops steps steps inputtrain input steps overwrites num epochsx traintrain batch size num epochs shuffle true conclusion whatever parameters num epochs lower bound determines number steps will run easy words epoch epoch considered number one pass entire dataset steps tensorflow one steps considered number epochs multiplied examples divided batch size epoch training epoch represents complete use training data gradients calculation optimizations train model step training step means using one batch size training data train model number training steps per epoch total number training examples batch size total number training steps number epochsnumber training steps per epoch according googlemachine learning glossary epoch defined full training pass entire dataset example seen thus epoch representsbatch size training iterationstotal number examples training model epochs batch size given total samples means model will able see whole dataset iterations model williterations iterations per epochepochsevaluation loss model parameters will performed iteration sinceaccepted answer yet default epoch run training data casestepstraining lenght batch size training data big can decide limit number steps epochbyp ivvfnvsn number steps reaches limitset process will start beginning next epoch workingdata usually transformed first list batches will fed model training step process one batch whetherbetter set steps epoch steps epochs donknowstraight answer results training cnn approaches using tensorflow timeseries data tutorials case approaches lead similar prediction training profiles differ steps epochs steps epochs divide lengthtrain batch size split training set many batches run algorithm requires one epoch analyze full training set epoch composed many iterations batches iterations number batches needed complete one epoch batch size number training samples used one iteration epoch one full cycle training dataset cycle composed many iterations number steps per epoch total number training samples batch size example training set images batch size number steps per epoch steps hope helps better understandingfollowing tutorial makepredictionusing python get error expectedarray gotarray instead think script older versions donknow convert version already try just supposed provide predict methodarray one value want process short can just replace work edit answer became popular thoughtadd little explanationshort version can use predict data dimensionality training dataexample question give computer bunch rowsvalues show correct responseswant predict using new values program expects bunch rows even want just one row two values row part another array problem occurring run prediction array fix problem reshaping call predict use approach faced issue except data type instance wanted predictneed convertarray reshape docs values will convert series numpy array faced problem just make array moreover put double squared brackets make single elementarray first bracket initializes array second makes element array simply replace last statement just insert argument double square bracket worked facing issue earlier somehow found solution can try api used allow scalar value now need givearray one feature dataframe list converts series convert back dataframe list worked just enclose numpy object two square brackets vice versa example initiallychangefix dimension issue can likenoney matrix independent variable dependent variable respectively dataframe int type gets convertedarrayarrayxypd pandas class python thus feature scaling turn doesnlead error matrix want matriceslcontains upper triangular elements elements including diagonal similarlyelements including diagonal numpy methodg extract upper triangle values flat vector can something like following similarly lower triangle use useargument usually used matrix symmetric put back extracted vectorsymmetric array one can follow answer triangle upper triangle lower code example use array creation routines saved keras whole model weights using models weights saved successfully error can successfully load weights simply using try load save model via load model getting error never received error used load models successfully using keras tensorflow backend python code training solution downgradingpy package case apparently putting back keras tensorflow correct versions enough downgradedpy package following command restarted ipython kernel worked versionpy superior previous build fixed setting downgradepy package following command resolve issue problem solved putting compile false load model saved usingformat filepy save formatcase probably due model saved different version keras got problem loading model generated similar kerasthink keras can load weights still kept error tensorflowpy python environment fixed downgrading python version downgrading python tensorflow keraspy resolved issue use kerasclassifier train classifier code save final model future prediction usually use code save model donknow insert saving modelcode kerasclassifiercode thank model save method saves details necessary reconstitute model example keras documentation can save model json weights hdf file format files model nummodel created contain model weights use trained model testing can simply load hdf file use prediction different dataload model saved files predict different data can use can use filepath save keras model single hdf file will contain python code probable last line allows save entirety state model single file saved models can reinstantiated via model returned load model compiled model ready used unless saved model never compiled first place arguments can save model load way generally save model weights file calling save function saving loading model case can simply save load model withoutcompiling model note preferred way saving loading keras model saving keras model loading model back information read documentation can save best model using example will save best model working directory since syntax keras save model changed years will post fresh answer principle earliest answer bogatron posted mar still good want save model including weights one file modelwill save model older kerasformat however new format tensorflow savedmodel format will used specify extensionhdf keras filename syntax case path folder given folder name yet exist will created two files two folders will created within folder keras saved assets variables far can still decide whether want store model one single file folder containing files folders see keras documentationtrying train network unbalanced data samplessamplessamplessamples read weighted cross entropy logits examples found binary classificationconfident set weights total samples weight idea behind understood penalize errors majority class value positively hits minority one right piece code read one others examples binary classification still clear note weighted cross entropy logits weighted variant sigmoid cross entropy logits sigmoid cross entropy typically used binary classification yes can handle multiple labels sigmoid cross entropy basically makes binary decision example face recognition net mutually exclusive labels subject wear glasses subject female etc binary classificationoutput channel corresponds binary soft decision therefore weighting needs happen within computation loss weighted cross entropy logits weighting one term cross entropy mutually exclusive multilabel classification use softmax cross entropy logits behaves differently output channel corresponds score class candidate decision comes comparing respective outputs channel weighting final decision therefore simple matter modifying scores comparing typically multiplication weights example ternary classification task also rely need tackle data imbalance class weights indeed inversely proportional frequency train data normalizing sum one number classes also makes sense note penalized loss based true label samples also penalized loss based estimated labels simply defining rest code need change thanks broadcasting magic general case want weights depend kind error make words pair labelsy choose penalize choosing labeltrue labelend whole prior weight matrix results weights full num samples num classes tensor goes bit beyond want might useful know nonetheless definition weight tensor need change code see answer alternate solution works sparse softmax cross entropy tensorflow compatible answer migrating code specifiedgnanswer benefit community information migration code tensorflow versionx please refer migrationallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago anyone know recent academic work done logo recognition images please answer familiar specific subject can search google logo recognition thank much anyone knowledgeable computer vision done work object recognition welcome comment update please refer algorithmic aspects approach think appropriate papers field whether work tested real world data efficiency considerations technical sides programming language used whether work image indexing content based image retrieval can also help try use local features like sift extracted features shall match workflow will like detect corners nike logo two sharp ends compute descriptors like siftinteger vector training stage remember matching stage find nearest neighbours every feature database obtained training finally set matches probably wrong seed wrong matches using ransac thusget matrix describes transform ideal logo image one find logo depending settings allow different kinds transforms just translation translation rotation affine transform szeliskibook chapter local features example find pepsi billboards distorted need findchannel logo screen rotated scaled easier pattern matching something conventional sift consider color information since logos usually constant colors though exact color depends lightning camera might want consider color information somehow worked logo detection recognition real world images also created dataset flickrlogos made publicly available including data ground truth evaluation scripts work treated logo recognition retrieval problem simplify multi class recognition allow systems easily scalable many logo classes recently developed bundling technique called bundle min hashing aggregates spatial configurations multiple local features highly distinctive feature bundles bundle representation usable retrieval recognition see following example heatmaps logo detections will find details internal operations potential applications approach experiments performance course also many references related work papers worked trademark matching retrieval sports video databases get pdf paper clusteren sdt used sift trademark image descriptors normalized threshold matching compute distance models images latest work able greatly reduce computation using meta models created evaluating relevance sift points present different versions trademarksay general working videos harder working photos due bad visual qualitystandards currently used marco worked project something similar first tried using haar training techniques using software opencv worked optimal solution needs source images looking logo fixed size contained logo able use cvmatchshapes known good match compare value returned deem good link says install xgboost following steps need run make root directory project python package directory run python step following error appear make term make recognized name cmdlet function script file operable program check spelling name path included verify path correct try skip step step directly another error appear anyone know install xgboost python windows platform thanks help case anyonelooking simpler solution doesnrequire compiling find woninstall missing dependency download install dependency first retry complains access permissions try opening command prompt administrator retry gives xgboost scikit learn wrapper savespain compiling note recent release microsoft visual studio instructions longer seem apply link returns errorcommentfinish bit build windows tools need build xgboost project get source code run lines note ran part cygwin using windows command prompt able changecopy arrive result however build fails reason recommend trying using cygwin build finishes successfully file called following now goodopen python can import package test installation went ahead ran basicget errors installed xgboost successfully windows bit python visual studio donneed mingw updated newer version xgboost steps step install cmake two new files just installed xgboost python python anaconda bit machine bit python simplegit required think works normal python use python download package version depends python version python python bit bit use command window usemake download folder pwd usefinished detailed steps see answer use python need downloadbuild built can download file built install directly download google drive download decompress paste python path lib site packages something look like python package folder showed use cmd windowrun use code python check whether installed mingw error information means installed mingw finished error information windowserror error means installed mingw one stepdownload mingw installed mingw add install pathposix sehv rev mingw bin path something likeprogram files mingwx posix sehv rev mingw bin mine donforget path finished can use python check yeahdonknow add path just google get solutions donworrysimple installing xgboost particular project using pycahrm need follow procedures given download xgboostcpwin using python use different version python like need install xgboostcpwin copy project interpreter directory can find directory project interpreter clicking file settings project interpreter pycharm open command promptdirectory project interpreter cmd write following command pip install xgboostcpwin python command worked anaconda prompt command can used directly screenshot attached proof pip install xgboost buildversion copy release dll lib files windowsrelease buildversion wrapper run python download visual basic studio can download community edition visual studio website free visual studio button upper right corner copy content git hub repository xgboost tree master windows open visual studio existing project visual studio couple drop menus need select releaseselect build build upper menu look something like attached screenshot see message build succeeded failed date skipped good browse python packages folder setup file xgb resides run install command python can find similar thread install xgboost python bit msys failing hope helps add solution disco ever attempting build bit windows machines step creating git checkout disco eversolution worked originally posted cortajarenaworth originally bit python running bit machine upload bit python xgboost work thanks disco ever answer trying build xgboost python anaconda environment windows bit machine used git mingw basic windows cmd everthing worked till copy stepmake using windows cmd modified copyxgboost make xgboost makegot error build failed stage much frustration just tired something different clicking script started executing auto finished executed step makeawe build successful seen awaited anaconda git bash windows cmd cygwin terminal opened spyder typed import xgboost success error thank everyone can install xgboost using either visual studio mingw since official xgboost website says msvc build yet updated tried using mingw running xgboost python package winsteps followed follow disco eversteps ming installation mentioned answers install git windows windows download link will also install git bash add git installation directory cmd system environment variable path list now clone xgboost desired location type following cmd xgboostroot directory script named build openopen git bash start building building now install python package can test importing xgboost python took whole day successfully installed xgboost windows bit box using tdm gcc openmp enabled instead mingw following linkhelpful link important points pay attention installationimportant install openmp otherwiseget error message link provides step step instruction installingquote building xgboost fair nothing wrong official guide installing xgboost windows stilllove stress several points save time makefile win modified version thanks zhou xiyou original makefile suit building process windows can wget download sure use unix thi windows cmd issue mkdircommand git bash recommended sure use recursive option git clone sure use proper mingw tdm gcc recommended note default wouldninstall openmp need specifiy otherwise building fail another helpful link official procedure official guide good luck like add small workaround disco eversolution unable perform cloning cygwin workaround perform command prompt windows rest task cygwin usec xgboostline make work cygwin updated last part like installation complete can uninstall git cygwin xgboost mingw must kept note makeuse gcccheck gcc version environment win anaconda python run makeshows std mutex error use gccecho gcc anacondadefault gcc choose gcc mingwgcc works finally useanaconda install xgboost python packet can install xgboost using following steps gather information system python version system architecture bit bit download related whl gohlke pythonlibs suitable file xgboostcpdone update question added graduate student university ghent belgium research emotion recognition deep convolutional neural networksusing caffe framework implement cnns recentlyrun problem concerning class imbalanceusing training samples approx labeled positively remaining samples labeled negativelyusing sigmoidcrossentropyloss layer calculate loss training loss decreases accuracy extremely high even epochs due imbalance network simply always predicts negative precision recall zero backing claim solve problem like scale contribution loss depending prediction truth combination punish false negatives severely mentor coach also advised use scale factor backpropagating stochastic gradient descent sgd factor correlated imbalance batch batch containing negative samples update weights added one custom made layer caffe report metrics precision recall experience caffe code limited lot expertise writingcode anyone help point right direction adjust sigmoidcrossentropyloss sigmoid layers accomodate following changes thanks advance incorporated infogainlosslayer suggested shaialso added another custom layer builds infogain matrixbased imbalance current batch currently matrix configured followsplanning experimenting different configurations matrix future tested imbalance results shown network learning useful things now results epochs numbers reached around epochs didnchange significantly results stated merely proof concept obtained training simple network imbalanced dataset donuse infogainloss layer compensate imbalance training set infogain loss defined using weight matrixcase meaning entries can set entriesreflect difference errors predicting can find define matrixcaffe thread regarding sample weights may find post interesting shows modify softmaxwithloss layer take account sample weights recently modification cross entropy loss proposed tsunglin priya goyal ross girshick kaiming piotr dollfocal loss dense object detection iccv idea behind focal loss assign different weight example based relative difficulty predicting example rather based class size etc brief time got experiment loss feels superior infogainloss class size weights also come across class imbalance problem classification task right now using crossentropyloss weight documentation works fine idea give loss samples classes smaller number images weight class inversely proportional image number class snippet calculate weight class using numpy letsuppose sequence integers want predict next integer given last integers etc suppose setup model like understanding model following structure please excuse crude drawing first question understanding correct note drawn previous statestt entering picture exposed specifying stateful true simple next integer prediction problem performance improve providing extra information long previous state results previous integers brings main question seems standard practice example see blog post timeseriesgenerator keras preprocessing utility feed staggered set inputs model training example confused seems requires outputlstm cell correspondingtime step see figure tensorflow docs stateful boolean default false true last state sample index batch will used initial state sample index following batch seems internal state isnavailable available final state see figure understanding correctclearly shouldnfeeding non overlapped windows samples model using stateful true answer depends problem hand case one step prediction yes can donwhether will significantly impact learning batchsample mechanism seesee additional info section models treat samples independent examples batch samples like feeding sample time times differences seemodelperspective data split batch dimension batch shape features dimensions batch shape two dontalk relation two via gradient seeoverlapoverlap batch perhaps best approach understand information basedbegin timeseries binary classification tie prediction suppose minute eeg recordings timesteps task seizure non seizure take samples shape feed two take neural net will never confuse seizure non seizure samplesalso clueless sample will massively overfit information sees per iteration barely differsbasically feeding batch several times row now suppose lot reasonable now windows overlap rather prediction overlap bad one step prediction information landscape now changed dramatically changes loss function good practice minimizing first make sure understand entire post nothingreally optionalkey overlapoverlap per batch goal balance twomain edge ever use prediction lstm stateful may actually entirely useless problem stateful used lstm canprocess entire sequencesplit different gradients desired backpropagation former idea lstm considers former sequence assessment latter words overlap stateful separate batches batchindependence state samples use stateful lstm benefits considering previous batch assessment next can include one step predictions canfeed entire seq lstm pass states stateful per implies causally follows will wreck training instead batchsample additional info batch set samples greater assume always latter answer three approaches iterate data batch gradient descent entire dataset stochasticone sample time minibatchpractice however call last sgd also distinguishbgd assume answer differences bonus diagrams set fairly complicated models training looking way save load model optimizer states trainer models consist different combinations several weight models shared weights frozen weights depending trainer etc bit complicated example share short able use model filemodel filestopping starting training using weight fileworks fine testing model training finished attempt continue training model using method loss come even close returning last location read optimizer state saved using method makes sense however need method saving loading states optimizers trainer models seems though keras accomplish seem case anymore least adam optimizer solutions current keras can extract important lines load model save model functions saving optimizer states save model loading optimizer states load model combining linesexample using think solution first save optimizer weights path ready reload optimizer show newly instantiated optimizer size weights will update calling error thrown optimizer expects weight list length zero completing alex trevithick answer possible avoidcalling simply saving state variables applying gradient reloading can useful loading modelfile looks cleaner imo saving loading functions following thanks alex upgrading keras using pickle solved issue keras release keras models can now safely pickled anyone trying useyangsolution distributed setting might run following error similar solve problem simply need run modeloptimizer weights setting replica using following reason isnneeded setting model weights make sure create via call load weights model within strategy scope might get error along lines valueerror trying create optimizer slot variable scope different scope used original variable want full example created colab showcasing solution code works tensorflowusing universal sentence encoder model together adam optimizer basically make use dummy input sets optimizer correctly afterwards set weights save weights optimizer load optimizer version longer accessible can eventually switch class finally class using logisticregression class scikit learn version flight delay dataset use pandas select columns fill nan values make sure categorical columns marked category data type call get dummies pandas now train test data set call score method get around however call roc auc score method get much lower number around reason roc auc much lower score method provides start saying auc lower score exactly like comparing apples oranges assume score mean accuracy critical discussion anything else principle according experience leastpractitioners think auc score measures something different actually common unfortunate use just like higher better metric like accuracy may naturally lead puzzles like one express truth roughly speaking auc measures performance binary classifier averaged across possible decision thresholds decision threshold binary classification value decide label sample recall probabilistic classifiers actually return valueusually interpreted probability scikit learn predict proba returns now threshold methods like scikit learn predict return labels set default possibility may even desirable come cases imbalanced data example point take home given clarifications particular example provides interesting case point get good enough accuracy model care according auc classifier slightly better mere random guessing provided class representation data reasonably balanced answer now hopefully obvious care practical cases care classifier deployed specific threshold classifier purely theoretical abstract situation averaged across possible thresholds pose little interest practitioner pose interest researcher coming new algorithm assume case imbalanced data argument changes accuracy practically useless consider precision recall confusion matrix instead reason auc started receiving serious criticism literature donmisread analysis roc curve highly informative useful wikipedia entry references provided therein highly recommended reading thus practical value auc measure called question raising possibility auc may actually introduce uncertainty machine learning classification accuracy comparisons resolution one recent explanation problem roc auc reducing roc curve single number ignores fact tradeoffs different systems performance points plotted performance individual system emphasis mine see also dangersknow exactly air del use label original data guess imbalanced featuremuchs case accuracy metric meaningful use precision recall confusion matrix instead see also thread just extreme example labelscan accuracy classifier simply naively classifying samples case also low auc fairly close case general much needed opinion discussion exactly auc see trying implement fully convolution network semantic segmentation wondering specific strategy set values following hyper parameters depend number images training set order set values meaningful manner need bits information regarding data training set size total number training examples letcall quantitytraining batch size number training examples processed together single batch usually set input data layer train example file train batch size set letdenote quantityvalidation set size total number examples set aside validating model letdenotevalidation batch size value set batch size test phase example set letcallnow training like getbiased estimate performance net every run net validation set test iter iterations cover entire validation set need test itervb often like get estimationreally large validation set slow net validating often will make training process long hand validating often enough may prevent noting training process failed converge test interval determines often validate usually large nets set test interval ordersmaller faster nets may choose lower values order cover entire training set completing epoch need runtb iterations usually one trains several epochs thus max iter epochstb regarding iter size allows average gradients several training mini batches see thread fro information trying understand process model evaluation validation machine learning specifically order training validation test sets must used letsay dataset want use linear regression hesitating among various polynomial degrees hyper parameters wikipedia article seems imply sequence however seems strange can fit model training set havenchosen yet hyper parameters polynomial degree case see three alternative approachs sure correct question wikipedia article wrong according experience frequent point confusion among newcomerstwo separate ways approaching problem standard point always put aside portion data test set used reason assessing performance model end case using test set validation set bad practice done choose will cut another portion remaining data use separate validation set will proceed cross validation case separate fixed validation set required essentially first third approaches valid mutually exclusive second one describevalidation set certainly said choosecv donassign separate validation set apart brief mention cross validation wikipedia article actually describes first approach questions approach better course answered level generality approaches indeed valid used depending circumstances loosely speaking say traditionalsettings people choosecross validation cases practical deep learning settings loosely speaking people going separate validation set instead wikipedia means actually first approach split data training set validation set test set use training set fit model find best parameters coefficients polynomial just means use training data fit model afterwards use validation set find best hyper parameters case polynomial degree wikipedia article says successively fitted model used predict responses observations second dataset called validation dataset means use validation dataset predict values previously training set trained model get score good model performs unseen data repeat step hyperparameter combinations want look case different polynomial degrees want try get score every hyperparmeter combination finally use test set score model fitted training set need validation set pretty explained stackexchange question fastest train one model every hyperparameter also donneed much data two approach slowest trainfoldsclassifiers plus final one training data validate every hyperparameter combination also need lot data split data three times first partfolds least variance results pretty unlikely getgood classifiers good validation result coincidence happen likely first approach cross validation also way unlikely overfit approach pros cons two also less likely overfitting end will depend much data get complex models like neural networks much time calculationpower willing spend edit desertnaut mentioned keep mind use training validationset training data evaluation test set also confused training validation set second neural network terminology example training examples batch size will take iterations complete epoch fyi tradeoff batch sizenumber iterations train neural network term batch ambiguous people use designate entire training set people use refer number training examples one forward backward pass answer avoid ambiguity make clear batch corresponds number training examples one forward backward pass one can use term mini batch epoch iteration describe different things epoch describes number times algorithm sees entire data set time algorithm seen samples dataset epoch completed iteration describes number times batch data passed algorithm case neural networks means forward pass backward pass every time pass batch datacompleted iteration example might make clearer say dataset examples samples batch sizespecified want algorithm run epochs therefore epoch batches batch gets passed algorithm therefore iterations per epoch sincespecified epochs total iterations training many neural network training algorithms involve making multiple presentations entire data set neural network often single presentation entire data set referred epoch contrast algorithms present data neural network single case time iteration much general term since asked together epoch assume source referring presentation single case neural network understand difference must understand gradient descent algorithm variants start actual answer like build background batch complete dataset size total number training examples available dataset mini batch size number examples learning algorithm processes single pass forward backward mini batch small part dataset given mini batch size iterations number batches data algorithm seen simply number passes algorithm done dataset epochs number times learning algorithm sees complete dataset now may equal number iterations dataset can also processed mini batches essence single pass may process part dataset cases number iterations equal number epochs case batch gradient descent whole batch processed training pass therefore gradient descent optimizer results smoother convergence mini batch gradient descent takes time batch gradient descent guaranteed find optimum exists stochastic gradient descent special case mini batch gradient descent mini batch size guess context neural network terminology order define iteration first need know batch size batch size probably wouldnlike process entire training instances one forward pass inefficient needs huge deal memory commonly done splitting training instances subsets batches performing one pass selected subset batch optimizing network backpropagation number training instances within subset batch called batch size iteration know networktraining instances one pass order complete one epoch wait splitting training instances batches means can process one batch subset training instances one forward pass batches term iteration comes play definition number forwarding passes number batches created network order complete one epoch going training instances called iteration example training instances want batching size iterations complete epoch hope answer question training data shuffle pick mini batches adjust weights biases using one mini batch completed one iteration run mini batches completed epoch shuffle training data pick mini batches iterate second epoch typicallysplit test set small batches network learn make trainingstep step number layers applying gradient descent way small steps can called iterations epoch corresponds entire training set going entire network can useful limit need trainneed large dataset involves many data itemstrained data itemsnn one one called iteration whole dataset goes called epoch believe iteration equivalent single batch forward backprop batch sgd epoch going entire dataset someone else mentioned epoch contains iterationsactually epoch letdefine epoch number iterations data set order train neural network epoch complete cycle neural network seen data one might said images train model however memory space might sufficient process images hence split training model smaller chunks data called batches images batch size iterations neural network looks entire data called epoch point one might need multiple epochs train model letsay epochs epoch iteration subset samples training example gradient descent algorithm neural network good reference randomly generate subset inputs gradient descent algorithm epoch effective also explained page please take look according googlemachine learning glossary epoch defined full training pass entire dataset example seen thus epoch representsbatch size training iterationstotal number examples training model epochs batch size given total samples means model will able see whole dataset iterations model williterations iterations per epochepochsevaluation loss model parameters will performed iteration epoch full training pass entire dataset example seen thus epoch representsbatch size training iterationstotal number examples iteration single update modelweights training iteration consists computing gradients parameters respect loss single batch data bonus batch set examples used one iteration one gradient update model training see also batch size sourceknow many clusters exist end may individual vectors existing part cluster euclidean distance lessvectors space existing algorithms approach used can use hierarchical clustering rather basic approach lots implementations available example included pythonscipy see example following script produces result similar following image threshold given parameter distance value basis decision made whether points clusters will merged another cluster distance metric used can also specified note various methods compute intra inter cluster similarity distance furthest points distance cluster centers methods also supported scipys hierarchical clustering module single complete according post think want use complete linkage note approach also allows small single point clusters donmeet similarity criterion clusters will become relevant situations lots data points answers comments suggest might also want look dbscan algorithm nice overview clustering algorithms also look demo page pythonscikit learn library image copied place can see algorithm makes assumptions number shape clusters need taken account implicit assumptions imposed algorithm explicit assumptions specified parameterization answer moooeeeep recommended using hierarchical clustering wanted elaborate choose treshold clustering one way compute clusterings based different thresholdstcompute metric quality clustering premise quality clustering optimal number clusters will maximum value quality metric example good quality metricused past calinski harabasz briefly compute average inter cluster distances divide within cluster distances optimal clustering assignment will clusters separated clusters tightest way donuse hierarchical clustering can also use something likemeans precomputepickhighest calinski harabasz score let know need referencesscour hard disk papers check dbscan algorithm clusters based local density vectors can determine number clusters automatically also considers outliers part cluster wikipedia page links implementations use optics works large data sets optics ordering points identify clustering structure closely related dbscan finds core sample high density expands clusters unlike dbscan keeps cluster hierarchy variable neighborhood radius better suited usage large datasets current sklearn implementation dbscan fine tune eps min samples per requirement want add moooeeeepanswer using hierarchical clustering solution work though quite random pick threshold value referrence source test got better method threshold easily picked dendrogram will see plot like click drawing horizontal line let say distance number conjunctions will desire number clusters choose threshold clusters now value cluster list will assigned cluster corresponding point ori array may solution case distance two distinct input data points always greaterwant compute number clusters input data may look mcg hierarchical clustering method automatic stop criterion see free seminar paper contains bibliographic references needed way fuzzy sort lines ocr output output sometimes order within blocks lines usually order case items sort dictionaries describe words locationy sizeh general clustering algorithms seemed like overkill needed maintain order items sort can set tolerance tol line spacing called fieldtroublecoordinate ocr output based outline around word later word line mightcoordinate lower earlier word full sortwork much like clustering algorithm intention bit different interested statistics data points interested exactly cluster placed also important maintain original order maybe way fuzzy sort using sorting built ins might alternative clustering optionsproblemstrying recover pca done scikit learn features selected relevant classic example iris dataset returns can recover two features allow two explained variance among dataset said diferently can get index features information included pca attribute components described documentationcomponentsfeatures get components linearly related different features note coefficient represents correlation particular pair component feature important side comment note pca sign affect interpretation since sign affect variance contained component relative signs features forming pca dimension important fact run pca code might get pca dimensions signs inverted intuition think vector negativespace essentially representing direction space check post reference edit others commented may get values components attribute principal component linear combination original variablesoriginal variables beta corresponding weights called coefficients obtain weights may simply pass identity matrix transform method column coef matrix shows weights linear combination obtains corresponding principal component example shows second principal componentmostly aligned sepal width highest weight absolute value since data normalized can confirm principal components variance equivalent coefficient vector norm one may also confirm principal components can calculated dot product coefficients original variables note need use floating point precision error way question phrased reminds misunderstanding principle component analysis first trying figurelikehope others wonspend much time road nowhere penny finally dropped notion recovering feature names suggests pca identifies features important datasetstrictly true pca understand identifies features greatest variance dataset can use quality dataset create smaller dataset minimal loss descriptive power advantages smaller dataset requires less processing power less noise data features greatest variance best important features dataset insofar concepts can said exist bring theory practicalities rafasample code consider following case post pca array rows data data scaled data scaledfour columns reduced four two critical point two columns components terminologically consistent post pca array two best columns data scaled two new columns determined algorithm behindpca module second columnrafaexample informed sepal width column valuesdata scaled sepal widthinteresting find much column original data contributed components post pca dataset notion recovering column names little misleading certainly misled long time situation match post pca original columns number principle components set number columns original however point using number columns data changed gone come back printsfeature namedimportantd given fitted estimator pca components found represent directions highest variance dataset performed pca analysis original dataset compressed dataset transformed pca also selected numberwant keep explain almost variance now struggling identification original features important reduced dataset find feature important among remaining principal components dimension reduction code furthermore tried also perform clustering algorithm reduced dataset surprisingly score lower original dataset possible first assume call features variables samples observations case something like following creating biplot function shows everything one plot example using iris data example please note basic idea using pca tool feature selection select variables according magnitude largest smallest absolute values coefficients loadings see last paragraph plot details overview part explain check importance features plot biplot part explain check importance features save pandas dataframe using feature names visualizegoing using biplot now importance feature reflected magnitude corresponding values eigenvectors higher magnitude higher importance letsee first amount varianceexplainexplainstogether keeppc explain now letfind important featurescomponentsfeatures thus lookingfirst principal component first row can conclude feature var biplot important also clearly visible biplotoften use plot summarize information visual way sum look absolute values eigenvectors components correspondinglargest eigenvalues sklearn components sorted explained variance larger absolute values specific feature contributes principal component important features ones influence components thus large absolute value score component get important features pcs names save pandas dataframe use printsfeature namedimportantd nice article source friends linkbfc aff fedfbpca library contains functionality demonstration extract feature importance following plot explained variance make biplot can nicely seen first feature variancealmost horizontal plot whereas second variancealmost vertical expected variancefollowedetc biplotsee nice addition expectedplotdirectionjust started experiment aws sagemaker like load databucket pandas dataframe sagemaker python jupyter notebook analysis use boto grab datam wondering whether elegant method part sagemaker framework python code simplest case donneed boto just read resourceseven simpler prateek stated make sure configure sagemaker notebook instance accessdone configuration step permissions iam role look seems can specify inputdataconfig searchdatasource ref document first hit even python page also access bucket file system usingfs make sure amazon sagemaker role policy attached accesscan done iam can also use aws data wrangler similar answerstring code sample import csv filetested sagemaker notebook use pip conda installfs pip installfs multiple ways read data sagemaker make response comprehensive adding details read data sagemaker studio notebook memorymounting options though notebooks recommend data intensive modeling used prototyping based experience multiple ways data can read botofs can also used conjunction python libraries like pandas read data memory can also used copy data local instance efs two options provide mount like behaviour data appears local directory higheroperations options pros difference softmax activation function following sample codeconfusing cross entropy binary multi class problems formula use correct directly correspondsq expected probability distributionsclasses particularcan following example notecomputingstill multi class cross entropy formulatime correct formula though mathematicallypartial case multi class case meaningq different simplest caseq number corresponding probability class important donget confused commonq part sum previousone hot vector nownumber zero oneprobability distribution nows number probabilityvector individual component considered independent binary classification see answer outlines difference softmax sigmoid functions tensorflow definitiondoesnmean one hot vector different features definitionmeans features probability explains use sigmoid function cross entropy goal squash logit interval formula still holds multiple independent featuresexactly see last three tensors equal prob part cross entropy contains correct valuenow clear taking sumq along axis doesnmake sense setting thoughvalid formula multi class case can understand differences softmax sigmoid cross entropy following way anyway cross entropy softmax cross entropy looks exactly formula sigmoid looks little different multi binary probability distribution binary probability distributionp can treat two class probability within binary probability distributionwhat meaning none output shape none sample number hidden dimension none means dimension variable first dimension keras model always batch size donneed fixed batch sizes unless specific cases instance working stateful true lstm layersdimension often ignored define model instance define input shape actuallyignoring batch size defining shape sample internally shape will none allowing variable batch size sample batch shape batch size will automatically defined fit predict methods none dimensions batch dimension can none many others instanceconvolutional network expected input batchsize height width channels can shapes like none none none allowing variable image sizes recurrent networksconvolutions can also make length timesteps dimension variable shapes like none none featuresorchannels yes none summary means dynamic dimension batch mini batch can set batch size model summary method partincorporates keras method print summary trying create simple deep learning based model predictx looks like deep learning able learn general function outside scope training set intuitively can think neural network might able fitx multiplication involved inputs please note asking create model fitalready achieved want know answers following questions path complete notebook training code evaluation random test set deep learning example good predicting simple non linear function good predicting values sample space training data given remarks comments network certainly deep letaccept analysis indeed correct model seem good job inside training scope order getquestion interesting one kind questions exactly suitable since exact meaning limited arguably lettry rephrase expectmodels predict numerical functions outside numeric domain trained example different domain may enlightening suppose built model able detect recognize animals photos high accuracy hypothetical models exist indeed complain model detect recognize airplanes trees refrigerators etc name photos put like answer clear obvious complain fact certainly even surprised behavior first place temptinghumans think models able extrapolate especially numeric domain since something easilymodels exceptionally good interpolating fail miserably extrapolation tasks one present trying make intuitive think whole world models confined domain training sets example model able generalize recognize animals unseen photos long animals mind quotes ones seen training similar manner model good job predicting function value arguments sample used training neither case models expectedbeyond training domain world example model beyond animals similarly model beyond corroboration consider recent paper neural arithmetic logic units deepmind quoting abstract neural networks can learn represent manipulate numerical information seldom generalize outside range numerical values encountered training see also relevant tweet prominent practitioner third question clear now hot area current research see papermodels limited definitely forget scary tales agi foreseeable future limited put dongiven limitation extrapolating useful arguably real question interest answer obviously yeah question appear programming within scope defined help center closed years ago trained neural network theano tensorflow will report variable called loss per epoch interpret variable higher loss better worse mean final performance accuracy neural network lower loss better model unless model fitted training data loss calculated training validation interperation model two sets unlike accuracy loss percentage summation errors made example training validation sets case neural networks loss usually negative log likelihood residual sum squares classification regression respectively naturally main objective learning model reduce minimize loss functionvalue respect modelparameters changing weight vector values different optimization methods backpropagation neural networks loss value implies poorly certain model behaves iteration optimization ideally one expect reduction loss several iterationaccuracy model usually determined model parameters learned fixed learning taking place test samples fed model number mistakes zero one loss model makes recorded comparison true targets percentage misclassification calculated example number test samples model classifies correctly modelaccuracy also subtleties reducing loss value instance may run problem fitting model memorizes training examples becomes kind ineffective test set fitting also occurs cases employ regularization complex model number free parameterslarge number data pointslow two different metrics evaluate modelperformance usually used different phases loss often used training process find best parameter values model try optimize training updating weights accuracy applied perspective find optimized parameters use metrics evaluate accurate modelprediction compared true data letuse toy classification example want predict gender oneweight height data follows stands male stands femalexkghywxcmxkghuse simple logistic regression modelexpxbh findb define loss first use optimization method minimize loss iterative way updatingb example typical loss binary classification problem can minus sign added front summation sign donknowb letmake random guess sayb loss now loss learning algorithm will find way updateb decrease lossb finalb output gradient descent accuracy now letassumehat decide prediction female otherwise therefore algorithm predictyaccuracy make wrong predictiony make correct onenow accuracyamiranswer back propagation said optimization methodthink treated way find gradient weightscommon optimization methodgradientdescent adam just clarify training validation test data sets training set used perform initial training model initializing weights neural network validation set used neural network trained used tuning networkhyperparameters comparing changes affect predictive accuracy model whereas training set can thought used build neural networkgate weights validation set allows fine tuning parameters architecture neural network modeluseful allows repeatable comparison different parameters architectures data networks weights observe parameter architecture changes affect predictive power network test set used test predictive accuracy trained neural network previously unseen data training parameter architecture selection training validation dataeasy two separate scalar summaries individually puts separate graphs displayed graphmuch easier see gap whether begin diverge due overfitting built way work around way thank much work around use two summarywriter different log dir training set cross validation set respectively will see something like rather displaying two lines separately can instead plot difference validation training losses scalar summary track divergence doesngive much information single plot compared adding two summaries helps able compare multiple runs adding multiple summaries per run just anyone coming accross via search current best practice achieve goal just use expected result many thanks niko tip custom scalars confused official custom scalarmuch going study quite figured worked show exactly needs done create custom scalar graph existing model put together following complete example consists original model augmented three blocks code indicated original model scalars graph modified model scalars graph together following custom scalar custom scalar chart simply layout combines original two scalar charts unfortunately resulting graph hard read values color distinguished marker however consistent tensorboardconvention one color per log idea follows group variables want plot inside single chart prerequisite tensorboard plotting variable individually scalars heading accomplished creating scalar summary variable writing summaries log nothing new plot multiple variables chart tell tensorboard summaries group together specified summaries combined single chart custom scalars heading accomplish writing layout beginning log tensorboard receives layout automatically produces combined chart custom scalars ordinary scalars updated assuming original model already sending variables scalar summaries tensorboard modification necessary inject layout main iteration loop starts custom scalar chart selects summaries plot means regular expression thus group variables plotted together can useful place variables respective summaries separate name scope way regex can simply select summaries name scope important notegenerates summary variable distinct variable example variablevar can create summarysummarymyvar custom scalars chart layout cares summaryname scope original variable example creating two get summary update orange line shows result evaluation stage correspondingly blue line illustrates data training stage also useful postteam can refer completeness since tensorboard now possible can use custom scalars plugin need first make tensorboard layout configuration write event file tensorboard example category group charts chart corresponds single plot displays several scalars together chart can plot simple scalars multilinechartcontent filled areas marginchartcontent tag member multilinechartcontent must list regexmatch tags scalars want group chart details check proto definitions objects need write layout one files writing separate file also works view data tensorboard need open custom scalars tab example image expect keys train losses dict match val losses grouped graph tensorboard really nice tool declarative nature can make difficult get exactly want recommend checkout losswise plotting keeping track loss functions alternative tensorboard losswise specify exactly graphed together get something looks like notice data fed particular graph explicitly via loss data appears projectdashboard addition example losswise automatically generate table columns min training loss min validation loss can easily compare summary statistics across experiments useful comparing results across large number experiments please let contribute code sample answer given lifu huang first download finally run tensorboard logdir summaries port get machine learning task get group randomoffer bound parameter want know parametrization truncnorm complicated function translates parametrization something intuitive instance generator parameters mean standard deviation truncation range can usegenerate value numpy arraygenerated values plot three different truncated normal distributionslooking truncated normal distribution scipy function called truncnorm standard form distribution standard normal truncated rangenoticedefined domain standard normal convert clip values specific mean standard deviation usemyclip mean std myclipmean std truncnorm takesshape parameters example bounded returns random variates using rvs methodhistogram plot besides bakkal suggestion might also want take look vincent mazet recipe achieving rewrittenrtnorm module christoph lassner can subdivide targeted range convention equal partitions calculate integration area call uniform method partition according surfaceimplemented python quad vec eval points full output true working sign language detection project jupyter notebook running code live detection encountered error shown opencvusers appveyor appdata local temp pip req build drropencv modules highgui src error unspecified error function implemented rebuild library windows gtkcocoa support ubuntu debian install libgtk dev pkg configrun cmake configure script function cvshowimage code caused errorinstalled opencv using using pip install edit solution seems work majority users case see proposed answer sachin mohan exact error using yolov windows rebuilding library typing worked frustration hours later saw solution comment first answer karthik thilakan worked conda environment thanks karthik installed another gpu finally upgraded tensorflow week suddenly issue arose finally found mistake uninstalling reinstalling opencv works people issue stated clearly text file opencv python dist packages named metadata states four different packages see options select one install multiple different packages environment file says always use packages use pyqt opencv create gui referring packages server headless environments gui library dependencies run result one opencv versionlikely found problem uninstall reinstall opencv might solve problem masterful solution simply uninstall headless version one care guis used server environments problem wrote similar program issue different versions opencv packages can check command output opencv contrib python opencv python opencv python headless turned opencv python headless must version program run properly solution change opencv python version opencv python headless case can run worked exact issue weeks backlike perhaps complement answers touching headless elephant room complex project incorporates house subprojects colleagues tend developed tested independently cross contamination occurs however since one used opencv python another went opencv python headless final build installed problem whenever number functions particularly pertaining visualisation now failed worse pip list revealed opencv versions installed make matters worse whenever uninstalled installed opencv python simple upgrade never worked claimed latest version nothing needed upgrading started working hate witchcraft lib site packagesfind following two folders whatever version might folders pip gets metadata actual code fact donimport rather importimportcases fact headless crippled drop real thing look listfindfolder libraries deposit code folder know comes saving files last scene winsmiss john bercow now libraries saving folder order since dondepend one another case poetry used manage dependencies alphabetical order default drumroll headless comes last point just decidednuts remove headless altogetherdev team just grasping strawslooked int whole drop thing colleagues developing simple came gathering requirements nice proper just left headless option canwhenever multi part projects highly advise run pip list environment built check couple find always remove headless subset main one achtung check venv line means project will importing libraries standard ones global python install happen headless global environmentstill trouble error mostly pycharm ide resolved changing project interpreter none given solution internet worked solved issue trying move set files windows ubuntu ltd running cli inference error mentioned opening post cropped threw error used set commands windows started execute cli platforms use opencv python try reinstall opencv can also save image single command open drive img need waste time constructed cldnn convolutional lstm deep neural network structure raw signal classification task training epoch runs seconds hyperparameters seems difficult optimize research various ways optimize hyperparameters found bayesian optimization although still fully understanding optimization algorithm feed like will help greatly like ask questions regarding optimization task greatly appreciate insights problem although still fully understanding optimization algorithm feed like will help greatly first let briefly explain part bayesian optimization methods aim deal exploration exploitation trade multi armed bandit problem problem unknown function can evaluate point evaluation costs direct penalty opportunity cost goal find maximum using trials possible basically trade know function finite set points good bad can try area around current local maximum hoping improve exploitation can try completely new area space can potentially much better much worse exploration somewhere bayesian optimization methodsucb build model target function using gaussian processstep choose promising point basedmodel note promising can defined differently different particular methodsexample true functionxsinblack curve interval red dots represent trial red curvemean blue curve mean plus minus one standard deviation can seemodel doesnmatch true function everywhere optimizer fairly quickly identified hot area around started exploit set bayesian optimization regards deep network case space defined possibly transformed hyperparameters usually multidimensional unit hypercube example suppose three hyperparameters learning rate regularizer continuous hidden layer sizeinteger space optimization dimensional cube pointpcube corresponds trinityfollowing transformation function trying optimize cost validation setepochs correct target function neural network validation accuracy clearly evaluation expensive requires least several epochs training also note target function stochasticblocker bayesian optimization though obviously increases uncertainty spearmint good starting point task suggestions task spearmint good library can definitely work can also recommend hyperopt research ended writing tiny library basically two reasons wanted code exact bayesian method use particular found portfolio strategy ucbconverged faster anything else case plus another technique can save training time called learning curve prediction idea skip full learning cycle optimizer confident model doesnlearn fast areasaware library implements coded end paidinterested code github trying get applesample coremodels demoed wwdc function correctly using googlenet try classify images see apple machine learning page model takes cvpixelbuffer input image calledusing demo code always getting unexpected runtime error output rather image classification code convert image got code previous stackoverflow post last answer recognize code may correct idea believe section contains error model calls following type input image rgb donneed bunch image mangling use coremodel image new vision framework can wwdc session vision bit infotomorrow afternoon can use pure coreml resize image expected image size inputs can find mimodel file demo project uses pure coreml vision variants can find rather url want use vnimagerequesthandler can use ciimage classifying images vision core mli algorithm running set objects algorithm produces score value dictates differences elements set sorted output something like lay values spreadsheet see make groups way programatically get groupings maybe clustering algorithm using machine learning library overthinkinglooked scikit examples way advanced sort look largest gaps trivial fastpossiblewant something advanced use kernel density estimation kde look local minima split data set number duplicates question good option donknow number clusters meanshift output algorithm modifying quantilevariable can change clustering number selection criteria can use clustering group trick understand two dimensions data dimension can see spatial dimension looks like can create matrix numpy like can perform clustering matrix kclustoutput will look like interesting part first column matrix says centers alongdimension can assign points cluster based five centers closest looking example posted bvlc caffe git training meta parameter meta parameter mean value assign weight decay meta parameter govern regularization term neural net training regularization term added networkloss compute backprop gradient weight decay value determines dominant regularization term will gradient computation rule thumb training examples weaker term parameters deeper net larger filters larger innerproduct layers etc higher term caffe also allows chooseregularization defaultregularization setting however since cases weights small numbersl norm weights significantly smallernorm thus choose use regularization typemight need tune weight decay significantly smaller value learning rate may usually change training regularization weight fixed throughout weight decay regularization term penalizes big weights weight decay coefficient big penalty big weights also big small weights can freely grow look answer specific caffe better explanation difference neural net weight decay learning rate read thread difference svc linearsvc scikit learn now data set binary classification problem problem one one one rest strategy difference functions ignore want try parameters functions give result first course set kernel linear svc however just get result functions find answer documents anybody help find equivalent parameter set looking updated modified following code example scikit learn website apparently result output figure previous code mathematical sense need set another element easily fixed increasing intercept scaling linearsvc implementation bias regularized true svc true svm thus svm consequently will never exactly equal unless bias problem assume two different models personally consider linearsvc one mistakes sklearn developers class simply linear svm increasing intercept scaling however scale much will also fail now tolerance number iterations crucial sum linearsvc linear svm use trained xor neural network matlab got weights just curiosity tried write matlab code computes output network two neurons hidden layer one output tansig activation function code got problem input say outputs simulating network generated matlab outputs adequately wrong wrote simple example xor network used newpr defaults tansig transfer function hidden output layers check result computing output important thing remember default inputs outputs scaled range efficiently expressed matrix product one line usually donuse sigmoid output layer sure tansig sure looking weights appropriately trained network looks likegot network trained xor meaning xor meaning building image processing classifier code api predict image class image whole code running except line pred test image api made django framework using python point running code like normally without making apirunning perfectly test image input tensorflow model match just assumption want debug guess print image size compare first layout model definition check whe size width height depth matchhi building image classifier one class classificationused autoencoder running model getting error line autoencoder valueerror error checking target expected model shape none got array shapesimple incompatibility output shape decoder shape training data target means output seegot maxpoolings dividing image size three upsamplings multiplying decoderinput final output autoencoder big doesnmatch data must simply work model make output shape match training datausing wrong api take look fit method source codelabel data hope helpwhen train neural networks typically use gradient descent relies continuous differentiable real valued cost function final cost function might example take mean squared error put another way gradient descent implicitly assumes end goal regression minimize real valued error measure sometimes want neural network perform classification given input classify two discrete categories case end goal user cares classification accuracy percentage cases classified correctly using neural network classification though goal classification accuracy neural network trying optimize neural network still trying optimize real valued cost function sometimes point direction sometimes donparticularrunning cases neural network trained correctly minimize cost function classification accuracy worse simple hand coded threshold comparisonboiled minimal test case using tensorflow sets perceptron neural network hidden layers trains absolutely minimal dataset one input variable one binary output variable assesses classification accuracy result compares classification accuracy simple hand coded threshold comparison results respectively intuitively single outlier large input value generates correspondingly large output value way minimize cost function try extra hard accommodate one case process misclassifying two ordinary cases perceptron correctly toldjust match actually want classifier classification accuracy continuous differentiable function canuse target gradient descent can train neural network ends maximizing classification accuracy can train neural network ends maximizing classification accuracyasking way get continuous proxy functioncloser accuracy start loss function used today classification tasks deep neural nets invented goes back several decades actually comes early days logistic regression equation simple case binary classification idea behind exactly come continuous differentiable function able exploit vast still expanding arsenal convex optimization classification problems safe say loss function best far given desired mathematical constraints mentioned consider problem solved finished least principle old enough remember era activation functions practically available tanh sigmoid came relu gave real boost field similarly someone may eventually come better loss function arguably going happen research paper answer fact current loss function comes elementary considerations probability information theory fields sharp contrast current field deep learning stand upon firm theoretical foundations creates least doubt better proposal loss may just around corner another subtle point relation loss accuracy makes latter something qualitatively different former frequently lost discussions let elaborate logistic regression etc probabilistic ones return hard class memberships class probabilities continuous real numbers limiting discussion simplicity binary case converting class probability hard class membership implicitly involving threshold usually equalclass now can find many cases whet naive default choice threshold will work heavily imbalanced datasets first come mindchoose different one important point discussion threshold selection central importance accuracy completely external mathematical optimization problem minimizing loss serves insulation layer compromising simplistic view loss just proxy accuracy nicely put answer cross validated thread statistical component exercise ends output probability class new sample choosing threshold beyond classify new observationpart statistics part decision component enlarging somewhat already broad discussion can possibly move completely away limiting constraint mathematical optimization continuous differentiable functions words can away back propagation gradient descend actually already least sub field reinforcement learning year new research openai something called evolution strategies made headlines extra bonus ultra fresh dec paper uber subject generating much enthusiasm community think forgetting pass output simgoid fixed output question appear programming within scope defined help center closed years ago noticed one hot encoding used particular data set matrix used training data learning algorithms gives significantly better results respect prediction accuracy compared using original matrix training data performance increase happen many learning algorithms either learn single weight per feature use distances samples former case linear models logistic regression easy explain suppose dataset single categorical feature nationality valuesfrenchassume without loss generality encoded weightfeature linear classifier will make kind decision based constraintxequivalentlyxproblem now weightencode three way choice three possible valuesxw either three lead decisionbuk french lead decision frenchgive decisionpossibility model learnus given label french odd one one hot encoding effectively blow feature space three features will get weights decision function nowukukfrfrususxbooleans space linear function can express sum disjunction possibilitiesus might predictor someone speaking english similarly learner based standard distance metricsnearest neighbors samples will get confused without one hot encoding naive encoding euclidean distance distance frenchdistanceuk one hot encoding pairwise distances equal true learning algorithms decision trees derived models random forests deep enough can handle categorical variables without one hot encoding regarding increase features one hot encoding one can use feature hashing hashing can specify number buckets much less number newly introduced features want predict categories want predict items set using one hot encoding akin letting categories neighbour categories regression integers categories instead organized certain way certain order now happens assign category category category without one hot encoding algorithmprediction isnsure choose predict despite thinkseither see goes goes data inputs shouldnsupposed neighbours donshow algorithm update question can answered facts citations editing post closed years ago eigenvectors can neural nodes input many hidden layers model zero hidden layers will resolve linearly separable data unless already know data isnlinearly separable doesnhurt verify use complex model task requires linearly separable simpler technique will work perceptron will job assuming data require separation non linear technique always start one hidden layer almost certainlywill need data separable using mlp mlp probably needs single hidden layer theoretical justification reason purely empirical many difficult classification regression problems solved using single hidden layer mlps yet donrecall encountering multiple hidden layer mlps used successfully model data whetherbulletin boardstextbooks academic papers etc exist certainly circumstances justify use empirically quite rare many nodes hidden layer mlp academic literature experience etc gathered often rely upon several rules thumb rot also found reliable guidesguidance accurate even wasnusually clear next rot based improving convergence begin model building err side nodes hidden layer first extra nodes hidden layer isnlikely harm mlp will still converge hand nodes hidden layer can prevent convergence think way additional nodes provides excess capacity additional weights store release signal network iteration training model building second begin additional nodes hidden layereasy prune later iteration progress common diagnostic techniques assist hinton diagram just visual depiction weight matrices heat map weight values rots based size input layer size output layer rule thumb size hidden layer somewhere input layer size output layer number inputs outputsrot based principal components typically specify many hidden nodes dimensions principal components needed capture variance input data set yetfaq author calls rules nonsense literally ignore number training instances noise targets values response variables complexity feature space view always seemed knowstalking choose number neurons hidden layer based whether mlp includes form regularization early stopping valid technique optimizing number neurons hidden layer model building test obsessively testing will reveal signatures incorrect network architecture instance begin mlp hidden layer comprised small number nodes will gradually increase needed based test results training generalization error will high caused bias underfitting increase number nodes hidden layer one time generalization error begins increase time due overfitting high variance practice way input layer size data vactor number features model bias node including response variable course output layer soley determined model regression one node versus classification number nodes equivalent number classes assuming softmax hidden layer start one hidden layer number nodes equal size input layer ideal size likely smallernumber nodes number input layer number output layer rather larger just empirical observation bulk observation experience project justified additional time required start single hidden layer comprised small number nodes explained just add nodes hidden layer one time calculating generalization error training error bias variance generalization error dipped just begins increase number nodes point choice see figure automate selection best number layers best number neurons layers can use genetic optimization key pieces can also consider difficult choose number neurons hidden layer choose number hidden layers neural network usually applications one hidden layer enough also number neurons hidden layer number inputs example number outputs example best way choose number neurons hidden layers experimentation train several neural networks different numbers hidden layers hidden neurons measure performance networks using cross validation can stick number yields best performing network recently theoretical work hidden layers number nodes loss function true functionapproximating neural network obey technical properties paper can choose depth order logwidth hidden layers orderd betalogn sample sizedimension input vector beta smoothness parameter true function since beta unknown will probably want treat hyperparameter can guarantee probability converges function sample size approximation error converges function sample size give rate note isnguaranteed best architecture can least give good place start experience suggests things like dropout can still help metric another list parameters passed keras classification problems want minimize cross entropy loss also want assess model performance auc case cross entropy loss function auc metric metric model performance parameter one can see model judging validation set epoch training important note metric important keras callbacks like earlystopping one wants stop training model case metric isnimproving certaining epochs contrived example mind letthink linear regressionplane case loss function mean squared error fitted line minimize error however reason interested area curve fitted line thus can one metrics monitor metric model minimizes mean squared error loss training setusing data set removed irrelevant code basically now readsy outputs perceptron learning algorithm reason converging globalerror converge therefore get infinite loop use smaller training set like points works pretty ideas problem wrote algorithm similarperceptron algorithm edit example smaller training set current code perceptron successfully learns direction decision boundary unable translate someone pointed accurate version problem lies fact perceptron bias term following outputshort animation code using matlab showing decision boundary iteration might help put seeding random generator start main instead reseeding every call randomfloat better change doesnrelyarray right size increase iterations insideloop whereas originalcode outsideloop better move printf iteration outsideloop pause statement alsoremove pause statement change even changes program still doesnterminate using data set output consistent giving error oscillating somewhere last thing try test originalprogram dataset also doesnterminatesomething wrong algorithm dataset looks correct see visualization comment globalerror will become zero will converge zero said give maxiterations maxerror values applicable problemtrained sentiment classifier model using keras library following steps broadly now scoring using model able save model file load file howeverfound way save tokenizer object file withoutprocess corpus every time need score even single sentence way around common way use either pickle joblib example use pickle order save tokenizer tokenizer class function save date json format data can loaded using tokenizer json function keras accepted answer clearly demonstrates save tokenizer following comment problem generally scoring fitting saving suppose list texts comprised two lists train text test text set tokens test text subset set tokens train text optimistic assumption fit texts train text gives different results texts sequences test text compared first calling fit texts texts text sequences test text concrete example results course optimistic assumption satisfied set tokens test text disjoint train test test results list empty bracketscreated issue issue link gist code demonstrate save restore tokenizer without original documents tokenizer fit prefer store model information json file reasons mainly mixedpython environment will allow even sort keys true found following snippet provided following link thusv save objects load objects quite easy tokenizer class provided two funtions save load save load method call get config method handle currently process designing recommender system text articles binary case interesting interesting one specifications continuously update changing trends can tell best way make use machine learning algorithm supports incremental online learning algorithms like perceptron winnow support online learning completely certain support vector machines scikit learn python library support online learning support vector machine one algorithms can make use obviously completely tied using support vector machines usuallyalgorithm binary classification due round performance willing change whatever fits best end online algorithms svms exist become important specify want kernel linear svms many efficient algorithms developed special case linear svms linear case use sgd classifier scikit learn hinge lossregularization will get svm can updated online incrementall can combine feature transforms approximate kernel get similar online kernel svm one specifications continuously update changing trends referred concept drift will handled simple online svm using passiveaggresive classifier will likely give better resultslearning rate decrease time assuming get feedback training running can attempt detect decreases accuracy time begin training new model accuracy starts decrease switch new one believe become accurate jsat drift detection methods see can used track accuracy alert changed also online linear kernel methods bias noteauthor jsat maybenaive think worth mentioning actually update sci kit sgd classifier present data incrementally short answer sklearn implementation existing others support online svm training possible train svm incremental way trivial task want limit linear case answer yes sklearn provides stochastic gradient descent sgd option minimize svm criterion can also try pegasos library instead supports online svm training problem trend adaptation currently popularcommunity raff stated called concept drift numerous approaches often kinds meta models analyze trend behaving change underlyingmodel example forcing retrain subset data two independent problems way scale svm split large dataset batches can safely consumed svm algorithm find support vectors batch separately build resulting svm model dataset consisting support vectors found batches updating trends achieved maintaining time window time run training pipeline example training day enough information monthhistorical data create traning dataset historical data obtained recent days sgd batch learning tasks normally decreasing learning rate goes training set multiple times purely online learning make sure learning rate set constant eta desired value therefore process follows interested online learning concept drift previous work learning concept drift overview definitions related work doi rep rep type pdf survey concept drift adaptation mpechen publications pubs gama acmcs adaptationcd maloof pubs canuse flask production thought gunicorn flask flask application loading machine learning models sizecollectively concurrency web application canupto requests ram machinebest way run application can start app multiple workers async workers gunicorn flask gunicorn workers multiprocessing information flask concurrency post many concurrent requests single flask process receive best thing use pre fork mode preload app true will initialize code master process simply fork worker processes handle requests running linux assuming model readsmart enough reuse physical memory amongst keras talking tensorflow differences relationships typical applicationsmathematical background cross entropy types one know cross entropy types without logits just one cross shannon entropy defined machine learning usageactual ground truth distributionpredicted distribution functions listed just helper functions accepts different ways representq basically main things consider either possibles outcomes binary classification just two outcomesxx single float identifies whole distribution neural network binary classification single output logistic regresssionpossible outcomes one defineoutputs one perx one either produces proper probabilities meaningx sumx one just produces score fixed method transforming score probability example single real number can transformed probability taking sigmoid set real numbers can transformed taking softmaxpj one true class targets hard like image represent cat soft targets like sure cat actually dog depending three aspects different helper function used end one just use categorical cross entropy mathematically defined however since things like hard targets binary classification popular modernlibraries provide additional helper functions make things simpler particular stacking sigmoid cross entropy might numerically unstable one knows two operations applied together numerically stable version combined implementedimportant notice apply wrong helper function code will usually still execute results will wrong example apply softmax helper binary classification one output network will considered always produce true output final note answer considers classification slightly different consider multi label case single point can multiple labelssum one use sigmoid cross entropy logits despite multiple output units purpose logits can seen non activated outputs model losses logits will apply activation internally functions allow choose logits true logits false will tell function whether apply applyknowrest reduce batch size number neurons model runs fine generic way calculate optimal batch size based model gpu memory program doesncrash short want largest batch size possible terms model will fit gpu memory woncrash program recent deep learning book goodfellowal chapter minibatch sizes generally driven following factors practice usually means powers larger better provided batch fits gpu memory might want also consult several good posts stack exchange just keep mind paper keskaral large batch training deep learning generalization gap sharp minima quoted several posts received objections respectable researchers deep learning community hope dec new paper yoshua bengio team three factors influencing minima sgd nov worth reading sense reports new theoretical experimental results interplay learning rate batch size update mar interest also another paper revisiting small batch training deep neural networkst nicolas gervais runs contrary larger better advice quoting abstract best performance consistently obtained mini batch sizesm contrasts recent work advocating use mini batch sizes thousands can estimate largest batch size using max batch size available gpu memory bytes size tensors trainable parameters use summaries provided pytorchsummary pip install keras builtin model need people seem prefer batch sizes powers two probably automatic layout optimization gpu donforget linearly increase learning rate increasing batch size letassume teslahandmemory function find batch size training model ran similar gpu mem error solved configuring tensorflow session following see google colaboratory resourceexhaustederror gpui trained cnn vgg google colab generatedfile now problem can predict output successfully google colab downloadtrained model file try predict output laptop getting error loading model code error ran issue changing tensorflow import keras import keras life worth living fixed problem works wow just spent hours life trying figure dmitri posted solution trained keras model google colab now able load locally systemjust basically reposting worked looks like kind serialization bug keras wrap load model customobjectscope eliminate errors import things directly keras tensorflow mixing project may result problems problem fixed way just donsave optimizer model just change save line like second parameter tells keras overwrite model file existedone tells save optimizer model edit ran problem another system today helped time saved model conf json weightsused rebuild model another machine can like save like rebuild model like something helped wasnanswers custom objects glorotuniform glorot uniform either kaggle colabs works worked importing tensorflow keras loading architecture weights separtly loading archtiecture model change problem solved problem model built tensorflow using loaded tensoflow using solved upgrading everything tensorflow building model new version load without error json file problem mentioned derk one comment can write following import line remember write instead different computation graph construct graph instead generally operations overloaded tensors least oney expressionsyy equivalent main reason might use specify explicit name keyword argument createdpossible overloaded operator version note neithery example numpy arraysy will create tensorflowalways creates tensorflowconverts arguments writing library function might accept tensors numpy arrays might prefer use following operators overloaded tensorflow python api please notebinary overloadedy will simply return python boolean whethery refer tensor need use explicitly check element wise equality goes equalbinary mrry nicely explained real difference will just add using will beneficial name operation tensorboard useequivalent otherwisebrevity use overloaded version image horizontal vertical lines fact image bbc website converted horizontal vertical lines problem want able find rectangles image want write computer program find rectangles anyone know suggest ideas get started task easy person find visual rectangles sure describe program image bbc website wrote code converts bbc website image horizontal vertical line problem lines completely meet corners sometimes completely form rectangle thanks opencv image processing computer vision library writtenimplementation hough transform simple hough transform find lines image generalized one finds complex objects good start rectangles closed corners also corner detectors cornerharris can help ran houghlines demo provided opencvresult image gave detected lines marked red source believe looking generalized hough transform computer vision algorithm called generalized hough transform maybe can solve problem open source code implemented algorithm just search assumingreasonably noise free image video screen one simple floodfill algorithms work might need run dilate erode image close gaps normal way find lines hough transform find lines right angles opencv easiest way take look question opencv object detection center point several different approaches problemuse morphological image processing tool like one will flexibility define rectangle even something exactly closed fill algorithm will fail another possibility use machine learning approach basically data driven definition driven like previous onegive algorithm several examples rectangle will eventually learn bias error rate iterate left right hit color pixel use modified flood fill algorithm info algo flood fill wiki another approach find colored pixel imageupwards nowdefined single line use ends lines approx match lines rectangles pixel perfect kind tresholding flood fill work use modification edge tracking algorithm createarraydata struct row represents horizontal pixel line screen column vertical line iterate pixels left right whenever find coloured one add coordinates array iterate array findying lines storing begin end pixel one different data structure knowing begin line left top pixel can easily check see lines comprise rectangle get image nearly touching horizontal vertical lines just rectangles will bit luck first show boxes thick fat lines leaving thick fat artifacts image step step thick fat artifacts will removed boxes remain need tweek number repeats step best resultsinterested image morphology book really good introductory course took sample black white pixels centerblock considered input left output right spending couple days trying achieve task like share experience went answering question useobject detection train using dataset assumes module already installed please refer documentation disclaimer answer meant right way training object detection module simply sharing experience workedopen suggestions learning still newgeneraldr section answer consists corresponding edit see reading section please read edit clarifications corrections tips added section tools used labelimg tool creating pascal voc format annotations create pascal voc datasetsimplicity folder naming convention answer follows pascal voc peek may datasetnotice folder following structure vocdevkit voc annotations imagesets action layout main segmentation jpegimages segmentationclass segmentationobject time amendments made following folders annotations images corresponding xml files will placed use suggested tool create annotations worry truncated difficulty tags will ignored training eval binaries jpegimages location actual images make sure type jpegcurrently supported order create tfrecords using provided script imagesets main simply consists text files class exists corresponding classname folder structure vocdevkit voc annotations image generated annotation imagesets main class generated classname classname jpegimages bunch jpeg images generating label map dataset prepared need create corresponding label maps navigate models object detection data open pascal label explicitly grab aeroplanechange file name class train text file make sure vocdevkit inside models object detection canahead generate tfrecords pleasecode first run problems self explanatory documented pipeline configuration instructions self explanatory cover segment sample configs can found object detection samples configs looking train scratch just make sure remove fine tune checkpoint detection checkpoint nodesconfig file looked like reference can continue tutorial run training process visualize sure run eval parallel training order able visualize learning process quote jonathan huang best way just run binary parallel training pointing directory holding checkpoint trained logs eval dir specify can point tensorboard want see map lifted first hours want see convergeshard tell without looking plots many steps need edit july never expected response get much attention decided come back review tools fellow apple users actually use rectlabel annotations pascal voc digging around finally realized represents none recommended ids start visualize running evaluation directed tensorboard eval directoryshow map category along categoryperformance good like seeing training data parallel eval run tensorboard different port point train directory wrote blog post medium experience trained object detector particularraccoon detector tensorflow dataset might also useful others complimentary eshirimaanswer want create transformer use sklearn pipeline creating class implements fit transform methods purpose transformer will remove rows matrix specified number nans issue facing can changey matrices passed transformer believe done fit method since accessy since python passes arguments assignment reassignnew matrix fewer rows reference originallost course truepossible maintain referenceusing pandas dataframe easily drop rows many nans may right way use case current code looks like modifying sample axis yet comply scikit learn transformer api need outside calls scikit learn preprocessing now transformer api used transform features given sample something new can implicitly contain information samples samples never deleted another option attempt impute missing values need delete samples treat preprocessing using scikit learn modify internal code sklearn pipeline define transformer removes samples least value feature target nan fitting fit transform removes samples least value feature nan inference transform important note transformer returnsy fit transform need handle behaviour sklearn pipeline modify original sklearn pipeline two specific points fit fit method rest remains unchanged required order unpack values generated dropna fit transformy newy full pipeline work another trial intermediate preprocessing step complex behaviors can achieved simple modifications according needs interested also pipeline fit transform pipeline fit predict need operate changes package imblearn built top sklearn contains estimator functionsampler allows manipulating features arraytarget arraypipeline step note using pipeline step requires using pipeline class imblearn inherits one sklearn furthermore default context pipeline method resample nothing called immediately fit fit resample read documentation ahead time addingo matias responseexample using imblearn define pipeline step drops rows missing values note use imblearn pipeline can solve easily using just need put alternationsfunction get transformer calling can use pipeline threshold can set outside drop nans function eickenberg proper clean answer nevertheless like keep everything one pipeline interested created library yet deployed pypi allow apply transformationusing code can alter number rows put transformer modify numbers rows splitxy transformer transformer splitxy transformer keep columns name also added sklearnpandaswrapper wrap sklearn transformer usually return numpy array keep columns name can use function transformer use deep copies pipeliney remain protected fit can first assign call deep copy new class variables reduce transform nanorderedusingmachine learning following standard machine learning methodology like randomly split data training validation test data setsknow related questions split data sets obvious split data sets way correct approach use data sets including validation set tune hyperparameters linked approach two groups using floor doesnextend naturally threecheck results run just result looks like test res test cut standard tool partitioning based shares following approach shown post workingcode divide dataframe three new dataframes testing validation test three subsets non overlapping seem overly complexsimple way using sample split dataset even arbitrary number setsrather reusable code one solution split also ensures overlapping however trouble adapt split anyone help appreciate caret also support data splitting function createdatapartition outcomeunbalanced factor yes vice versa ideally random sampling occurs within class preserve overall class distribution data case createdatapartition example note outcome unbalanced splitting train test verification note preserve overall class distribution think approach easiest one first splits data training data rest idxnottrain rest splitted validation data set total data rest testing data total data let know work just simplified versionin keras tensorflow backend current input pattern available custom loss function current input pattern defined input vector used produce prediction example consider followingtraintesttraintest train test splity test size random state shuffle false current input pattern currenttrain vector associatedtrain termedtrue loss function designing custom loss function intend optimize minimize value requires access current input pattern just current predictiontaken lookalso looked cost function isnjustpredtrue also familiar previous examples produce customized loss function presumablytruepred defined elsewheretaken look source code without successwondering whether need define current input pattern whether already accessible loss function can wrap loss function inner function pass input tensor commonly done passing additional arguments loss function can verify input tensor loss value mostly input tensor part will change differentpassed model can use add loss pass external layers loss case input tensor example use model inference mode removing target inputs actually contradiction facts possible answers question conventional answer splitting can information leakage done test set contradicting answer training set chosen whole dataset used feature selection feature selection feature importance score orders likely dynamically changed change random state train test split feature selection particular work changes generalization feature importance can done desirable secondly training set used feature selection test set may contain certain set instances defies contradicts feature selection done training set overall historical data analyzed moreover feature importance scores can evaluated given set instances rather single test unknown instance actually difficult demonstrate using whole dataset selecting features can lead astray one demonstration using random dummy data python scikit learn since datarandom ones samples features labelsbinary expect never able exceed baseline accuracy setting around letsee happens apply wrong procedure using whole dataset feature selection splitting wow get test accuracy binary problem according basic laws statistics getting something close someone call nobel prize committee mistakenly think test data unseen fact test data already seen model building process feature selection particular badly can reality difficult see suppose finished model deployed expecting something similar accuracy practice new unseen data get really new data course qualitative change generated will model perform faced really unseen data difficult checktrue sent model battle thinking capable accuracy reality performs just random letsee now correct procedure select features based training set test accuracyclose enough theoretically predicted one case kudos jacob schreiber providing simple idea check thread contains useful examples although slightly different context one ask cross validation conventional answer correct arguments contradicting answer actually hold doubts useful imagine simply access test set model fitting process includes feature importance treat test set literally unseen data since unseen used feature importance scores hastie tibshirani clearly argued long ago correct wrong way perform processes summarized issue blog post perform feature selection although discussion cross validation can easily seen arguments hold case train test split argument actually holds contradicting answer overall historical data analyzed nevertheless necessary price pay order independent test set performance assessment otherwise logic use test set training shouldnwrap test set solely performance assessment model used stage model building including feature selection update comments trends test set may different standard often implicit assumption training test sets qualitatively similar exactly due assumption feeljust use simple random splits get reasons believe data change significant ways train test model deployment whole rationale breaks completely different approaches required also can high probability fitting certain way overfitting use test set way pipeline including feature selection suggest arguably linked blog post enough arguments including quotes links convincing classic example testimony dangers overfitting drop spots minute competition went began use much feature selection preprocessing however made classic mistake cross validation method including cross validation folds mistake see short description section elements statistical learning lead increasingly optimistic cross validation estimates already said although discussion cross validation difficult convince perfectly applies train test case feature selection done way model performance enhanced nobody can argue course catch exact performance talking kaggler quoted indeed getting better performance going along applying mistaken procedure model faced real unseen data moment truth unsurprisingly flopped admittedly trivial stuff may take time internalizecoincidence hastie tibshirani demonstrate even research papers procedure performed wrongly advice keep safe stages model building including feature selection pretend donaccess test set becomes available need assess performance final model need somehow descriptive example showing fold svm classification two class set data just one example matlab documentation fold can someone helpcomplete example using following functions bioinformatics toolbox svmtrain svmclassify classperf crossvalind output obtained accuracy one setosa instance mis classified non setosa update svm functions moved statistics toolboxai trying approximate sine function using neural network wrote tested neural network simple ocr problem already worked trouble applying approximate sine problem training error converges exactlyguessingcompletely random using one input neuron inputone output neuron result single hidden layer can vary number neuronscurrently trying around feeling problem using sigmoid transfer function requirement application outputs output sine try correct tried multiplying output subtracting didnfix problemthinking kind conversion somewhere make work ideas use linear output unit simple example usingtrain network normalize target sin function range can keep sigmoid transfer function note mapped target training train simulate network can map back output net following matlab code illustrate reason network shouldnwork although definitely low side approximating sine wavetry least maybe even doesnwork think need give detail system back propagation learning rate etc get behavior use vanilla gradient descent try using different training algorithm far java applet concerned notice something interesting converge use bipolar sigmoid start non random weights results previous training using quadratic function getting error try use confusion matrix first deep learning project new using mnist dataset provided keras trained tested model successfully however try use scikit learn confusion matrix get error stated searched answer answers error none worked found online probably something loss function use categorical crossentropy code tried changing sparse categorical crossentropy just gave run fit function model code left imports sake brevity can fix confusion matrix needs labels predictions single digits one hot encoded vectors although done predictions using convert single digit ones follows confusion matrix comeproblem repeated solution overallquestion closed unable receive answer like add answer question hopeillegal code self explanatory desertnaut gave exact reasons need explain stuff author question tried pass predicted features separately fit functions believe can give better understanding newcomer extract features pre trained weights transfer learning reshape training process model sequential api compile run evaluate two numpy arrays light points time points like use time series analysis methods data tried works correct thing indeed measurements evenly time spaced just declare time points pandas dataframe index frame get error donknow correct also seems pandas timeseries deprecated tried gives length mismatch nevertheless donunderstand comes rdf light tdf time tried defining rdf pandas series get tried instead replacing index gives error seasonal decompose method line can work unevenly spaced data thinking creating approximately evenly spaced time array adding many unknown values existing values using interpolation evaluate points think cleaner easier solution seasonal decompose requires freq either provided part datetimeindex meta information can inferred monthly docstring seasonal mean illustrate using random sample data far good now randomly dropping elements datetimeindex create unevenly space data running seasonal decomp data works question useful result even without gaps data complicate inference seasonal patterns see example use interpolate release notes statsmodels qualifies procedure followsworking libsvm must implement classification multiclasses one versus can libsvm version use think question clear libsvm donuse automatically one versus will use one svm every class else can defined parameters svmtrain function read readme libsvm according official libsvm documentation section libsvm implements one one approach multi class classificationnumber classesk classifiers constructed one trains data two classes classification use voting strategy binary classification considered voting votes can cast data pointsend point designated class maximum number votes one approach build many binary classifiers classes trained separate one class rest predict new instance choose classifier largest decision function value mentioned idea trainsvm models one separating one class rest binary classifiers use probability outputsoption predict new instances picking class highest probability consider following example implementation one approach multi class svm give example classification classes using support vector machines svm matlab something like svms originally designed binary classification extended handle multi class problems idea decompose problem many binary class problems combine obtain prediction one approach called one builds many binary classifiers classes trained separate one class rest predict new instance choose classifier largest decision function value another approach called one one believe used libsvm buildsk binary classifiers trained separate pair classes uses majority voting scheme max win strategy determine output prediction also approaches using error correcting output code ecoc build many somewhat redundant binary classifiers use redundancy obtain robust classifications uses idea hamming codes example one one sample output matlab support multiclass svm moment use svmtrain classes achieve much easier use standard svm package used libsvm can confirmeasy usenew world tensorflowworking simple example mnist dataset classification like know can obtain metricsg precision recall etc addition accuracy loss possibly showcode since get accuracy loss can get metrics thank advancesorry simple question already answered somewhere adding another answer cleanest way order compute metrics correctly test setmarch first thing need create custom callback send test data starting tensorflowprecision recall available built metrics therefore need implement hand addition removed kerasversions misleading computed batch wise manner global true values precision recall actually different can look ensures correct calculation metrics list available metrics keras documentation includes recall precision etc instance recall get timbus answer work found interesting explanation says meaning accuracy depends loss function one corresponds sparse categorical crossentropy makes lot sense metrics can use depend loss chose truepositives wonwork case sparsecategoricalaccuracy loss meansworking class turn means true positives defined used binary classification problems loss like will work designed multiple classes mind example case answers gave shape mismatches list supported metrics seedocumentedstill new matlabjust trying break function explanation syntax general idea standardizing greatly help use function standardize set training data provided large matrix break lines code snippet help greatly thank much code accepts data matrix sizexm dimensionality one data sample matrixtotal number samples therefore one column matrix one data sample data samples stacked horizontally columns now true purpose code take columns matrix standardize normalize data data sample exhibits zero mean unit variance means transform found mean value column matrix variance standard method normalizing values statistical analysis machine learning computer vision actually comesscore statistical analysis specifically equation normalization given set data points subtract value question mean data points divide respective standard deviationcall code following given matrix will calltwo ways can call code first method automatically infers mean columnstandard deviation columnmeanstdwill returnn vectors give mean standard deviation column matrixsecond method allows manually specify meanstandard deviation sigma columnpossibly use debugging specifysigman vectors case returned meanstdidenticalsigma code bit poorly written imho can certainly achieve vectorized gist code finds mean every column matrixusing method duplicates vector becomesxmatrix subtract matrixwill subtract column respective mean also compute standard deviation column mean subtraction normalizedividing column respective standard deviation btw stdsuperfluous stdalreadyn vector stdmeans grab rows ith column alreadyn vector can simply replaced stdbit overkill taste method performs thing method provide mean standard deviation columnsake documentation commented code can suggest another way write code use mighty powerful bsxfun function avoids duplication elements can hood rewrite function looks like argue new code much faster using repmat fact known bsxfun faster former approach especially larger wondering someone explain simple step step process english understand takes comparisons times occurred probability idea training data related actual dataset please give explanation role training set plays giving simple example fruits like banana example accepted answer many elementsnnnearest neighbors different algorithmnn naivebayes classification algorithms conceptuallynn uses idea nearness classify new entitiesnn nearness modeled ideas euclidean distance cosine distance contrast naivebayes concept probability used classify new entities since question naive bayesd describe ideas steps someonetry equations plain english much possible someone can understand appreciate nuances naive bayes need know couple related concepts first namely idea conditional probability bayes rule familiar concepts skip section titled getting naive bayes conditional probability plain english probability something will happen given something else already happened letsay outcomeevidenceway probabilities defined probability outcomeevidenceprobabilityoccurring multiplied probgivenhappened one example understand conditional probability let say collectionsenators senators democrats republicans also either male female select one senator completely randomly probability person female democrat conditional probability can helpanswer probability democrat female senator prob senator democrat multiplied conditional probability female given democrat compute exact thing reverse way conceptually wayp evidence known outcomeoutcome known evidence often know frequently particular evidence observed given known outcome use known fact compute reverse compute chance outcome happening given evidenceoutcome given know evidenceevidence given know outcome times prob outcome scaledevidence classic example understand bayes rule now just preamble get naive bayes far talked one piece evidence reality predict outcome given multiple evidence case math gets complicated get around complication one approach uncouple multiple pieces evidence treat piece evidence independent approach called naive bayes many people choose remember notice things equation just run formula possible outcome since trying classify outcome called class class label job look evidence consider likely class class assign label entity take simple approach class highest probability declared winner class label gets assigned combination evidences lettry example increase understandingasked fruit identification example letsay data pieces fruit happen banana orange fruit know characteristics fruit training set will use predict type new fruit encounter can pre compute lot things fruit collection called prior probabilities didnknow fruit attributes guess base rates probability evidence probability likelihood letsay given properties unknown fruit asked classify told fruit long sweet yellow banana orange fruit can simply run numbers outcomes one one choose highest probability classify unknown fruit belonging class highest probability based prior evidence fruit training set overwhelming margin classify sweet long yellow fruit likely banana look eventually comes just counting multiplication can pre compute terms classifying becomes easy quick efficient letp evidence now quickly compute following three quantities assign class label whichever highest number done despite name naive bayes turns excellent certain applications text classification one area really shines question understand divided two parts part one need better understanding naive bayes classifier part two confusion surrounding training set general machine learning algorithms need trained supervised learning tasks like classification prediction etc unsupervised learning tasks like clustering training step algorithms taught particular input dataset training set later may test unknown inputs never seen may classify predict etc case supervised learning based learning machine learning techniques like neural networks svm bayesian etc based upon general machine learning project basically divide input set development set training set dev test set test set evaluation set remember basic objective system learns classifies new inputs never seen either dev set test set test set typically format training set however important test set distinct training corpus simply reused training set test set model simply memorized input without learning generalize new examples receive misleadingly high scores general example data can used training set cases also remember partition original set training test sets randomly now come question naive bayes demonstrate conceptve bayes classification consider example given indicated objects can classified either green red task classify new cases arrive decide class label belong based currently existing objects since twice many green objects red reasonable believe new case hasnobserved yet twice likely membership green rather red bayesian analysis belief known prior probability prior probabilities based previous experience case percentage green red objects often used predict outcomes actually happen thus can write prior probability green number green objects total number objects prior probability red number red objects total number objects since total objects green red prior probabilities class membership prior probability green prior probability red formulated prior probability now ready classify new object white circle diagram since objects clustered reasonable assume green red objects vicinitylikely new cases belong particular color measure likelihood draw circle aroundencompasses number chosen priori points irrespective class labels calculate number points circle belonging class label calculate likelihood illustration clear likelihoodgiven green smaller likelihoodgiven red since circle encompasses green object red ones thus although prior probabilities indicatemay belong green given twice many green compared red likelihood indicates otherwise class membershipred given red objects vicinitygreen bayesian analysis final classification produced combining sources information prior likelihood form posterior probability using called bayes rule named rev thomas bayes finally classifyred since class membership achieves largest posterior probability naive bayes comes supervising machine learning used make classifications data sets used predict things based prior knowledge independence assumptions call naiveassumptions assumes features dataset equally important independent really optimistic rarely true real world applications classification algorithm makes decision unknown data set based bayes theorem describe probability event based prior knowledge diagram shows naive bayes works formula predictuse naive bayes algorithm lettake exampleb woks step first find likelihood table shows probability yes diagram step find posterior probability class reference refer blog refer github repository naive bayes examples ram narasimhan explained concept nicely alternative explanation code example naive bayes action uses example problem book page data set will using dataset give hypothesis age income medium student yes creadit rating fair probability will buy will buy computer code exactly answers question just create file called named new python output try explain bayes rule example chance random person selected society smoker may reply letassumeright now say random person man years old may say fact try update initial guess new pieces evidencesmokerp smoker evidence bayes rule way relate two probabilities evidence may increase decrease chance example fact man may increase chance provided percentage man among non smokers lower words man must indicator smoker rather non smoker therefore evidence indicator something increases chance know indicator feature can compare commonness probability feature given conditions commonness alonefvsf example know smokers menstill enough say whether man indicator smoker example probability man society also knowing someone man doesnhelpmen contribute society smokers knowing someone man increases chance smoker increases initial guess resulting however probability man society regardless fact percentage men among smokers high evidence someone man decreases chance smoker note formula assumed man independent features multiplied means knowing someone effect guessing man woman may true example maybe adolescence society man must decide smoker two classes uses formula calculate probability class evidence features assigns class highest probability input provide required probabilities uses training set example counts people training set smokers find contribute sample smokers checks many men women tries build probability distribution features class based trainingreading things neural networks understand general principle single layer neural network understand need aditional layers nonlinear activation functions used question followed one derivative activation function used backpropagation purpose activation function introduce non linearity network turn allows model response variable aka target variable class label score varies non linearly explanatory variables non linear means output reproduced linear combination inputs output renders straight line word affine another way think without non linear activation function networkmatter many layers behave just like single layer perceptron summing layers give just another linear function see definition just common activation function used backprop hyperbolic tangent evaluated linear activation function can used however limited occasions fact understand activation functions better important look ordinary least square simply linear regression linear regression aims finding optimal weights result minimal vertical effect explanatory target variables combined input short expected output reflects linear regression shown linear activation functions can used top figure second figure linear function will produce desired results middle figure however non linear function shown produce desired results activation functions linear neural networks linear activation function effective one layer deep regardless complex architecture input networks usually linear transformation input weight real world problems non linear make incoming data nonlinear use nonlinear mapping called activation function activation function decision making function determines presence particular neural feature mapped zero means absence feature one means presence unfortunately small changes occurring weights reflected activation values can take either therefore nonlinear functions must continuous differentiable range neural network must able take input infinity infinite able map output ranges cases thus need activation function non linearity needed activation functions aim neural network produce nonlinear decision boundary via non linear combinations weight inputs allow linear activation functions neural network output will just linear transformation input enough form universal function approximator network can just represented matrix multiplication able obtain interesting behaviors network thing goes case neurons affine activation functionsxc constants generalization linear activation functions will just result affine transformation input output exciting either neural network may contain neurons linear activation functions output layer require company neurons non linear activation function parts network note interesting exception deepmindsynthetic gradients use small neural network predict gradient backpropagation pass given activation values find can get away using neural network hidden layers linear activations feed forward neural network linear activation number hidden layers equivalent just linear neural neural network hidden layer example consider neural network figure two hidden layers activation can last step combination several linear transformation can replaced one transformation combination several bias term just single bias outcome even add linear activation replace neural net single layer neuralincrease approximation power linear neural net need non linear activation functions approximate non linear functions real world problems highly complex non linear fact activation function non linear two layer neural network sufficiently large number hidden units can proven universal function approximator several good answers will good point book pattern recognition machine learning christopherbishop book worth referring getting deeper insight severalrelated concepts excerpt page section activation functions hidden units network taken linear network can always find equivalent network without hidden units follows fact composition successive linear transformations linear transformation however number hidden units smaller either number input output units transformations network can generate general possible linear transformations inputs outputs information lost dimensionality reduction hidden units section show networks linear units give rise principal component analysis general however little interest multilayer networks linear units present paper makes use stone weierstrass theorem cosine squasher gallant white establish standard multilayer feedforward network architectures using abritrary squashing functions can approximate virtually function interest desired degree accuracy provided sufficently many hidden units available hornikal neural networks squashing function example nonlinear activation function maps like sigmoid activation function times purely linear network can give useful results say network three layers shapes limiting middle layer two dimensions get result plane best fit original three dimensional space easier ways find linear transformations form nmf pca etc however case multi layered network behave way single layer perceptron neural networks used pattern recognition pattern finding non linear technique suppose sake argument use linear activation functionwxevery single neuron set something likeclass else class now can compute loss using square error loss back propagate model learns correct wrong last hidden layer updated value willll alphasecond last hidden layer updated value willll alphalith last hidden layer updated value willw alphalx resultsmultiplying weight matrices together hence resulting possibilitiesbarely changes due vanishing gradientw changes dramatically inaccurately due exploding gradientw changes enough givegood fit score casehappens means classification prediction problem probably simple linear logistic regressor based one never required neural network first place matter robust hyper tuneduse linear activation function will never able tackle non linear requiring pattern recognition problems remember sigmoid functions used derivative fitsalgorithm easy calculate something simple likexx donremember exactly math actually function derivatives can used understand logic behind non linear activation functions first understand activation functions used general real world problems requires non linear solutions trivial need functions generate non linearity basically activation function generate non linearity mapping input values desired range however linear activation functions used limited set cases need hidden layers linear regression usually pointless generate neural network kind problems independent number hidden layers network will generate linear combination inputs can done just one step words behaves like single layer also desirable properties activation functions continuous differentiability since using backpropagation function generate must differentiable point strongly advise check wikipedia page activation functions better understanding topic important use nonlinear activation function neural networks especially deep nns backpropagation according question posed topic first will say reason need use nonlinear activation function backpropagation simply put linear activation function used derivative cost function constant respect input value input neurons affect updating weights means can figure weights effective creating good result therefore forced change weights equally deeper general weights updated follows means new weight equal old weight minus derivative cost function activation function linear function derivative input values direct effect weight update example intend update weights last layer neurons using backpropagation need calculate gradient weight functiony estimated neuron output actual output value respectivelyinput neurons gradderived input factor subtracted current weight new weight obtained can now compare two types activation functions clearly activating function linear functionxnew weight will can see weights updated equally matter input value use non linear activation function like tanhnow can see direct effect input updating weights different input value makes different weights changes think enough answer question topic useful mention benefits using non linear activation function mentioned answers non linearity enables nns hidden layers deeper nns sequence layers linear activator function can merged layer combination previous functions practically neural network hidden layer take advantage benefits deepnon linear activation function can also produce normalized output layeredseveral neurons can used learn linearly inseparable problems example xor function can obtained two layers step activation functionrequirement fact rectified linear activation function useful large neural networks computing gradient much faster induces sparsity setting minimum bound see following details discussion whether rectified linear activation function can called linear function yes technically nonlinear function linear pointhowever still correct say linear points donthinkuseful nitpick chosen identity function still true chose relu example recent popularity canfigure pipeline transforms final estimator make question clearer steps work edit thanks answers can make question clearer call pipeline pass steps two transformers one estimatorg happens call canfigure estimator can transformer transformer can fitted transformer scikit learn class fit transform method fit transform method predictor class fit predict methods fit predict method pipeline just abstract notionexistingalgorithm oftentasks need perform sequence different transformations find set features generate new features select good features raw dataset applying final estimator good example pipeline usage pipeline gives single interface steps transformation resulting estimator encapsulates transformers predictors inside now can something like just pipelines can easily perform grid search set parameters step meta estimator described link steps except last one must transforms last step can transformer predictor answer edit call transformer inside pipeline will fitted outputs previous transformer first transformer learned raw dataset last estimator may transformer predictor can call fit transform pipeline last estimator transformer implements fit transform transform fit methods separately can call fit predict predict pipeline last estimator predictor just cancall fit transform transform pipeline last step predictor thinkrkhav right idea scikit learnpipeline class useful tool encapsulating multiple different transformers alongside estimator one object call important methods fit predict etc letbreak two major components transformers classes implement fit transform might familiar sklearn preprocessing tools like tfidfvectorizer binarizer look docs preprocessing toolssee implement methods find pretty cool estimators can also used transformation steps estimators classes implement fit predictfind many classifiers regression models implement methods can readily test many different models possible use another transformer final estimator doesnnecessarily implement predict definitely implements fit means wouldnable call predict edit letgo text based example using labelbinarizer want turn list labels list binary values now binarizer fitted data will structure called classes contains unique classes transformer knows without calling fit binarizer idea data looks like calling transform wouldnmake sense true print list classes trying fit data get following error trying fit binarizer vec list try get following now calling transform vec object get following estimators used transformers letuse decisiontree classifier example feature extractor decision trees great lot reasons purposesimportant ability rank features tree found useful predicting call transform decision tree will take input data find thinks important features can think transforming data matrixrowscolumns smaller matrixrowscolumnscolumnsimportant features decision tree foundalgorithms typically process tabular data may want preprocessing post processing dataalgorithm pipeline way chain data processing steps pipeline series steps data transformed comes old pipe filter design pattern instance think unix bash commands pipes redirect operators however pipelines objects code thus may class filter another class combine steps final pipeline pipelines may combine pipelines series parallel multiple inputs outputs like view pipelining machine learning pipelines steps pipeline must two methodsalso possible call method chain scikit learnpipe filter design pattern simply beautiful use deep learning automl complex production level pipelines scikit learn first release pre deep learning era howeverone known adopted machine learning library still growing top uses pipe filter design pattern software architectural stylemakes scikit learn fabulous added fact provides algorithms ready use however massive issues comes following able already sure scikit learn convenient built however needs refresh solutions neuraxle make scikit learn fresh useable within modern computing projects note step pipeline doesnneed one fit transform methods inherit nonfittablemixin nontransformablemixin provided default implementation one methods nothing starter possible pipelines steps also optionally define methods following methods provided default allow managing hyperparameters info suggested solutions read entries big list links dataset large json file read store trainlist variable next pre process order able work done start classification finally use put html order show chart tps label code variables moment part method multi class case everything need can found confusion matrix example confusion matrix looks likelooking per class can found like using pandas numpy can classes like two lists predicted actual values appears can pass function will calculatefpfn something like think will able calculate rates interest performance measure like specificity sensitivity according scikit learn documentationequal number observations known group predicted groupthus binary classification count true negativesfalse negativestrue positivesfalse positivescan obtain parameters confusion matrix structure confusion matrixmatrix follows assuming first index related positive label rows related true labels details one set labels parameter case data contains single case metrics library confusion matrix method gives desired output can use classifier want used kneighbors example docs hope helps just case looking multi class example can try output scikit version can like works fine source might want use pandaspart confusion matrix pandasgive detailed information check think answers fully correct example suppose following arraysactualpredic computefntn values manually followsfntn however use first answer results given followsfntn correct first answer false positive actual predicted opposite also false negative use second answer results computed followsfntn true positive true negative numbers correct opposite correct computations please let know missing something falsenegatives none answers given far worked sometimes ended confusion matrix single entry following code able mitigate issue please notegroundtruthhat prediction although relate scikit learn also tried answers found working worksfix invoketheshellbuggy code currently appears accepted answer openaireinforce actor critic example reinforcement learning following code reinforce actor critic one using uses similar use cases far understanding goes doc doesngive clear distinction happy know differences functions stack concatenates sequence tensors along new dimension cat concatenates given sequence seq tensors given dimensionshape functions analogous output reference definitions cat concatenates given sequence seq tensors given dimension consequence specific dimension changes size adding elements row increases dimensionality column space stack concatenates sequence tensors along new dimension like think torch append operation since can index get original tensor poping front arguments appends tensors front tensor related unit tests didnwrite tests worked real code trustfine feel free help adding tests want someone looking performance aspectsdone small experiment case needed convert list scalar tensors single tensor conclusion even want additional dimension using post taken pytorch forum author original post assignment makeagent will learn play video game usingwant create new environment using openai gym donwant use existing environment can create new custom environment also way can start develop makingagent play specific video game without help openai gym see banana gym extremely small environment see main page repository look like contents follow link details mentioned especially functions foo definitely possible say documentation page close end look source code existing environments inspiration available github installation environments implement scratch rather created wrapper around existing environments gave interface convenient reinforcement learning want make probablydirection try adapt something already exists gym interface although good chance time consuming another option may interesting purposeopenaiuniverse example universe easy use gym beginner recommendation start vanilla implementation standard environment get passed problems basicsoriginal close reasonresolved calculate output size convolution layer exampleconvolution layer takesx input filters sizecan use formulaks input formula note stride defaults provided number filters provided user can find two ways simple method input size filter size second method standard find output size let start simple since square matrices input filter let get one dimension can apply dimensionimagine building fences treestrees buildfences now apply analogy convolution layers output size will input size filter size filter cansteps fences mentioned letcalculate output idea dimension nowimage one filter apply times will another dimensionx great guide want know advanced convolution arithmeticnpn size output layerx number filters width height depth filters stride padding dataset containing grayscale images want train state art cnnmuch like fine tune pre trained model like ones problem almost models can find weights trained imagenet dataset contains rgb images canuse one models input layer expects batch shape batch size height width case images batches way can use one modelsthought dropping input layerloaded weights adding like top layers approach correct modelarchitecture changed weights trained specific input configuration replacing first layer pretty much render rest weights useless edit elaboration suggested prune cnns builtdeeper can extract high level features derived lower level features previous layers extracted removing initial layers cnn destroying hierarchy features subsequent layers wonreceive features supposed input case second layer trained expect features first layer replacing first layer random weights essentially throwing away training done subsequent layers need retrained doubt retain knowledge learned initial training end edit easy way though can make model work grayscale images just need make image appear rgb easiest way repeat image array times new dimension will image channels performance model rgb images numpy can easily done like way works first creates new dimension place channels repeats existing array times new dimensionalso pretty sure keras imagedatagenerator can load grayscale images rgb converting grayscale images rgb per currently accepted answer one approach problem efficient certainly can modify weights modelfirst convolutional layer achieve stated goal modified model will work box reduced accuracy finetunable modifying weights first layer render rest weights useless suggested othersadd code pretrained weights loaded framework choice need figure grab weights first convolutional layer network modify assigning channel model required modification sum weight tensor dimension input channels way weights tensor organized varies framework framework pytorch default channels channels kernel height kernel width tensorflow believe kernel height kernel width channels channels using pytorch example resnet model torchvision shape weights conv summing dimension results tensor shape bottomincluded snippet code work resnet models torchvision assuming argument inchans added specify different number input channels model prove works three runs imagenet validation resnet pretrained weights slight difference numbers runminimal irrelevant finetuned simple way add convolution layer base model feed output base model like try convert grayscale image fake rgb image dropping input layer will work will cause following layers will suffer can concatenate black white images together expand color dimension faced problem working vgg along gray scale images solved problem like follows letsay training images train gray images row containing unrolled gray scale image intensities directly pass fit function will create error fit function expecting channel rgb image data set instead gray scale data set passing fit function following create dummy rgb image data set just like gray scale data set shape dummy rgb image difference using number channel therefore just copy whole data set times channels dummy rgb images dimensions examples height width channel finally pass dummy rgb images instead gray scale data set like numpydepth stack function img img img natural wayre already using scikit image can get desired result using gray rgb believe can use pretrained resnet channel gray scale images without repeating times image done replace first layer pythorch keras idea might similar following layer copy sum channel axis weights new layer example shape original weights check output new model output gray scale image input image one channel image input image channel image gray scale channels equal model resnet modified model model resnet original resnet modelreally easy example resnet convkernel size stride padding bias false just final step update state dict run follow results convkernel size stride padding bias false see input channel grayscale images just simply expand grayscales rgb images using following transform stage add resnet model input input shape resnet definition like title wondering difference stratifiedkfold parameter shuffle true stratifiedshufflesplit advantage using stratifiedshufflesplit stratkfolds test set overlap even shuffle included stratkfolds shuffle true data shuffled start divided number desired splits test data always one splits train data rest shufflesplit data shuffled every time split means test sets may overlap splits see block example difference note overlap elements test sets shufflesplit output use tend use stratkfolds cross validation use shufflesplit split train test set splitssure use cases ken syme already good answer just want add something shuffle true data shuffled random state otherwise data shuffled default examplesplits data classes labeldependent variable test sets cover data without overlap difference stratifiedkfold just shuffles splits therefore test sets overlap stratifiedshufflesplit shuffles time splitting splitssplits times test sets can overlap output examples kfold stratifiedkfold stratifiedshufflesplit pictorial output extension ken symecodeusing minmaxscaler model sklearn normalize features model now want use scaler normalize test set donwant use training data time way save scaler load later different file updateanswer otherwise identical mine even better pickle creates much larger files method can use sklearnbuilt toolactually expert bit research helpful links think pickle dump models file think link also helpful talks creating persistence model somethinggoing want try can learn sklearn externals let know doesnhelpunderstanding something model note can installed pip install joblib note file extensions can anything onegzxz lzma corresponding compression protocol will used docs methods can use pickle save scaler load back thousand audio files want classify using keras theano far generatedspectrograms bigger probably better just trying get algorithm work point audio file read image matrix end get big image matrix feed network image classification tutorial found mnist classification code code runs get result expected point everything runs perfectly however apply algorithm dataset accuracy gets stuck code follows tried changing network adding epochs always get result matter donunderstand getting result help appreciated thank edit found mistake pixel values read correctly fixed now actually get grayscale pixel values now dividing makes sense however still get result likely reason optimizer suited dataset list keras optimizers documentation recommend first try sgd default parameter values still doesnwork divide learning rate times necessary learning rate reachesstill doesnwork another problem summary replace line change learning rate times doesnwork problem see loss getting lower just epochs another solution see mentioned caused similar problem activiation function last neuron especialy relu something non linear like sigmoid words might help use non linear activation function last layer last layer output now used non linear activation function output directly solution original answer answer google searching problem might benefit someone accuracy changing means optimizer found local minimum loss may undesirable minimum one common local minimum always predict class number data points use weighting classes avoid minimum examination found issue data dirty input different outputs hence creating confusion clearing data now accuracy goes still enough good least can now work way now data clear used code test check one check documentation better results mnist mistake added softmax end instead sigmoid try latter worked expected one output layer softmax always gives values happened faced similar issue one hot encoding target variable using nputils keras solved issue accuracy validation loss stuck using weights balancing target classes improved performance solutionproblem solution loop instead epochs got accuracy increment using sigmoid activation can also test following relu first hidden layer mentioned problem mainly arises type optimizers chosen however can also driven fact topping dense layers activation functions softmax example casefinds local minimum able descent point rolling around acc val acc values hope helps similar problem binary class labeled testing different kinds optimizer activation functions found root problem labeling classes words changed labels instead problem solved faced problem multi class try changing optimizer default adam change sgd can also try different activation functionsrelu sigmoid softmax softplus etc imp links optimizers activations pointed others optimizer probably doesnsuit data model stuck local minima neural network least able overfit data training acc close similar problem solved trying different optimizers case sgd rmsprop case problem binary using softmax activation function doesnwork changed sigmoid works properly exactly problem validation loss accuracy remaining epochs increased batch sizetimes reduced learning ratetimes etc work last try inspired monolingualranjabanswers worked solution add batchnormalization arrange order conv dropout batchnorm activation pool recommended ordering batch normalization dropout know old question today comment thetechguy workscode tried playing lot optimizers activation functions thing worked batchnormalization guess good practice can import simply add hidden layer problem case caused non regularized column data column huge value fixing solved just converted values around problem solution change last layer activation function softmax sigmoid since dealing binary classification problem attempting applymeans set high dimensional data points dimensions wondering implementations find optimal number clusters remember reading somewhere way algorithm generally inter cluster distance maximized intra cluster distance minimized donremember saw great someone can point resources discuss using scipymeans currently related library fine alternate ways achieving better algorithm please let know one approach cross validation essence pick subset data clusterclusters ask clusters compared rest data assigning data points cluster memberships falling different clusters memberships roughly data fitclusters otherwise try differentalso pca principal component analysis reduce dimensions tractable number pca run suggests variance coming say dimensions can pickbasis explore four cluster memberships assigned take look wikipedia page determining number clusters data set also might want try agglomerative hierarchical clustering approach need know number clusters will incrementally form clusters cluster till one exists technique also exists scipy one interesting approach evidence accumulation fred jain based combining multiple runsmeans large number clusters aggregating overall solution nice aspects approach include number clusters determined process final clusters donspherical visualization hint good parametersmeans visualize several runs differentusing graphgrams see weka graphgram package best obtained package manager introduction examples can also found also make sure dimension fact independent many called multi dimensional datasets multiple representations thing wrong data wrong use multiple versions thing support cluster argumentalpha one way runmeans largemuch larger think correct number say running mean shift algorithm point mean shift uses whole data will move points mean shift will find amount clusters running mean shift withoutmeans possibility just slow usuallyn steps runningmeans will speed thingsnk steps cluster number unknow use hierarchical clustering instead begining every isolated one cluster every two cluster will merged distance lower threshold algorithm will end merger goes hierarchical clustering algorithm can carry suitabledata new machine learning deep learning learning purposes tried play resnet tried overfit small data different images see can get almost loss accuracy problem predictions training images correct training images image labels python code model overfit data predictions means images got label can happenbatch normalization layers training phase batch normalized testing phase batch normalized example batchnormalization layer default moving mean initialized moving variance initialized given also default momentumneed update moving averages quite lot times converge real mean varianceprediction wrong early stage correct epochs can verify forcing batchnormalization layers operate training mode training accuracy loss close zero now evaluate modelobserve high loss low accuracy updates moving averages still pretty close initial values however manually specify learning phase variable let batchnormalization layers use real batch mean variance result becomesobserved fitalso possible verify changing momentum smaller value example adding momentum batch norm layers resnet prediction epochs resnetnd version much higher accuracy resnet predicting given image classical egyptian cat predictedegyptian cattiger cattabbyplastic bagn lynxcomparing efficientnet accuracy resnet predicts quite bad result accuracy adopting given weights provided francios cholett related weights related inherent complexity model words necessarytrain model predict given image efficientnet need training predict image instance given classical cat image shows final result follows adoption decode predictions predictednematodecleaveroboeballpointspatula adoptionpredictedrecreational vehiclesulphur crested cockatooremote controlsamoyedwallet therefore resnet models suitable predict image without training even provided weights users can feel value epochs training prediction helps obtain better moving average users want easy prediction efficientnet good choice given weights seems predicting batch images will work correctly keras better prediction image individually calculate accuracy manually example following code donuse batch prediction use individual image prediction happens basicallybest fit precision lost precision lost models fit gives problems varied found term tensor really confusing need clarify following questions tensorflow doesnfirst class tensor objects meaning notion tensor underlying graphexecuted runtime instead graph consistsnodes connected representing operations operation allocates memory outputs available endpoints etc can think endpoints tensor tensor corresponding nodename can fetch value tensor nodename execution granularity happens operation level run method will executewill compute endpoints just endpointpossiblenode outputs like case tensors associated possible tensors without underlyingnode can examine happens underlying graph something like can fetch using const value similarly value creates regular node name placeholder feed feed dict placeholder feed dict value can feed fetch placeholder can see result attachingsee creates two nodes variable variable read endpoint valid value fetch nodes however variable special ref type meaning can used input mutating operations result python callpython magic substitute variable read variable depending whether mutation necessary since ops endpoint dropped another example queue close method will create new closenode connects queuesummarize operations python objects like variable queue map different underlying tensorflownodes depending usage ops like pythontensor typed multi dimensional array examplearray floating point numbers representing mini batch images dimensions batch height width channel basically every data tensor tensorflow hence name however graph every node operation can tensors inputs outputs already mentioned others yes tensors way understood first visualize understandddd tensors picture source knoldus now context tensorflow can imagine computation graph like one ops take two tensorsinput multiplies tensors adds result multiplications produce result tensormultiplications addition ops happen nodes computation graph tensorscan constant tensors variable tensors placeholders doesnmatter long data type compatible shapes broadcastable achieve operations data stored matricespixel grayscale image fitstwo dimensional matrix color image need dimensions color values per pixel red green blue three dimensional table will needed dimensions store batch color images four dimensional table needed dimensions multi dimensional tables called tensors list dimensions shape source tensorflowcentral data type tensor tensors underlying components computation fundamental data structure tensorflow without using complex mathematical interpretations can say tensor tensorflow describes multidimensional numerical array zerodimensional collection data determined rank shape tensors tensorflow thought mask zero true will outputinput value following layers skip computation something mask zero works example actual output numbers random however thought output will actually setting mask zero true embedding layer result returning zero vector rather behavior embedding layer change return embedding vector index zero can confirm checking embedding layer weights get weights instead affect behavior following layers rnn layers inspect source code embedding layer see method called compute mask output mask will passed mask argument following layers support masking implemented call method base layer layer makes following layers ignore inputs steps minimal example can see outputs lstm layer second forth timesteps output first third timesteps respectively means timesteps masked update mask will also considered computing loss since loss functions internally augmented support masking using weighted masked objective compiling model can verify using following example process informing model part data actually padding ignored called masking three ways introduce input masks keras models given code introduce input masks using information refer tensorflowcreating model two inputs model configuration shown labeluses labelingx data following error will continue occur error checking model input list numpy arrays passing model size model expected expected see arrayinstead got following list arrays array try generator generator inputs edit add generator output image numpy array target implementation multiple inputs timeseriesgenerator adapted able test unfortunately meet example imagedatagenerator approach build wrapper class multiple generators len getitem can use generator generator assign weight certain features input classifier like svm something people first probably whole concept machine learning use statistical analysis assign optimal weights interfering whole concept thus need really strong evidence crucial process trying model reason model currently missing said general answer purely model specific will allow weight features random forest bias distribution sample features analyse towards ones interested svm enough just multiply given feature constant remember told normalize features svm can use scale features steer classifier towards given features ones high values will preffered will actually work linear weight norm regularized models regularized logistic regression ridge regression lasso etc best way assumen weight particular featuref first need normalize features feature scaling methods need also normalize weights featuresf range multiply normalized weightn new transformed features remember need transform test data now can check performance models without introducing feature introducing feature already mentioned wouldnsuggest using index weights jobhowever ranking weights opinion will done original data source database table txt etc updating additional field always range certainly always absolute correlation corresponding features parameterstrying run linear regression pyspark want create table containing summary statistics coefficientsvaluesvalues column dataset however order train linear regression model create feature vector using sparkvectorassembler now row single feature vector target column try access sparkbuilt regression summary statistics give raw list numbers statisticsway know attribute corresponds value really difficult figure manually large number columns map values back column names example current output something like coefficientsvaluestatistic coefficient standard errors numbers mean nothing unless know attribute correspond dataframe one column called features contains rows sparse vectors ever bigger problem one hot encoded features one variable encoding lengthwill getcorresponding coefficientsvaluesvalues etc today spark doesnprovide method can create letsay data looks like processed using following pipeline get linearregressionmodel transform data extract flattenattributes map output can see actual order columns will two classes usually binary numeric give exact order columnsone line answer thanks pratiklodha core plot scatterplot matplotlib calculate linear best fit line using ordinary least squares regression follows multivariate manyvalues caselist listssingle list example higher order polynomial functions example just linearpowerbinomialpowerquadraticspowerexample get best fit curves following extracted christopher bishopspattern recognition machine learningaccepted answer question provides small multi poly fit library will exactly need using numpy can plug result plottingoutlined just pass arraysy points degree order fit require multipolyfit returns coefficients can use plotting using numpypolyval note code amended multivariate fitting plot image part earlier non multivariate answer note part answer earlier still relevant donmultivariate data instead coeffs mpf use coeffsy non multivariate data sets easiest way probably numpypolyfity deg rcond none full falsenone cov false least squares polynomial fit fit polynomialxx degdeg degree deg pointsy returns vector coefficientsminimises squared error slightly context resulting function polynomial still interesting perhaps one major problem polynomial fitting rungephenomenon higher degree dramatic oscillations will occur isnjust constructed either will come back bite remedy created smoothfit ago solves appropriate least squares problem gives nice results implementing logistic regression using batch gradient descent two classes input samples classified classes training data using following sigmoid function using following cost function calculate cost determine stop training getting cost step nan values htheta either zero cases determine cost value iteration gradient descent code logistic regression two possible reasons may happening apply sigmoid logit function hypothesis output probabilities almost approximatelys cost function log log will produce inf accumulation individual terms cost function will eventually lead nan specificallytraining example output hypothesis logx small number close examining first part cost function givelogwill fact produce nan similarlytraining example output hypothesis also logx small number givelogwill produce nan simply put output hypothesis either close close likely due fact dynamic range feature widely different part hypothesis specifically weighted sumtheta training example will give either large negative positive values apply sigmoid function valuesget close one way combat normalize data matrix performing training using gradient descent typical approach normalize zero mean unit variance given input featureknfeatures new normalized featurek new can foundk mean featuresstandard deviation featurealso known standardizing data can read details another answer gave code standardizing data work using linear algebra approach gradient descentassuming prepended data matrix column ones knowing can normalize data like mean standard deviations feature storedsx respectively can learn code works reading post linked wonrepeat stuff isnscope post ensure proper normalizationmade mean standard deviation first column respectively xnew contains new normalized data matrix use xnew gradient descent algorithm instead now find parameters perform predictions must normalize new test instances mean standard deviation training set parameters learned respect statistics training set must also apply transformations test data want submit prediction model assuming new data points stored matrix callednormalize perform predictions now can perform predictions can change threshold whatever believe best determines whether examples belong positive negative class mentioned comments normalize data costs appear finite suddenlynan iterations normalization can get far learning rate alpha large iteration will overshoot direction towards minimum thus make cost iteration oscillate even diverge appearing happening case cost diverging increasing iteration point large canrepresented using floating point precision one option decrease learning rate alpha see cost function decreasing iteration popular method determine best learning rate perform gradient descent range logarithmically spaced values alpha seeing final cost function value choosing learning rate resulted smallest cost using two facts together allow gradient descent converge quite nicely assuming cost function convex case logistic regression certainly letassume observation cost function will get value nanadding log undefined hence rayryeng pointed log produces nan inf isnkosher actually huge problem algorithm believes can predict value perfectly incorrectly assigns cost nan instead can avoid multiplying infinity instead writing cost function matlab ideaadd log htheta costadd log htheta cost mathematically equivalentlog hthetalog htheta without running numerical problems essentially stem htheta equal within limits double precision floating point happened indetermination type can happen one predicted valuesequals either case solution add statement python code follows way actual valuepredicted oneequal cost needs computed expected behavior notice givenconverging left addend canceledright addend tends toward happensconverges opposite addend also rare scenario probably wonneed worryy viceversa dataset standarized weights properly initialized wonissue know cross validation used selecting good parameters finding needtrain whole data withoutoption problem face trainoption get cross validation accuracyg model cansee valuesgamma case retrain btw applying fold cross validationg need help get bestgamma use code available libsvm faq another question cross validation accuracy usingoption similar get train withoutoption use model predict two accuracy similar another question cross validation basically improves accuracy model avoiding overfitting needs model place can improve right besides different model cross validation accuracy will different right one question cross validation accuracy valuegamma graph something like valuesgamma retrain model new parameters value reason thanks instead using whole data training performfold cross validation trainingfolds testing remaining fold one time report average accuracy thus returns cross validation accuracy assuming classification problem otherwise mean squared error regression scalar number instead actual svm model want perform model selection implement grid search using cross validation similar find best valuesgamma shouldnhard implement create grid values using meshgrid iterate overall pairsgamma training svm model say fold cross validation choosing values best use entire dataset determine parameters train dataset going overfit data ideally divide dataset parameter search portionuse portion train testwill get better results use whole dataset course model likely generalize want determine true performance model need parameter selection trying first load pre trained weights remove one three models internal non last layers replace another layer canseem find documentation examplelike take two conv layers block replace just one conv layer loading original weights layers ideas assuming model vgg model initialized either function weights imagenet now need insert new layer middle way weights layers will saved idea disassemble whole network separate layers assemble back code specifically task output code another way building sequential model see following example swap relu layers prelu need simply add layers donwant add new layer written rnn language model using tensorflow model implemented rnn class graph structure built constructor want run validation set training managing state inside training loop passing graph via feed dictionary constructor define rnn like training loop looks likey batches training data document idea pass latest state along batch except start new document zero state running true however donknow pass complicated lstm state object via feed dictionary also donknow arguments pass line constructor correct strategy still isnmuch example code documentation dynamic rnn available tensorflow issues appear relevant blog post wildml addresses issues doesndirectly spell answer see also tensorflow remember lstm state next batch stateful lstm one problem tensorflow placeholder can feed python list numpy array think cansave state runs tuples lstmstatetuple solved saving state tensor like initial state num layers batch size state size two components lstm layer cell state hidden state comes article great building graph unpack create tuple state like get new state usual way shouldnlike models apply particular domain models trained separately different datasets inference sequential tried parallelize call models thanks multiprocess library python unstable advisedidea got make sure models share common pretrained model want make single model multiple inputs multiple outputs following drawing shows like inference will call single model will operations time saw functional api keras possible idea inputs datasets dimension pictures anyone example multi input multi output model shares common structureok example code returns error layers concatenate line propagates shape taken account efficientnet model can easilykeras using awesome functional api will walk build multi different type classification regression using functional api according last diagram need one input model three outputs different types demonstrate will use mnist handwritten datasetnormally class classification problem data set will create additionally class classifier whether digit even odd also regression part predict square digitimage input give approximatelysquare data set training pairs will xtrainyylast diagram model building letbuild model accordingly using functional apikeras see model definition mnist samplesgrayscale image input set wayguessing data set probably rgb change input dimension accordingly one thing note definingc model definition set name variable important names set cls clsrespectively can also see diagram last tails compile run now can see name variable important order run model need compile first proper loss function metrics optimizer now know classification regression problem optimizer can loss function metrics changed model multi type output model classifications regression need set proper loss metrics types please seedone see last output model represented name variables set proper compilation hope understand part now time train modeloutputs last layer optimizes concern loss function fyi one thing mention essential parameter compile model might need loss weights weight loss contributions different model outputs see answer prediction inference letsee output now hope model will predict things digit even odd square value like quickly check output layers model passing xtrain know model predictions based comment can extend model take multi input need change things demonstrate will use train test samples mnist data set model multi input next need modify parts model take multi input next now plot will see new graph now can train model follows now can test multi input model get multi want select topprincipal components matrix pca completed matlab return pxp matrix doesncoefsscoresuse code gives memory error donunderstand matlab returns lesser dimensional matrix return error pca byteserror eigs think falling preyproblem since trying find dimensions data completely non physical please ask problemproposed solutionorder get meaningful answer will use post tell pca good fit case tell will solve problem since toldmathematically unsound problem will try explain pca user said way reduce dimensions means somewhere problem one hundred fifty three thousand six hundred dimensions floating aroundlot heck lot explaining physical reason existence might bigger problem trying solve mathematical problem trying fit many dimensions observations will work since even observations linear independent vectors feature space can still extract dimensions since rest simply found since observations can fitunique dimensionspoints dimensions infinite number possibilities location like trying fit plane two pointsline can fit third dimension will perpendicular line undefined rotational direction hence left infinite number possible planes fit two points first componentsdimensions left fitting void used data get dimensions create dimensions impossible can get observationspca need observations dimensions might ask easy fit unique line point unique plane two points unique dimensional hyperplane points sadly two points fit line get fit error jay done day letgo home watchsadly boss will call next morning since fit rubbishinstance points scattered around fit without errors least closer representing actual data since first two outliers see illustrative figure red points first two observations extract first componentsexact fits zero dimensions might even attempt calculate beyonddimension stick zero array entriesdr use pca help solve problem long tellproblem pca dimension reduction algorithm tries reduce number features principal componentsrepresents linear combination total features done order reduce dimensions feature space trying explain variance across observations using features however donneed much informations will explain variance across sample will surprised case reason basicly overfitting algorithm finds noise explain every observation sample rayryeng telling correct want reduce feature spaces will need observationss mean anything rule thumb rather stable one reason matlab givings able correctly extract linear combinations explained variance across sample hand relevant features looking dimensional reduction flows rather feature elimination processes will keep relevant feature nulling irrelevant ones just make clear feature space rubbish isninformation just noise variance explained will irrelevant will indeed less example see following want reduce feature space ways even smallpca one good luck matlab tries waste much resources computing still can want just use convert image data caffeformat leveldb lmdb usingexample use code imagenet data need shuffled can writepositives negatives like data need shuffled labels look like caffe sample datatrue use random subset data size batch size shuffle samples think learning process donshuffle caffe sees samples expect algorithm deduce simply predict time everything cool plenty hit first caffe will confident predicting always will difficult move model point hand constantly sees mix learns beginning meaningful features separating examples bottom line advantageous shuffle training samples especially using sgd based approaches afaik caffe randomly sample batch size samples rather goes sequentially inputbatch size batch size samplesdr shuffle new matplotlib working simple projects get acquainted wondering might plot decision boundary weight vector formw basically separates two classes sayc using matplotlib simple plotting line pointw sinceweight vector extend like directions need right now thanks advance decision boundary generally much complex just linedimensional case better use code generic case will also work linear classifiers simplest idea plot contour plot decision function examples sklearn documentationi trying convert model tensorflowformat kerasformat view post hoc attention visualisation tried code can anyone help even possible latest tensorflow version save model using model will saved justfile will saved folder comprises variables folder assets folder addition saved shown screenshot example model saved name model load using name folder model instead saved shown instead one change can replace complete working code convert model tensorflow saved model formatkeras saved model formatshown output new continuing code output command print loaded model shown can seen summary models modelstrying image classification two classes images balanced classes train model get low constant validation accuracy decreasing validation loss sign overfitting underfitting also noteattempting retrain inceptionmodel new classes different dataset overfitting underfitting occurs model specific specific enough training data doesnextrapolate true domainjust say overfitting now save poor typing fingers think wikipedia image good clearly green line decision boundary trying separate red class blue overfit although will training data lacks regularized form like see generalizing cmu slides overfitting cross validation also make problem clearintuition good measure overfitting observed numerically testing error reflect training error obviously testing error will always expectation worse training error certain number iterations loss testing will start increase even loss training continues decline overfitting can observed plotting decision boundary wikipedia image dimensionality allows looking testing loss addition training loss fit procedure dongiveenough points make graphsexample someone asking similar question showing loss graphs look like loss curves sometimes pretty logarthmic note trend training error still decreasing testing error risebig red flag overfitting discusses loss curves slightly cleaner real life example cmu lecture ovefitting anntop graph overfitting bottom graph occur model many parameters susceptible overfitting likedegree polynomialpoints likewise model enough parameters can underfit certain regularization techniques like dropout batch normalization traditionallyregularization combat believe beyond scope question footnotesreason keep writing overfitting underfitting since reasoning indicators flipped obviously decision boundary hasnlatched onto true border enough opposed tightly wrapped individual points general overfitting common avoid since iterations parameters current theme lots data lot parameters maybe really worried underfitting doubt one way formalize idea black line preferable green one first image wikipedia penalize number parameters required model model selectioniusing pydantic model basemodel fastapi converting input dictionary converting pandas dataframe assign function machine learning prediction shown works finejust quite sureoptimized right way since convert input two times get predictions alsosure going work fast case huge number inputs improvementsway even using pydantic models can work directly avoid going conversions loop first use descriptive names variables objects example pass pydantic model directly predict function accepts data array pydantic model available options listed use donwish use pandas dataframe shown question use dict method get values attributes model convert list preferably use pydanticdict method avoid looping individual items calling predict function multiple times using instead case donwish using pandas dataframe code know error occurring transform feature list mismatch fit transform can solve can get rest features want use partial fit sgd classifier instead using need labelencoder onehotencoder can store original values use new data changing code like will give required results encoder fitted refreshedcontains columns refreshedcontains literally reported error either delete columns appearing refreshedjust fit encoder new version refreshedcontains columns appearing refreshednumpy array like transform like reduce memory demand resulting however get ideas ultimately numpy array contains labels binary classification problem far used float keras ann worked fine achieved pretty good performance actually necessary run categorical donneed use categorical since guess multi label classification avoid confusion let explain binary classification meaning sample may belong one two classes multi class classification meaning sample may belong one many classes multi label classification meaning sample may belong zero one one classes ignoring fact application categorical pointless scenario following solves memory issue question appear programming within scope defined help center closed years ago predict value categorical discrete outcome use logistic regression believe use linear regression also predict value outcome given input values difference two methodologies linear regression output probabilitiestempting use linear regression output probabilitiesmistake output can negative greater whereas probability can regression might actually produce probabilities less even bigger logistic regression introduced source outcome dependent variable continuous can one infinite number possible values logistic regression outcome dependent variable limited number possible values dependent variable logistic regression used response variable categorical nature instance yes true false red green bluendth etc linear regression used response variable continuous instance weight height number hours etc equation linear regression gives equation formmxmeans equation degree however logistic regression gives equation formexx coefficient interpretation linear regression coefficient interpretation independent variables quite straightforward unit increase variable dependent variable expected increase decrease xxx however logistic regression depends family binomial poisson etc link log logit inverse log etc use interpretation different error minimization technique linear regression uses ordinary least squares method minimise errors arrive best possible fit logistic regression uses maximum likelihood method arrive solution linear regression usually solved minimizing least squares error model data therefore large errors penalized quadratically logistic regression just opposite using logistic loss function causes large errors penalized asymptotically constant consider linear regression categorical outcomes see problem model predicts outcome truthlost nothing linear regression try reduce logistic wouldnmuch linear regression outcome dependent variable continuous can one infinite number possible values logistic regression outcome dependent variable limited number possible values instancecontains area square feet housescontains corresponding sale price houses use linear regression predict selling price function house size possible selling price may actually many possible values linear regression model chosen instead wanted predict based size whether house selluse logistic regression possible outputs either yes house will sellhouse will just add previous answers linear regression meant resolve problem predicting estimating output value given elementsayx result prediction continuous function values may positive negative case normally input dataset lots examples output value one goal able fit model data set able predict output new different never seen elements following classical example fitting line set points general linear regression used fit complex models using higher polynomial degrees resolving problem linear regression can solved two different ways logistic regression meant resolve classification problems given element classifycategories typical examples example given mail classify spam given vehicle find category belongs car truck van etcbasically output finite set discrete values resolving problem logistic regression problems resolved using gradient descent formulation general similar linear regression difference usage different hypothesis function linear regression hypothesis form theta model trying fitx input vector logistic regression hypothesis function different function nice property basically maps value range appropiate handle propababilities classificatin example case binary classificationx interpreted probability belong positive class case normally different classes separated decision boundary basically curve decides separation different classes following example dataset separated two classes can also use code generate linear regression curvedf detailsqqlmod traintrainfit summary frame lineqplot standardized residuals simply put linear regression regression algorithm outpus possible continous infinite value logistic regression considered binary classifier algorithm outputs probability input belonging label basic difference linear regression basically regression model means will give non discreet continuous output function approach gives value example givenfexample given training set different factors price property training can provide required factors determine will property price logistic regression basically binary classification algorithm means will discreet valued output function example givenfthreshold classify else classify example given set brain tumour size training data can use size input determine whether benine malignant tumour therefore output discreet either function basically hypothesis function quite similar solving solution others said one logistic regression predicting category fitn linear regression predicting value want predict cancern probability use logistic want know many years will live use linear regression regression means continuous variable linear means linear relationxtrying predict salary years experience salary independent variableyrs experience dependent variableybtrying find optimum value constantb will givebest fitting line observation data equation line gives continuous valuelarge value line called linear regression model logistic regression type classification technique dnt misled term regression predict whetherfirst need findy wprobabilitygivenformuale probaibilityrelatedformualecan make classification tumour chance cancer tumour less chance cancer red point will predicted whereas green point will predicted agree comments differences like linear regression residuals assumed normally distributed logistic regression residuals need independent normally distributed linear regression assumes constant change value explanatory variable results constant change response variable assumption hold value response variable represents probability logistic regression glm generalized linear models assume linear relationship dependent independent variables however assumes linear relationship link function independent variables logit model short linear regression gives continuous output logistic regression gives discrete output kind outputs put simply linear regression model test cases arrive far away threshold say predictiony case hypothesis will change becomehcanx logistic regression used predicting categorical outputs like yes low medium high etc basically types logistic regression binary logistic regression yes approved disapproved multi class logistic regression low medium high digits etc hand linear regression dependent variablecontinuousmxsimple linear regression equationslopey intercept multilinear regression independent variablexetc linear regression outcome continuous whereas logistic regression outcome limited number possible values discrete example scenario given valuesize plot square feet predictingie rate plot comes linear regression instead wanted predict based size whether plot selluse logistic regression possible outputs either yes plot will sellcase linear regression outcome continuous case logistic regression outcome discrete continuous perform linear regression require linear relationship dependent independent variables perform logistic regression require linear relationship dependent independent variables linear regression fitting straight line data logistic regression fitting curve data linear regression regression algorithm machine learning logistic regression classification algorithm machine learning linear regression assumes gaussian normal distribution dependent variable logistic regression assumes binomial distribution dependent variable basic difference linear regression logistic regression linear regression used predict continuous numerical value looking predicting value categorical logistic regression come picture logistic regression used binary classification unable understand page standardscaler documentation sklearn can anyone explain simple terms assume matrixrow line sample observation column variable feature expected input sklearnfunction way number samples number features main idea normalize standardize features variables columnsindividually applying machine learning model standardscaler will normalize features columnindividually column feature variable wills find upvoted answer page wrong quoting value dataset will sample mean value subtracted neither true correct see also standardize data python tutorial verify mean feature column verify std feature column update concerning input parameters mean std false true provided answer standardscaler difference std false true mean false true idea behind standardscaler will transform data distribution will mean value standard deviation case multivariate data done feature wise words independently column data given distribution data value dataset will mean value subtracted divided standard deviation whole dataset feature multivariate case standardscaler performs task standardization usually dataset contains variables different scale standardized common scale building machine learning model calculate can read useful want compare data correspond different units case want remove units consistent way data transform data way variance unitary mean series following simple working example explain standarization calculation works theory part already explained answers calculation can see output mean std deviation data position standardization data position standardization result standardization check mean std deviation standardization noteclose references compare effect different scalers data outliersdifference normalization standardization mean data scaled sklearn standardscaler zero answers great needed simple example alleviate concerns past wanted make sure indeed treating column separately now reassured canfind example caused concern columns scaled separately described sample variance usesdenominator population variance usedenominator calculation variance understand better please see code uses scaled data first column data set applying standardscaler columnwill mean standard deviation formulas listed others page rationale algorithms require data look like see sklearn docs apply standardscalar row basis row column assuming working pandas dataframe points called standard scalar dividing standard deviation distribution distr feature similarly can guess minmaxscalar original distribution remains applying standardscalar common misconception distribution gets changed normal distribution just squashing range gives error runtimeerror input type weight type get error model gpu data cpu need send input tensors gpu like stay consistent rest code error will raised input tensors gpu model weights arencase need send model weights gpu see documentation cuda opposite cpu new api use method advantage obvious important device may tomorrow something cuda try avoid wrong check device hardcode general can use code already mentioned previous answers issue can model trained gputested cpucase need port modelweights data gpu cpu like note still check configuration arguments set gpu cpu piece code can used training gpu testing cpu loading model weights inputs device can using device pointed others however might case also datatype saved weights input tensors different case must also change datatype model weights inputs problem cnn model put device work notice pytorch documentation self tensor already correct self returned otherwise returned tensor copy self desired might need instead just first approachsafe side first check cuda available case want load model now probably get error runtimeerror input type weight type needed convert type input data convert result works perfectlylearning different methods convert categorical variables numeric machine learning classifiers came across wanted see differed terms performance usage found tutorial use onehotencoderhelpful feature feelingvice versa know onehotencoder gives sparse matrixsure used benefits pandas method using inefficiently machine learning almost definitely want use might able use bit convenient note integers crux sklearn encoder creates function persists can applied new data sets use categorical variables consistent results note apply encoder created viatrain new data settest consider happenstest contains different levelstrain one variables example letsaytrain color contains red green additiontest color sometimes contains blue usetest will end additional color blue columntrain doesninconsistency will probably break code later especially feedingtest sklearn model trainedtrain want process data like productionreceiving single example timeusecreated encoder can reuse produce output every time columns red green can explicitly control happens encounters new level blue thinkimpossible can tell throw error handle unknown error otherwise can tell continue simply set red green columns handle unknown ignore onehotencoder process string values directly nominal features strings need first map integers converts string columns one hot representation unless columns specified really like carlanswer upvoted will just expand carlexample bit people hopefully will appreciatejust cache save columns variable col list resulting get dummies use update question related google colabnotebook settings hardware accelerator gpu question written tpu option added reading multiple excited announcements google colaboratory providing free teslagpu tried run free teslafree small slice free connect google colab west coast canada getsupposedgpu ram users get accessgpu ram clearlygpu ram insufficientdl worksure get little debug function scraped together works gpu setting notebook executing jupyter notebook running code gives lucky users get access full card will see see flaw calculation gpu ram availability borrowed gputil can confirm get similar results run code google colab notebook calculations correct way get gpu ram free box updatesuregetusers get note please donsend suggestions kill potentially stuck runaway parallel notebooks might consuming parts gpu matter slice boat run debug codesee still get total gpu ram update still prevent another dozen answers suggesting invalid context thread suggestion kill letclose thread answer simple writing google simply gives gpuwhereas others period dec update problem still exists questionupvotes continue still mar update year later google employee amif commented state things stating problem doesnexist anybody seems problem needs simply reset runtime recover memory yet upvotes continue tells problem still exists despite amifsuggestion contrary dec update theory google may blacklist certain accounts perhaps browser fingerprints robots detect non standard behavior total coincidence quite time issue googlecaptcha website happened requirego dozens puzzlesallowed often taking min accomplish lasted many months sudden month get puzzles googlecaptcha gets resolved just single mouse click used almost year agotelling story time given gpu ram colabsuspicion theoretical google black list arentrusted given lot resources free wonder find correlation limited gpu accesscaptcha nightmare said totally coincidence last night ran snippet got exactly got today think probable reason gpus shared among vms time restart runtime chance switch gpu also probability switch one used users updated turns can use gpu normally even gpu ram freethought cause resourceexhaustederror got last night execute cell just killcause runtimestate including memory filesystem gpu wiped clean restarted waitpress connect button top right reconnect restart jupyter ipython kernel find python pid kill pid please see image note kill python pid jupyter python just give heavy task google colab will askchangeram example run code twice click get ram sure blacklisting true rather possible cores shared among users ran also test results following seems getting also full core however ran times got result maybe will repeat check times day see change believe multiple notebooks open just closing doesnactually stop process havenfigured stop used top find pid python running longest using memory killed everything back normal now google colab resource allocation dynamic based users past usage suppose user using resources recently new user less frequently uses colab will given relatively preference resource allocation hence get max colab close colab tabs active sessions reset runtime one want usedefinitely get better gpu allocationtrying use tensorflow two days now installing reinstalling python matter get error message trying useboilerplate code matter always get trace back anyone know can fix error upgrade tensorflow can still useapi replacing solution use tensorflow filename notice use actually importing script file current working directory rather real tensorflow module google order module will searched importing directory containing input script current directory file specified pythonpath list directory names syntax variable path installation dependent default happened tensorflow working pretty install tensorflow gpu along side previous tensorflow error arose steps started working problem conda remove tensorflow gpu tensorflow tensorflow base conda install tensorflow instead shape none dtype use something like shape none dtype donwant disablecompletely works using python tensorflow appears placeholder reset default graph others removed version ran issue using docker image tensorflow tensorflow latest gpuautomatically pulls latest version working upgraded automatically started getting error messages fixed specific image tensorflow tensorflow gpuinfo can foundprtnofosftpchlespnndyeflt can disablebehavior using following code one perfectly working also got error may version tensorflow installing tensorflow got relief error using tensorflow code developedx may code work either can follow link pip install tensorflow version import old version tensorflow instead new version import need use keras model tensorflow recent version support placeholder uninstalled using command conda remove tensorflow installed using command conda installconda forge tensorflow latest version series can change per wish requirement seeing version use command conda search tensorflow worked anaconda windows try gpu please take look migrate tensorflow code tensorflow codes need migrated tensorflow get tensorflowlikely code isncompatible newer version tensorflow fix runupgradescript faced issue ubuntu lts tensor flow installed existing python installation workaround uninstall tensorflow pip pip uninstall python python install single version python used python install tensorflow python non gpu tensorflow run command gpu tensorflow run command suggest install gpu vanilla version tensorflow error shows using tensorflow version command version usework use placeholder tensflow version need use tensflow need change code fix tensflow problem tried upgrade tensorflow solved reinstalling tensorflow keras pip uninstall tensorflow pip uninstall keras pip install tensorflow pip install keras problem tensorflow version one running something placeholder can work simply uninstall tensorflow install version everything will work may typo incorrectly wrote placeholder word case misspelled placehoder got error like attributeerror module object attribute placehoderworking classification problem unbalanced classeswant predict class probability binary classification problem scikitusing default doesns default method change scikit classifiers class weight auto option class weight auto predict use actual population proportion threshold way classifier like multinomialnb doesnsupport class weight using predict proba calculation classes threshold can set using example threshold scikit learn binary classification whichever class greatest probability multiclass classification many problems much better result may obtained adjusting threshold however must done care holdout test data cross validation training data adjustment threshold test data just overfitting test data methods adjusting threshold based receiver operating characteristics roc youdenj statistic can also done methods search genetic algorithm peer review journal article describing medicine inefficient find brute force search pythoncode scikitusing default probabilistic classifiers yessensible threshold mathematical viewpoint others explained way classifier like multinomialnb doesnsupport class weight can set class prior prior probabilityy per classeffectively shifts decision boundary generic classifier basic approaches based tunable threshold existing methods create complex rules classification least shouldnseen thresholding first one answer question scikitclassifier default threshold thing second class weighting threshold classifier ability deal imbalanced classes something dependent particular classifier example svm case way weighting slack variables optimization problem prefer upper bounds lagrange multipliers values connected particular classes setting auto means using default heuristic simply translated thresholding naive bayes hand directly estimates classes probability training set called class prior can set constructor class prior variable documentation prior probabilities classes specified priors adjusted according data case someone visits thread hoping ready use function python example cutoff designed reflect ratio events non events original datasety prob result predict proba method assuming stratified train test split feel free criticize modify hope helps rare cases class balancing question dataset highlyallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago processing time series graph like detect patterns look similar using sample time series example like able detect patterns marked kindalgorithm assuming marchine learning techniques need use achieve libraryc can use sample result small project partition ecg data approach switching autoregressive hmm google havenheard datapoint predicted previous datapoint using bayesian regression model created hidden states junk state capture data beat separate hidden states corresponding different positions within heartbeat pattern pattern states constructed directly subsampled single beat pattern two transitions self transition transition next state pattern final state pattern transitioned either junk state trained model viterbi training updating regression parameters results adequate cases similarly structure conditional random field probably perform better training crf require manually labeling patterns dataset donalready labelled data editexample python code perfect gives general approach implementsrather viterbi training may slightly stable ecg dataset eamonn discords ecg general statistical counterpart called cross correlation given known patternt noisy compound time series containing pattern shiftedz liketttxzt cross correlation functiony give peaksz weka powerful collection machine learning software supports time series analysis tools know enough field recommend best method however java based can call java codec without great fuss packages time series manipulation mostly directed stock market suggested cronos comments idea pattern recognition beyond obvious good model length series able predict small bumps certain distance last small bump big bumps follow series exhibits self similarity models used cronos designed model donmindrequest version timesearcher folks hcil pattern recognition system drawing pattern looks like checking whether model general enough capture instances low false positive rate probably user friendly approach will find others require quite background statistics pattern recognition strategiessure package work best something similar one point college tried automatically detect certain similar shapesy axis bunch different graphs something like following class labels like features like using deep learningoptiondone java deeplearningexperimenting lstm tried hidden layer hidden layers process time series found things java app needs perform partial least squares regression appear java implementations plsr weka might something like point longer api hand found goodimplementation added bonus used people whose result want replicate means less chance things willwrong differences way plsr implemented question good enough simple use package enable java callpass parameters function read back results option java spawnprocess monitor data read written disk two recommend missing obvious third option successfully used two alternatives past jri rserve alternatives never used rcaller work duncan temple lang stats rosuda mailing list archive indicates list remains active also code put googlecode example wrote blog article provides detailed example use jri rjava jni based bridge type thing focused linux dev environments also compare contrast alternative approaches mathy stuff callingsimilar frameworks url windowsrserve believe written java gripe wasnbit used simple client writtenworkedsure java client lot better fastr graalvm based implementationembedding jvm application simple details articlelike reset randomize weights layers keras deep learning model reason want able train model several times different data splits without slow model recompilation every time inspired discussiontrying following code however partly works partly becuaseinspected values seem change restart training cost values much lower initial cost values first runalmost likesucceeded resetting weights save initial weights right compiling model training training reset model reloading initial weights gives apples apples model compare different data sets quicker recompiling entire model reset layers checking initializers update kernel initializer merely restore initial weights can following code slightly different depending whetherusing tensorflow theano found clone model function creates cloned network architecture new model weights example use comparing weights execute code several times will notice cloned model receives new weights time tensorflow answer original weights new weights try set weights example build model say two convolutional layers define weightsusing simpleuse take peek layers inside model set weight convolutional layersee first layer actually input donwant changerange starts zero generate input test predict output model change want check output sample output peek layers can see first layer input others convolutional layerssimplest way actually reset weights clone model mentioned danielsaromo returns new model trainable params initialized scratch use weights reinitialize model thus model compilation knowledge loss optimizer needed two caveats though first mentioned clone modeldocumentation clone model will preserve uniqueness shared objects within model another caveat large models cloning might fail due memory limit randominitialize weights compiled untrained modelnote wdim elsedonwantinitialize biases stay use can anyone tell set random state zero splitting train test set seen situations like random state set consequence random state cross validation doesnmatter random state integer matters set value want validate processing multiple runs code way seen random state used many official examples scikit elsewhere also random state name suggests used initializing internal random number generator will decide splitting data train test indices case documentation stated random state none randomly initialized randomstate object returned random state integer used seed new randomstate object random state randomstate object passed check validate data running code multiple times setting random state fixed value will guarantee sequence random numbers generated time run code unless randomness present process results produced will always helps verifying output random state set integer train test split will return results execution random state set none train test split will return different results execution see example output donmention random state code whenever execute code new random value generated train test datasets different values time however use particular value random state random state value everytime result willvalues train test datasets random state splits randomly selected data twist twist order data will particular value randombool accpeted value starting integer pass random statepermanent orderorder will get random state remain execuit random state come back random stateget order like integer willever random state none splits randomly time still doubt watch donspecify random state code every time run execute code new random value generated train test datasets different values time however fixed value assigned like random state matter many times execute code resultvalues train test datasets random state none default means every time run program will get different output splitting train test varies within random state int value means every time run program will get tehe output splitting train test varies within random state integer value implies selection random combination train test set test size set generated permutation combination train test combination one state suppose dataset need param tuning model state will considered woninference accuracy case random forest also similar story different way random state make sure data values will training testing data sets fixes order data train test split say dataset one feature data pointssay testset specified test data percentage goingdifferent combinations data refer picture link tabular explanation different values random state may produce different results training phase internally train test split function uses seed allows pseudorandomly separate data two groups training test set number pseudorandom data subdivision corresponds seed value aspect useful ensure reproducibility experiments unfortunately use one seed rather another lead totally different datasets even modify performance chosen machine learning model receives training set input can read following article deepen aspect need know features major contributors classification svm classifier something called feature importance forest algorithms anything similar yes attribute coef svm classifier works svm linear kernel kernels possible data transformed kernel method another space related input space check explanation output function looks likeusing rbf radial basis function kernal can use doc one line code fit svm model implement plot follows resuit will contributing features svm model absolute values created solution also works python based jakub macinacode example fully convolutional neural network input images can size however need specify input shape create network keras therefore can use keras deal different input size without resizing input images size thanks help yes just change input shape shapechannels none nonechannels number channels input imageusing theano backend though using tensorflow might change none nonechannels use input shape none none none shape denotes variable dimension note layers will work variable dimensions since layers require shape information flatten using kerasfunctional api input layer rgb dataset gray dataset implementing arbitrarily sized input arrays computational kernels can pose many challenges need know big buffers reserve weakly much unroll loops etc main reason keras requires constant input shapes variable sized inputs painful deal commonly occurs processing variable length sequences like sentences nlp common approach establish upper bound size crop longer sequences pad sequences zeros size also include masking zero values skip computations padded areas except convolutional layers keras might still support maskedsuredata structures overhead padding prohibitive start getting memory errors easiest workaround reduce batch size letknow experience applying trick images just use none specifying input shape still know pass different shaped images fitallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago seems likereally designed handle datasets can pull entirely memorypackages recommended signal processing machine learning large datasets can pulled memorysimply wrong way open robust free suggestions look large memory memory data subsection high performance computing task view cran bigmemorytwo popular packages bigmemory related biganalytics bigtabulate bigmemory website good presentations vignettes overviews jay emersonrecommend reading adler oehlschl gel colleagues excellent slide presentationswebsite also consider storing data database reading smaller batches analysis likely number approaches consider get started consdier looking examples biglm package presentation thomas lumley investigate packages high performance computing task view mentioned answers packages mention simply oneshappened experience think amount data can process limited ones programming skills anything else although lot standard functionality focused memory analysis cutting data chunks already helps lot ofcourse takes time program picking standardcode often times quite possible cutting data can exale done using can take look high performance computing task view packages deliver box memory functionality also put data database spatial raster data excellent raster package provides memory analysis machine learning tasks can recommend using biglm package used regression data large fit memory usingreally big data one can use hadoop backend use package rmr perform statistical analysis via mapreduce hadoop cluster depends algorithms need may translated incremental form small part data needed given moment best suggestion perform machine learning incrementally reading new batches data disk however many algorithms especially implementations really require whole dataset size dataset fits disk file system limitations can use mmap package allows map file disk memory use program note however read writes disk expensivesometimes likes move data back forth frequently careful data canstored even hard drive will need use distributed machine learning systems onebased system revolutiondesigned handle really large datasets unfortunately open source costs quite lot money may try get free academic license alternative may interested java based apache mahout elegant efficient solution based hadoop including many important algorithms memory sufficient enough one solution push data disk using distributed computing think rhadoophadoop may one solution tackle large amount dataset need cluster simple univariate data set preset number clusters technically closer binning sorting data sinceboss calling clusteringgoing stick name current method used systemk means seems like overkill better way performing task answers posts mentioning kde kernel density estimation density estimation method work see kde returns density tell split data bins fixed number bins independent dataone requirements specifically one pull using scikit learn input file looks like want group sls number clusters bins output file will look like write code fits problem best boilerplate never assume code download net correct split cut red markers green markers best estimates cluster centers little error accepted answer quit anony mousse cancomment suggest edit due reputation line editedmiindexmima value uselimit risk error splitting upper lower linspace upper lower data example run code see difference split result result improving responses yasirroni dynamically print clusters just line can changed ensure clusters taken extracting loss accuracy numerical data without launching gui tensorboard logdir can use tensorboardpython classes script extract data can export data tensorboardlike export data visualize elsewherepossible can directly depend underlying classes tensorboard uses loading data python summary event loading data single run python summary event loading data multiple runs keeping organized classes load groups event files discard data orphaned tensorflow crashes organize data tag another option script tensorboard scripts serialize will load logdir just like tensorboard write data disk json instead starting server script setup make fake tensorboard backends testing bit rough around edges using eventaccumulator size guidance finish useranswer can just export list scalars csv file easily pandas loss csv anyone interestedadapted useranswer function parsing tensorboard scalars dictionary pandas dataframes try bat optimalbuilding model converts string another string using recurrent layers grus tried dense timedistributed dense layer last one layer donunderstand difference two using return sequences true especially seem number parameters simplified model following summary network makes sense understanding timedistributed applies layer timepoints dense layer parameters weights biases however switch simple dense layer still parameters wonder dense will use last dimension shape effectively treat everything else batch like dimensionlonger sure difference dense timedistributed dense update looking also uses docs will effect called every time step question still remains timedistributed achieves case timedistributeddense applies dense every time step gru lstm cell unrolling error function will predicted label sequence actual label sequence normally requirement sequence sequence labeling problems however return sequences false dense layer applied last cell normally case rnns used classification problem return sequences true dense layer applied every timestep just like timedistributeddense per models change second model return sequences false dense will applied last cell try changing model will throw errorwill size batch size inputsize sequence sequence full sequence label problem example architecture model model sample sequence sequence models model full sequence label model piece code verifies timedistirbuted denseidentical densedifferencelooking clustering points map latitude longitude recommendations suitable algorithm fast scalable specifically series latitude longitude coordinates map viewporttrying cluster points close together order remove clutter already solution problem see wondering formal algorithm solves problem efficiently virtual earth applicationused clustering describedlightning fast easily extensible google maps hacks hack hack cluster markers high zoom levels also see wikipedia clustering algorithms look indexing points using quadtile scheme based upon scale quad splitssimilarly located points will near index allowing clustering happen efficiently quadtiles example morton codes python example linked wikipedia article may help looked various libraries found complex couldnunderstand word decided make clustering algorithm goes code java calculates pixel distance tow lat long points particular zoom level main function actually calculates clusters arraylist lat long points iterated length inner loop copy arraylist iterated positionleaving top loopindexelement taken centre centroid points compared pixel distance less add cluster remove elements top arraylist copy arraylist formed cluster restart process reinitializing index centroid selected clusters element deletedis possible use gridsearchcv without cross validation trying optimize number clusters kmeans clustering via grid search thus donneed want cross validation documentation also confusing fit method option unsupervised learning says use none unsupervised learning want unsupervised learning need without cross validation appears option get rid cross validation much searching able find thread appears can get rid cross validation gridsearchcv useslice none slice none tested coded version grid search without cross validation get results methods posting answer question case others issue edit answer jjrrquestion comments example use casegoing answer question since seems like unanswered still using parallelism method loop can use multiprocessing module think usingshufflesplit test sizesplitssplits better solution like post suggested recently came following custom cross validator based answer passed gridsearchcv properly disabled cross validation hope can helpgetting error valueerror tensor tensor placeholder shape dtype int element graph code running perfectly fine without default however need call multiple times time memory wonfree probably memory leak sure want restore pre trained neural network set default graph testing multiple times like default graph without making larger time code model output try first need use predict create model session hasnrestored yet placeholders variables ops defined model init placed new graph makes default graph inside block key line means instance equals instance inside block moment exist two different graphs later create session restore graph canaccess previous instance sessionshort example best way deal give names nodes input target etc save model look nodes restored graph name something like method guarantees nodes will graph session calling python function calls tensorflow external module make sure model isnloaded global variable else may loaded time usage happened calling tensorflow model flask server use line making models will make new graph use new models issue resolved using keras apis save load model one models trained code use particular model prediction condition saved entire model hdf file model training recreate reload saved model time prediction helped get rid error inside def loadpredictor save just loading model add model make predict function function becomes issue trying make model using another class uses keras create model got issue corrected followingi training simple model keras nlp task following code variable names self explanatory train test validation set dataset classes final layer network outputs labels also one hot encoded first epoch gives outputs evaluate model testing dataset also shows accuracy around however labels one hot encoded need prediction vector classes can generate confusion matrix etc use shows total predicted classes accurate however accuracy wrong loss function okay categorical class labels choice sigmoid activation function prediction layer okay difference way keras evaluates model please suggest can wrong first try make deep model donmuch understandingwrong found problem metrics accuracy calculates accuracy automatically cost function using binary crossentropy shows binary accuracy categorical accuracy using categorical crossentropy automatically switches categorical accuracy now calculated manually usingyang right point cost function activation function multi class problems one can get categorical binary accuracy using metrics binary accuracy categorical accuracytrying understand gmm reading sources available online achieved clustering usingmeans seeing gmm comparemeans understood please let know concept wrong gmm like knn sense clustering achieved cases gmm cluster independent mean covariance furthermoremeans performs hard assignments data points clusters whereas gmm get collection independant gaussian distributions data point probability belongs one distributions understand better used matlab code achieve desired clustering used sift features purpose feature extraction usedmeans clustering initialize values vlfeat documentation based means covariances priors main question now kind lost now also means covariances vectors sizeexpectingsince column cluster cluster one mean covariance know sift features expecting means covariancesmeans used matlab command knnsearchy basically finds nearest neighbourpointachieve gmm know collection probabilities ofcourse nearest match probability will winning cluster confused tutorials online taught achieve means covariances values say much actually use terms clustering thank think help first look gmm model representsusing functions statistics toolbox able using vlfeat letstart case mixture two dimensional normal distributions gaussian represented pair mean variance mixture assign weight component prior example mix two normal distributions equal weightsfirst centered secondvariances equal respectively first second distributions sigma cat can see mean effectively shifts distribution variance determines wide narrow flat pointy prior sets mixing proportions get final combined model ideaclustering distribution represents cluster example one dimensional data given instanceassign belonging first cluster mode probability can see instance falls first bell curve whereas take point middle answer ambiguous point assigned class much less certainty concepts extend higher dimension multivariate normal distributions one dimension covariance matrix generalization variance order account inter dependencies features example mixture two mvn distributions dimensions intuition behind covariance matrix affects shape joint density function instancematrix diagonal implies two dimensions donco vary case pdf look like axis aligned ellipse stretched either horizontally vertically according dimension bigger variance equal shape perfect circle distribution spread dimensions equal rate finally covariance matrix arbitrary non diagonal still symmetric definition will probably look like stretched ellipse rotated angle previous figure able tell two bumps apart individual distribution representd higher dimensions think representing hyper ellipsoidsdims nowperforming clustering using gmm goal find model parameters mean covariance distribution priors resulting model best fits data best fit estimation translates maximizing likelihood data given gmm model meaning choose model maximizesdata model explained solved iteratively usingalgorithmstarts initial estimate guess parameters mixture model iterativelyscores data instances mixture density produced parametersscored instances used update parameter estimates repeated algorithm converges unfortunatelyalgorithm sensitive initialization model might take long time converge set poor initial values even get stuck local optima better way initial gmm parameters usemeans first step likeshown code using mean cov clusters initializecluster analysis techniques first need decide number clusters use cross validation robust way find good estimate number clustersclustering suffers fact lot parameters fit usually requires lots data many iterations get good results unconstrained modelmixturesdimensional data involves fittingddm parameterscovariance matrices size dxd plusmean vectors lengthplus vector priors lengthproblem datasets large number dimensions customary impose restrictions assumption simplify problem sort regularization avoid overfitting problems instance fix covariance matrix diagonal even covariance matrices shared across gaussians finallyfitted mixture model can explore clusters computing posterior probability data instances using mixture component likeshowedexample gmm assigns instance cluster according membership likelihood complete example clustering data using gaussian mixture models right insight behind clusteringmeans gmm mentionned gaussian mixtures take data covariances account find maximum likelihood parameters maximum posteriori map gmm statistical model need use iterative process calledalgorithm iteration composedstep expectationstep maximization repeat convergence convergence can easily estimate membership probabilities data vectors cluster model covariance tells data varies space distribution large covariance means data spread vice versa pdf gaussian distribution mean covariance params can check membership confidence test point distribution however gmm also suffers weaknessmeans pick parameternumber clusters requires good understanding datanoticed score get hence model created different every time run code despite fixing seeds random operations problem happen run cpu googled found common issue using gpu train good detailed example short code snippets verify existence problem pinpointed non determinism function however caseusing different hardwaredifferent version cuda libraries tensorflow seems like many different parts cuda libraries non deterministic doesnseem easy figure exactly part get rid also must designlikely sufficient efficiency increase exchange non determinism question since gpus popular training nns people field must way deal non determinism cansee elseable reliably tune hyperparameters standard way handle non determinism using gpudr much longer see neural network operations mathematical operations expect everything deterministic convolutions activations cross entropy everything mathematical equations deterministic even pseudo random operations shuffling drop noise likes entirely determined seed see operations computational implementation hand see massively parallelized computations can source randomness unless careful heart problem run operations several parallel threads typically know thread will end first important threads operate data example applying activation function tensor deterministic threads need synchronize compute sum result may depend order summation turn order thread ended first broadly speaking two options keep non determinism associated simpler implementations take extra care design parallel algorithm reduce remove non determinism computation added constraint usually results slower algorithms route takes cudnn mostly deterministic one recent releases deterministic operations norm rather exception used offer many non deterministic operations importantly used offer operations reduction people needed implement cuda variable degree consideration determinism libraries theano ahead topic exposing early deterministic flag user turn can see description far offering guarantee sometimes will select implementations deterministic slower particular gpu will avoid using atomicadd sometimes will still use non deterministic implementation see flags cover cases tensorflow realization need determinism rather lateslowly getting helped advance cudnn front also long time reductions non deterministic now seem deterministic fact cudnn introduced deterministic reductions version may helped course seems currently main obstacle tensorflow towards determinism backward pass convolution indeed one operations cudnn proposes non deterministic algorithm labeled cudnn convolution bwd filter algo algorithm still list possible choices backward filter tensorflow since choice filter seems based performance indeed picked efficient familiar tensorflowc code take grain salt important debugging issue determinism merely important mandatory need reproduce steps led problem currently real issue toolkits like tensorflow mitigate problem option debug live adding checks breakpoints correct locations great deployment another aspect things often desirable deterministic behavior part human acceptance nobody reasonably expect medical diagnosis algorithm never fail awkward computer give patient different diagnosis depending run although doctors immune kind variability reasons rightful motivations fix non determinism neural networks aspects say need accept embrace non deterministic nature neural net training purposes training stochastic use stochastic gradient descent shuffle data use random initialization dropout importantly training data random sample data standpoint fact computers can generate pseudo random numbers seed artifact train loss value also comes confidence interval due stochastic nature comparing values optimize hyper parameters ignoring confidence intervals make much sense therefore vain opinion spend much effort fixing non determinism many cases startingtf wantmodels run deterministically following lines need added beginning program important note first line sets random seed following python numpy tensorflow second line makes tensorflow operation deterministic get mnist network train deterministically gpunote resulting loss repeatable either method selecting deterministic algorithmstwo methods result different losses also solution doesnmake complicated modelusing repeatable check cuda cudnn non deterministic algorithms exist trying create neural network optimize using pytorch getting valueerror optimizer got empty parameter list code call gives informative error valueerror optimizer got empty parameter list find hard understand exactly networkdefinition makes network parameters following expanding example found pytorchtutorial code canreally tell difference code makes mine think parameters optimize make network parameters like linked example netactor directly store layers eventually uses forward stored simple list want know items stored list work containers specifically makingcurrently working classifying images different image descriptors since metrics using precomputed kernels given nxn kernel matrices totalimages want train test svmexperienced using svms though confuses though enter input training using subset kernel mxmnumber training images trains svmfeatures however understood correctly limits use test data similar amounts features trying use sub kernel size mxn causes infinite loops training consequently using features testing gives poor results results using equal sized training test sets giving reasonable results want classify say one image train given amount images class test rest doesnwork can remove dependency number training images features can test number imagesusing libsvm matlab kernels distance matrices ranging seem already figured use precomputed kernel must include sample serial number first column training testing data let illustrate example outputassignment trying build collaborative filtering model netflix prize data data using csv file easily imported data frame now need create sparse matrix consisting users rows movies columns cell filled corresponding rating value try map values data frame need run loop row data frame taking lot timeplease can anyone suggest better approach sample code data sample data dataframe sparse matrix created end want something like columns movie ids rows user ids interpretation something like user rated movie star user rated movie star users movies rows data frame code takes just mins create user item matrix like get suggestions matrix package constructor made especially type data otherwise might like knowing cool feature function known matrix indexing tried definitely recommend sparsematrix approach will probably faster loop use will lot fastersure someone will point can use instead convertswithout making copy data set enormous can make deep learning general started working basic classification examples one example classifying non linear dataset created using sklearn full code available notebook accurately classified using pretty basic neural net interest health data decided try use network structure classify basic real world dataset took heart rate data one patient altered values labelled anomalies labelled completely arbitrary just wanted see classification work complete notebook example intuitive first example reaches loss epochs whereas second example reaches loss epochs perhaps naive thinking heart rate example much easier classify insights help understand seeing great input data normalizedget convergence iterations key difference two examples datafirst example centered around low variance hand data second example centered around relatively large variance initial bias data taken account randomly initialize weights done based assumption inputs roughly normally distributed around zero almost impossible optimization process compensate gross deviation thus model gets stuck sub optimal solution normalize inputs subtracting mean dividing std optimization process becomes stable rapidly converges good solution details input normalization weights initialization can read sectional delving deep rectifiers surpassing human level performance imagenet classification iccv reason compute mean std data advance can still use yields similar convergance epochs numerical stability better use need remove output sigmoid will computed inside loss see example thread regarding related sigmoid cross entropy loss binary predictions letstart first understanding neural networks work neural networks observe patterns hence necessity large datasets case example two pattern intend findlabel condition can represented formula sigmoidplug various values formula can see values label others label inferred formula anything long gives correct values basically apply formulabinput data learn valuesb now initially values random gettingvalue random value maybe fast since loss great learning rate allows values jump fast reach loss decreasing apply learning rate takes time reach closer hence slow decrease loss values get closer steps taken even slower can confirmed via loss values constantly decreasing initially deceleration higher becomes smaller network still learning slowly hence deep learning use method called stepped learning rate wherewith increase epochs decrease learning rate learning fastersince tensorflow plan unifying high level apis kerasmuch familiar removing sessions altogether wondering can create custom keras layer custom gradientseen quite limited guide creating custom layers keras doesndescribe want operation custom gradient first unification apis call keras doesnprevent things like tensorflow now want build keras model custom layer performs custom operation custom gradient following write function performs custom operation define custom gradient info note function treatdy tensors numpy arrayscreate custom keras layer performs customexampleassume layer doesntrainable parameters change shape input doesnmake much difference can refer guide posted check one now can use layer keras model will work example trained googlenet model scratch didngive promising results alternative like fine tuning googlenet model dataset anyone know steps follow assuming trying image classification steps finetuning model original classification layer loss classifier outputs predictions classesmum output setneed replace new layer appropriate num output replacing classification layer need make new training dataset new labels want fine tune see example post make lmdb dataset finetuning model can train modelweights choose fix weights usually filters lower deeper layers train weights top layers choice ususally depends amount training data available examples weights can afford finetune layer holds trainable parameters parammultcoefficient determines susceptible weights sgd updates setting parammult means fix weights layer will changed training process edit train fine tuning useful trick achieve promising accuracy compared past manual feature shai already posted good tutorial fine tuning googlenet using caffe just want give recommends tricks fine tuning general cases time face task classification problem new dataset dog following four common situationsn practice time enough data train network scratch may enough pre trained model whatever cases mentions thing must care enough data train cnn yes can train cnn scratch however practice still beneficial initialize weight pre trained model need check whether data different original datasets similar can just fine tune fully connected neural network fine tune svm however different original dataset may need fine tune convolutional neural network improve generalization trying train large model therefore can fit small batch size gpu memory working small batch sizes results noisy gradient estimations can avoid problem can change iter size solver parameters caffe accumulates gradients iter sizebatch size instances stochastic gradient descent step increasing iter size can also get stable gradient use large batch size due limited memory stated post batch size problem theory efficiency stochastic gradient descent proven batch size make sure implement batch correctly samples randomly picked data want fold cross validation one support vector machine classification matlab tried somehow mix two related answersnew matlab syntax didnmanage make work till now hand saw just following lines cross validation libsvm readme files couldnfind related example optionrandomly splits dataparts calculates cross validation accuracy mean squared error see libsvm faq meaning outputs anyone provide example fold cross validation one classification mainly two reasons cross validation first case interested process involves trainingmodels fold training one final model entire training set report average accuracyfolds now since using oneapproach handle multi class problem model consistssupport vector machines one class following wrapper functions implementing oneapproach functions support cross validation finally simple demo illustrate usage compare oneone approach used default libsvm may confusing one two questions libsvm try adjust answer ignore select folds rest exactly linked question assume data loaded data labels labels removed data layer removed bottom data conv layer got error removed bottom label loss layer got error fix create deploy file two main differences train prototxt deploy one inputs training data fixed pre processed training dataset lmdb hdf etc deploying net require process inputs random fashion therefore first change remove input layers layers push data labels train test phases replace input layers need add following declaration declaration provide actual data net tells net shape expect allowing caffe pre allocate necessary resources loss top layers training prototxt define loss function training usually involve ground truth labels deploying net longer access labels thus loss layers converted prediction outputs example softmaxwithloss layer converted simple softmax layer outputs class probability instead log likelihood loss loss layers already predictions inputs thus sufficient just remove update see tutorial information besides advices shai may also want disable dropout layers although jia yangqing author caffe said dropout layers negligible impact testing results google group conversation deeplearning tools suggest disable dropout deploy phase example lasange working one deep learning model trying combine two different modeloutput overall structure like first model takes one matrix examplenow second model takes two input matrix want make two matrices trainable like tensorflow able getting clue make matrix matrixtrainable merge output networks give input went question couldnfind answer problem statement different mine tried far overview model update modelmodel merging like right way matmul two keras model donknow merging output correctly model correct greatly appreciate anyone kindly gives advice make matrix trainable merge modeloutput correctly give input thanks advancesince going custom trainable weights way keras creating custom layer now since custom layer inputs will need hack will explained later layer definition custom weights now layer used like layer defined can start modeling first letsee model side going use trainableweights layer first letsimulate new model mentioned now entire branch finally can join branches whole model notice didnuse model modelcan want submodels needed unless want later get individually usages even created donneed change code usealready part graph now train since outputnow problem categorical crossentropy comment doubts output shapetrying understand identify statistical outliers groups dataframe will need group rows conditions reduce groups single row later find outliers reduced rows using dataset like like group different conditions step reducing data frame single row ideas straightforward way take mean dataframe problem columns categorical continuous take mean entire data frame converting categorical columns freq count columns looks likegroup now can take mean reduce data frames single row concatinating reduced rows single dataframe final reduced rows data frame looks like row represents reduced data frame group want find outliers reduced dataset tried find outliers using zscore doesnseem work feel like way without much complexitystuck proceed can reduce groups single rows find outliers reduced dataset get mean std need loop column get mean std set max min value accept column knowing data represents makes harder try explore used groupby mean reduce rows imagined binary columns input decimal output pivot make one row making new column named input pivoting needed columns adjusting names reducing columns pcaseems outlier thanks reading practice gaussian distribution data cases falls outside mean outside range distribution thus gaussian gaussian like distributions better rewrite previous answer data taken loop column range need covering distribution sure really needin paper girshickfast rcnn iccv section truncated svd faster detection author proposes use svd trick reduce size computation time fully connected layer given trained model can use trick replace fully connected layer truncated one linear algebra background singular value decomposition svd decomposition matrixthree matricesv ortho normal matricesdiagonal elements decreasing magnitude diagonal one interesting properties svd allows easily approximatelower rank matrix suppose truncatek leading elements instead elements diagonal rankapproximationusing svd approximate fully connected layer suppose model deploy trained weights python little net surgery now deploy weights actually ross girshickpy faster rcnn repo includes implementation svd step compress usually need fine tune compressed model recover accuracy compress sophisticated way see example accelerating deep convolutional networks classification detection zhangal alsosvd just made adaboost classifier parametersestimators svc support vector classifier code dataset independent variables categorical dependent variable dataset datapoints whenever run will take much time result way check execution time better way practice never use svms base classifiers adaboost adaboost similar ensemble methods conceived using decision trees base classifiers specifically decision stumps good reason still today donspecify explicitly base classifier argument assumes value decisiontreeclassifier max depth dts suitable ensembling essentially unstable classifiers case svms hence latter expected offer much used base classifiers top svms computationally much expensive decision trees let alone decision stumps reason long processing times observed unless good reason stick svms base classifiers highly doubt remove base estimator svc order revert default setting probably will fine similar experience recently case though realised wasnscalingusing svm base estimator just make sure scale data can use standardscaler sklearn always required prior using svm dataframe want get name column column particular row contains column use multiple per row question ambiguous recommend reading link sammywemmycomment understand problemtalk mask firsthappening work way outward starting within returns false unless least one element within series along dataframe axis true equivalent giveshandy series mask column names will use example automate solution automate get output row index col name col name row values although will slower large datasets trick next step loop iterates contentsdf dict checks mask created earlier prints intended results see generated sample data can easily reproduced future please try ask questions posted sample data can reproduced way helps understand problem better easieranswer getting column name dividing sections want new column name condition unique will give col name row looking min maximumcase condition satisfied multiple columns example looking columns contain looking list possible adjust dataframe looking numerical condition columns contains value happy learningi following tutorial also called som type machine learning algorithm iris data ran code tutorial code fits kohonen network iris data observation data set assigned one colorful circles also called neurons pictures question plots identify observations assigned circles suppose wanted know observations belong circles outlined black triangles possible right now trying use classif somehow trace points circle better way update jonny phelps showed identify observations within triangular form see answer still sure possible identify irregular shaped forms labelling points plotlanguage user showed assign arbitrary numbers circle grid based plot use som classif statement find observations circles thanks edit now shiny app plotly solution also possible can mouse individual neurons display associated iris rownames called based grid approach can just assign row numbers concatenated strings individual neurons shown upon mouseover full shiny app allows lasso selection shows table data can see using grid wayisolating circles within plotting grid made assumption classifier value matches row index grid will need validation let know helps problem output data validation plotting grid elaborated example post however iris data set suppose problemsom kohonen package outlier detection also added code snippets might need show think answers questions also nice compare performance somsne used som experiment data generated real wine data set also nice prepare heat maps variables best analysistrying make xor gate using perceptron network reason network learning plot change error graph error comes static level oscillates region add bias network moment error changing number learning rounds correct red color line line expecting error change anything wrongcode canseem figurecausing error help much appreciated thanks advance one hidden layer network backpropagation can customized run experiments relu sigmoid activations several experiments concluded relu network performed better reached convergence sooner sigmoid loss value fluctuated happens gradient sigmoids becomes increasingly small absolute valueincreases end result weights obtained trainingww found following youtube series extremely helpful understanding neural nets neural networks demystified little know also can explained answer want even better understanding neural nets suggestfollowing linkn modelling one neuron error calculated epoch sum total sum squared errors want improve question update question focuses one problem editing post closed years ago terms artificial intelligence machine learning difference supervised unsupervised learning can provide basic easy explanation example since ask basic question looks likeworth specifying machine learning machine learning class algorithms data driven normal algorithms data tells good answer example hypothetical non machine learning algorithm face detection images try define face round skin like colored disk dark area expect eyes etc machine learning algorithm coded definition learn examplesshow several images faces faces good algorithm will eventually learn able predict whether unseen image face particular example face detection supervised means examples must labeled explicitly say ones faces ones arenunsupervised algorithm examples labeledsay anything course case algorithm invent face can try cluster data different groups different horses since another answer mentions though incorrect way intermediate forms supervision supervised methods smart way avoid large number labeled examples active learning algorithm decides thing label might ask confirm gorilla indeed picture face semi supervised learning two different algorithms start labeled examples tell way think large number unlabeled data discussion learn supervised learning data feed algorithm tagged labelled help logic make decisions example bayes spam filtering flag item spam refine results unsupervised learning types algorithms try find correlations without external inputs raw data example data mining clustering algorithms applications training data comprises examples input vectors along corresponding target vectors known supervised learning problems pattern recognition problems training data consists set input vectorswithout corresponding target values goal unsupervised learning problems may discover groups similar examples within data called clustering pattern recognition machine learning bishop supervised learning inputprovided expected outcomeoutput model supposed produce inputoften called class label corresponding inputunsupervised learning class exampleprovided unsupervised learning can thought finding hidden structure unlabelled data set approaches supervised learning include classificationnaive bayes decision tree learning algorithm cart numeric value prediction approaches unsupervised learning include clusteringmeans hierarchical clustering association rule learning can tell example suppose need recognize vehicle car one motorcycle supervised learning case input training dataset needs labelled input element input training dataset specify represents car motorcycle unsupervised learning case label inputs unsupervised model clusters input clusters based case labels like car instance often training neural network supervised learningtelling network class corresponds feature vectorfeeding clustering unsupervised learning let algorithm decide group samples classes share common properties another example unsupervised learning kohonenself organizing maps always found distinction unsupervised supervised learning arbitrary little confusing real distinction two cases instead range situations algorithm can less supervision existence semi supervised learning obvious examples line blurred tend think supervision giving feedback algorithm solutions preferred traditional supervised setting spam detection tell algorithm donmake mistakes training set traditional unsupervised setting clustering tell algorithm points close cluster just happens first form feedback lot specific latter short someone says supervised think classification say unsupervised think clustering try worry much beyond supervised learning supervised learning based training data sample data source correct classification already assigned techniques utilized feedforward multilayer perceptron mlp models mlp three distinctive characteristics characteristics along learning training solve difficult diverse problems learning training supervised ann model also called error backpropagation algorithm error correction learning algorithm trains network based input output samples finds error signal difference output calculated desired output adjusts synaptic weights neurons proportional product error signal input instance synaptic weight based principle error back propagation learning occurs two passes forward pass input vector presented network input signal propagates forward neuron neuron network emerges output end network output signalnnn induced local field neuron definednnn output calculated output layern compared desired responsen finds errorn neuron synaptic weights network pass remains backward pass error signal originated output neuron layer propagated backward network calculates local gradient neuron layer allows synaptic weights network undergo changes accordance delta rule recursive computation continued forward pass followed backward pass input pattern till network converged supervised learning paradigm ann efficient finds solutions several linear non linear problems classification plant control forecasting prediction robotics etc unsupervised learning self organizing neural networks learn using unsupervised learning algorithm identify hidden patterns unlabelled input data unsupervised refers ability learn organize information without providing error signal evaluate potential solution lack direction learning algorithm unsupervised learning can sometime advantageous since algorithm look back patterns previously considered main characteristics self organizing maps som computational layer also called competitive layer since neurons layer compete become active hence learning algorithm called competitive algorithm unsupervised algorithm som works three phases competition phase input patternpresented network inner product synaptic weightcalculated neurons competitive layer finds discriminant function induce competition among neurons synaptic weight vector close input vector euclidean distance announced winner competition neuron called best matching neuron cooperative phase winning neuron determines center topological neighborhoodcooperating neurons performed lateral interactionamong cooperative neurons topological neighborhood reduces size time period adaptive phase enables winning neuron neighborhood neurons increase individual values discriminant function relation input pattern suitable synaptic weight adjustments upon repeated presentation training patterns synaptic weight vectors tend follow distribution input patterns due neighborhood updating thus ann learns without supervisor self organizing model naturally represents neuro biological behavior hence used many real world applications clustering speech recognition texture segmentation vector coding etc reference many answers already explain differences detail found gifs codeacademy often help explain differences effectively notice training images labels model learning names images noticedone just grouping clustering model doesnknow anything image machine learning explores study construction algorithms can learn make predictions rather following strictly static program instructions supervised learning machine learning task inferring function labeled training example pair consisting input object typically vector desired output value also called supervisory signal supervised learning algorithm analyzes training data produces inferred function can used mapping new examples computer presented example inputs desired outputs given teacher goal learn general rule maps inputs supervised learning algorithm takes known set input data known responses data output trains model generate reasonable predictions response new data unsupervised learning learning without teacher one basic thing might want data visualize machine learning task inferring function describe hidden structure unlabeled data since examples given learner unlabeled error reward signal evaluate potential solution distinguishes unsupervised learning supervised learning unsupervised learning uses procedures attempt find natural partitions patterns unsupervised learning feedback based prediction results teacher correct learning scheme model find patterns discover groups input data use unsupervised learning methods need large amount data train models willingness ability experiment explore course challenge isnsolved via established possible learn larger complex models supervised give variously labelled example data input along correct answers algorithm will learn start predicting correct results based inputs thereafter example email spam filter unsupervised learning just give data dontell anything like labels correct answers algorithm automatically analyses patterns data example google news supervised learning say kid goes kinder garden teacher shows toys house ball car now teacher gives toys will classify box house ball car based previous experience kid first supervised teachers getting right answers sets tested unknown toys unsupervised learning kindergarten example child given toys told segment similar ones based features like shape size color function etc will try make groups sayc group word supervise means giving supervision instruction machine help find answers learns instructions can easily predict new case unsupervised means supervision instruction find answers labels machine will use intelligence find pattern data will make prediction will just try find clusters similar data supervised learning given data answer given email labeled spam spam learn spam filter given dataset patients diagnosed either diabetes learn classify new patients diabetes unsupervised learning given data without answer letgroup things given set news articles found web group set articles story given database custom data automatically discover market segments group customers different market segments reference supervised learning every input pattern used train network associated output pattern target desired pattern teacher assumed present learning process comparison made networkcomputed output correct expected output determine error error can used change network parameters result improvement performance unsupervised learning learning method target output presented network teacher present desired pattern hence system learns discovering adapting structural features input patternstry keep simple supervised learning technique learning given data set system already knows correct output data set system learns predicting value accuracy check using cost function check close prediction actual output unsupervised learning approach little knowledge result instead derive structure data donknow effect variable make structure clustering data based relationship among variable data donfeedback based prediction inputtarget outputtrain algorithm generalize missing parts supervised target given supervisor telling algorithm exampleoutputalthough segmentation clustering compression usually counted direction hard time come good definition lettake auto encoders compression example inputgiven human engineer tells algorithm target alsosense different supervised learning clustering segmentationsure really fits definition machine learning see question supervised learning labeled data learng house data along price learn predict price unsupervised learning find trend predict prior labels giveng different people class new person comes group new student belong supervised learning know input output example given set cars find ones red ones blue whereas unsupervised learning find answer little without idea output example learner might able build model detects people smiling based correlation facial patterns words smiling supervised learning can label new item one trained labels based learning training need provide large numbers training data set validation data set test data set provide say pixel image vectors digits along training data labels can identify numbers unsupervised learning require training data sets unsupervised learning can group items different clusters based difference input vectors provide pixel image vectors digits ask classify categories may know labels provided training labels supervised learning basically input variablesoutput variableuse algorithm learn mapping function input output reason called supervised algorithm learns training dataset algorithm iteratively makes predictions training data supervised two types classification regression classification output variable category like yes true false regression output real values like height person temperature etcsupervised learning input dataoutput variables called unsupervised learning unlike supervised learning correct answers teacher algorithms left devises discover present interesting structure data types unsupervised learning clustering association supervised learning basically technique training data machine learns already labelled suppose simple even odd number classifier already classified data training therefore uses labelled data unsupervised learning contrary technique machine labels data can say case machine learns scratch simple supervised learning type machine learning problem labels using labels implement algorithm regression classification classification applied output like form true false yes regression applied put real value house price unsupervised learning type machine learning problem donlabels means data unstructured data cluster data grouping data using various unsupervised algorithm supervised machine learning process algorithm learning training dataset predict output accuracy predicted output directly proportional training data length supervised learning input variablestraining dataset output variabletesting dataset use algorithm learn mapping function input output major types algorithms classification algorithms predictive algorithms application areas voice recognition predictselect particular candidate predict stock market price supervised learning supervised learning algorithm analyzes training data produces inferred function can used mapping new examples categories problem regression predict results within continuous output map input variables continuous function example given picture person predict age classification predict results discrete output map input variables discrete categories example tumer cancerous unsupervised learning unsupervised learning learns test data labeled classified categorized unsupervised learning identifies commonalities data reacts based presence absence commonalities new piece data can derive structure clustering data based relationships among variables data feedback based prediction results categories problem clustering task grouping set objects way objects group called cluster similar sense groups clusters example take collection different genes find way automatically group genes groups somehow similar related different variables lifespan location roles popular use cases listed difference classification clustering data mining references supervised learning unsupervised learning machine learning coursera towardsdatascience supervised learning unsupervised learning example supervised learning one bag orange build model one mixed bag apple orange please classify unsupervised learning one mixed bag apple orange build model another mixed bag please classify simple wordsunderstanding feel free correct supervised learning know predicting basis provided data column dataset needs predicated unsupervised learning try extract meaning provided dataset donclarity predicted question answer outcome unsupervised learning groups clusters similar data together receive new data associate identified cluster group understandfeatures hope will help supervised learning supervised learning know output raw inputdata labelled training machine learning model will understand need detect give output will guide system training detect pre labelled objects basis will detect similar objects provided training algorithms will knowstructure pattern data supervised learning used classification example can different objects whose shapes square circle trianle task arrange types shapes labelled dataset shapes labelled will train machine learning model dataset based training dateset will start detecting shapessupervised learning unsupervised learning unguided learning end result known will cluster dataset based similar properties object will divide objects different bunches detect objects algorithms will search different pattern raw data based will cluster datasupervised learning used clustering example can different objects multiple shapes square circle triangle will make bunches based object properties object four sides will consider square three sides triangle sides circle data labelled will learn detect various shapes machine learning field trying make machine mimic human behavior train machine just like identify features recognize patterns train way train machine feeding data various features machine algorithm identify pattern within data classify particular category machine learning broadly divided two category supervised unsupervised learning supervised learning concept input vector data corresponding target value output hand unsupervised learning concept input vectors data without corresponding target value example supervised learning handwritten digits recognition image digits corresponding digit example unsupervised learning grouping customers purchasing update question can answered facts citations editing post closed years ago supposeworking classification problem fraud detection comment spam two problemsworking right nowcurious classification task general know classifier use cases one natural first choice principles choosing one examples type answerslooking manningalintroduction information retrieval book data labeled limited amount use classifier high bias example naive bayesguessing higher bias classifier will lower variance good small amount dataton data classifier doesnreally matter much probably just choose classifier good scalability guidelines even answers likeexplain model upper management person maybe use decision tree since decision rules fairly transparent good care less implementation library issues though also somewhat separate question besides standard bayesian classifiers standard state art methods comment spam detection opposed email spam first need identify problem depends upon kind data desired task predicting category predicting quantity otherwise different algorithms within approach mentioned choice particular algorithm depends upon size dataset source folds train model usingfolds predict performance using fold left possible combination folds first leavefoldkth train remaining folds finishing estimate mean performance folds maybe also variance standard deviation performance choose parameterdepends time usual valuesevenn size dataleave one cross validation prefer letsay methods ann svm knn etc parameter combinations method depending method simply run cross validation method parameter combination select best model method parameterstrain best method parameters data final model things say example use lot methods parameter combinationslikely will overfit cases like use nested cross validation nested cross validation perform cross validation model selection algorithm first split datafolds step choosetraining data remaining one test data run model selection procedure explained possible combinationfolds finishing willmodels one combination folds test model remaining test data choose best one last model train new one method parameters datafinal model course many variations methods things didnmention need information look publications topics book opencv great two pages pages searching amazon preview word discriminative probably google books also will let see pages question two pages greatest gem found book short boosting often effective large amount training data available random trees often effective can also perform regressionnearest neighbors simplest thing can often effective slow requires lots memory neural networks slow train fast run still optimal performer letter recognition svm among best limited data losing boosting random trees large data sets available things might consider choosing algorithm use include need train incrementally opposed batched need update classifier new data frequently tons dataprobably want use bayesian neural nets svm need work training data onedata composed categorical numeric think bayesian works best categorical binomial data decision trees canpredict numerical values audience need understand classifier works use bayesian decision trees since can easily explained people neural networks svm black boxes sense canreally see classifying data much classification speed need svmfast comes classifying since need determine side line data decision trees can slow especiallycomplex complexity neural nets svms can handle complex non linear classification prof andrewoften states always begin implementing rough dirty algorithm iteratively refine classification naive bayes good starter good performances highly scalable can adapt almost kind classification task alsok nearest neighbours neighbour hassle best fit algorithm data will model thus doncare dimensionality fit decision boundary issue computation cost quadratic need compute distance matrix may good fit high dimensional data another good starter algorithm random forests composed decision trees highly scalable number dimensions generally quite acceptable performances finally genetic algorithms scale admirably dimension data minimal knowledge data minimal simplest implementation microbial genetic algorithm one linecode inman harvey one complex cmamogamoea remember often canreally know will work best data try algorithms real side note want theoretical framework test hypothesis algorithms theoretical performances given problem can use pac probably approximately correct learning framework bewareabstract complex summary gist pac learning says use less complex complex enough complexity maximum dimensionality algo can fit algorithm can fit data words use occamrazor sam roweis used say try naive bayes logistic regressionnearest neighbour fisherlinear discriminant anything else take always run basic classifiers first get sense data often experience leastgood enough supervised data train naive bayes classifier unsupervised data can trymeans clustering another resource one lecture videos series videos stanford machine learning watched back video think lecturer discusses generally accepted conventions training classifiers advantages tradeoffs etc always keep account inferenceprediction trade want understand complex relationship occurring datarich inference algorithm hand interested result canhigh dimensional complex less interpretable algorithms like neural networks selection algorithm depending upon scenario type size data set many factors brief cheat sheet basic machine learning trying understand role flatten function keras code simple two layer network takes dimensional data shape outputs dimensional data shape printsshape however remove flatten line printsshape donunderstand understanding neural networks dense input shape function creating hidden fully connected layer nodes nodes connectedinput elements therefore nodes output first layer already flat output shape first layer second layer takes input outputs data shape output first layer already flat shape need flatten read keras documentation entry dense will see call result dense network inputs outputs applied independently stepsx transforms dimensional vectorvectorget output layer sequence vectorsxxx shape order behavior specify may first flatten inputvector apply dense edit people struggled understand explaining image flatten works converting matrix single array short read flattening tensor means remove dimensions except one exactly flatten layer long read take original model flatten layer created consideration can get following model summary summary next image will hopefully provide little sense input output sizes layer output shape flatten layer can read none tip read fact none position means batch size inputs recall first dimension means batch size second means number input features role flatten layer keras super simple flatten operation tensor reshapes tensor shape equal number elements contained tensor non including batch dimension note used method provide output shape parameter details came across recently certainly helped understand aharley vis convinput convmaxpoolingetc flatten layers end show exactly formeddefine final classifications rule thumb first layer network shape data example dataimages layers neurons infeasible makes sense flatteninstead wriitng code handle add flatten layer begining arrays loaded model laterautomatically flattenedflatten make explicit serialize multidimensional tensor tipically input one allows mapping flattened input tensor first hidden layer first hidden layer dense element serialized input tensor will connected element hidden array use flatten way input tensor mapped onto first hidden layer ambiguous flattening converting data dimensional array inputting next layer flatten output convolutional layers create single long feature vector architectures instead using can use second case first create tensor using placeholder create input layer reshape tensor flat form basically flatten convenient function automatically course ways specific use cases keras provides enough flexibility manipulate way want create model keras flatten class important deal multi dimensional inputs image datasets can model input layer build neural network model pass data every single neuron model effectively can understand easily fashion mnist dataset images dataset pixels hence print first image python can see multi dimensional array really canfeed input layer deep neural network first image fashion mnist tackle problem can flatten image data feeding neural network can turning multidimensional tensor one dimensional array flattened array now elements can create input layer neurons handle element incoming data can using single line code sort please let know confusion flatten input tensoriworking sentiment analysis problem data looks like data unbalanced since instances labeled classification using scikitsvc problem know balance data right way order compute accurately precision recall accuracyscore multiclass case tried following approaches first second third however getting warnings like can deal correctly unbalanced data order compute right way classifiermetrics think lot confusion weights used sure know precisely bothers going cover different topics bear weights class weight parameter used train classifier used calculation metrics using different class weights numbers will different simply classifier different basically every scikit learn classifier class weights used tell model important class means training classifier will make extra efforts classify properly classes high weights algorithm specific want details works svc doc make sense feel free mention classifier want know performing can use metrics mentioned accuracy recall scoreaccuracy considered poor choice gives high scores models just predict frequent class will detail metrics note exception accuracy naturally applied class level can see print classification report defined class rely concepts true positives false negative require defining class positive one get warning usingscore recall precision without defining computed question rephrased classification report output one global numberscore options scikit learn warning say pick one specify average argument score method one choose want measure performance classifier instance macro averaging take class imbalance accountscore class will just importantscore class use weighted averaging howeverget importance class whole argument specification metrics super clear scikit learn right now will get better version according docs removing non obvious standard behavior issuing warnings developers notice last thing want mention feel free skipaware scores meaningful computed data classifier never seen extremely important score get data used fitting classifier completely irrelevantway using stratifiedshufflesplit gives random splits data shuffling preserve label distribution lot detailed answers donthink answering right questions understand question two concerns can use scoring functions scikit learn multiclass problem single class problemsway end tangible interpretable numbers classes class lower classes training samples class know unbalanced data fact problem can act accordingly described answers thread however class distribution present data want predict unbalanced training data good representative data hence unbalance good thing posed question responding question metric used multi class classification imbalanced data macromeasure macro precision macro recall can also used easily interpretable binary classificaion already incorporatedmeasure excess metrics complicate methods comparison parameters tuning micro averaging sensitive class imbalance method example works good common labels totally messes others micro averaged metrics show good results weighting averaging isnsuited imbalanced data weights counts labels moreover hardly interpretable unpopular instance mention averaging following detailed survey strongly recommend look sokolova marina guy lapalme systematic analysis performance measures classification tasks information processing management application specific question however returning taskresearch topics commonly used metrics can infer looking literature main evaluation metricsapril daryl chang multiclass sentiment prediction using yelp business link note authors work almost distribution ratings see figure panglillian lee seeing stars exploiting class relationships sentiment categorization respect rating scales proceedingsannual meeting association computational linguistics association computational linguistics link lee moontaegrafe multiclass sentiment analysis restaurant reviews final projectsn link explore accuracy mse considering latter better pappas nikolaos rue marconi andrei popescu belis explaining stars weighted multiple instance learning aspect based sentiment analysis proceedings conference empirical methods natural language processing epfl conf link utilize scikit learn evaluation baseline approaches state code available however canfind need write letter authors work pretty new seems written python cost different errors care avoiding gross blunders look mse difference matters much try mae since doesnsquare diff otherwise stay accuracy approaches metrics try regression approaches since generally outperforms multiclass classifiers like svc ova svm firstlittle bit harder using just counting analysis tell data unbalanced example positive observation just noise error breakthrough science never knowalways better use available knowledge choice status wise okayreally unbalanced look data sometimes can find one two observation multiplied hundred times sometimesuseful create fake one class observations data clean next step use class weights prediction model multiclass metrics experience none metrics usually used two main reasons firstalways better work probabilities solid prediction else separate models prediction give class secondmuch easier compare prediction models build new ones depending one good metric experience recommend logloss mse just mean squared error fix sklearn warnings just simply yangjie noticed overwrite average parameter one values micro calculate metrics globally macro calculate metrics label weighted macro auto weights warnings came calling metrics functions default average value binary inappropriate multiclass prediction good luck fun machine learning edit found another answerer recommendation switch regression approaches agree far remember even thing multiclass regression yes multilabel regression far different yespossible cases switch regression classification classes somehow sorted pretty rare recommend scope scikit learn try another powerful classification tools gradient boosting random forest favorite kneighbors many can calculate arithmetic geometric mean predictions timeget even better email contains date time location text becomes hyperlink possible create appointment look map simply tapping link works emails english languages also love feature like understand naive way many regular expressions run however going scale will work specific language date format etc think apple must using concept machine learning extract entitiespmh etc idea apple able extract entities quickly email client machine learning algorithm apply accomplish task likely use information extraction techniques demo stanfordsutime tool sutime process extract attributesgrams consecutive words document use classification algorithm feed positive negative examples might get away examples merrier algorithm learns based examples can apply future examples hasnseen might learn rules decent video google engineer subjecttechnology apple actually developed long time ago called apple data detectors can read appliescontextual actionsneat called temporal expression identification parsing google searches get starteden safe sclient psyq timebank timeml timexen safe sclient psyq temporal expression tagger one part puzzle nsdatadetector class used recognize standard types like phone numbers wrote parser using pyparsingreally simple just need get different ways right arenmany took hours pretty fast apple patent system method performing action structure computer datastory patent apples patent nsdatadetectorin keras can return output now save history attribute history object file uses use following way save history dictionary case want plot loss accuracy later later want load history can use comment answer accurately states storing history json work anymore tensorflow keras issues typeerror object type float json serializable ways tell json encode numpy objects can learn questionnothing wrong using json casejust complicated simply dumping pickle file can convert pandas dataframe object can saved suit needs step step easiest way saving loading history dictionary can retrieve desirable values using keys model history can saved file follows history objects history field dictionary helds different training metrics spanned across every training epoch loss will return loss modelepoch training order save pickle dictionary simple save different lists dictionary appropriate file came across problem values inside list keras json seriazable therefore wrote two handy functions use cause savehist just needs get path json file saved history object returned keras fit fit generator methodsure many ways fiddled around came version first custom callback enables grabbing updating history end every epoch also callback save model handy crash shutdown can pick training last completed epoch second helper functions exactly things say called losshistory callback need set history filename something like data set model filename something like data modelone final tweak make sure mess history end training assuming stop start stick callbacks whenever want history loadhist history filename gets history back funkiness comes json lists wasnable get work without converting iterating anyway know workscranking days now donknow missed anything canget work let know can save history attribute csvlogger callback will helpful code saves model weight history training form datasheet file will create associated file given model path home user modelpickled path home user model history pickle upon reloading model callback will continue epoch left trying grasp timedistributed wrapper keras get timedistributed applies layer every temporal slice input experiment got results understand short connection lstm layer timedistributed just dense layer bear results models got output shape none can anyone explain difference timedistributed dense layer rnn layer keras building sequential model usually second dimension one sample dimension related time dimension means example data dim sample time width length channel apply convolutional layer using timedistributed applicable dim sample width length channel along time dimension applying layer time slice order obtainoutput case dense keras version dense default applied last dimension input shapempget output shapemcase dense timedistributed dense equivalent want make simple neural network uses relu function can someone give clue can implement function using numpy couple ways timing results following code get multiplication seems fastest can much easier waycompletely revising original answer points raised questions comments new benchmark script takes care use different ndarray implementation iteration results edit jirassimok mentioned function will change data place runs lot faster timeit causes good resultskind cheating sorry inconvenience found faster method relu numpy can use fancy index feature numpy fancy indexs per loop mean std dev runs loops benchmark richardhncomparison fair andreabiagiocomment place methodx will modifyfirst loop benchmark timing get results place maximum method bit faster maximum method may omits variable assignmentstill slower multiplication method sinceimplementing relu func may savebackprop relu recommend use multiplication method numpy didnfunction relu define follow example parametersrelu want implement can use following codematrix relualso equalabssingle neuron net net activity neuroninput net dotx dot dot productx weight vector input vector respectively dot function defined numpy package python neurons layer net vector precise implementation want improve question update question focuses one problem editing post closed years ago community reviewed whether reopen question months ago left closed original close reasonresolved xgboost guide training model can saved model feature map can also dumped text file saved model can loaded follows questions following solved problem functions save model dump model save model difference dump model can save feature name save tree text format load model will work model save model model dump model can used example xgbfi loading model need specify path models saved example model loaded file edit xgboost documentation version dump model used saving model interpretation saving loading model save model load model used please check docs details also difference learning api scikit learn api xgboost latter saves best ntree limit variable set training early stopping can read details article save load xgboost python save model method recognize format file name json specified model saved json otherwise text file donuse pickle joblib may introduces dependencies xgboost version canonical way save restore models load model save modellike store archive model long term storage use save model pythonrelevant documentation latest versions xgboost also explains difference dump model save model note can serializeserialize models json specifying json extension using convenient allows proper version control model sincesimple text file easy way saving loading xgboost model joblib library using sklearn api can use following used booster method loading will get xgboost booster within python api sklearn booster sklearn api yeah seems pythonic way load saved xgboost model data using sklearn api trying transfer learning purpose want remove last two layers neural network add another two layers example code also output error removed layer using pop tried add outputting error know probable reason error improper use syntax use edit tried remove add layers keras allowing added loading external weights showing error can take output last model create new model lower layers remains check use models update edit new error trying create new model global img actually used previous model creation actually defining local img global img obviously connected upper layers symbolic graph nothing loading weights better resolve problem instead use working intended see issue suggested two options one option recreate model copy layers instance want remove last layer add another one can another option use functional model output means last layeroutput final output code actually didnremove layers added another head path alternative wesams answer donknow layer names can simply cut last layer viausing scikit learn python develop classification algorithm predict gender certain customers amongst others want use naive bayes classifier problem mix categorical dataregistered online accepts email notifications etc continuous dataage length membership etc havenused scikit much suppose gaussian naive bayes suitable continuous data bernoulli naive bayes can used categorical data however since want categorical continuous data model donreally know handle ideas much appreciated least two options transform data categorical representation computing percentiles continuous variables binning continuous variables using percentiles bin boundaries instance height person create following bins small small regular big big ensuring bin contains approximately population training set donutility perform automatically scikit learn complicated fit unique multinomialcategorical representation data independently fit gaussianmodel continuous part data multinomialmodel categorical part transform dataset taking class assignment probabilities predict proba method new features multinomial probas gaussian probas refit new model new features hopelate recently wrote library called mixed naive bayes written numpy can assume mix gaussian categorical multinoulli distributions training data featuresexample letassume first features categorical distribution last gaussian fit method just specify categorical features indicating columns follow categorical distribution pip installable via pip install mixed naive bayes information usage simple answer multiply resultnaive bayes based applying bayes theorem naive assumption independence every pair features meaning calculate bayes probability dependent specific feature without holding others means algorithm multiply probability one feature probability second feature totally ignore denominator since just normalizer right answer yaronapproach needs extra step step normalization step take look remykaremmixed naive bayes example lines probabilities gaussian categorical modelsp respectively multiplied together line line extract normalized line fourth line bottom extract hybrid features can check implementation author presented mathematical justification quora answer might want check will need following steps easy enough see can add prior instead using learned example data set doesncontain categorical features variablesquite clear regression data predict price now want regression analysis data contain categorical features features district condition material security type can regression data transform string categorical data numbers manually mean create encoding rules according rules transform data numeric values simple way transform string data numbers without create encoding rules manually maybe libraries python can used risks regression model will somehow incorrect due bad encoding yes will convert everything numbers requires thinking attributes represent usually three possibilities carefull infuse information application case categorical data can create dummy variables values possible valueg can easily done pandas will result create mapping sortable categoriesg old renovated new also possible pandas result use mean category past known events say dataframe last known mean prices cities result linear regression categorical variables careful dummy variable trap dummy variable trap scenario independent variables multicollinear scenario two variables highly correlated simple terms one variable can predicted others can produce singularity model meaning model just wonwork read idea use dummy variable encoding drop first true will omit one column category converting categorical variable dummy indicator variables will lose relevant information simply point dataset can fully explained rest features complete code can housing dataset categorical features one numerical features trying predict first need split initial dataset input variables prediction assuming pandas dataframe look like input variables prediction convert categorical variable dummy indicator variables drop one category now check shapedrop first true will see columns less one categorical variables can now continue use linear model scikit learn implementation look like can use dummy coding case python libraries dummy coding options example pandas one way achieve regression categorical variables independent variables mentioned using encoding another way usinglike statistical formula using statmodels library code snippet dataset summary regressiondoes tensorflow something similar scikit learnone hot encoder processing categorical data using placeholder realize can manually pre process data sending tensorflow built convenient tensorflow now native one hotcan cases let compute cross entropy directly sparse labels instead converting one hot previous answer case want old way salvadoranswer correct used nativeinstead numpy though can natively tensorflow using sparse dense operators output labels one hot matrix batch sizenum labels note also assume will eventually part release tensorflow also cases can let training without needing convert one hot encoding edited add end may need explicitly set shape labels shape inference doesnrecognize size num labels component donneed dynamic batch size derived size can simplified edited change assignment outshape per comment availableeasy use assume possible categories cat dog bird human instances cat human depth indices keep mind provide index will get zeros one hot vector old answer function available looking though python documentation found anything similar one thing strengthen belief exist example write one hot manually can also scikitlearn numpy simple short way one hot encode integer list intergers recent versions tensorflow nightlies maybe evencalled hand dense matrix want look aggregate values want use embedding lookup function maybedue changes tensorflow since nov dgaanswer produced errors get work following modifications take lookused input data see can use sparse indices argument indicates onesoutput shape set number possible outputs sparse values desired type will determine type output type sparse valuesembedding ops scikit flow examples deal categorical variables etc just begin learn tensorflow suggest trying examples tensorflow skflow first familiar tensorflow fairly easy insert tensorflow code build custom model want also examples hope examples images text understanding get started letknow encounter issues post issues tag skflow current versions tensorflow implement following function creating one hot tensors one hot mentioned dga tensorflow need specify depth otherwiseget pruned one hot tensor like manually note arguments order couple ways way version cfb dga example shortened bit ease understanding worksversion sep tensorflow compatible answer can efficiently using tensorflow transform code performing one hot encoding using tensorflow transform shown information refer tutorialtransform binary prediction model trained logistic regression algorithm want know features predictors important decision positive negative class know coef parameter comes scikit learn package donknow whether enough importance another thing can evaluate coef values terms importance negative positive classes also read standardized regression coefficients donknow say features like size tumor weight tumor etc make decision test case like malignant malignant want know features important malignant malignant prediction make sort sense one simplest options get feeling influence given parameter linear classification model logistic one consider magnitude coefficient times standard deviation corresponding parameter data consider example alternative way get similar result examine coefficients model fit standardized parameters note basic approach number techniques finding feature importance parameter influence exist usingvalues bootstrap scores various discriminative indices etc pretty sure get interesting answersusing tfidfvectorizer scikit learn feature extraction text data csv file score can review text pulled data dataframe can run vectorizer code traceback error get checked csv file dataframe anythingread nan canfind anything rows none return isnan truereview head looks like need convert dtype object unicode string clearly mentioned traceback doc page tfidf vectorizer fit transform raw documentsnone parameters raw documents iterable iterable yields either str unicode file objects find efficient way solve problem course can usereviewconvert entire series found using function will consume much memory series want convert really big test seriesrows data astypewill consumememory instead use lambda expression convert data series str result will also accepted fit transform function will faster will increase memory usagesure will work doc page tfidf vectorizer fit transform raw documentsnone parameters raw documents iterable iterable yields either str unicode file objects actually iterable must yieldsreviews dataset tried astypevalues worked answer python avoid memoryerror transform text data unicode using astypecross entropy formula following give loss instead loss since log example treating output probabilities required mathematical definition cross entropy pytorch treats outputs donneed sum need first converted probabilities uses softmax functionpbecomes translating output probabilities whence understanding correct pytorch doesncompute cross entropy way pytorch uses following formula since scenarioclass evaluate expression get pytorch considers natural logarithm like add important note often leads confusion softmax loss function really activation function specific task used multi class classification normalize scores given classes get probabilities class sum softmax combined cross entropy loss calculate loss model unfortunately combination common often abbreviated using term softmax loss whereas pytorch calls cross entropy loss combination sic computes fact cross entropy log probability predictions inputs sometimes called logits technically putting mass target predicted distribution given log probability inputs pytorchcrossentropyloss expects unbounded scores interpretable logits log odds input probabilitiestraditionally defined run keras neural network model might see something like console time goes loss hopefully improves want log losses file time can learn tried doesnwork sure level logging need situation also tried using callback like obviously isnwriting file whatever method callback logging module anything else love hear solutions logging loss keras neural network file thanks can use csvlogger callback example look keras callbacks simple solution problem every time fit methods used result special callback called history callback returned field history dictionary metrics registered every epoch get list loss function values every epoch can easlyeasy save list file update try update solution problem recording loss every batch written keras callbacks documentation create callback paragraph old question goes keras history output perfectly matches pandas dataset input want entire history csv one line history csv cheers can redirect tensorflow quite easy get loss accuracy epoch returns history object validation loss values validation metrics values validation data donvalidation data save list data text file use code best create lambdacallback now just add like problem train data placed ram due train data size need method first builds one tree whole train data set calculate residuals build another tree like gradient boosted tree obviously call model param batch dtrain loop will help case just rebuilds whole model batch try saving model train first batch successive runs providesmall experiment ran convince works first split boston dataset training testing sets split training set halves fit model first half get score will serve benchmark fit two models second half one model will additional parameter xgb model passing extra parameter didnmake difference expect scores similar fortunately new model seems perform much better first reference version process update parameter might helpexperiment output created gist jupyter notebook demonstrate xgboost model can trained incrementally used boston dataset train model experiments one shot learning iterative one shot learning iterative incremental learning incremental training passed boston data model batches size gist gistiterate data multiple times model converge accuracy attained one shot data learning corresponding code iterative incremental learning xgboost xgboost version looks like donneed anything call provide model result previous batch based problem regarding dataset size really need incremental learning dealing streaming app instance check spark flink two frameworks can train large datasets small ram leveraging disk memory framework deal memory issues internally flink solved first spark caught recent releases take look paulperrycode change one line train split round len train idx train split len train idx model update will changed lot leaf result dump file updated model good update sample set relative small binary logistic updated model unusable update sample set one class one possible solution tested used dask dataframe act pandas dataframe assume utilize disk reads ram helpful links link mentions use xgboost also see also see experimental options xgboost ready production agree desertnaut solution dataset split batches initial fit without xgb model parameter first next fits will xgb model parameter likeusing sklearn apibased xgboostincremental decision tree see gaenari continuous chunking data can inserted updated rebuilds can run concept drift reduces accuracytrying learn scikit learn machine learning using boston housing data set based new model clf sgd trying predictbased first instancetrain however result quite odd instead range price houses guess value scaled back trying figure success tip welcome thank much can use inverse transform using scalery object bit late game just donscalescalingactually loose units regression loss optimization actually determined relative differences features btw house prices monetary value common practice take logarithm obviously need get back actual dollars euros using weight calculations occurrence ratio tools additionally will grateful point python based solution library thanks one way extract words occur frequently document expect chance example say larger collection documents term markov almost never seen however particular document collection markov shows frequently suggest markov might good keyword tag associate document identify keywords like use point wise mutual information keyword document given pmi term doc logterm doctermdoc will roughly tell much less surprised come across term specific document appose coming across larger collection identify best keywords associate document just sort terms pmi score document pick highest score want extract multiword tags see stackoverflow question extract common significant phrases series text entries borrowing answer question nltk collocations covers extract interesting multiword expressions usinggram pmi lines code first key python library computational linguistics nltk natural language toolkit stable mature library created maintained professional computational linguists also extensive collection tutorials faqs etc recommend highly simple template python code problem raised question althoughtemplate runs supply text stringdone will return list word frequencies ranked list words order importance suitability keywords according simple heuristic keywords given document obviously chosen among important words documentwords likely distinguish another document priori knowledge textsubject matter common technique infer importance weight given word term frequency importance frequency turn distributions mapping words probabilities used dissect corpus product reviews latent ideas spoken across documents customer service product usability etc basic model advocate way convert topic models single word describing topic people come kinds heuristics model trained recommend try playingrequire hand annotate anything great flip side might deliver topics expecting give simple solution problemsure cleverer stats based solutions though need solution use larger project rather interests sake yahoo boss key term extraction method latent dirichlet allocation hierarchical dirichlet process can used generate tags individual texts within greater corpus body texts extracting important words derived topics basic example run lda corpus define two topics find text corpus one topic another top words define first topic define second without duplication considered tags given text method provides strong results tags generally represent broader themes given texts general reference preprocessing needed codes found can find tags following process using gensim heuristic way deriving optimal number topics lda found answer although hdp require number topics input standard cases still use lda derived topic number hdp can problematic assume corpus found topics want tags per text assume variable corpus preprocessed list lists subslist entries word tokens initialize dirichlet dictionary create bag words texts converted indexes component tokens words create lda hdp model following code produces ordered lists important words per topic note num tags defines desired tags per text find coherence topics across texts percentage text coheres given topic words associated topic can combine tags following corpus tags will list tags text based coherent text derived topics see answer similar version generates tags whole text corpus dataset sklearn plotted distribution load used fewest number variables attributes regression can get distribution type parameters distribution closely resembles know target values positive skewed positve skew right skew way python provide distributions get best fit target data vector actually suggest fit based datagiven realllllly useful people theoretical statistical knowledge little experience applying real data bonus make sense use type approach figure posterior distribution real data use approach best knowledge automatic way obtaining distribution type parameters sample inferring distribution sample statistical problem opinion best can attribute try fit attribute reasonably large list possible distributions python example scipy evaluate fits pick best one can done performing kolmogorov smirnov test sample distributions fit implementation scipy picking one minimisestest statistic bonus make sensebuilding model variables pick fit one although goodness prediction depend quality data distributions using fitting building model can use code fit according maximum likelihood different distributions datas can see sample snippet use parameters obtained fitting empirical distribution theoretical ones scipy python can pick distribution best log likelihood also criteria match best distribution bayesian posterior probability aic bic bicc values bonus questionthink generic answer set data significant obtained conditions real word datas can code also works fitter provides iteration process possible fitting distributions also outputs plot summary table statistic values fitter package provides simple class identify distribution data samples generated uses distributions scipy allows plot results check probable distribution best parameters basically iterative fit test procedure described answers conveniently executed module resulty series code parameters fitted distributions dict get list available distributions testing takes long timebest use implemened get common distributions potentially extend likely distribution done code make sure current newer fitter version installed logging errors previous one conda environment needed similar question see may interrested michel baudin answer explaining code assesses around different distributions available openturns library chooses best one according bic criterion looks something likeslightly confused regard save trained classifiertraining classifier time want use obviously really bad slow save load need code thanks advance helpusing python nltk naive bayes classifier save load later went thru problem save object since elefreqdistr nltk class anyhow nltk slow training took mins decent set decided implement version algorithm run pypy rename pyx install cython takes minutes set can simply save data jsonimplement pickle faster better started simple github project check code retrain pickled classifer using decision tree error raised situation appeared used back propagation can solve traceback recent call last file ipython inputaeline module runfileprogramdata anaconda lib site packages scipy lib numpy wdirprogramdata anaconda lib site packages scipy lib fileprogramdata anaconda lib site packages spyder utils site line runfile execfile filename namespace fileprogramdata anaconda lib site packages spyder utils site line execfile exec compile filename exec namespace fileprogramdata anaconda lib site packages scipy lib numpy line module module named happening due version incompatibility numpy scipy numpy latest versions deprecated able get rid error needed upgrade scipy pip installscipy facing error using lexnlp package got fixed installing install lexnlp knowexplicitly using project knowsolved using also faced issue loading model fixed upgrading libraries try installing numpy version using pip pip assuming already installed pip using jetsonaarch based device can solve issue installing latest numpy scipy libraries also worksbased systems can skip libatlas base dev gfortranbased systems solved link apparently open issue downgrade numpy like know way implement different score function scikit learn package like one tensorflow model get different score will run session get prediction really need sklearn calculate precision recallscore can easily expressish way looking formulas now actual predicted values vectors can calculatetnfn using now metrics easy calculate maybe example will speak previous answers specify handle multi label case version implementing three types multi labelscore tensorflow micro macro weighted per scikit learn update wrote blog post compute streaming multilabelscore case helps anyonelonger process donwant overload answer outputs since enough reputation add comment salvador dalis answer wayrealy good idea use metrics apis provided exampletrained linear regression modelcaretnow trying generate confusion matrix keep getting following error error pred testing final data reference factors must number levels error occurs generating confusion matrix levels objects figure problem structure levels given help greatly appreciated making cracked issue guess happened data argument casted factor expected try hope helps table pred table testing final will see least one number testing set never predicted meant different number levels example custom made function get around problem however found trick works fine give exactly confusion matrix function whenever try build confusion matrix make sure true values prediction values factor datatype pred testing final must type factor instead check levels check type variables convert factor testing final type int conver factor build confusion matrix something like follows seem work idea similar nayriz key make sure factor levels match similar error forced glm predictions class dependent variable example glm will predict numeric class target variable factor class ran error erroneous code result corrected code result problem due nas target variable datasetusing tidyverse can use dropfunction remove rows contain nas like basemight look something like get error creating confusion matrix creating confusion matrix need make sure predicted value actual value data type factors data types must convert factor data factors generating confusion matrix conversion start compiling confusion matrix using regression trying generate confusion matrix believe confusion matrix used classification task generally people usermse metrics tried many examplesmicro accuracy scikit learn seemicro accuracy always true script outputmicro accuracy classification tasks every test case guaranteed assigned exactly one class microequivalent accuracy woncase multi label classification dealing multi class classification every test data belong class multi label casecan call true negatives true positives formula wise correctionscore precision recall precision recall micoaverage precision recallaccuracy equal cases every instance must classified one one class simple way see looking formulas precisiontprecalltpnumerators everyone class another classesfp makes denominators precision recallwill also equal inputs able show issue investigated came just thinking theory impossible accuracyscore every single dataset reasonscore independent true negatives accuracy taking datasetacc adding true negatives getacc just try find can use caffe just took look different prototxt files examples folder one option donunderstand possible values seem somebody please explain options common practice decrease learning rateoptimization learning process progresses however clear exactly learning rate decreased function iteration number use digits interface caffe will able visually see different choices affect learning rate fixed learning rate kept fixed throughout learning process inv learning rate decayingstep learning rate piecewise constant dropping everyiterations multistep piecewise constant arbitrary intervals can see exactly learning rate computed function sgdsolver dtype getlearningrate solvers sgd recently came across interesting unconventional approach learning rate tuning lesliesmithwork pesky learning rate guessing games report leslie suggests usepolicy alternates decreasing increasing learning rate work also suggests implement policy caffe look inside caffe master src caffe proto can find online will see following descriptionsdealing imbalanced dataset want grid search tune modelparameters using scikitgridsearchcv oversample data want use smote know can include stage pipeline pass gridsearchcv concern think smote will applied train validation folds supposed validation set oversampled right whole pipeline will applied dataset splits yes can turn around thanks lot advance yes can done imblearn pipeline see imblearn pipeline handle samplers correctly described similar question called predict will skip sampling method leave data passed next transformer can confirm looking source code work correctly need following fill details necessary pipeline will take care rest fine tuning mobilenet new classes add new layers get error also using get error lower mean saw fine tuning scripts arguments name modelcase tensor must passed layer calling argument therefore must like make clear equivalent confused random state parameter sure decision tree training needs randomness thoughts practical decision tree learning algorithms based heuristic algorithms greedy algorithm locally optimal decisions made node algorithms guarantee return globally optimal decision tree can mitigated training multiple trees ensemble learner features samples randomly sampled replacement basically sub optimal greedy algorithm repeated number times using random selections features samples similar technique used random forests random state parameter allows controlling random choices interface documentation specifically states int random state seed used random number generator randomstate instance random state random number generator none random number generator randomstate instance used random algorithm will used case passing value whether specific int randomstate instance will change rationale passing int value otherwise make outcome consistent across calls call random state value every timeget result cited part documentation misleading underlying problem greediness algorithm cart algorithm deterministic see finds global minimum weighted gini indices repeated runs decision tree can give different results sometimes possible split data using different features still achieve gini index described two splits equally good case random state parameter effect issue linked teatraderanswer discusses detail result discussion following section added docs emphasis added random state int randomstate instance none default none controls randomness estimator features always randomly permuted split even splitter set best max featuresfeatures algorithm will select max features random split finding best split among best found split may vary across different runs even max featuresfeatures case improvement criterion identical several splits one split selected random obtain deterministic behaviour fitting random state fixed integer see glossary details illustrate letconsider following example iris sample data set shallow decision tree containing just single split output code will alternate two following trees based random state used reason splitting either petal length petal width will perfectly separate setosa class two classes can see leftmost setosa node contains setosa observations change just one observation data one previous two splitting criteria longer produces perfect separation random state will effect will always end result example first split will now always petal length since split petal width can separate setosa classes words lesser decreases gini score random forest consists many decision trees create individual tree random selections features samples see random forest parameters details bigger role random state parameter case training just single decision tree true default parameters worth noting parameters affected randomness changed default value notably setting splitter random couple related issues many machine learning models allow randomness model training specifying number random state ensures get results run considered good practice use number model quality wondepend meaningfully exactly value significant difference choosing currently training epochs epoch takes long time graph showing improvement looks jumpy datapoints figure can get smoother graph use epochs want know first downside based said sounds like need larger batch size course implications impact steps per epoch number epochs solve jumping around implications larger batch size reduce epochs adjust steps per epoch steps per epoch connect epochs naturally want epoch generator pass training data one time achieve provide steps per epoch equal number batches like equation largest batch size lower steps per epoch next will choose epoch based chosen validation choose think best steps per epoch tells network many batches include epoch definition epoch considered complete dataset run model entirety words means training samples run model discussion letassume size training examplesalso definition know batch sizetensorflow page says steps per epoch want run training specific number batches dataset can pass steps per epoch argument specifies many training steps model run using dataset moving next epoch now suppose training sizebatch sizemeans data grouped batches according quote maximum value can assign steps per epoch computed one answers ioannis nasios however necessary set value example can choose value just need aware training will performed number batches reason jumpy error values size batch correctly mentioned answer chris farr training evaluation dataset reset end epoch instead just keep drawing next batches dataset will eventually run data unless infinitely looping dataset advantage low value steps per epoch different epochs trained different data sets kind regularization however limited training size using subset stacks want decision one make steps per epoch denote number batches selected one epoch steps selected network will train batches complete one epoch select large number epochs can computationali wish implement early stopping keras skleangridsearchcv working code example modified grid search hyperparameters deep learning models python keras data set may downloaded modification adds keras earlystopping callback class prevent fitting effective requires monitor val acc argument monitoring validation accuracy val acc available kerasclassifier requires validation split generate validation accuracy else earlystopping raises runtimewarning early stopping requires val acc available note fixme code comment note replace val acc val loss question can use cross validation data set generated gridsearchcvfold algorithm instead wasting training data early stopping validation set answer question edited clarified rushing implementation issues always good practice take time think methodology task arguably intermingling early stopping cross validation procedure good idea letmake example highlight argument suppose indeed use early stopping epochs fold cross validationhyperparameter selection suppose also end hyperparameter setgiving best performance say binary classification accuracy now suppose second best hyperparameter setgives accuracy examining closely individualfolds see best casecv folds exhausted max epochs early stopping kicked say epochs respectively now imagine examining second best setseefolds exhausted epochs stopped early enough epochs conclusion experiment arguably found inconclusive situation experiments might reveal actually best hyperparameter set provided course thought look details results first place needless say automated callback might missed best model despite fact actually tried wholeidea implicitly based equal argument course never true practice approximated best possible way feel number epochs hyperparameter just include explicitlyrather inserting back door early stopping thus possibly compromising whole process mention early stopping hyperparameter patience intermingling two techniques doesnmean course use sequentially obtained best hyperparameterscan always employ early stopping fitting model whole training set provided course separate validation set field deep neural nets still young true yet establish best practice guidelines add fact thanks amazing community sort tools available open source implementations can easily find admittedly tempting position mixing things just happen available necessarily saying attempting just urging caution combining ideas may designed work along old answer question edited clarified see updated accepted answer sure understood exact issue question quite unclear include many unrelated details never good asking question see donactually include arguments validation data model kerasclassifier function call interesting donfeel need training data will take care training validation folds provided want keep hyperparameter values included example function call simply can see clear explained examples regarding use gridsearchcv keras single split want splits can usevalidation split fixed ratio construct splits meet criteria might paranoid donuse early stopping data set validation data set since indirectly used create model also think using early stopping final model also done hyper parameter input image data input non image data implemented architecture tensorflow pytorch examples found one inputlayer can define forward func process inputs separately combine middle layer combine assume mean concatenate two inputs assuming concat along second dimension note define number inputsbuilding model keras using tensorflow function reduce sumnormalize last layer encountered problem searched solution related keras tensor code error valueerror output tensors model must output tensorflow layer thus holding past layer metadata found tensornormalize shape dtype float noticed without passinglayer functions model works fine can someone please explain problem suggestion fix found way work around solve problem anyone encounters issue can use lambda layer wrap tensorflow operations issue adding tensorsx somewhere model instead using addx solved problemtrying convert string array categorical variables integer array categorical variablesrealize can done loop imagine easier way thanks use often can used recreate original array uniques years isnmentioned answers personal reasons always pandas imported modules necessarily sklearn also quite straightforward one way use categorical function return value categoricalactually design matrix hence call argmax get close desired format another option use categorical pandas series another way use insist values start resulting array simplyafterwards might worth bring sklearn dependency project good option sklearn already imported another approach use pandas factorize map items number can also try something like better knowwish set specific index valuestwo categories next code will work like charm lstm rnn can used text generation shows way use pre trained glove word embeddings keras model sample approach tried sample code psuedocode train lstm predict will appreciatedcreated gist simple generator builds top initial idealstm network wired pre trained word vec embeddings trained predict next word sentence data list abstracts arxiv websitehighlight important parts code fine except number iterations train default iter seems rather low besidesdefinitely bottleneck lstm training takes much longer iter looks better result embedding matrix saved pretrained weights array shape vocab size emdedding size code almost correct except loss function since model predicts next wordclassification task hence loss categorical crossentropy sparse categorical crossentropychosen latter efficiency reasons way avoids one hot encoding pretty expensive big vocabulary note passing pre trained weights weights order work sparse categorical crossentropy loss sentences labels must word indices short sentences must padded zeros common length pretty straight forward model outputs vector probabilities next word sampled appended input note generated text better diverse next word sampled rather picked argmax temperature based random samplingused described doesnmake much sense able produce sentences look least grammatically sound sometimes link complete runnable scriptlearning keras api tensorflow guide tensorflow website found example custom loss funciton reduce mean function custom loss function will return scalar right define loss function like far know first dimension shapestruepred batch size think loss function return loss values every sample batch loss function shoud give array shape batch size function gives single value whole batch maybe example wrong anyone give help problem read source code model class provide loss function please notefunction loss class method ths loss function used construct lossescontainer object stored stored lossescontainer losses according source code lossfunctionwrapper class overall loss value training batch calculated lossfunctionwrapper call method inherited loss class first calls method obtain array losses every sample training batch losses fianlly averaged get single loss value whole batchmethod loss function provided method calledthink custom loss funciton return array losses insead single scalar value besides write custom loss class method call method custom loss class also return array rather signal value opened issue githubconfirmed custom loss function required return one loss value per sample example will need updated reflect actually far know shape return value loss function important can check reduction types reduction documentation compile method documentation says loss argument partially addressing point loss string name objective function objective functiony truepredtrue ground truth values shape batch sizedn except sparse loss functions sparse categorical crossentropy shape batch sizednpred predicted values shape batch sizedn returns weighted loss float tensor custom loss instance used reduction set none return value shape batch sizednper sample per timestep loss values otherwise scalar model multiple outputs can use different loss output passing dictionary list losses loss value will minimized model will sum individual losses additionworth noting built loss functionskeras usually reduced last dimension doubt custom loss function returns scalar value work can run following snippet will see model train converge properly opened issue githubconfirmed custom loss function required return one loss value per sample example will need updated reflect think question posteddel totally legit correct custom loss function return loss value per sample explanation provided today also correct end depends kind reduction used one uses class api create loss function reduction parameter automatically inherited custom class default value sum batch size used simply averaging loss values given batch options sum computes sum instead averaging last option none array loss values returned also mentioned keras documentation differences reduction irreverent one using reduction automatically handledkeras lastly also mentioned custom loss function created array losses individual sample losses returned reduction handled framework linksscalar machine learning loss use sum losses individual training examples scalar value since examples using single network thus need single loss value update parameters using parallel computation making container simpler feasible way keep track indices losses computed using batches train whole training set tensorflow documentation missed clearly stated clarified keras documentation says note important difference loss functions like like function version perform reduction default class instance also states default loss functions return one scalar loss value per input sample dimensionality can increased multiple channel scalar value loss question pytorchbackward function donthinkgetting right output output maybethink output suppose causexx please read carefully documentation backward better understand default pytorch expects backward called last output network loss function loss function always outputs scalar therefore gradients scalar loss using chain rule thus default backward called scalar tensor expects arguments example yields expectedda however call backward tensor longer scalar function expectsactually need outputjkpytorch support non scalar function derivatives instead pytorch assumes intermediate tensor somewhere upstream scalar loss function chain rule provideslossj upstream gradient size actually argument provide backward casegd lossij gradients calculated chain rulelossjlossjjj since provided upstream gradients got provide upstream gradients ones yields expectedchain rulecurrently working problem compares three different machine learning algorithms performance data set divided data set training testing sets performed grid search best parameters algorithm using gridsearchcvtraintrain first question suppose perform grid search training set suppose whole data set second question know gridsearchcv usesfold implementation mean performed cross validation usedtraintrain three algorithms compare gridsearchcv answer appreciated thank estimators scikit name endsperform cross validation need keep separate test set measuring performance need split whole data train test forget test data pass train data grid search gridsearch will split train data train test tune hyper parameters passed finally fit model whole train data best found parameters now need test model test data kept aside beginning will give near real world performance model use whole data gridsearchcv leakage test data parameter tuning final model may perform newer unseen data can look answers describe gridsearch detail yes gridsearchcv performs cross validation understand concept correctly want keep part data set unseen model order test train models train data set test testing data set almost might want check encode country column like succeed get desire transformation via using onehotencoder nowgetting depreciation message use categories auto transformation done independent columns like country age salary etc achieve transformation datasetcolumn actually warnings futurewarning handling integer data will change version currently categories determined based range max values future will determined based unique values want future behaviour silence warning can specify categories auto case used labelencoder onehotencoder convert categories integers can now use onehotencoder directly second categorical features keyword deprecated version will removed can use columntransformer instead use columntransformer instead deprecationwarning future define columns onehotencoder directly unless want use categories auto first message also tells use onehotencoder directly without labelencoder first finally second message tells use columntransformer like pipe columns transformations equivalent code case see also columntransformer documentation example encoding categorical data basically changing text numerical datacountry name version can write code can see donneed use labelencoder anymore reminder will keep previous datacolumn will replace will encoded use labelencoder directly use onehotencoder way can one hot encoding pandas python give names newly formed columns add dataframe check pandas documentation issue following worked hope helps use following code code solve error updating code note add dtype canconvert one hot encoder anything imports basically question guy example nltk book naive bayes classifier considers whether word occurs document feature doesnconsider frequency words feature look bag words one answers seems suggest candone built nltk classifiers case can frequency bag wordsclassification nltk scikit learn implementation multinomial naive bayes right variant naive bayes situation support vector machine svm probably work better though ken pointed comments nltk nice wrapper scikit learn classifiers modified docssomewhat complicated oneidf weighting chooses best features based chi statistic passes multinomial naive bayes classifier bet somewhat clumsysuper familiar either nltk scikit learn printed perfect decent consideringsuper easy problemtrained features nltk bayes classifier nominal numeric means can take finite number discrete values labels cantreated frequencies bayes classifier directly use word frequency feature something like use frequent words text feature setquite different thing maybe classifiers nltk depend frequency wouldnknow lookedsayworth checking sentence word multiple times will just add probs multiple times word appears multiple times class training data reflect word count added accuracy countgrams tri grams etc separate features helps manually write classifiers understand exactly happening need imporve accuracy use pre packaged solution doesnwork enough much can need help understanding error executing code error raise valueerrory must size csv file rows column takentest set visible code printtrain shape seebettrainmatrix single columntrainvector turn get different sizes think usingtrain plotting error originates solve problem slicing will give dimensional array including rows columns excluding last column slicing will give dimensional array including rows second column make array also dimensional use reshape none instead will makey comparable alternative making arrays dimensional making one dimensional one instead selecting first column selecting second column try will make evenly spaced array error will gone permanently train randomforestregressor model bit python pickle object trying unpickle object bit python get following error valueerror buffer dtype mismatch expected sizegot long long really idea fix help hugely appreciated edit detail occurs random forest code uses different types indices bit bit machines can unfortunately fixed overhauling random forests code since several scikit learn devs working anyway put todo list now training testing machines need pointer size ease please use python bit version decentralize model faced issue recently taking step resolved try running bit version hope helps fixed problem training model machine training model jupyter notebook windowstrying load raspberrygot error therefore trained model raspberrymaintained fixed problem problem trained model python bit installed system got solved installing python bit version training model custom dropout implemented seemsimplemented dropout function incorrectly modify order correctly utilize dropout posts useful getting point hintondropout lines pythonimplemented dropout function incorrectly fact implementation known inverted dropout inverted dropout dropout implemented practice various deep learning frameworks inverted dropout jump inverted dropout can helpful see dropout works single neuron since train phase neuron kept probabilityp testing phase emulate behavior ensemble networks used training phase end authors suggest scaling activation function factortest phase order use expected output produced training phase single output required test phase section multiplicative gaussian noise thus inverted dropout bit different approach consists scaling activations training phase leaving test phase untouched scale factor inverse keep probabilityq thus inverted dropout helps define model just change parameter keep drop probability run train test model direct dropout instead force modify network test phase donmultiplyoutput neuron will produce values higher respect one expected successive neurons thus following neurons can saturate explodeinverted dropout common implementation references dropout regularization coursera andrewinverted dropout dropout scaling activation versus inverting dropout analysis dropout implement inverted dropout pytorch implement numpy implement tensorflow implementation torchused far problem defined anywhere code also takes forever fit fit operation occurs results cross val scoreparameters throw callbackalso run model trained test set need able save trained model later source code kerasclassifier can pass arguments fit used dondataset test can tell works will try adapt solution change line small explainationhappening kerasclassifier taking possibles arguments fit predict score uses accordingly method called made function filters argumentsfunctions can called pipeline guess several fit predict calls inside stratifiedkfold step train different splits everytime reason takes forever fit fits times one fit epochs asked kfold repeating step different folds edittook time download dataset try things network input features clearly show data prep please change targets labels changed objective original code binary crossentropy categorical crossentropy didnchangearray either data preparation change objective back binary crossentropy now networkoutput size last dense layer dataset obviously categories trying output classes wonmatch target please change back last layer choose use categorical crossentropyback binary crossentropy now network compiles start troubleshout solution now get real error message turns feed fit params whatever cross val score function feeding parameters pipeline order know part pipeline want send parameters specify like error saying process couldnunpack callbacks split values actually looking name pipelinestep apply working now awarehappening function recreate model scratch times trains times different parts datasetepochs sayingepochs times also happening consequence using tool since models always differents means fit method applied times different models therefore callbacks also applied different times files saved modelcheckpoint get overriden find best model last run intrinsec tools use donsee way around comes consequence using different general tools werenespecially thought used together possible configurations try list callbacks list callbacks want apply find detailsmentioned parameters fed kerasclassifier legal fitting parametersalso worth mention using multiple runs gpus might problem due several reported memory leaks especially using theano also noticed running multiple fits consequently may show results seem independent using sklearn api edit try also instead putting callbacks list wrapper instantiation done worked far despite tensorflow keras scikeras documentation suggesting can define training callbacks via fit method setup turns like nassimben suggests model constructor instead rather try matricesx want find euclidean distance across rows getmatrix end code one loop computes euclidean distance every row vectorrow vectors without using loops original input variablesarrayx array want compute euclidean distance matrix operation one entirely vectorized operation distcontains distance ith instance jth instancedistexample distance ostensibly written numpy however shown problem element wise subtraction operationinvolves incompatible array sizes specifically first dimension order element wise subtraction pad eithersatisfy numpybroadcast ruleschoose pad extra dimension becomesx allows arrays dimensions line broadcasting numpy broadcasting see tutorial scipy manual final example tutorial can perform padding either can see using either approach will allow dimensions lineuse first approach will work createxarray now can put difference expression dist equation statement get final result note sum axis means take sumx arraythird axis axis starts arrays small command will work just fine however large arrays may run memory issues note example numpy internally createdx array perform broadcasting generalize dimensionszdimensionsxnumpy will internally createbz array broadcasting can avoid creating intermediate array mathematical manipulation computing euclidean distance sum squared differences can take advantage mathematical fact sum squared differences can rewritten note middle term involves sum element wise multiplication sum multiplcations better known dot productmatrix operation actually matrix multiplication can thus rewrite can write following numpy code note answer exactly previous implementation advantage need create intermediatex array broadcasting completeness letdouble check dimensions summand threesums allowed broadcasting expected final dist array dimensionsuse dot product lieu sum element wise multiplication also discussed tutorial problem recently working deep learning stanfordn assignment used error means ran memory fact produced arrayhuge prevent error can use formula simplify code simply use functionality already included scipyspatial module recommend using will vectorized highly optimized hood evident answer ways can using defaults euclideancodeworking pulled kaggle mostly classes imbalanced class equals classclassclasshowever care classfollowing type calculationsweightweight classbetter methods select weights feel free last linetrying properly set class weightsclass weights however get following error class weight supported dimensional targets possible add dense layer last layer just use dummy layer can pass class weights use output last convlayer prediction possible modify loss functionaware post however just passing weights loss function woncut loss function called separately class currentlyusing following loss function donsee way can input class weights someone wants full working code see post remember change final convlayernum classes instead can always apply weights originallossfunc can import weightslist list weights ordered class using compile can change balance input samples instance samples class samples class pass samples class twice input arrays instead working class can also work sample create array weights sample input array lentrain len weights fit passing array sample weight argumentfit generator generator will return weights along train true pairs return yield inputs targets weights struggling use random forest python scikit learn problem use text classification classes positive negative neutral features extract mainly words unigrams need convert numerical features found way dictvectorizerfit transform problem fit transform method working train dataset contains around instances try convert test set numerical features around instances get memory error saying possibly cause workaround many thanks supposed fit transform test data transform otherwise will get different vectorization one used training memory issue recommend tfidfvectorizer numerous options reducing dimensionality removing rare unigrams etc update problem fitting test data simply split small chunks instead something like can record results stats analyze afterwards particulari built simple neural network get weights way get weights matricesx without biases can get biases values quite simple just second element array returned get weights dense layerscomplete working example implemented tensorflow keras can view output biases weights using following codelooking weights bias validation dataset need perform repeatedcv get optimal tunings alpha lambda example optimal tunings alpha lambda respectively question run coef finalmodel assume give coefficients corresponding best model get different sets coefficients get coefficients corresponding best tuningseen recommendation get best model coef finalmodel besttune lambda however returns null coefficients case returning best tunings related lambda alpha addition edit searching everywhere internet can find now points direction correct answer blog post says finalmodel returns model corresponding best alpha tuning coef finalmodel besttune lambda returns set coefficients corresponding best values lambda true answer question however single blog post canfind anything else back claim still skeptical can anyone validate claim finalmodel returns model corresponding best alpha question solved thanks bit playing code find odd glmnet train chooses different lambda ranges depending seed example optimum lambda works giving coefficients best alpha lambda using model predictpredictedx now seed used lambda values times smaller gives empty coefficients since lambdaopt range tested lambda now predicting upon modelpredicted first level quite odd behavior probably worth reportingi getting following errorcode called exit value titanic data available kaggle output tried usingdtree running lines gives errorable figuregoing wrong using similar code different dataset working fine ideas can debug code thanks anyone interested data can found first think meant write next notice structure cabin embarked columns two factors empty character level name check levels train embarked pointfalls modify data algorithm will now run without error just case can take look error also error occurs special characters name variable example one will get errorrussian alphabet character name variable worked finally got idea reading post intuition behind way train test data set will consistent factor levels error using numeric dataset without missing values long time discovered dataset predictive attribute called outcomecontrol use name error cause solution changing column name way createcontrol object change value label attribute pass object parametermethod also struggled hours problem return code building model predicting hint answer marco written small function remove factor levels equal data frame vector see code however sinceallow pass reference functions use result function can change original dataframe call functions may look like however seemssimilar problem character columns containing empty cell will probably extend handle also character attributes also got error illegal characters factor levels one columns used problem resolved trying implement batch gradient descent data set single feature multiple training examplestry using normal equation get right answer wrong one code performs batch gradient descent matlabvector target valuesmatrix first column full ones second columns values variable implemented using vectorizationdelta element column vector initialized zeroes cost functionthetasumh thetaerror simple delta declaration inside first loop every time accumulate weighted differences training sample output start accumulating beginningaccumulating errors previous iteration takes error previous learned version theta account isncorrect must put beginning first loop addition seem extraneous computecost callassuming calculates cost function every iteration given current parametersgoing create new output array called cost shows iterationalso going call function assign corresponding elements array fwiw donconsider implementation completely vectorized can eliminate second loop using vectorized operations let cover theorypage using gradient descent terms linear regression want seek best parameters theta linear regression coefficients seek minimize cost functioncorresponds number training samples availablecorresponds ith training examplecorresponds ground truth value associated ith training samplehypothesis given note context linear regressiontwo values theta want compute intercept term slope can minimize cost functiondetermine best regression coefficients can givebest predictions minimize error training set specifically starting initial theta iterate iterations many see fit iteration update theta parameters relationship parameter want update need determine gradient cost function respect variable evaluate current state theta work using calculus getunclear derivation happened refer nice mathematics stack exchange post talks specifically can calculate entries delta quite easily analyzing samples together onemean can just operations delta delta can completely vectorized single statement thetax samplecan conveniently place single sum statement caneven replace purely matrix operations first can compute thetax input samplequickly using matrix multiplication supposedata matrix composesrows correspondingtraining samplescolumns correspondingfeatures similarly theta learned weight vector gradient descentfeatures accounting intercept term computetheta get can see computed hypothesis sample placed vector element vector hypothesis ith training sample now recall gradient term parameter gradient descent want implement oneparameters learned vector putting vector givesfinally therefore knowalready vector lengthcan compactly compute gradient descent iteration trying build classifier lightgbm imbalanced dataset imbalance ratio params used code training shown ranget best model best round got aucsimilar score validation set predicting test set getting bad results sure train set sampled perfectly parameters needed tuned reason problem resample dataset highest class reduced issue despite extreme class imbalance dataset still using default threshold deciding final hard classification case rather big topic strongly suggest research try googling threshold cut probability imbalanced data pointers get emphasis added donforget thresholding intelligently make predictions always best predict model probability greater another threshold may better end look receiver operating characteristic roc curves classifier just predictive success default probability threshold relevant academic paper finding best classification threshold imbalanced classification set classification threshold testing set prediction results ultimately determined according prediction probabilities threshold typically set prediction probability exceeds sample predicted positive otherwise negative however ideal cases particularly imbalanced datasets post optimizing probability thresholds class imbalances highly recommended applied predictive modeling blog also relevant take home lesson auc seldom enough roc curve often best according experience least many practitioners get wrong check also classification probability threshold thread provided links cross validated key point statistical component exercise ends output probability class new sample choosing threshold beyond classify new observationpart statistics part decision component read cnn tutorial tensorflow trying use model project problem now data reading around images training around testing validation files png format can read convert use instead write binary file containing contents numpy array file similar format used cifar datafiles might want generate multiple files order get read parallelism note writes binary data row major order metadata pickling array will add python specific metadata tensorflowparsing routines understand write modified version read cifar handles record format modify distorted inputs use new dataset intended minimal set steps given starting point may efficient png decoding using tensorflow ops larger change question specifically asked want know can pass numpy array defined instead filenames reader can fetch records one one array instead files can feed numpy array queue directly will invasive change cifar letassume following array question can define queue contains entire data follows enqueuepopulate queue another efficient approach feed records queue parallel thread see answer details work alternatively enqueue batch time will efficient want know can pass numpy array defined instead filenames reader can fetch records one one array instead files wraps python function uses tensorflow operator might helpexample however sincementioned images stored png files think simplest solution replace nltk package provides method show informative features find important features class output like answered question get informative features scikit learn classifiers can also work scikit learn however binary classifier answer question outputs best feature question can identify featureassociated class like example outstanding informative pos class seagal informative negative class edit actually want list informative words class can thanks case binary classification seems like coefficient array flatten lettry relabel data two labels letdiagnostics seems like features counted vectorized flattened save memory lettry now see can simply actuallyread larsmans comment carefully gave hint binary classes coefficient get informative features scikit learn classifiers basically need self explanatory sorted zip labelid feature namesretrieves coefficient classifier given class label sorts ascending ordergoing use simple example code can get two classes left right side model simple fully connected network like saving model want give input layer right now isnworking inputs tuple etc error message way can pass inputs middle network get output instead giving input start getting output end help will highly appreciated first must learn keras apply layer input new node created inside layer connects input output tensors layer may multiple nodes connecting different input tensors corresponding output tensors build model nodes traversed new graph model created consists nodes needed reach output tensors input tensors model model inputs outputs now like feed intermediate layer model get output model since new data flow path need create new nodes layer corresponding new computational graph can like fortunately model consists one branch simply use loop construct new model however complex models may easy may need write codes construct new model another method achieving result initially create new input layer connect lower layers weights purpose firstinitialize layers name reload corresponding weights parent model using new parent name true will load required weights parent connect new inputs finally load corresponding weights can easily use sorry ugly function naming best problem proposed solutions worked looking something explicit future reference reference shared layersi trying teach svm algorithm using data clicks conversion people see banners main problem clicks around databig disproportion use simple svm testing phase always predict view class never click conversion average gives right answers disproportion gives right prediction check click conversion ones can tune svm algorithm select another one take consideration disproportion basic approach use called class weighting scheme classical svm formulationparameter used control missclassification count can changedc parameters used class respectively common choicec givenputn sizes class respectively punish svm missclassifing less frequent class much harder missclassification common one many existing libraries like libsvm supports mechanism class weight parameters example using python sklearn particular sklearn can simply turn automatic weighting setting class weight auto paper describes variety techniques one simple bad method svm just replicating minority classbalance glmnet function different get computing coefficients definition use lambda value somebody explain data responsedesign matrixscaled read glmnet will see penalized objective function gaussian response case ridge penalty betaused proportional different usually see textbook regarding ridge regression formula write textbook result glmnet expect textbook uses penalized least squares glmnet uses penalized mean squared error note use original codesolveusing crossprod solveefficient see follow section end now letmake new comparison note set intercept false call glmnet conceptual meaning will affect practice conceptually textbook computation intercept want drop intercept using glmnet practically sincey standardized theoretical estimate intercept even intercepte true glment default can check estimate interceptnumerically hence estimate coefficients notably affected answer just showing follow using crossprod solveinteresting chance reference simulation comparisonxwill first take transposetxcrossprody will transpose wrapper dgemm caseopb crossprod wrapperopb similarly tcrossprodopb major use crossprodtx similarly tcrossprodxx case dsyrk instead dgemm called can read first section builtfunction slowreason benchmark awaresquare matrix crossprodtcrossprodequally fast involve different amount floating point operations may read side notice fasterfunction tcrossprod symmetric dense matrix multiplication regarding solvelsolveplease read first section compute diagsolvex efficiently without taking matrix inverse adding top zheyuaninteresting post experiments see can get results intercept follows part enron project built attached model summary steps used kbest find scores sorted features trying combination higher lower scores used svm gridsearch using stratifiedshuffle used best estimator predict calculate precision recall problem estimator spitting perfect scores case refit best classifier training data run test gives reasonable scores doubt question exactly gridsearch test data split using shuffle split object send assumed fit anything test data true predict using test data give high scores right since used random state value shufflesplit created copy grid fit also predict using shufflesplit two wrong gridsearchcv gauthier feuillen said used search best parameters estimator given data description gridsearchcv last step getting different scores first second approach first approach data used training predicting data second approach prediction previously unseen data basically grid search will second case good one otherwise actually predicting data trained case second option keep best parameters gridsearch following python test code arguments works count predictions variable outputs however try use rdd created using following code doesnappear work anymore outputs can see predictallcomes back empty passed mapped rdd values going format noticeable difference can see first example uses parallelize produces parallelcollectionrddwhereas second example just uses map produces pythonrdd predictall work passed certain type rdd possible convert rdd typessure get working two basic conditions can easily reproduce behavior check dependent way rdd created first use example data build model next see products users present training data now create test data check predictions far good next map using logic code still fine next create invalid data repeat experiment expected predictions invalid input finally can confirm really case usingmodel completely independent training prediction python code can see corresponding user item training data means arrays training set supposed specifying order convwork getting dreaded error really donunderstand need donlet name confuse layer time steps features dataset made samples sample values data shape directly applicable repeats array inputtimes example way convlayer gets input shape check documentation information side note ask using sentence classification word sentence usually mapped high dimensional word vector representation seen image results data shape time steps features want use character one hot encoded embeddings look something like simple example one single sample shape characters along time series dimension features help understand tutorial mentioned bit better convlayer temporal convolution along first dimension batch dimension course put something like will need slice data time steps temporal slices feed network however arrays dontemporal structure convlayer lookingallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago worked recently darpa network traffic packets derived version used kdd intrusion detection evaluation excuse limited domain knowledge computer networks derive features darpa packet headers features used kdd intending continue work unb iscx intrusion detection evaluation dataset however want derive pcap files features used kdd save csv format fast easy way achieve careful data set artificial data generated using closed network proprietary network traffic generators hand injected attacks among issues raised important seemed validation ever performed show darpa dataset actually looked like real network traffic mahoney chan built trivial intrusion detection system ran darpa tcpdump data found numerous irregularities including due way data generated malicious packets ttl whereas almost benign packets ttl darpa dataset extension kdd cup dataset fundamentally broken one draw conclusions experiments run using strongly recommend researchers stop using kdd cup dataset feature extraction used iirc majority features simply attributes parsedtcp udp headers port number last octetpacket flags findings longer reflect realistic attacks anymore anyway todays tcpstacks much robust time data set created ping death instantly lock windows host every developer tcpstack now aware risk malformed packets stress test stack things features become pretty much meaningless incorrectly set syn flags etc longer used network attacks much sophisticated likely longer attacking tcpstack services running next layer bother finding low level packet flags used flawed simulation using attacks worked earlyknn caret want provide significance test can wilcoxon test provided sample data follows perform one way deal problem generate several performance values knncan compare using statistical test can achieved using nested resampling nested resampling performing train test splits multiple times evaluating model test set instance use bostonhousing data just select numerical columns example make simple far know way perform nestedcaret box simple wrapper needed generate outer folds nesteduse bootstrap resampling inner resample loop tune hyper parameters now loop outer folds perform hyper parameter optimization using train set predict test set extract just mae results glmnet learner instance now compare two using comparing two algorithms one can use want wish compute cross val score using roc auc multiclass problem tried reproducible example made iris data set one hot encode target use decision tree classifier finaly perform cross val failing last line throw following error env python sklearn question bugmaking miss use unnecessary annoyance cross validation functionality scikit learn default data shuffled arguably good idea make shuffling default choice course pre suppose shuffling argument available cross val score first place unfortunately docs happening samples iris dataset stratified now foldprocedure samples stratified shown error message saying hopefully start making sense one validation folds one label present roc calculation possible let alone fact validation fold model sees labels unseen respective training folds just shuffle data compute collection bits hamming distancedistance input parameterefficiently compute vector wonalways dimension efficiency welcome even paying memory attempt output first bijection hamming distbit vectors subsetsaka kardinalityset indices changed bits henceenumerate subsets changed indices instead quick glance history shows referencekeep track correct cardinalitites course considering efficiency probably pointless since solution problem exponential anyways hamming distanceukv exactlybits set words computingm masksk bits set gives words desired hamming distance notice set mask dependnreasonably small precompute sets masksbits sett iterate sets required donenough memory may generatebit patterns fly see discussion details output response kastrinis answer like verify can extended basis example like output identicalalso toggling bit different way like build gbm modelo data set imbalanced using balance classes parameter grid search parameter tuning like use fold cross validation wonderingo deals class balancing case will training folds rebalanced want sure test fold rebalanced class imbalance settings artificially balancing test validation set make sense sets must remain realistic say negative class will include samples order see model will predicting positive class interest without many false positives artificially inflating minority class reducing majority one will lead performance metrics unrealistic bearing real relation real world problem trying solve corroboration max kuhn creator caretpackageauthor highly recommended applied predictive modelling textbook chapter subsampling class imbalances caret ebook never want artificially balance test set class frequencies line one see wildbalancing makes sense training set prevent classifier simply naively classifying instances negative perceived accuracy hence can rest assured setting describe rebalancing takes action training set folds way force balancing using weight columns use different weights different classeso weights columnicurrently using cross entropy loss function imbalance data set performance great better lost functionbroad subject imho try focal loss introduced tsunglin priya goyal ross girshick kaiming piotr dollar handle imbalance prediction object detection since introduced also used context segmentation idea focal loss reduce loss gradient correct almost correct prediction emphasizing gradient errors can see graph blue curve regular cross entropy loss one hand non negligible loss gradient even classified examples hand weaker gradient erroneously classified examples contrast focal loss curves smaller loss weaker gradient classified examples stronger gradients erroneously classified examples trying sklearn pipeline first time using titanic dataset want first impute missing value embarked one hot encoding sex attribute just want one hot encoding steps two steps embarked working expected embarked column remains addition one hot encoding shown output columnimputation one hot encoding embarked single step working expected reason behind something wrong also didnfind information related columntransformer transformers applied parallel sequentially example embarked ends transformed data twice first transformer keeping string type second transformer time one hot encoded imputed first just uncomment second step embarked pipeline remove embarked categorical cols see also consistent columntransformer intersecting lists columns donthinkquite duplicate want develop cnn model identify hand signs american sign language created custom dataset contains images hand sign using dataset split images hand sign training set images hand sign validation set question randomly shuffle images creating dataset based previous experience led validation loss lower training loss validation accuracy training accuracy check link random shuffling data standard procedure machine learning pipelines image classification exception purpose break possible biases data preparation can clearly see dataset prepared way first samples label next label last label try perform fold cross validation dataset without shufflingfind folds containing single label try foldfolds will include one labeljust theoretical possibility actually happened even bias exists shuffling never hurts always just safe side never based previous experience led validation loss lower training loss validation accuracy training accuracy check link noted answer highly unlikely due shuffling data shuffling anything sophisticated essentially just equivalent shuffling deck cards may happened insisted better shuffling subsequently ended straight flush hand obviously due better shuffling cards two cents topic first make sure extract test set equal number samples hand sign hand sign samples hand sign samples think referred stratified sampling comes training set huge mistake shuffling entire set however splitting training set training validation set make sure validation set good enough representation test set one personal experiences shuffling splitting training set training validation sets validation set turned easy predict therefore saw good learning metric values however performance model test set horrible learning sklearn custom transformers read two core ways create custom transformers wanted compare two approaches implementing meta vectorizer functionality vectorizer supports either countvectorizer tfidfvectorizer transforms input data according specified vectorizer type however canseem get two work passing step code option using custom class code option creating custom transformer function using functiontransformer imports sample data issue countvectorizer tfidfvectorizer require inputd cases doc columntransformer states parameter columns transformers tuple passed string rather list columns str array like str int array like int array like bool slice callable indexes data second axis integers interpreted positional columns strings can reference dataframe columns name scalar string int used transformer expectsd array like vector otherwisearray will passed transformer callable passed input datacan return select multiple columns name dtype can use make column selector therefore following will work case text text can adjust example functiontransformer accordingly observe final remark pass handle unknown ignore onehotencoder prevent possibility error arisen case unknown categories seen test phase cross validation seen training phase learning kohonen packagepurpose making self organizing maps som also called kohonen networks type machine learning algorithm followinglanguage tutorial time factor numeric variables run som algorithm time using supersom function instead able successfully make basic plots however problem arises try make individual plots variable produces error error incorrect number dimensions similar error nas coercion produced attempting cluster som network can someone please tell wrong thanks sources produces list treat like one calling getcodes som produces list containing items namedselecting items list either usingg must set variable prior calling plot can like regarding kmeans kmeans needs matrix object can coerced matrix factors categorical data coerced numeric either drop factors find another method drop factors edit alternatively can specify code directly getcodes using idx like want improve question update question focuses one problem editing post closed years ago can someone explain difference classification clustering data mining can please give examples understand main idea general classification set predefined classes want know class new object belongs clustering tries group set objects find whether relationship objects context machine learning classification supervised learning clustering unsupervised learning also look classification clustering wikipedia please read following information asked question data mining machine learning persons will use terms supervised learning unsupervised learning explain difference clustering classification let first explain key word supervised unsupervised supervised learning suppose basket filled fresh fruits task arrange type fruits one place suppose fruits apple banana cherry grape already know previous work shape every fruit easy arrange type fruits one place previous work called trained data data mining already learn things trained data response variable says fruit features grape like every fruit type data will get trained data type learning called supervised learning type solving problem comes classification already learn things can job confidently unsupervised suppose basket filled fresh fruits task arrange type fruits one place time donknow thing fruits first time seeing fruits will arrange type fruits will first take fruit will select physical character particular fruit suppose taken color will arrange based color groups will thing like red color group apples cherry fruits green color group bananas grapes now will take another physical character size now groups will thing like red color big size apple red color small size cherry fruits green color big size bananas green color small size grapes job done happy ending didnlearn thing means train data response variable type learning known unsupervised learning clustering comes unsupervised learning classification given new data set new label example company wants classify prospect customers new customer comes determine customer going buy products clusteringgiven set history transactions recorded bought using clustering techniques can tell segmentation customers sure number heard machine learning dozen might even know couple might worked machine learning algorithms see going lot people familiar technology will absolutely essential years now siri machine learning amazonalexa machine learningshopping item recommender systems machine learning lettry understand machine learning simple analogy year old boy just fun letcall kylo ren letassume kylo ren saw elephant will brain tell remember minimum thinking capacity even successor vader brain will tell saw big moving creature grey color sees cat next brain tells small moving creature golden color finally sees light saber next brain tells non living object can play brain point knows saber different elephant cat saber something play doesnmove brain can figure much even kylo doesnknow movable means simple phenomenon called clustering machine learning nothing mathematical version process lot people study statistics realized can make equations work way brain works brain can cluster similar objects brain can learn mistakes brain can learn identify things can represented statistics computer based simulation process called machine learning need computer based simulation computers can heavy math faster human brains lovemathematical statistical part machine learning donwanna jump without clearing concepts first letget back kylo ren letsay kylo picks saber starts playing accidentally hits stormtrooper stormtrooper gets injured doesnunderstandgoing continues playing next hits cat cat gets injured time kylo sure done something bad tries somewhat careful given bad saber skills hits elephant absolutely sure trouble becomes extremely careful thereafter hits dad purpose saw force awakens entire process learning mistake can mimicked equations feeling something wrong represented error cost process identifying saber called classification clustering classification absolute basics machine learning letlook difference kylo differentiated animals light saber brain decided light sabers move therefore different decision based solely upon objects present data external help advice provided contrast kylo differentiated importance careful light saber first observing hitting object can decision wasncompletely based saber different objects short help difference learning clustering called unsupervised learning method classification called supervised learning method different machine learning world often dictated kind data present obtaining labelled data things helplearn like stormtrooper elephant cat kylocase often easy becomes complicated data differentiated large hand learning without labels candisadvantages like knowing label titles kylo learn careful saber without examples help wouldnknow just know suppose donekind lame analogy get point just getting started machine learning classification can classification continuous numbers classification labels instance kylo classify stormtrooperheight lot answers heights can etc simple classification like types light sabers red limited answers infact can represented simple numbers red can blue can green can know basic math know different called discrete continuous numbers respectively classification discrete numbers called logistic regression classification continuous numbers called regression logistic regression also known categorical classification donconfused read term elsewhere basic introduction machine learning will dwell statistical side next post please let know need corrections second part postednew comer data mining textbook says classiciation supposed supervised learning clustering unsupervised learning difference supervised learning unsupervised learning can found assignment predefined classes new observations based learning examples one key tasks machine learning popularly dismissed unsupervised classification quite different contrast many machine learners will teach assigning classes objects without predefined limited view people much classification typical example hammer classifier everything looks like nail classification problem also classification people get hang clustering instead consider structure discovery task clustering find structure data know clustering successful learned something new failed got structure already knew cluster analysis key task data mining ugly duckling machine learning donlisten machine learners dismissing clustering iterated literature unsupervised learning bllsht exist oxymoron like military intelligence either algorithm learns examples supervised learning learn clustering methods learning computing minimum maximum average data set unsupervised learning computation learned output thus term unsupervised learning totally meaningless means everything nothing unsupervised learning algorithms however fall optimization category examplemeans least squares optimization methods statistics donthink need label unsupervised learning instead continue call optimization problemsprecise meaningful plenty clustering algorithms involve optimization fit machine learning paradigms stop squeezing umbrella unsupervised learning learning associated clustering program learns user supposed learn new things data set clustering can group data desired properties number shape properties extracted clusters classification number shape groups fixed clustering algorithms give number clusters parameter however approaches find appropriate number clusters first like many answers state classification supervised learning clustering unsupervised means classification needs labeled data classifiers can trained data start classifying new unseen data based knows unsupervised learning like clustering uses labeled data actually discover intrinsic structures data like groups another difference techniques related previous one fact classification form discrete regression problem output categorical dependent variable whereas clusteringoutput yields set subsets called groups way evaluate two models also different reason classification often check precision recall things like overfitting underfitting etc things will tell good model clustering usually need vision expert interpret find donknow type structure type group clusterclustering belongs exploratory data analysis finally say applications main difference classification word says used discriminate instances belong class another example man woman cat dog etc clustering often used diagnosis medical illness discovery patterns etc classification predict results discrete output map input variables discrete categories popular use cases email classification spam non spam sanction loan customer yes capable paying emi sanctioned loan amount cancancer tumour cells identification critical non critical sentiment analysis tweets tweet positive negative neutral classification news classify news one predefined classes politics sports health etc clustering task grouping set objects way objects group called cluster similar sense groups clusters popular use cases marketing discover customer segments marketing purposes biology classification among different species plants animals libraries clustering different books basis topics information insurance acknowledge customers policies identifying frauds city planning make groups houses study values based geographical locations factors earthquake studies identify dangerous zones recommendation system references geeksforgeeks dataaspirant leafnodes classification predicts categorical class labels classifies data constructs model based training set values class labels class label attribute uses model classifying new data cluster collection data objects similar one another within cluster dissimilar objects clusters clustering aims finding groups data cluster intuitive concept mathematically rigorous definition members one cluster similar one another dissimilar members clusters clustering algorithm operates unlabeled data setproduces partition classes class labels class contains similar objects whereas objects different classes dissimilar classes clear cut meaning simplest case mutually exclusive example signature verification signature either genuine forged true class one two matter might able guess correctly observation particular signature clustering method grouping objects way objects similar features come together objects dissimilar featuresapart common technique statistical data analysis used machine learning data mining classification process categorization objects recognized differentiated understood basis training set data classification supervised learning technique training set correctly defined observations available book mahout action think explains difference classification algorithms related still quite different clustering algorithmsmeans algorithm classification algorithms form supervised learning opposed unsupervised learning happens clustering algorithms supervised learning algorithm onegiven examples contain desired value target variable unsupervised algorithms arengiven desired answer instead must find something plausible one liner classification classifying data pre defined categories one liner clustering grouping data set categories key difference classification taking data putting pre defined categories clustering set categories want group data known beforehand conclusion written long post topic can find based date specification file classifying create clusters set sheets mean something similar among sheets two definitions data mining supervised unsupervised someone tells computer algorithm code thing like apple thing like orange supervised learning using supervised learning like tags sample data set classifying dataget classification hand let computer find differentiate features given data set fact learning unsupervised classifying data set called clustering case data fed algorithm dontags algorithm find different classes machine learninglargely perceived task performs achieves opinion thinking clustering classification notion task achieve can really help understand difference two clustering group things classification kind label things letassume party hall men suits women gowns now ask friend questionsheyy can help group people possible answers friend can give can group people based gender male female can group people based clothes wearing suits wearing gowns can group people based color hairs can group people based age group etc etc etc numerous ways friend can complete task course can influence decision making process providing extra inputs like can help group people based gender age group hair color dress etcq need pre work teach inform friend can take informed decision letsay said friend people long hair women people short hair mennow point person long hair ask friend man woman answer can expect woman course can men long hairs women short hairs party answer correct based learning provided friend can improve process teaching friend differentiate two examplerepresents task clustering achieves clustering provide data people algorithm friend ask group data nowalgorithm decidebest way group gender color age group can definitely influence decision made algorithm providing extra inputsrepresents task classification achieves give algorithm friend data people called training data made learn data corresponds label male female point algorithm certain data called test data ask determine whether male female better teaching betterprediction pre workclassification nothing just training model can learn differentiate clusteringpre work part grouping hope helps someone thanks classification data set can different groups classes red green black classification will try find rules divides different classes custering data set class want put class grouping clustering purple circles classification rules good will mis classification testingrules correct enough clustering good will lot outliersdata points able fall cluster key differences classification clustering classification process classifying data help class labels hand clustering similar classification predefined class labels classification geared supervised learning clustering also known unsupervised learning training sample provided classification method case clustering training data provided hope will help believe classification classifying records data set predefined classes even defining classeslook pre requisite valuable data mining like think unsupervised learning correlation along critical levels believe requires understanding statistics mathsi recently started studying deep learningtechniques started searching frameworks simplify process build net training found tensorflow little experience field seems speed big factor making bigsystem even working deep learning python chosen google make tensorflow wouldnbetter make language can compiled interpreted advantages using python language likemachine learning important thing realize tensorflow part core written pythonwritten combination highly optimizedcuda nvidialanguage programming gpus much happens turn using eigen high performancecuda numerical library nvidiacudnn optimized dnn library nvidia gpus functions convolutions model tensorflow programmer uses language likely python express model model written tensorflow constructs actually executed python run insteadactually created dataflow graph says take particular inputs apply particular operations supply results inputs operations model executed fastcode part data going operations never copied back python code programmer drives execution model pulling nodes training usually python serving sometimes python sometimes rawone pythonfunction call uses either process callrpc distributed version calltensorflow server tell execute copies back results said letre phrase question tensorflow choose python first supported language expressing controlling training models answer simple python probably comfortable language large range data scientists machine learning expertsalso easy integrate controlbackend also general widely used inside outside google open source given basic model tensorflow performance python isnimportant natural fitalso huge plus numpy makes easy pre processing python also high performance feeding tensorflow truly cpu heavy thingsalso bunch complexity expressing model isnused executing shape inference matmulshape resulting data automatic gradient computation turns nice able express python though think long termprobably movebackend make adding languages easier hope course support languages future creating expressing modelsalready quite straightforward run inference using several languagesworks now someone facebook contributedbindingsreviewing now etcwritten python writtenuses high performant numerical libraries cuda code can check looking github core written pythonprovide interface many languages pythonjavacome data analysis world can think like numpy written python provides interface python web developer think database postgresql mysql can invoked java python php python frontend language people write modelspopular due many reasons opinion main reason historical majorityusers already use another popular choicewill provide interface python library probably doomed obscurity written python mean model executed python contrary written model right way python never executed evaluationgraph except exists debugging avoided real model exactly executed pythonside different example numpy example eigoperation will compute transpose fast languagefortran return python take python together compute multiplication fast language return python compute eigenvalues return python nonetheless expensive operations like matmul eig calculated efficiently still lose time moving results python back forcedefined graph tensors flow pythoncuda something else python allows create extension modules usingc interfacing native code still getting advantages python gives tensorflow uses python yes also contains large amountsallows simpler interface experimentation less human thought overhead python add performance programming important partslatest ratio can check shows inside tensorflowtakes code python takes codepython official languages google wonder provide fast regressionpython inside computational algebra python used everything else including testing knowing ubiquitous testing today wonder python code contributes muchfive text files input countvectorizer specifying minmaxcountvectorizer instance min max document frequency exactly mean frequency word particular text file frequency word entire overall corpus five text files differences minmaxprovided integers floats documentation doesnseem provide thorough explanation supply example demonstrate use two parameters someone provide explanation example demonstrating minmaxmaxused removing terms appear frequently also known corpus specific stop words example default maxmeans ignore terms appear documents thus default setting ignore terms minused removing terms appear infrequently example default minmeans ignore terms appear less document thus default setting ignore terms add point also understanding minmaxtf idf betterdefault values meaning considering terms generated definitely tokens clustering process thing want terms later will take longer time quality clustering reduced one might think allowing terms present might lower qualityidf doesntf idf measurement instinctively will give low score terms effectively making influential appear many documents sum pruning terms via minmaximprove performance quality clusters example crucial point set min max mistakenly lose important terms thus lower quality unsure right threshold depends documents set sure machineprocessing capabilities leave min max parameters unchanged per countvectorizer documentation using float range refer document frequency percentage documents contain term using int refers absolute number documents hold term consider example text files documents set maxtranslate documents set maxsimply translate documents source code example copied github shows max doc count constructed maxcode minsimilar can foundpage defaults minmaxrespectively basically says term found documentignored similarlyfound documentsignored maxminused internally calculate max doc count min doc count maximum minimum number documents term must found passed self limit features keyword arguments high low respectively docstring self limit features defaults minmaxrespectively defaults really donanything said believe currently accepted answer ffisegydd answer isnquite correct example run using defaults see minmaxtokens appear least one document used tokens tokens appear documents usedtest one candidate everywhere get tokens kept stopwords messing around arguments will clarify configurations fun insightalso recommend playing around stop words english seeing peculiarly words except seven removed including everywhere goal minignore words occurrences considered meaningful example text may names people may appear two documents applications may qualify noise eliminated analysis similarly can ignore words common maxinstead using minimum maximum term frequency total occurrences word eliminate words minmaxlook many documents contained term better known document frequency threshold values can absolute value value representing proportion documents ignore words appeared documents see usage examples just looked documentation sklearn rare words lower frequency values frequency values range fractions maxupper ceiling value frequency values minjust lower cutoff value frequency values want remove common words set maxlower ceiling value want remove rare words set minhigher cutoff value keep everything maxminlet know sure makes tells keras stop training loss didnimprove epochs want stop training loss became smaller constant thrseen documentation possibility make callback nothing found stop training process need advice found answer looked keras sources find code earlystopping made callback based usage min delta minimum change monitored quantity qualify improvement will count improvement one solution callepoch inside loop can put break statement inside loop whatever custom control flow want solved problem using custom callback following custom callback code assign thr value want stop training add callback model taking tensorflow practice specialization learned elegant technique just little modified accepted answer letset example favorite mnist data set metrics accuracy thus callback class condition set accuracy can choose metric monitor training like example importantly can set different conditions different metric use simultaneously hopefully helps model stop training added return statement setting stop training parameter true calling true end function add return statementusing custom training loop can use rolling list can appended left hand items gets popped list longer maxlenlinefull example donallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago looking method calculate number layers number neurons per layer input size input vector size output vector size training set usually best net determined trying different net topologies selecting one least error unfortunately really hard problem internal structure network better network will representing complex solutions hand much internal structure slower may cause training diverge lead overfitting prevent network generalizing new data people traditionally approached problem several different ways try different configurations see works best can divide training set two pieces one training one evaluation train evaluate different approaches unfortunately sounds like case experimental approach isnavailable use rule thumb lot people come lot guesses works best concerning number neurons hidden layer people speculated example input output layer sizeset something near inputs outputsnever larger twice size input layer problem rules thumb donalways take account vital pieces information like difficult problem size training testing sets etc consequently rules often used rough starting points lettry bunch things see works best approach use algorithm dynamically adjusts network configuration algorithms like cascade correlation start minimal network add hidden nodes training can make experimental setup bit simpler theory can result better performance wonaccidentally use inappropriate number hidden nodeslot research subjectreally interested lot read check citations summary particular lawrencegiles tsoi size neural network gives optimal generalization convergence properties backpropagation technical report umiacscsinstitute advanced computer studies university maryland college park elisseeff paugam moisysize multilayer networks exact learning analytic approach advances neural information processing systems cambridgemit presspractice difficult based coded trained dozens mlps textbook sense getting architecture right tune network architecture performance resolution improved optimization architecture hard agree rare cases degree optimization required practice meet exceed prediction accuracy neural network required spec almost never need spend lot time network architecture three reasons true parameters required specify network architecture fixed decided data model number features input vector whether desired response variable numerical categorical latter many unique class labelschosen remaining architecture parameters fact tunable nearly always time experience highly constrained fixed architecture values parameters tightly bounded max min value optimal architecture determined training begins indeed common neural network code include small module programmatically tune network architecture training removing nodes whose weight values approaching zero usually called pruning according table architecture neural network completely specified six parameters six cells interior grid two number layer type input output layers always one one neural networks single input layer single output layermust least one input layer one output layer less second number nodes comprising two layers fixed input layer size input number nodes input layer equal length input vector actually one neuron nearly always added input layer bias node similarly output layer size fixed response variable single node numerical response variable assuming softmax used response variable class label number nodes output layer simply equals number unique class labels leaves just two parameters discretion number hidden layers number nodes comprising layers data linearly separable often know time begin codingdonneed hidden layersfact case useproblem choose simpler linear classifier first number hidden layers nearly always one lot empirical weight behind presumption practice problems solved single hidden layer become soluble adding another hidden layer likewise consensus performance difference adding additional hidden layers situations performance improves second third etc hidden layer small one hidden layer sufficient large majority problems question mentioned whatever reason find optimum network architecture trial error another way tuneconfiguration without using trial error pruning gist technique removing nodes network training identifying nodes removed network noticeably affect network performance resolution data even without using formal pruning technique can get rough idea nodes important looking weight matrix training look weights close zeronodes either end weights often removed pruning obviously use pruning algorithm training begin network configuration likely excess prunable nodes words deciding network architecture err side neurons add pruning step put another way applying pruning algorithm network training can much closer optimized network configuration priori theory ever likely give number nodes comprising hidden layer granted value less can smaller larger size input layer beyond probably knowmountain commentary question hidden layer configuration nns see famousfaq excellent summary commentary many empirically derived rules thumb commonly relied size hidden layer input output layers jeff heaton author introduction neural networks java offers recited page just linked likewise scan application oriented neural network literature will almost certainly reveal hidden layer size usually input output layer sizes doesnmean middle fact usually better set hidden layer size closer size input vector reason hidden layer small network might difficultly converging initial configuration err larger size larger hidden layer gives network capacity helps converge compared smaller hidden layer indeed justification often used recommend hidden layer size larger nodes input layerbegin initial architecture will encourage quick convergence can prune excess nodes identify nodes hidden layer low weight values eliminatefactored network used mlp commercial software one hidden layer one node input nodes output nodes fixed ever got change number hidden layers play generalisation achieved never really got great difference achieving just one hidden layer one node changing number hidden layers just used one hidden layer one node worked quite also reduced computations tempting software premise want separate data train test set apply normalization data split make difference building predictive model first need split data training test set validation set useful donforget testing data points represent real world data feature normalization data standardization explanatory predictor variables technique used center normalise data subtracting mean dividing variance take mean variance whole datasetintroducing future information training explanatory variables therefore perform feature normalisation training data perform normalisation testing instances time using mean variance training explanatory variables way can test evaluate whether model can generalize new unseen data points comprehensive read can read article feature scaling normalisation nutshell example assuming following datarepresents featurescontains corresponding label step create training testing sets step normalise training data step normalize testing data specific setting train test split need distinguish two transformations two common examples mean centering subtracting mean feature scaling unit variance dividing standard deviation subtracting mean dividing standard deviation common transformation sklearn implemented normalizer see exhaustive detail example transforming feature taking logarithm raising value power transformations first type best applied training data centering scaling values retained applied test data afterwards using information test set train model may bias model comparison metrics overly optimistic can result fitting selection bogus model transformations second type can applied without regard train test splits modified value observation depends data observation data observationquestion garnered misleading answers rest answer dedicated showing misleading term normalization ambiguous different authors disciplines will use term normalization different ways absence specific articulation normalization means thinkbest approach question general sense possible view question normalizer class mentioned question matter software programming language library mentioned either moreover even intent ask normalizer answers still misleading mischaracterize normalizer even within library terminology can inconsistent example pytorch implements normalize creates outputs norm normalizer class example rescales observation row individually sum squares every row corner case row sum squares equal rescaling done first sentence documentation normalizer says normalize samples individually unit norm simple test code validates understanding prints true result arraydescribed documentation normalizer implements fit transform fit transform methods even though just pass methods consistent interface across preprocessing methods methods behaviors needs distinguish different data partitions normalizer class subtract column means another answer writes donforget testing data points represent real world data feature normalization data standardization explanatory predictor variables technique used center normalise data subtracting mean dividing variancelettry using code snippet answer value column means trainzero column means subtracted columns centered column means simple prove sumnumbersxxs mean numbersn sumssscan write similar code show columns divided variance neither columns divided standard deviation usual choice applying normalizer class whole data set change result take mean variance whole datasetintroducing future information training explanatory variables claim true far goes absolutely bearing normalizer class indeed giorgos myrianthouschosen example actually immune effect describing normalizer class involve means features expect normalize results will change depending data included training set example sample mean weighted sum every observation sample computing column means subtracting results applying data differ applying training data subsetalready demonstrated normalizer doesnsubtract column means furthermore tests show applying normalizer data just data makes difference results apply method separately apply together difference arrays first case due partitioning letjust double check combined arrays exception raisednumerically identical sklearntransformers sometimes stateful letmake new object just make sure isnstate related behavior second case still exception raised can conclude normalizer class makes difference data partitioned can use fit transform learn transform ask data will look different depending whether transform splitlog transformation order doesnmatter value transformed independently othersscaling centering data order matter outlier can drastically change final distributionallowing test set spill affect training set potentially causing overly optimistic performance measuresuses caret package good handling test train splits can add argument preprocessscale center train function will automatically apply transformation training data onto test datadr data different depending whether normalize split beforewant improve question update question focuses one problem editing post closed years ago please explain fit method scikit learn useful nutshell fitting equal training trained model can used make predictions usually predict method call elaborate fitting model method training data essentially training part modeling process finds coefficients equation specified via algorithm used take example umuttolinear regression example classifier can classify incoming data points test set otherwise using predict method case regression model will interpolate extrapolate predict used incoming data points also noted sometimes fit nomenclature used non machine learning methods scalers preprocessing steps case merely applying specified function data case min max scaleridf transformation note couple update question focuses one problem editing post closed years ago although methods provide better score better closeness prediction still cross entropy preferred every case peculiar scenarios prefer cross entropy mse cross entropy prefered classification mean squared error one best choices regression comes directly statement problems classification work particular set possible output values thus mse badly defined kind knowledge thus penalizes errors incompatible way better understand phenomena good follow understand relations will notice can seen maximum likelihood estimators simply different assumptions dependent variable derive cost function aspect probability distribution can observe mse happens assume error follows normal distribution cross entropy assume binomial distribution means implicitly use mse regression estimation useclassification hope helps little bit logistic regression example will use sigmoid function estimateprobability cross entropy loss function gradient descent minimize using mse loss function might lead non convex problem might find local minima using cross entropy will lead convex problem might find optimum solutionrtd rvfbjqq listsmm jpm wccsyvbhpcdizqnkpsz index also interesting analysis gave dice coefficient however used loop predicted images calculating dice coefficient dice coefficient two values different computed metric value turn one use popular metrics like mse categorical crossentropy mae etc mean loss value example property evaluation ends proper result case dice coefficient mean value across batches equal actual value computed whole dataset uses way computations direct cause problem function will give loss value every batch function will give actual predictions samples batch batches even use data differences will value loss function will almost always different predicted values two different things regularization returns final output model returns loss loss used train model via backpropagation answer videotokyo help understand difference understanding thought pca can performed continuous features trying understand difference onehot encoding label encoding came post following link use one hot encodinglabelencoderdictvectorizor states one hot encoding followed pca good method basically means pca applied categorical features hence confused please suggest disagree others can use pca binary data mean good thing will work pca designed continuous variables tries minimize variance squared deviations concept squared deviations breaks binary variables yes can use pca yes get output even least squared outputpca segfault data works just much less meaningfulwant supposedly less meaningful indeed french statistician used say data analysis find correct matrix diagonalize pca finds eliminate less informative duplicate information feature set reduce dimension feature space words imaginedimensional hyperspace pca findsmfeatures data variates way data may representeddimensional feature vectors mathematically kind eigen values eigen vectors calculation feature space important whether features continuous pca used widely many application mostly eliminating noisy less informative data comes sensor hardware classification recognition edit statistically speaking categorical features can seen discrete random variables interval computation expectationx variancexx still valid meaningful discrete rvs still stand applicability pca case categorical features consider case like predict whether going rain given day categorical featurego work given day yes clearly weather conditions depend work schedulerpassuming days work every weeksrandomly collected dataset pca probably lead dropping low variance dimension feature representation end day pca dimension reduction minimal loss information intuitively rely variance data given axis measure usefulness task donthink theoretical limitation applying categorical features practical value depends application data also case continuous variables following publication shows great meaningful results computing pca categorical variables treated simplex vertices niitsumaokadacovariance pca categorical variablescheungliueds advances knowledge discovery data mining pakdd lecture notes computer science vol springer berlin heidelberg including pdf paper authoruse pca combine categorical features high cardinality understood correctly first calculate conditional probabilities target class choose threshold hyperparameter create new binary variable conditional class probability categorical feature combined pca performed combine new binary variables number components retained specified hyperparameter pca dimensionality reduction method can applied set features example using onehotencoded data think pca reducing var leverage linear relation varsone categoral var coded onehotlinear relation onehoted cols canreduce pca exsits vars onehoted cols may can presented linear relation vars may can reduce pca depends relation know sklearn can get overall accuracy using something similar accuracy score gives overall accuracy can use sklearnconfusion matrix get accuracy references adding answer havenfound answer exact question online think calculation methods suggested incorrect remember accuracy defined put words ratio number correctly classified examples either positive negative total number examples test set one thing important notefn negative class agnostic meaning predicted specific class question example consider following second cat prediction second dog prediction false negatives simply bird question far know currently package provides method looking based definition accuracy can use confusion matrix method sklearn calculate original question posted ago might help anyone comes google like can code accuracy nothing ratio classified samples true positives true negatives total number samples given class instead considering samples take account class can try letfirst define handy function function will return indices listcertain value val last function will return class accuracy look question makes sense accuracy global measure thing class wise accuracy suggestions normalize true cases rows yields something called true positive rate sensitivity recall depending context likewise normalize prediction columnscalled precision positive predictive value question misleading accuracy scores class equal overall accuracy score consider confusion matrix gives accuracy calculated proportion correctly classified samples samples regarding confusion matrix numeratortn sum diagonal denominator sum cells every class opinion accuracy generic term different dimensions recallscore even specificity sensitivity etc provide accuracy measures different perspectives hence function classification report outputs range accuracy measures class instance precision provides proportion accurately retrieved instances total number instances true positives false negatives available particular class solution bro multilabel case can use built way getting accuracy scores class separately can use following snippet get accuracy sensitivity specificity can use will show precision recallscore class can also checkout links official documentation seems google colab gpudoesncome cuda toolkit can install cuda google colab gpugetting error installing mxnet google colab error incomplete installation leveraging gpus computations please make sure cuda installed run following line terminal try adjustdepending cuda versioncu also available can also disable gpu usage altogether invoking exception occurred usesee full traceback cuda showing notebook enabled gpu colab google colab comes options gpu without gpu can enable disable gpu runtime settings change hardware acceleration gpu check gpu running run following command output like following image means gpu cuda working can see cuda version also check pytorch capable using gpu run following code check tensorflow capable using gpu run following code pretty much believe google colab cuda nvcc version return installed cuda version mine switch using gpu cuda will availablebasically need match mxnetversion installed cuda versionused install mxnet colab first check cuda version outputted definecuda version installed mxnet think easiest way install mxnetjust use following code check whether works think colab right now just supporthigher versions wonwork information see following two websites google colab free gpu tutorial installing mxnet solution worked november query version ubuntu colab running run notebook using terminal without query current cuda version colab comparision next got cuda toolkit archive latest builds configure desired cuda versionversion distribution ubuntu copy installation instructions change last line include cuda version apt getinstall cuda otherwise recent version might installed cuda version will now updated run colab need cuda mxnet cuda broken google colab runs now however way uninstall install install mxnetcomplete jupyter code mediumi starting work tensorflow library deep learning information lacking use visual studio projects trying compile library visual studio compilerinstall use windows can use bazel windows production use install tensorflow use windows updated windows now ubuntu bash environment aka bash ubuntu windows available standard option opposed insider preview updates developers stackoverflow tag wsl option came windows anniversary update version released allows use apt get install software packages python tensorflow note bash ubuntu windows access gpu gpu options installing tensorflow will work dated installation instructions bash ubuntu windows basically correct steps necessary prerequisites enable windows subsystem linux feature gui reboot prompted run bash windows steps longer needed turn developer mode enable windows subsystem linux feature command line install tensorflow using apt get now test tensorflow run actual neural network learning developer preview bash windows see playing tensorflow windows scott hanselman uses bash windows bazel problem tensorflow made build automation tools make googlehouse build tool bazel bazel works systems based unix linuxx since current published known means build tensorflow uses bazel bazel work windows one can install run tensorflow natively windows bazel faq windows due unix heritage porting bazel windows significant work example bazel uses symlinks extensively varying levels support across windows versions currently actively working improving windows supportstill ways usable status see tensorflow issue see bazel issue solutions listed order complexity work needed hour may even work docker installation docker system build self contained versions linux operating system running machine install run tensorflow via docker completely isolates installation pre existing packages machine also look tensorflow docker image use current mac runningx see installation macx recommend linux system tends ubuntu lts download page virtual machine hardware virtualization full virtualization hours download install virtual machine commercial vmware free virtual box can install linux install tensorflowinstall tensorflow will using pip pythonpackage management system visual studio users think nuget packages known wheels see pip installation need build source see installing sources hours note plan using virtual machine never done consider using docker option instead since docker virtual machinetensorflow packaged togetherdual boot hours want run tensorflow machine windows make use gpu version will likely use option running hosted virtual machine type hypervisor will allow access gpu remote access another machine can install linuxtensorflow software allow remote connections can use windows machine present remote machine application running windows cloud services aws used tensorflow features want run model service cloud containerize docker tensorflow just works docker running docker aws provides highly reliable low cost way quickly build ship run distributed applications scale deploy docker using amis aws marketplace currently appears hold bazel however bazelroadmap list working windows available year two features listed windows remember bazel used build tensorflow get commands bazel runs correct source code libraries able build tensorflow windows see get commands executed bazel researched can look continuous integration info needed files info build testing readme site public experimental source code version bazel boots windows may able leverage getting bazel work windows etc also solutions require use cygwin mingw adds another layer complexity currently exist tensorflow feature request see tensorflow issue build tensorflow linux using bazel change build process output wheel can installed windows will require detailed knowledge bazel change configuration locating source code libraries work windows option suggest last resort may even possible see windows subsystem linux overview will know much reading referenced article can use bazel windows production use since experimental software use production machine remember need bazel build tensorflow use experimental code non production machine build wheel install wheel production machine see pip installation tldr currently several versions learning use vmware workstation host ubuntu lts ubuntu debian also one dual boot ubuntu lts windows machine access gpu machine vmware proper gpu recommend give machines leastmemory either ram ram swap space run memory times can confirm works windows subsystem linux also straightforward ubuntu bash windows first update package index install pip python install tensorflow package now installed can run cnn sample mnist set just tested cpu package now blogged michael sorry excavation question quite popular now different answer google officially announced addition windows server support tensorflow need gpu support tensorflow manual install pip windows another useful information included release notesphright mentioned commentswindows supports pythoninstalling tensorflow windows native pip tensorflow currently supports python bit cpu gpu supported installation instructions assuming python bit can now run something like following test whether tensorflow working fine tensorflow comes models locatedpython lib site packages tensorflow models assuming installed pythonpython example can run console initial support building tensorflow microsoft windows added commitabcfc bbfdbcontains initial version support building tensorflow cpu windows using cmake includes documentation building cmake windows platform specific code implementing core functions windows cmake rules buildingexample trainer program pip package python cmake rules support building tensorflow visual studio windows support work progress welcome feedback contributions full details features currently supported instructions build tensorflow windows please see file tensorflow contrib cmake release notes tensorflow now builds runs microsoft windows tested windows windows windows server supported languages include python via pip packagecuda cudnn supported gpu acceleration known limitations include currently possible load customlibrary gcs hdfs file systems currently supported following ops currently implemented depthwiseconv dnative depthwiseconv dnativebackpropfilter depthwiseconv dnativebackpropinput dequantize digamma erf erfc igamma igammac lgamma polygamma quantizeanddequantize quantizedavgpool quantizedbatchnomwithglobalnormalization quantizedbiasadd quantizedconcat quantizedconvquantizedmatmul quantizedmaxpool quantizedownandshrinkrange quantizedrelu quantizedrelu quantizedreshape quantizev requantizationrange requantize now tensorflow officially supported windows can install using pip command python without compile cpu versionindicates python wheel version can edit according preference install latest cpu version available can use gpu versionindicates python wheel version can edit according preference install latest gpu version available can use info following may work install virtual box create linuxinstall linuxrecommend ubuntu google often uses internally install tensorflow linuxcanmoment problem tensorflow uses bazel build another google internal tool exposed open source project support mac unix bazel ported windows another build system added tensorflow little chance run tensorflow natively windows said can install virtualbox install docker machine run linux container tensorflow inside managed install tensorflow win without docker using advice wontry install twice installmake sure visualinstalled install python toolsinstall python anaconda install pip conda python install numpy pip insideinstall tensorflow pip insidedidnmanage python managed also install win via cloud video tutorial youtubekmtroiplpr edit actually cloud fine problems tensorflow looks likeinstalled can see list modules installedclicking solution explorer python bit type script python interactive import tensorflowget error message writing answer wasnable get tensorflow install properly python version reverting python trick able installpip install tensorflow already installed anaconda windows easier way found similar virtualenv found helpful follow link install tensorflow windows can also use visual studiohow train batch different fit cases use train batch questionsimple answer primary author fit generator can use generator validation data general recommend using fit generator using train batch works fine methods exist sake convenience different use cases correct method train batch allows expressly update weights based collection samples provide without regard fixed batch size use cases want train explicit collection samples use approach maintain iteration multiple batches traditional training set allowing fit fit generator iterate batches likely simpler one case might nice use train batch updating pre trained model single new batch samples supposealready trained deployed model sometime laterreceived new set training samples previously never used use train batch directly update existing model samples methods can rather explicit use train batch case apart special cases like either pedagogical reason maintain cursor across different training batches else type semi online training update special batch probably better just always use fit data fits memory fit generator streaming batches data generator train batch gives greater control state lstm example using stateful lstm controlling calls needed may multi series data need reset state series can train batch used fit network trained series data without resetting stateright wrong depends datausing want network behave train batch will also see performance increase fit fit generator using large datasets doneasily serializable data like high rank numpy arrays write tfrecords case can save arrays numpy files load smaller subsets memory whole set wonfit memory can use loading another dataset calling train batch etc nowtrained entire set can control exactly much dataset trains model can define epochs batch sizes etc simple loops functions grab dataset indeed nbro answer helps just add scenarios say training seq seq model large network one encoders can create custom training loops using train batch use part data validate encoder directly without using callbacks writing callbacks complex validation process difficult several cases wish train batch regards karthick keras model training apis can use gan update discriminator generator using batch training data set time saw jason brownlee used train batch tutorials developgenerative adversarial network scratch keras tip quick search type controltype search box term want search train batch example writing small ann supposed categorize products classes based input variables order usefold cross validation kind confused excerpt presentation slide exactly validation test sets understand run training sets adjust weights single epoch validation understand test set used get error network happens next also confusing crossover take placemuch ask bullet list step appreciated seem bit confused remember going simplify things whenever given task devising neural network often also given sample dataset use training purposes letassume training simple neural network systemwy output computed calculating scalar product weight vectorgiven sample vectornow naive wayusing entire dataset say samples train neural network assuming training converges weights stabilise can safely say network will correctly classify training data happens network presented previously unseen data clearly purpose systems able generalise correctly classify data one used training real world situation however previously unseen new data available neural network deployed letcall production environment since tested adequately probably going bad time phenomenon learning system matches training set almost perfectly constantly fails unseen data called overfitting come validation testing parts algorithm letgo back original dataset samples split three sets training validation testingvausing carefully selected proportions usually good proportion now happens neural network trainedset weights correctly updated validation setused compute classification errormusing weights resulting trainingexpected output vector taken validation setcomputed output resulting classificationwerror higher user defined threshold whole training validation epoch repeated training phase ends error computed using validation set deemed low enough now smart ruse randomly select samples use training validation total setva epoch iteration ensures network will fit training set testing setused measure performance network data perfect purpose never used throughout training validation phase effectively small set previously unseen data supposed mimic happen network deployed production environment performance measured term classification error explained performance can also maybe even measured terms precision recall know error occurstopic anotherunderstood training validation testing mechanism one can strengthen network fitting performingfold cross validation somewhat evolution smart ruse explained technique involves performingrounds training validation testing different non overlapping equally proportionedvasets givenvaluewill split datasetvawill run algorithm recording testing performance taking world famous plot wikipedia show validation set helps prevent overfitting training error blue tends decrease number epochs increases network therefore attempting match training set exactly validation error red hand follows differentshaped profile minimum curve ideally training stopped point training validation error lowest references excellent book will give sound knowledge machine learning several migraines decideworth divide datanon overlapping folds foldcontain equal number itemsclasses stratified cross validation items class classfold validation fold contain random itemsnow collected aggregate results across folds final performancegoing apply real wild use best parameters grid search train datatrying image classification inceptionmodel imagedatagenerator keras create new images added onto dataset images will using function double images used training way know many images created now fed model short answer original images just transformed zooming etc every epoch used training therefore number images epoch equal number original images long answer epoch imagedatagenerator applies transformation images use transformed images training set transformations includes rotation zooming etcsomehow creating new data obviously generated images totally different original ones way learned model may robust accurate trained different variations image need set steps per epoch argument fit methodsamples batch sizesamples total number training data way epoch training sample augmented one time therefore transformed images will generated epoch thinkworth clarifying meaning augmentation context basically augmenting images use imagedatagenerator enabling augmentation capabilities word augmentation mean say original training images end images per epoch augmentation instead means use different transformation image epoch hence train model say epochs used different versions original image training different images whole training instead using just original images whole training put differently total number unique images increases whole training start finish per epoch attempt answer also question mind imagedatagenerator will add new images data set sense will make epochs bigger instead epoch will provide slightly altered images depending configuration will always generate new images matter many epochs epoch model will train different images different prevent overfitting way simulates online learning alterations happen memory want see images can save disc inspect see many generated get sense imagedatagenerator works pass save dir tmp img data gen outputs function flow directory see docs officially written imagedatagenerator batches generator tensor image data real time data augmentation data will looped batches means will fly apply transformations batch images randomly instance every new epoch new random transformations will applied way train little different set images time obtaining data always achievable possible using imagedatagenerator helpful way depends many epochs run today answered fitting model generator will make generator provide many images needed depending steps per epoch make things easier understand put mimicking classified data create generator parent folder run simple loop first thing confirm see message found images belonging classes loop will stop iterations will just keep incrementing printing endlessly got minestopped manually generator will provide many images requested whether augmented also note augmented images stored memory generated fly training lost training canread augmented images storing images good idearun memory soon storing huge images imagedatagenerator class ensures model receives new variations images epoch returns transformed images add original corpus images fact case model seeing original images multiple times definitely overfit model example like calculatemodel certainty confidence see deep model doesnknowtells image represents like know certain model certain also digits quite ambiguous like know images model just flipping coin found theoretical writings trouble putting code understand correctly evaluate testing image multiple times killing different neurons using dropout working mnist dataset running following model predict model get certainty predictions appreciate practical examples preferably keras will clarify looking example get certainty using method outlined yurin gal explanation method yields better results want implement dropout approach measure uncertainty following implement function applies dropout also test time use function uncertainty predictor course may use different function compute uncertainty made changes top voted answer now worksway estimate model uncertainty source uncertainty found simplest way obtain kind uncertainty measure look output softmax probabilities probs array will element vector numbers range sum can interpreted probabilities example probability digit just probs information can post processing typically predicted class one highest probability can also look class second highest probability etc simpler way set training true dropout layers want run inference essentially tells layer operatealways training mode always present training inference code found three conflicting results can someone explain use linearsvcsvc kernel linear seems like linearsvc marginally better svc usually finicky scikit decided spend time implementing specific case linear classification wouldnlinearsvc outperform svc mathematically optimizing svm convex optimization problem usually unique minimizer means one solution mathematical optimization problem differences results come several aspects svc linearsvc supposed optimize problem fact liblinear estimators penalize intercept whereas libsvm ones doniirc leads different mathematical optimization problem thus different results may also subtle differences scaling default loss function edit make sure set loss hinge linearsvc next multiclass classification liblinear onerest default whereas libsvm oneone sgdclassifier loss hinge different two sense uses stochastic gradient descent exact gradient descent may converge solution however obtained solution may generalize better svc linearsvc one important decision criterion linearsvc tends faster converge larger number samples due fact linear kernel special case optimized liblinear libsvm actual problem problem scikit approach call svm something svm linearsvc actually minimizing squared hinge loss instead just hinge loss furthermore penalizes size bias svm details refer question parameters svc linearsvc scikit learn equivalent one use purely problem specific due free lunch theorem impossible say loss function best period sometimes squared loss will work better sometimes normal hinge trouble fully understandingmeans algorithm interested exactly firstcentroids picked namely initialization rest like originalmeans algorithm will appreciate step step explanation example one wikipedia clear enough also commented source code also help using arrays please tellone interesting question thank bringing paper attentionmeans advantages careful seeding simple terms cluster centers initially chosen random set input observation vectors probability choosing vectorhighnear previously chosen centers one dimensional example observations let first centerprobability next cluster centerx proportionalxcccc supposepppve coded initialization procedure python donknow helps edit clarification output cumsum givesboundaries partition interval partitions length equal probability corresponding point chosen center sinceuniformly chosen will fall exactly one intervals break loop checks see partitionexample one liner say need select cluster centers instead selecting randomly like simplemeans will select first one randomly find points farthest first center points probably belong first cluster center far assign second cluster center nearby far points prepared full source implementationmeans based book collective intelligence toby segaranmenas initialization provided indeed two distance functions initial centroids standard one used basedpppppossible missing values scikit learn represented couldnfind documentation missing values simply supported scikit learn discussion mailing list attempt actually write code handle whatever donuse nan encode missing values since many algorithms refuse handle samples containing nans answer outdated latest release scikit learn class imputer simple per feature missing value imputation can feed arrays containing nans replaced mean median mode corresponding feature wish provide simple example found randomforestregressor handle nangracefully performance gets steadily worse adding features increasing percentages nanfeatures many nancompletely ignored even nanindicate useful information algorithm will never create split decision isnan ismissing algorithm will ignore feature particular level tree feature single nan subset samples lower levels tree sample sizes smaller becomes likely subset samples wonnan particular featurevalues split can occur feature tried various imputation techniques deal problem replace mean median predict missing values using different model etc results mixed instead solution replace nansingle obviously range value like enables tree split criteria unknown valueknown value however strange side effect using range values known values near range value get lumped together range value algorithm tries find good place split example knownget lumpedused replace nanmodel change depending range value less minimumgreater maximum get lumped minimum value maximum value respectively may may help generalization technique outcome will depend similar behavior minimum maximum value samples nan value samples come across similar issue running randomforestregressor data presencevalues throwing nan predictions scrolling around several discussions documentation breiman recommends two solutions continuous categorical data respectively according breiman random nature algorithm number trees will allow correction without much effect accuracy prediction feel case presencevalues sparse feature containing manyvalues think will likely affect replacing missing value mean median stat may solve problem fact value missing may significant example survey physical characteristics respondent may put height embarrassed abnormally tall small imply missing values indicate respondent unusually tall small opposite median value necessary model separate rule missing values attempt guess missing value will likely reduce predictive power modelg orange another python machine learning library facilities dedicated imputation chance use might soon since simple methods replacing nanzeros averages medians significant problems encounter problem practical case found packagecalled missforest can handle problem imputing missing value greatly enhance prediction instead simply replacing nas median mean missforest replaces prediction thinks missing value makes predictions using random forest trained observed values data matrix can run slow large data set contains high number missing values trade method similar option python predictive imputer run missing values input features first order business impute missing important question unless clear definitive mind true reality behind data may want curtail urge impute technique package first place historically resorted tree methods like decision trees mainlyleast felt imputing missing estimate regression like linear regression logistic regression evendistortive enough methods require imputing missing among columns called missing informativeness familiar concept familiar say bayesian really modeling big data besides talking chance face large number columns common practice feature extraction like text analytics may say missing means count fine know root cause reality especially facing structured data sources donknow simply dontime know root cause engine forces plug value nan place holders engine can tolerate may argue model good impute make sense one intriguing question leave missingness judged close context inside splitting process first second degree surrogate foresting actually make contextual judgement moot context perrandom selection however better problem least hurt much certainly make preserving missingness unnecessary practical matter large number input features probably good strategy impute sheer imputation perspective best practice anything univariate contestpretty much means useimpute modeling therefore unless somebody tellsable think enable carrying forward missing cells entirely bypassing subject best impute trying use pre trained modelproblem occurs isnmodel supposed take simple colored image expecting dimensional input usman ali wrote comment pytorchtoolboxes expects batch images input thus need call inserting singleton batch dimension input data please also note model using might expect different input sizexx pytorch documentation convolutional layers convlayers expect input shape passing grayscale images usual format wonwork get right shape will need add channel dimension can follows unsqueeze method adds dimensions specified index result shape model expects batch images need pass dimensional tensor can done follows method output model data method output model data unsqueeze will send first image whole batch similarly ith image can method output model data method output model data unsqueeze can someone explain random state means example hard coded isnobvious answer ultimate question life universe everything serious note random state simply sets seed random generator train test splits always deterministic donset seed different time relevant documentation random state int randomstate instance none optional default none int random state seed used random number generator randomstate instance random state random number generator none random number generator randomstate instance usedspecify random state code every time run execute code new random value generated train test datasets different values time however fixed value assigned like random state integer matter many times execute code resultvalues train test datasets random state ensures splits generate reproducible scikit learn uses random permutations generate splits random state provide used seed random number generator ensures random numbers generated order random state defined code every run train data will change accuracy might change every run random state constant integer defined train data will constant every run will make easy debug random state simply lot number set generated randomly operation can specify lot number whenever want set two columns large numbers read excel file read excel display dataframe two columns printed scientific format exponential can get rid format thanks output pandas way scientific notation applied controled via pandas display options simply presentational purposes may convert data strings formatting column column basis alternative straightforward method put following line top code format floats trysergeys worked trying feed huge sparse matrix keras model dataset doesnfit ram way around train model data generated batch batch generator test approach make sure solution works fine slightly modified kerasimple mlp reuters newswire topic classification task idea compare original edited models just convert finally part crash believe problem due wrong setup samples per epochtrully appreciate someone comment solution casesparse matrixarray can use lasagne instead keraswritten small mlp class following features supports dense sparse matrices supports drop hidden layer supports complete probability distribution instead one hot labels supports multilabel training supports scikit learn like api fit predict accuracy etc easy configure modifyis way calculate total number parameters lstm network found exampleunsure correct understood correctlyconsider following example per understandinginput vector lenghtnumber time steps example consider number hidden layers hence according formula postn examplen num units difference misunderstand example formula wrong number parameters lstm layer keras equals additional comes bias termssize input increased bias termsize output lstm layer finally image via post num units input dim concattt bias neural network layers yellow boxforgetinputoutputcellnum units num hidden units output dims think easier understand start simple rnn letassume units please ignore network concentrate visible units input size number dimensions number weights num units num units recurrent connections input dim num units input number biases simply num units recurrency means neuron output fed back whole network unroll time sequence looks like two dense layers makes clear num units num units weights recurrent part number parameters simple rnn can expressed num units num units input dim num units num units num units num units input dim now lstm must multiply number parameters number sub parameters inside unit nicely illustrated answer felixho formula expanding johnstrong means different weight bias variables gates read write frogetcell state within hidden state mentioned shared among timesteps along particular hidden state vector lstm outputh hidden state approach without extra projection lstm outputs letsayd lstm equations via others pretty much answered just clarification creating lstm layer number params follows params num features used num units num units additional bias take num features num features input shape lstm input shape window size num features way let tensorflow print extra training metrics using estimator api one can add summaries view result tensorboard see another post wondering elegant way get scalar summary values printed training already happens training loss nice already validation monitor case also interested training batch accuracyread possible change passing parameter can try creating logging hook passing estimator run body modelfunction estimator edit see output must also set logging verbosity high enough unless default can also use tensorboard see graphics desired metrics add metric tensorflow summary like cool thing useneed add summaries filewriter sincedone automatically merging saving periodically default average every steps donforget change line based accuracy parameter just added order see tensorboard need open new terminal type will able see graphics browser localhost playing tensorflowbrand new object detection api decided train publicly available datasets happened stumble upon grocery dataset consists images various brands cigarette boxes supermarket shelf along text file lists bounding boxes cigarette box image major brands labeled dataset brands fallmiscellaneous category followed tutorial managed train model dataset due limitations processing power used third dataset performed split training testing data used faster rcnn resnet model parameters config file default parameters providedglobal steps tested model images happy results failed detect camels top shelf whereas detects product images fail detect marlboros top row another issue model never detected label except label doesndetected crop instance product training data detects cigarette boxes confidence even negative images can somebody help going wrong can improve accuracy detect products belong category even though mentioned classes total edit added label map think figured going analysis dataset found skewed towards objects category frequency distribution category based indexing guess model hitting local minima just labelling everything category good enough problem detecting boxes tried training time didndifferentiate brands instead tried teach model cigarette box still wasndetecting boxes decided crop input image provide input just see results improve turns dimensions input image much largeraccepted model scaling imagesmeant cigarette boxes losing details decided test original model trained classes cropped images works like charm output model original image output model crop top left quarter provide input thanks everyone helped congrats tensorflow team amazing job api now everybody can train object detection models many images dataset training data better api performs tried training images per class accuracy pretty bad pretty much faced problems mentioned generated data accuracy improved considerablysorry couldncomment since donenough reputation maybe late now wanted post comments anyone struggles future unfortunatelydocumentation best struggled lot finding reason way model constructed allows maximumamount predictions per single image case think can easily test hypothesis editing original photo like obviously boxes actually drawn see better results pretty nasty limitation parameters configure like important default set seems dataset size rather small resnet large network will require even data train properly guessing conditional probability given tree branch condition exists however clear want read data used get diagramvalue leaf node represent raw score class can converted probability score using logistic function calculation use left leaf example means data point ends distributed leaf probability data point class regression model objective can reg squarederror leaf value prediction tree given data point leaf value can negative based target variable final prediction data point will sum leaf values trees point classification model objective can binary logistic leaf value representative like raw score probability data point belonging positive class final probability prediction obtained taking sum leaf values raw scores trees transforming using sigmoid function leaf value raw score can negative value actually represents probability please find details parameters outputs evaluation tree model ends terminal node aka leaf node value returned pseudocode left branch tree model correct probability values associated leaf nodes representing conditional probability reaching leaf nodes given specific branch tree branches trees can presented set rules example user mentioned answer one rule representing left branch tree model short tree can linearized decision rules outcome contents leaf node conditions along path form conjunction clause general rules form decision rules can generated constructing association rules target variable right can also denote temporal causal relations importing tensorflow ubuntu python using following commands program exits please specify solution problem downgrade tensorflow edit tobsta points comments option compile binaries source precompiled binaries versions use avx instructions supported older cpus see messageceleronsuccessed build tensorflowwithout avx instruction just build tensorflow celeronn wrote log used python also tested python python tested maybe possible use similar way think desired version tensorflow can installed via hack using anaconda firstdirectory sufficient space download anaconda check version want install want ensure integrity anaconda installed check using sha run anaconda script output like now get prompt anaconda will installed location enter location want installed press enter continue now per choice requirement can type yes wish installer initialize anaconda running conda init now instead using pip installing tensorflow will use conda will first set path using vim bashrc file put path instead anaconda bin like data anaconda bin whatsoever make effective run now create virtual environment now install tensorflow keras run particular version want install say version tensorflow keras virtual environment installing keras tensorflow work properlycaseenv running source anaconda bin activateenv can check installation runningitrying understand using kfolds cross validation sklearn python module understand basic flowconfused using sklearn kfolds cross val score understand cross val score function will fit model predict kfolds giving accuracy score fold dataset training testing data use cross val score function kfolds determine accuracy algorithm training data fold model now fitted ready prediction testing data case using can see cross val score clones estimator fitting fold training data cross val score will give output array scores can analyse know estimator performs different folds data check overfits data can know need fit whole training data estimator satisfied results cross val score can use predict test want load images total slice data limit number data points understand dataloader generator yielding data size specified batch size slice datasets can use elements another quick way slicing dataset using supported pytorchhelps randomly splitting dataset non overlapping new datasets given lengths can something like following can setsplit lensplit len required split lengths training testing datasets respectively important note create dataloader object immediately load data impractical large datasets provides iterator can use access sample unfortunately dataloader provide way control number samples wish extract will use typical ways slicing iterators simplest thing without libraries stop required number samples reached uselearning create convolutional neural networks using kerastrying get high accuracy mnist dataset apparently categorical crossentropy classes binary crossentropy classes since digits using categorical crossentropy however training testing dozens models binary crossentropy consistently outperforms categorical crossentropy significantly kaggle got accuracy using binary crossentropy epochs meanwhile canget using categorical crossentropy even using epochs isnmuch dongpu training takes forevermodel looks like now short answer see simply try calculate accuracy hand will see different one reported keras reason seems rather subtle issue keras actually guesses accuracy use depending loss function selected include simply metrics accuracy model compilation check source code keras define single accuracy metric several different ones among binary accuracy categorical accuracy happens hood since selected binary cross entropy loss function specified particular accuracy metric keras infers interested binary accuracy returns avoid nothing wrong principle still getting categorical accuracy required problem hand ask explicitly categorical accuracy model compilation follows training scoring predicting test set show two metrics nowgreat answer similar problem helped understand update post discovered issue already identified answer first binary crossentropy two classes binary name adapted binary output number softmax aimed checks number output doesnexplain result since categorical entropy exploits fact classification problem sure read data one one class per sampleone explanation can give using bag words classify textworking wondering add feature word sample code now clear text london tends much longer text new york add length text feature use another way classification combine two predictions way along bag words sample code greatnew machine learning scikit learn shown comments combination functiontransformer featurepipeline featureunion will add length text features used classifier assume new feature want add numeric logic first transform text sparse using tfidftransformer something similar convert sparse representation pandas dataframe add new column assume numeric end may want convert data frame back sparse matrix using scipy module feel comfortable assume data pandas dataframe called dataset containing text column numeric column code finally may want ensure new column successfully added hope text features sparse vector term weights color features small element one hot encoder dense vector colors type features also one hot encoder dense vector types good approach using sparkfacilities merge features one single large array measure things like cosine distance two objects can use vectorassembler pyspark example see encode assemble multiple features pysparki multi class classification problem dataset skewed instances particular class say different class want split dataset keeping ratio classes instances particular class want recordstraining set want instances record represented class instances record represented class can use sklearnstratifiedkfold online docs stratifiedfolds cross validation iterator provides train test indices split data train test sets cross validation object variation kfold returns stratified folds folds made preserving percentage samples class will preserve class ratios splits retain class ratios will work fine pandas dfs suggested aliuse stratifiedshuffledsplit accepts split ratio param sss stratifiedshufflesplittest size random state produce split simple pipeline seems canpass parameters models using modeltransformer class take link error message makes sense donknow fix idea fix thanks error message valueerror invalid parameterestimators estimator modeltransformer gridsearchcv special naming convention nested objects case ess rfcestimators stands according definition pipeline points propertyestimators obviously modeltransformer instances donproperty fix easy order access underlying object modeltransformer one needs use model field grid parameters becomeproblem code order use multiple jobs gridsearchcv need make objectsusing copy able achieved implementing methods get params set params can borrow baseestimator mixin wanna make model multiple inputs try build model like summary try train model problem thanks reading hopefully helping oom stands memory gpu running memory canallocate memory tensor things can useful information error weird shapeworking images normally channel top seems like passing entire dataset instead pass batches seems model put data one batch try specified batch size like still oom try reduce batch size happened can try reducing trainable parameters using form transfer learning try freezing initial layers use lower batch sizes think common reason case arise absence maxpooling layers use architecture add atleast one maxpool layer convlayers might even improve overall performance model can even try reducing depth model remove unnecessary layers apply min max scaling entire dataset splitting training validation test data split first apply min max set using min max values specific set lastly making prediction new input features input normalized using min max values training data fed network split scale imagine way idea real world data looks like couldnscale training data test data surrogate real world data treat way reiterate split scale training data use scaling training data testing data trying calculate silhouette score find optimal number clusters create get error says unable understand reason code using cluster calculate silhouette score read csv contains text clustered runmeanscluster values reason getting error error produced loop different number clustersfirst iterationclusters leads true words one cluster label thus prints array dtype int example different clusters cluster labels function works fine now letcause error documentation note silhouette coefficient defined number labelslabelssamples one way solve problem instead usingrange try start iterationk range works try changing min samples also algorithm metric valid list metrics algoritms use error gone tough time figuring use kevin murphyhmm toolbox toolbox great help anyone experience clarify conceptual questions somehow understood theory behind hmmconfusing actually implement mention parameter setting classes need hmms let say training vectors classclassnow system classify unknown sequenceeither class class instead answering individual question let illustrate use hmm toolbox example weather example usually used introducing hidden markov models basically states model three possible types weather sunny rainy foggy given day assume weather can one values thus set hmm states however example canobserve weather directly apparently locked basement instead evidence whether person checks every day carrying umbrella hmm terminology discrete observations hmm model characterized three things next either given probabilities learn training setdone can reasoning like computing likelihood observation sequence respect hmm model bunch models pick likely one sample code shows fill existing probabilities build model can sample bunch sequences model exampleexample can evaluate log likelihood sequence compute viterbi path probable state sequence training performed usingalgorithm best done set observation sequences continuing example can use generated data train new model compare original keep mind states order donmatchneed permute states comparing two models example trained model looks close original one things can hidden markov models classification pattern recognition different sets obervation sequences belonging different classes start training model set given new observation sequence classify computing likelihood respect model predict model highest log likelihood use toolbox mention use htk book describes function htk clearly available free list number emitting states linked length complexity feature vectors however certainly equal length array feature vectors emitting state can transition probability going back even back previous state depending architecturealso sure value give includes non emitting states start end hmm need considered also choosing number states often comes trial error good luck developping segmentation neural network two classes background object want find image image can see dataset unbalanced makes results wrong accuracy loss low model good finding background like base optimizer another metric like precision recall usefull case anyone know implement donuse precision recall optimize just track valid scores get best weights mix loss optimizer metrics meant thing gradient descent need compute gradient function need somehow smooth precision recall accuracy smooth function sharp edges gradient infinity flat places gradient zero hence can use kind numerical method find minimum function use kind combinatorial optimizationhard others stated precision recall directly usable loss function however better proxy loss functions found help whole family precision recall related functions precision fixed recall etc research paper scalable learning non decomposable objectives covers method sidestep combinatorial optimization use certain calculated bounds tensorflow code authors available tensorflow models repository additionally followup question stackoverflow answer adapts usable keras loss function special thanks francois chollet participants keras issue thread turned research paper may also find thread provides useful insights problem hand problem unbalanced datasetsuggest usescore metric optimizer andrewteaches one metric model simplest best way train model metrics like precision recallclear one important trying set limits one metric obviously impactsusing unfortunately implementationscore metric like one accuracy many keras metrics used epoch aakashgoel add user defined function getscore keras metricsceve implemented simple function article model trains nowscore keras optimizer metric results test accuracy went bitscore went lot problem regarding unbalanced dataset binary classification want increase recall sensitivity found built function recall recommended approach deal unbalanced dataset like use class weights sample weights see model fit api details quote class weight optional dictionary mapping class indices integers weight float value used weighting loss function training can useful tell model pay attention samples represented class weights inversely proportional class frequency loss will avoid just predicting background class understand formulated question imho practical approach issue facing think callbacks early stopping mechanisms provide one techniques can lead close possible want achieve please read following article jason brownlee early stopping read end say confusion matrix computedtrueprediction just shifts problem edit seraloukanswer class considered negatives variations positives using data can get metrics classes general case lot classes metrics represented graphically following image another simple way pycm supports multi class confusion matrix analysis applied problem since several ways solve none really generic see noredirectsolution seems used paper unclear count confusion two foreground pages false positive solution import numpyusetrueprediction currently performing multi class svm linear kernel using pythonscikit library sample training data testing data given model data want plot decision boundary visualize datasets can someone please help plot type data data given just mock data feel free change values helpful least suggest steps followed thanks advance choose features reason plotplot selecting features use visualization decision surface also written article source friends linkfddaf now next question ask can choose features lot ways univariatevalue feature ranking test see features variables important use plot also reduce dimensionality using pca exampleplot features using iris dataset edit apply pca reduce dimensionality edit aprilcan use mlxtendquite clean first pip install mlxtendtwo dimensional data matrixassociated vector training labels using libsvm say feature values following format think two scaling can applied scale instance vector vector zero mean unit variance scale colum matrix range example according experiments rbf kernel libsvm found second scaling improves results understand reason gives improved results anybody explain reason applying scaling second option gives improved results standard thing make dimension attribute column example zero mean unit variance brings dimension svm magnitude cjlin papers guide main advantage scaling avoid attributes greater numeric ranges dominating smaller numeric ranges another advantage avoid numerical diculties calculation kernel values usually depend inner products feature vectors nel large attribute values might cause numerical problems recommend linearly scaling attribute range believe comes original data lot original data extreme values columns opinion lose definition scaling linearly example range letsay column values remaining values low high scale data linearlyargue discernibility originally smaller scaled data comparison original data end believe much comes specifics data believe improved performance coincidental will certainly see difference magnitude every dataset try scaling methods time paper link listed answer can clearly see authors recommend data scaled linearly hope someone finds useful accepted answer speaks standard scaling efficient high dimensional data stored sparse matrices text data use case cases may resort max scaling variants works sparse matricestrying get hands experience keras holidays thoughtstart textbook example timeseries prediction stock datatrying given last hours worth average price changes percent since previous predict average price chanege coming hour however verifying test set even training set amplitude predicted series way sometimes shifted either always positive always negative shifted away change think correct kind thing came following minimal example show issue can see create training testing sequences selecting last hours next step tuple advancing hour repeating procedure model simple lstm dense layer expected plot individual predicted points overlap pretty nicely plot training sequences set trained sort match test sequences however get following result training data idea might going misunderstand something update better show mean shifted squashed also plotted predicted values shifting back match real data multiplied match amplitude can see prediction nicely fits real datajust squashed offset somehow canfigure presume overfitting since dimensionality data lstm units seems rather complex low dimensional datasetlist things try update let summarize discussed comments section just clarification first plot doesnshow predicted series validation set training set therefore first overfitting interpretation might inaccurate think appropriate question ask actually possible predict future price change low dimensional dataset machine learning algorithms arenmagicalfind patterns data exist past price change alone indeed informative future price change values timestepst happened correlated general presume model confident correlation amplitude prediction bigger try try overfit mse around zero real dataset apply regularizations update let explain get good fitlet consider lstm layer black box forget returnsvaluesvalue goes forward dense layer apply vector values functionb vectors definedbeginning usually near zerovalues lstm layertarget single value just epochb fitted data around zero actually apply predicted value someway apply target variableb nowb single values vectors applied single value almost work dense layer increase number epochs get better fitting update way see outliers data can try also use mae loss accuracy metrics problem week found solution thing worked using window normalization method described check partforecasting good daypoint aswell batch size increase helps completly simplernn fixes lstm problems relu elu activation learning rate increased default try cofigure smoternn soultion past data change time period betweens rows aquire data model find patterns seems work atm still trying push accuracy accuracy mean abosule error executing can get object count can use tensorflow object counting api open source framework built top tensorflow makes easy develop object counting systems count objects moreover provides sample projects can adopt develop specific case studies see tensorflow object counting api info please give star repo showing support open source community find useful solve simply print length codeimportant note number boxes always look code actually draws boxes visseedefining threshold min score thresh limit boxes drawn detections score can think drawing boxes probability accurate detection can adjust threshold increase number boxes drawn decrease low however will get lot inaccurate boxes add part count objects count number objects detected part will print count will print continuous manner can used print like final count value instead printing repeatedlythis common use machine learning pipelines work never understood meaning reshape exact question solid explanation answers pls numpy creating matrixitems like numpy internally stores items array items regardless shape object allowschange shape array dimensions long number items array change example reshaping objectok keep items reshapingwork enough items list back question notation unknown dimension meaning let numpy fill missing dimension correct value array remain number items equivalent internally numpy just calculating get missing dimension can even start array middle two examples equivalent will try mark two dimensions unknown numpy will raise exception know meaning one way reshape array means size dimension passed inferred thus means reshape second dimension size calculate correct size first dimension see documentation fact shows weights evolved optimizer however uncomment intermediate hidden layer train resulting network see weights evolving anymore evaluation estimate converging quickly fixed value becomes independient input signal idea happening question idea might wrong second exampledr deeper neural network becomes pay attention gradient flow see discussion vanishing gradients one particular case variables initializationadded tensorboard summaries variables gradients scripts got following layer network layer network charts show distributionsvariable first layer changed epoch clickable indeed can see rate change much higher layer networklike pay attention gradient distribution much closer layer network first variance around second one around vanishing gradient problemhelper codeinterested deep networks suffer extent universal solution will auto magically fix network techniques can push right direction initialization one replaced normal initialization lots tutorials xavier init can take look one example note set bias init slightly positive make sure relu outputs positive neurons least beginning changed picture immediately weights still moving quite fast moving note scalevalues gradients distribution became much less peaked thus much better courseend improve implement full autoencoder currently loss affected element reconstruction outputs arenused optimization can also play different optimizers adam choice learning rates looks exciting exactly code belongrecently discovered tensorboard callbacks somehow fiting trying make simple proof concept can see probabilities different classes given prediction however everything try seems output predicted class even though using softmax activation new machine learningsure making simple mistake feature available kerasusing keras tensorflow adapted one basic examples given keras classifying mnist dataset code exactly example except commented extra lines exports model local file second part simple script import model predict class given data print probabilities class using mnist class included keras codebase make example simple possible run first script export model second script classify examples get following output great seeing class predicted want see relative probabilities class example looking something like words need know sure prediction just prediction thought seeing relative probabilities part using softmax activation model canseem find anything keras documentation give probabilities instead predicted answer making kind silly mistake feature available turns problem fully normalizing data prediction script prediction script following lines data cast float divided just showings keras predict indeed returns probabilities classes reproduce issue system configuration prediction outputslice loaded model trained epochs code suspect rounding issue printing trained much epochs probabilities training set gotten close convince indeed get probabilities class predictions suggest try getting predictions model trained single epoch normally see much lesscase model trained epochs dataset consisting numeric values representing distances ranging till want cluster numbers howevertrying classical clustering approach establishdistance matrix representing distances two numbers dataset wonfit memory wondering smart way solve problem without need stratified sampling also tried bigmemory big analytics librariesstill canfit data memory largesmallalso particularlyeven worsen runtime may want try elki great index support trytree sorttimerecursive bulk loading index support makes lot lot lot faster insist usinggive least kmeans try fastcluster packagemeans runtime complexitynk parameternumber iterations fastclustern memoryn runtime implementation single linkage clustering comparable slink algorithm elkiagnes hierarchical clustering will usen runtimen memory implementation matters often implementationsarenbest imho except coreusually least competitive numerical precisionbuilt statisticians data minersfocus statistical expressiveness scalability authors arenblamejust wrong tool large datadata dimensional donuse clustering use kernel density estimation dimensional data specialordered good algorithm breaking dimensional data inverals exploit can sort data can use kmeans normally suitable amount data calculate important number centers perform hierarchical clustering approach coordinates least visualizing cluster big data largevis algorithm tangal largevispackage unfortunately orphaned cran due lacking package maintenance maintained version can still compiled github repository via installed rtools python version package exists underlying algorithm uses segmentation trees neigbourhood refinement findsimilar instances observation projects resulting neigbourhood network dim lower dimensions implementeduses openmp supported compiling multi processing thus sufficiently fast clustering larger data sets tested farusing python know will basic howeverreally confused like better understanding seaborn two numpy arraysylike use seaborn plotnumpy arraynumpy array can successfully plot data points taking account class labelarray thank can use seaborn functions plot graphs dir sns see plots output exact input output wanted can pyplot just importing seaborn changes pyplot color plot scheme stackoverflow post got problem custom loss function trying load saved model loss looks follows training used weighted loss function loss function everything worked training finished save modelfile standard questions can fix problem may possible reason wrapped loss definition keras doesnknow handle weights variable loss functionname losstruepred therefore loading back model need specify loss name full examples demonstrating saving loading keras models custom loss functions models please look following github gist files custom loss function defined using wrapper tested examples python tensorflow built simple network tutorial got error runtimeerror expected object type type mat help thankdr fix slight difference place operator therefore changes net moves device hand change inputs rather returns copy inputs resides device use device copy need assign variable henceinew machine learning tensorflow since donknow python decide use javascript version maybe like wrapper problem tried build model process natural language first step tokenizer text order feed data model lot research using python version tensorflow use method likefind similarstuck step donknow can transfer text vector can feed model please help transform text vectors lots ways depending use case intuitive one one using term frequencygiven vocabulary corpus words possible text document will represented vector entry represents occurrence word text document vocabulary following text will transformed vector one disadvantage technique might lots vector size vocabulary corpus others techniques however bag words often referred slight different version using faced issue handled following steps created npm module recently also helps anyonespeech api mahesh last month google added support detection spoken languages speech text api google cloud speechp betabit limited though provide list probable language codessaid supported voice command voice search modesuseful clue languages may audio docs alternative language codes string optional list additional bcp language tags listing possible alternative languages supplied audio see language support list currently supported language codes alternative languages listed recognition result will contain recognition likely language detected including main language code recognition result will include language tag language detected audio note feature supported voice command voice search use cases performance may vary use cases phone call transcription requests google cloud speech api require following configuration parameters encoding sampleratehertz languagecode possible google cloud speech api service automatically detect language used service will configured parameter languagecode start recognizing speech specific language mind parallel google cloud translation api input language automatically detected please consider automatically detecting language used audio file requires much bandwidth storage space processing power text file also google cloud speech api offers streaming speech recognition real time speech text service languagecode parameter especially required trouble fine tuning inception model keras managed use tutorials documentation generate model fully connected top layers classifies dataset proper categories accuracy using bottleneck features inception epochms step loss acc also able stack model top inception create full model use full model successfully classify training set inspection results processing full model match accuracy bottleneck generated fully connected model problem take full model attempt train accuracy drops even though validation remains epochs step loss accval loss val acc gets worse things progress epochs step loss acc val loss val acc thing think somehow training labels getting improperly assigned last trainsuccessfully done similar code using vgg searched code trying find discrepancy explain model making accurate predictions time drops training accuracy maintaining validation accuracy fine tuning canfigure help appreciated information code environment things going stand weird meant way using checked appear unrelated note since problem bit strange difficult debug without trained model dataset answer just best guess considering many things maywrong please provide feedback will delete answer work since inceptioncontains batchnormalization layers maybe problem due somehow ambiguous unexpected behavior layer set trainable parameter false now letsee root problem suggested fchollet set learning phase defining model fine tuning side note causing problem case keep mind use top model base whole sequential model stored one layer fullmodel can verify either using print hence used actually freezing last layer base model however since concatenate layer therefore trainable parameters problem occurs behave intended like previous replytry share thoughts see whether helps couple things called attention maybe worth reviewing note given issues separate models hope helps used caret logistic regressiondefault metric printed accuracy cohen kappa want extract matching metrics like sensitivity specificity positive predictive value etc find easy way final model provided trained data far can tell documentation use predicting anew confusion matrix calculates required parameters passing summary function doesnwork way extract information addition accuracy kappa somehow find train object returned caret train thanks advance caret already summary functions output metrics mention defaultsummary outputs accuracy kappa twoclasssummary outputs auc area roc curve see last line answer sensitivity specificity prsummary outputs precision recall order get combined metrics can write summary function combines outputs three try sonar data set defining train control important set classprobs true since metrics roc prauc can calculated based predicted class based predicted probabilities now fit model choice output roc fact area roc curve usually called auc auc area precision recall curve across cutoffswondering better use gridsearchcvjobs pick best parameter set modeljobsjobs big number likejobs based sklearn documentationjobs means computation will dispatched cpus computerintel cpu cores threads mean setjobs implicitly will equaljobs mean setjobs implicitly will equaljobs python scipy joblib inside gridsearchcv used detect number cpu cores reasonable schedule concurrent independent processes given request donejobs setting funny see cpu core virtualised machine cases can synthetically emulate cpu cores results trivial known intel cpu case doubts one can test trivialised case indeed small data set full blown model space search let storyprove similar host platform self detection may report details different systems settings better use gridsearchcv pick best parameter set modeljobsjobs big number likejobs scikit tools many followed practice used spawnjobs directive used required amount concurrent process instances escape shared gil lock stepping read elsewhere interested details process instantiation cost free time wise time domain costs also space wise space domain given fight battle dual edged sword attempt underbook cpu will let cpu cores possibly idling attempt overbook ram space will turn performance worse expected virtual memory will turn operating system swapping turns machine learning scaled data access timesx slowerhardly one will pleased overall effectsjobs reasonable amount processes subject amdahllawformulated one add overhead naive version will practical optimality peak maximum many cpu cores will help improve oneprocessing intentions beyond overhead costs sketched time space domains will actually deteriorate potential positive impact expectations used randomforestregressor indeed large data sets production can tell space domain worse enemies trying growjobs farther none system level tuning will ever overcome boundary ultra low latency ram real cpu cores practical recipe going indeed largerjobs computing plans additional simpler answer prof kevyn collins thompson course applied machine learning python cores systemjobs example willjobs additional effect maximum performance can obtained always usingjobs matricewant cluster clusters use method yields idxctrsget pointwant know rowscorresponds among given clusters possible matlab thank advance following complete example clustering canthink better way described built function save one line couldnfind onecode use donknow get meaning right want know cluster points belong can use knnsearch function easily two arguments will search first argument first one closest argument two assumingusing squared euclidean distance metric try predicted contain index closest centroid distances contain distances closest centroid take look inside kmeans function subfunction distfun shows also contains equivalents distance metrics small amount data somewhat obscure bsxfun permuted ctrs createsx array booleansacross second dimension permuted back row ids found probably practical large amounts serial pipeline can defined get best combination hyperparameters consecutive parts pipeline serial pipeline can implemented follows want try different algorithms step pipeline can support vector machines random forest require kindlevel meta gridsearch since type model one hyperparameters possible sklearn pipeline supports none steps list estimators certain part pipeline can toggled can pass none parameter named steps pipeline use estimator setting params passed gridsearchcv assume want use pca truncatedsvd add svd pipeline now just pass pipeline object gridsearchcv calling will search parameters elements params grid list using values one time estimators name parameters case pca truncatedsvdcomponents just want search parameter can simplified generalization scheme can make function can automatically populate param grid supplied gridsearchcv using appropriate values use function number transformers estimators now initialize pipeline object names used pipeline steps now finally set gridsearchcv object fit datai data matrixx matrix labelsx want split data matrixtwo random subsets column vectors training will data testing will data need still able identify labelcorresponds column vector couldnfind function ideas edit thought add two labelssure makes differencepretty easy use randperm generate random permutation indices many points simply use subsety extract training test data labels something like split point determines many points need place training set will need round case calculation yields decimal points also didnhard code data set might grow will work size data set choosetraintrain will contain data labels training settesttest will contain data labels test set first columntrain data point first element training set first elementtrain serving label particular trying finetune retrain inceptionv model data able convert image data tfr format data using pass converted data finetune inceptionflowers complete training evaluation according script file attaching logs two according discussion used following parameters input graph inceptionv logits predictions softmax operation named input graph following changes made private static final int image mean private static final float image std private static final string input name input input private static final string output name inceptionv logits predictions softmax output private static final string model file file android asset frozen tensorflow inception graph private static final string label file file android asset imagenet comp graph label strings inputs spotted variables spotted found possible outputs name inceptionv logits predictions softmaxsoftmax foundconst parameters variable parameters control edgestypes used const mul add sub identity sum reshape convrsqrt relu reciprocal square squareddifference mean stopgradient maxpool concatv squeeze randomuniform softmax realdiv queuedequeuev floor fifoqueuev biasadd avgpool please help understand can fix issue input network created can add images images name inputs name tensor followed success mllib tutorials canget one working found sample code linear least squares lasso ridge regression section linearregressionwithsgd codeexactlywebsite result training mean squared error gives problem predictions looks totally random wrong since perfect copy website example input data training set donknow look missing something please give advices clue search can read experiment thanks explained zero setting intercept true will solve problem set true regression line forcedorigin appropriate case sure included sample code fix problem change following line code pyspark although mentioned explicitly also code selvinsource question working changing step size doesnhelp much example linear regression sgd based requires tweaking step size see set step size get better results mse another example realistic dataset see tried use joblib train multiple scikit learn models parallel however call last line takes ages without utilizing cpu fact just seems block never return anything mistake test small amount data xtrain suggests copying numpy array across multiple processes reason delay check cpu also resources state figures across node read profile stunning moment sir computer scientist specializing algorithms data analysis training generalist nature skill set combines strong scientific background experience software architecture development especially solutions analysis big data offer consulting development services looking challenging projects area data science problem deeply determined respect elementary computer science algorithm rules problem demanding strong scientific background common sense problem especially big data requires smell things actually work step never hire fire straight every consultant respect facts answer referred suggest anything less granted promises ignoring facts might successful sinmarcom advertisement media businesses case customer tolerates dishonesty manipulative habit scientifically fair quantitative domains unforgivable step never hire fire straight every consultant claimed experience software architecture especially solutions big data pays zero attention accumulated lumpsum add overhead costs going introduced respective elements system architecture processing starteddistributed across pool hardware software resources unforgivable step never hire fire straight every consultant turns passive aggressive facts fit wishes starts accuse knowledgeable person already delivered helping hand rather improve communication skills instead learning mistakesure skill may help express obvious mistakes way yet gigantic mistakes will remain gigantic mistakes every scientist fair scientific title never resort attack helping colleague rather start searching root cause mistakes one sascha may suggest take little break stackoverflow cool work little interpersonal communication skills nothing straight intellectually unacceptable nasty foul sascha imperative form syntax constructor ignites immense amount activities start least guess happens scientifically fair approach test several representative cases benchmarking actual execution collect quantitatively supported facts draw hypothesis model behaviour principal dependencies cpu core count ram size afunction complexity resources allocation envelopes etc collected representatively enough data nop case reasonably scaledlandscape runs run jobs spawn cartesian space datapoints generate least first hand experience actual system costs launching actually intrinsically empty processes overhead workloads related imperatively instructed syntax constructor spawning system scheduler just joblib managed nop fun instances letalso agree real world problems machine learning models included way complex tools just tested nop fun cases pay already benchmarked overhead costs even paid getting literally zero product thus scientifically fair rigorous work will follow simplest ever case already showing benchmarked costs associated setup overheads smallest ever penalty sine qua non forwards direction real world algorithms live best next adding larger larger payload sizes testing loop collect representatively enough quantitative data costs actual remote process mem allocations running nop fun just mem allocator reasonable wide landscape sizescaling reasonably scaledlandscape runs run jobs spawn cartesian space datapoints touch new dimension performance scaling extended black box process test experimentation inside tool leaving magics yet leftopened one may soon notice static sizing matters also mem transport bandwidth hardware hardwired will start cause problems moving data cpu mem costsway smart shuffling bytes inside cpu core cpu core private cpu core shared cpu die shared cache hierarchy architecture alone non local numa transfer exhibits order magnitude add pain letstart burn oil fine starting smell things hood actually work will grow become ugly dirty still nothing extraordinary compared common grade payloads domain machine learning manyspace dimensions amlmodelspace asetofhyperparameterspace adataset state space impact scope processing requiredncomplexity almost immediately engineered just one cpu core soon gets harnessed even single job run indeed nasty smell starts naive read resources usagecoordinated cpu load mixtures get road mixes task related cpu loads start get mixed naive read resources usagecoordinateds scheduler processes happen fight common resorted just naive shared use policy resources introducing swaps cpu introducing cache misses memfetches yes swaps penalties added speaking paying kindlatency fees one forgets process touch fileio orders magnitude slower shared pure serial nature device prayers help ssd included just orders magnitude less still share running device incredibly fast wear tear grave virtual memory paging swaps start literally deteriorate rest far somehow just coincidence read weaklyordinated concurrently scheduled processing read decreased individual process test performance fact matters light weight resources monitor class may help similarly bit richer constructed resources monitor may report widers context see additional resource stealing contention race conditions deteriorate actually achieved process flow besides gradually built records evidence real world system deployment add overheads accumulate costs recentlyformulated amdahllaw extended cover add overhead costs plus process atomicity indivisible parts sizing defines maximum add costs threshold might reasonable paid distributed processing provide computing process speedup dis obeying explicit logicformulated amdahllaw causes process proceed worse processed pure serial process scheduling sometimes results poor design operations practices may look case method blocks process training images downscaled versions associatedimage thus input output images arendimension nowusing hand crafted sample images eventually like able use ishhigh resolution images dataset dataset however images dimensionguessingcrop order obtain uniform dimension currently code set takes bunchx images applies transformations augment data flips thus obtain basic set imagesform downscale factor thus obtaining trainset consits images dimensionx question case can use preprocessing tool keras offers ideally like able input varying sized images high quality crop downsizex data augment flips whatnot substracting mean also partlike achieve set represent validation set reusing validation set want downscale factor images generate training set two sets split appropriately obtain ultimately famoustraintraintesttestjust hesitant throwing workdone far preprocess mini samplethinking can done single built function maybe givefirstproject hence understanding keras documentation isnalways clearestthinking factworkingy different size maybe function doesnapply project thank yes can use keras preprocessing function snippets helpsuggestion clean nice just like offer another way using imgaug convenient way augment images lots different waysusefull want implemented augmentations ever need uselibrary keras unfortunatly doesnway make crops way allows implementing custom functions example function generating random crops set size imageleast big chosen crop size can combine function builtin imgaug function example flip functionsalready using like function generate lots different crops image example image possible results note result actual images just merged one image visualization image set generated also simple add new functions applied images example remove mean functions mentionedanother way performing random center crop resizing using native imagedatagenerator flow directory can add preprocess line appears commonfind way perform crop resizing without rewriting many classes due limitations cropping method enumerated interpolation field methods delimited first part interpolation second crop random supported crop methods none center random crop method specified none assumed just drop preprocesspreprocess end result like computer program can accept list inputs outputs apply algorithm went input outputanother numbergiven list input outputrealize algorithm input output depending wanted given number asked produce output program respond given number asked produce input respond obviously rather simple hardcode program althoughlike learn program teach algorithm understand will get rather complicated rather fast can reliably type input output signal dependency instead support otherwise need kindcomplex neural network many functional generators insane complexity unknown reliability solution simplify dependencies like polynomial degree exponential anyway think just input points will enough first determine type dependency try find coefficients particular function generator example mixed type signals need much input points covering big enough range probably need kind approximation search coefficients minimizing distance known inputs generated output enough points can normalize dataset use correlation coefficient compare supported function generators simplify decisioning notes need specify new tensorflow canget input placeholder often dimensioned size batches used training example found official mnist tutorial best right way dimension create model input train specifying model input want leave batch size none means can run model variable number inputs one batching important efficiently use computing resources next important line sending elements input can also change just one without modifying graph specify batch size number instead none first snippet change time ideal specially production model trained mnist put handmade sample image raises valueerror input layer sequential incompatible layer expected axis input shape value received input shape none already checked input model shape mnisttrain shape image please help valueerror input layer sequential incompatible layer expected axis input shape value received input shape none need extra dimension full working code model eval inferencefollowing code generates tri gram removing stopwords want allow trigram stopword middle start end processor needs written need suggestions yes need supply analyzer function will convert documents features per requirements according documentation analyzer string word char charcallable custom callable need take care first splitting sentence different parts removing special chars like comma braces symbols etc convert lower case convertgrams default implementation works single sentences following order need handle want pass custom callable analyzer param tfidfvectorizer can extend tfidfvectorizer class override last steps something like use like edit answer questions heavily discussed sum spark gone bad compute cost kmeans saw one can compute cost kmeans model wondering able compute unbalanced factor functionality provide spark easy way implement able find ref unbalanced factor similar yaelunbalanced factor comments found idea tot total will equal number points assigned clustersunbalanced factor holds square number points assigned cluster finally usesuftot tot compute python something like working python tensor flow miss units argument know solve looks like post mostly code please add please add details code try changing line dense output dim num classes activation softmax dense num classes activation softmaxexperience keras find parameter called output dim documentation page dense think meant provide units labelled output dim keras dense layer documentation follows using following will work units means output dim saying need neurons hidden layer weights initialized uniform function input layer independent variables dataset input dim feed hidden layer thinkversion issue updated version keras dense output dim argument can see documentation link dense arguments units mandatory instead line use oritrouble importing machine learning algorithms scikit learn installed whenever type example says recognized internal external command operable program batch fileusing anaconda windows compatibility issue missing something idkstill new python feel lost thanks needs run python repl command line sure start one typing python statements need write import command python terminal can activate python terminal using python command issue internal external command can solved just steps make sure undo hidden apps worked mei performing cnn google colab notebook pro version thoughtrain takes shape model gets trained rows one faced issue model runs fine local machinejupyter notebook runs rows number batches default batches contain samles use keras instead log will show internally one showing number samples trained keras another showing number iterations can probably train samples time need batch inputs gpu memory can try increasing batch size much can pointget error like oomerror cuda memory etc tabular data columns contain text data can see picture cleaning text converted text matrixes object data types categories using tokenizer final result making tokens converting trainx trainy label lost implement lstm seen many examples mostly one column target column confused adjust data lstm data want look link datai using svm implementation opencv based libsvm ios possible obtain weight vector training thank dealing able obtain weights obtaining weights one obtain first support vectors add multiplied alpha values trick instance variable float decision function protected opencv framework change order access cursory glance doc source code tells surface answer hyperplane parameters seem tucked away cvsvmsolver class cvsvm contains object class called solver see can get members implementedalgorithm gmm using post gmms maximum likelihood optimization using numpy unsuccessfully follows run algorithmtime series datasetequal returns output like following believe working wrong since outputs two vectors one represents means values one represents variances values vague point made doubtful implementation returns backoutputs can seen doesnneed really visualize outputs btw input data time series data checked everything traced multiple times bug shows input data wondering elegant way implement via numpy scikit learn helps will appreciated update following current output expected output mentioned comment critical point see means initialization following default implementation sklearn gaussian mixture instead random initialization switched kmeans seems yield desired output much consistently finally can see purely random initialization generates different results letsee resulting means one can see different results cases resulting means constant meaning inizalization chose similar values didnchange much iterating adding print statements insidegmm will clarify another problem also initialization variances changes implementation result trying implement weighted average two tensors tensorflow weight can learned automatically following advice design custom layer keras model attempt following now problem training model saving loading valueremains possible parameter receive gradient updates printing trainable variables model parameter listed therefore included calling weight can learned automatically also introduce constrain weights must sum grant simply apply softmax weights dummy example combine method output two fully connected branches can manage every scenario custom layer full example regression problem end can also visualize value weights way details please see evaluate accuracy loss trained model good caffe took model snapshot end iteration using python script tried construct confusion matrix accuracy reported using thank advance differences validation step test phase python code running using different mean file train test phase train using mean file phase test using mean file python evaluation code uses training mean file validation good practice different settings train validation input images new height copr size settings means caffe reads image scalescrops center sizepython code seems scale inputwithout cropping feed net different inputs please verify differences training prototxt deploy decidedback basics simple function approximation see everything working correctly see parameters affected learning process code came problem predictions around value can see used extratreesregressor sklearn commented lines check protocol actually correct wrong neural network working actual problemtrying solve computefunction mountain car problem using neural network different function approximator changes result tinker changes made replacing low layer activations hyperbolic tangents replacing static dataset random generator replacing sgd adam said still problems parts code havenable locate yet likely scaler random process managed get good approximation changing architecture training following codebit overkill least know problem coming howeverstill baffled found papers saying using two hidden layers five neurons approximatefunction mountain car problem training network minutes get good results will try changing batch size original problem see results can getoptimistici trying solve optimization problemsimilar knapsack problem can solved using dynamic programming problem want solve similar problem indeed may solve cplex let show opl model mod data dat givesann artificial neural networks svm support vector machines two popular strategies supervised machine learning classificationoften clear method better particular projectcertain answer always depends often combination along bayesian classification used questions stackoverflow already asked regarding annsvm ann svm classification difference among ann svm knn classification question support vector machine artificial neural network text processing questionlike know specifically aspects ann specifically multilayer perceptron might make desirable use svm reason askeasy answer opposite question support vector machines often superior anns avoid two major weaknesses anns anns often converge local minima rather global minima meaning essentially missing big picture sometimes missing forest trees anns often overfit training goes long meaning given pattern ann might start consider noise part pattern svms donsuffer either two problems howeverreadily apparent svms meant total replacement anns specific advantageann svm might make applicable certain situationslisted specific advantages svm ann nowlike see list ann advantages judging examples provideassuming anns mean multilayer feed forward networksnets short multilayer perceptrons direct competition svms one specific benefit models svms size fixed parametric models svms non parametric ann bunch hidden layers sizeshn depending number features plus bias parameters make model contrast svm least kernelized one consists set support vectors selected training set weight worst case number support vectors exactly number training samples though mainly occurs small training sets degenerate cases general model size scales linearly natural language processing svm classifiers tens thousands support vectors hundreds thousands features unheard also online trainingnets simple compared online svm fitting predicting can quite bit faster edit pertains general case kernelized svms linear svm special case parametric allow online learning simple algorithms stochastic gradient descent one obvious advantage artificial neural networks support vector machines artificial neural networks may number outputs support vector machines one direct way createary classifier support vector machines createsupport vector machines train one one handary classifier neural networks can trained oneadditionally neural network will make sense one whole whereas support vector machines isolated systems especially useful outputs inter related example goal classify hand written digits ten support vector machines support vector machine recognize exactly one digit fail recognize others since handwritten digit meant hold information just class makes sense try solve artificial neural network however suppose goal model personhormone balance several hormones function easily measured physiological factors time since last meal heart rate etc since factors inter related artificial neural network regression makes sense support vector machine regression one thing note two actually related linear svms equivalent single layers perceptrons multi layer nns can expressed terms svms see details want use kernel svm guess kernel however anns universal approximators guessing done width approximation accuracy height approximation efficiency design optimization problem correctly fit please see bibliography fitting also depends training examples scan correctly uniformly search space width depth discovery subject integer programming suppose bounded functionsbounded universal approximators range example parametrized real sequence compact supportproperty exists sequence sequences draw examples testsy distributionixi prescribed support find best letrandom variable fitting average usingdyxlet explain selecterror minimized rare set values perfect fit however since rare average never want minimize second although discrete approximationkeep mind support length free one answermissing multi layer perceptron able find relation features example necessary computer vision raw image provided learning algorithm now sophisticated features calculated essentially intermediate levels can calculate new unknown features also consider svm system can applied directly non metric spaces set labeled graphs strings fact internal kernel function can generalized properly virtually kind input provided positive definiteness requirement kernel satisfied hand able use ann set labeled graphs explicit embedding procedures must considerednew tensorflow greatly benefit visualizationsunderstand tensorboard useful visualization tool run remote ubuntu machine avoid issues making remote server accept local externaleverything port server will forwarded machine port can port forward another ssh command need tied connecting server alternative answer thus ordering steps arbitrary local machine run sshflocalhost localhost user remote remote machine run tensorboard logdir path port navigate example http localhost local machine explanation ssh commandremote commandsput ssh backgroundmachine porta machine portb forward machine porta local scope machine portb remote scope donneed anything fancy just run connect server url port host tells tensorflow listen connections ipv addresses local machine another option canget working reason simply mount logdir directory filesystem sshfs sshfs user host home user project summary logs summary logs run tensorboard locally bind option useful port will automatically selected incrementally can directly run following command terminal remote server run tensorboard can also start tensorboard within ipython notebook remote server open traffic localaddress able see remote tensorboard warning internet traffic can access system havenspecified singleaddress can access anyone may able view tensorboard results runaway creating skynet create ssh connection using port forwarding run tensorboard command can easily access tensorboard browser proper answer troubleshooter hopefully helps less seasoned networkers like case firefox ubuntu browser connecting showing blank page tensorboard logo tab log activity shown still donknow reason didnlook much anybody knows please let know solved switching ubuntudefault browser exact steps pretty much olivier moindrotanswer check ssh tunnel effectively working simple echo server like python script can help said hope helps cheers andres another approach use reverse proxy allows view tensorboard internet connected device without sshing approach can make far easier tractable view tensorboard mobile devices example steps download reverse proxy ngrok remote machine hosting tensorboard see minute setup run ngrok http assuminghosting tensorboard port save url ngrok outputs enter browser view tensorboard special thanks sam kirkiles anyone must use ssh keys corporate server just add ssh rsa end sshflocalhost localhost myname servername ssh rsa running tensorboard give one option hostsystem can access system using httphost system explicit connection optimizer loss optimizer know get gradients loss without call liks loss context minimize loss didnpass gradients optimizer without delving deep internals pytorch can offer simplistic answer recall initializing optimizer explicitly tell parameters tensors model updating gradients stored tensors grad requires grad attributes call backward loss computing gradients tensors model calling makes optimizer iterate parameters tensors supposed update use internally stored grad update values info computational graphs additional grad information stored pytorch tensors can found answer referencing parameters optimizer can sometimes cause troubles model moved gpu initializing optimizer make sure done setting model constructing optimizer see answer details call compute gradient loss true store updates parameters based although answers point sets grad attribute tensors requires grad true computational graph loss leafcase optimizer just iterates list parameters tensors received initialization everywhere tensor requires grad true subtracts value gradient stored grad property simply multiplied learning rate case sgd doesnneed know respect loss gradients computed just wants access grad property canxtrain step want compute new gradients doncare gradients previous batch zeroing grads lead gradient accumulation across batches answers explainedlike give specific example explain mechanism suppose functionxupdating gradient formulainitial valuesy calculating gradienty current valuey finally using sgd optimizer update valuey according formula letsay defined model model loss function criterion following sequence steps pred will gradattribute references function created ties back model therefore will information model working try removing gradattribute example model gradients will none consequently weights will get updated optimizer tied model pass create optimizer short answer gradient parameters set required grad true parameters variable defined code likehaccording optimizer function defined previously code update parameters finally get minimum loss error question appear programming within scope defined help center closed years agofollowing tutorial machine learning basics mentioned something can feature label know feature property data used canfigure label know meaning word want know means context machine learning briefly feature input label output applies classification regression problems feature one column data input set instancetrying predict type pet someone will choose input features might include age home region family income etc label final choice dog fish iguana rock etctrained model will give sets new input containing features will return predicted label pet type person feature machine learning feature means property training data can say column name training dataset suppose training dataset height sex age features label output get model training called label suppose fed dataset algorithm generates model predict gender male female model pass features like age height etc computing will return gender male femalecalled label comes visual approach explain concept imagine want classify animal shown photo possible classes animals case label possible class associations machine learning algorithm will predict features pattern colors forms part images feathers low level interpretation pixel values label bird features feathers label cat features furr prerequisite basic statistics exposurelinear regression can answered sentence alike definition changes according necessities let explain statement suppose dataset purpose consider age height heart rate body temp calories might one among various columns column represents distinct features property solidify understanding clear puzzle lettake two different problems prediction case case case might consider using gender height weight predict calories burnt exercise predictioncalories label calories column want predict using various features likegenderheightweight case second case might want predict heart rate using gender weight feature heart rate label predicted using featuresgenderweight understood explanation wonreally confused label features anymore lettake example want detect alphabet using handwritten photos feed sample images program program classifies images basis features got example feature context lettercan thought like concave facing right question now arises store features need namerole label comes existence label given features distinguish features thus obtain labels output provided features input labels associated unsupervised learning feature briefly explained input fed system label output expecting example fed many features dog like height fur color etc computing will return breed dog want know suppose want predict climate features given historic climate data current weather temperature wind speed etc labels months combination can help derive tried code successfully saves best model file named error get stored complete model weights hdf file simple load weights sets weights network still need define architecture calling load weights see following sample code build basic keras neural net model save model json weights hdf load according official documentation can install hdfpy save models keras can first testpy installed running errors importingpy good save need installpy realized accidently using whereas syntax intended used load model function normal way just writing worked done waythis question appear programming within scope defined help center closed years ago know lot explanations cross entropystill confused method describe loss function can use gradient descent algorithm find minimum using loss function cross entropy commonly used quantify difference two probability distributions context machine learning measure error categorical multi class classification problems usually true distribution one machine learning algorithm trying match expressed terms one hot distribution example suppose specific training instance true labelpossible labelsc one hot distribution training instance therefore can interpret true distribution mean training instance probability class probability classprobability classnow suppose machine learning algorithm predicts following probability distribution close predicted distribution true distribution cross entropy loss determines use formulax true probability distribution one hotx predicted probability distribution sum three classesc case loss note matter logarithm base use long consistently use one happens python numpy log function computes natural log log baseexample expressed python using numpy wrong far away prediction true distribution machine learning optimizer will attempt minimize loss see example loss using natural log log baseunits nats say loss nats log instead log base units bits see page explanation gain intuition loss values reflect letlook extreme examples letsuppose true one hot distribution now suppose machine learning algorithm really great job predicted classhigh probability compute cross entropy loss can see loss tiny extreme supposealgorithm terrible job predicted classhigh probability instead resulting loss will reflect larger error now happens middle two extremes supposealgorithm canmake mind predicts three classes nearly equal probability resulting loss cross entropy one many possible loss functions another popular one svm hinge loss loss functions typically writtentheta can used within gradient descent iterative algorithm move parameters coefficients towards optimum values equation replacethetapnote need compute derivativeprespect parameters first answer original questions directly method describe loss function correct cross entropy describes loss two probability distributions one many possible loss functions can use example gradient descent algorithm find minimum yes cross entropy loss function can used part gradient descent reading one answers related tensorflow short cross entropymeasure far predicted value true label cross refers calculating entropy two features true labels like term entropy refers randomness large value means prediction far real labels weights changed reducethus finally leads reduced difference prediction true labels thus better accuracy adding posts simplest form cross entropy loss known binary cross entropy used loss function binary classification logistic regression whereas generalized version categorical cross entropy used loss function multi class classification problems neural networks idea remains model computed softmax class probability becomes close target label training instance represented one hot encoding corresponding cce loss decreases zero otherwise increases predicted probability corresponding target class becomes smaller following figure demonstrates concept notice figure bce becomes lowp high low simultaneously agreement cross entropy closely related relative entropydivergence computes distance two probability distributions example two discrete pmfs relation shown following figure newbie convolutional neural networks just idea feature maps convolution done images extract features glad know details applying batch normalisation cnn read paper convolutional layers additionally want normalization obey convolutional property different elements feature map different locations normalized way achieve jointly normalize activations mini batch locations alg letset values feature map across elements mini batch spatial locations mini batch sizefeature maps sizeq use effec tive mini batch sizebpq learn pair parametersk per feature map rather per activation alg modified similarly inferencetransform applies linear transformation activation given feature map total confused say different elements feature map different locations normalized way know feature maps mean different elements weights every feature map understand location spatial location means understand sentence alg letset values feature map across elements mini batch spatial locations glad someone cold elaborate explain much simpler terms letstart terms remember output convolutional layer rank tensorhcbatch sizew feature map sizenumber channels indexyhw spatial location nowbatchnorm applied usual way pseudo code basically computeswmeanswstandard deviations acrosselements may notice different elements different spatial locations mean variance gathervalues way totally possible convolutional layer special property filter weights shared across input image can read detail posts reasonable normalize output way output value takes mean variancehvalues different locationscode looks like case pseudo code totalmeans standard deviations one computedhvaluesmean say effective mini batch difference two axis selection equivalently mini batch selection clarification maximanswer puzzled seeing keras axis specify channels axis doesnmake sense normalize channels every channel conv net considered different feature multivariate regression example andrewml course usually want normalize every feature std normalize square feet across examplesstd wantmeans stds want mean std per channel feature checking testing realized issuebit confusion misconception axis specify keras actually axis calculations exactly opposite behavior numpy works specified axis one operation etc actually built toy modelcalculatedmanually took mean std across first dimensionsnngotc results calculatedmu std using broadcasting got identical results keras results hope helps anyone confusedsure say make sense please edit mention downvoting location spatial location mean position pixels image feature map feature map comparable sparse modified version image concepts represented different elements feature map different locations normalized way normalisation algorithms local dependent close surrounding location things far apart image probably mean every pixel regardless location treated just like element set independentlydirect special surrounding alg letset values feature map across elements mini batch spatial locations get flat list every values every training example minibatch list combines things whatever location featureallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years agolooking open source implementation preferably python textual sentiment analysis anyone familiar open source implementation can usewriting application searches twitter search term say youtube counts happy tweetssad tweetsusing googleappenginepythonlike able classify returned search results twitterlike python havenable find sentiment analyzer far specifically python familiar open source implementation can use preferably already python hopefully can translate python note textsanalyzing short tweets ideally classifier optimized short texts btw twitter support operators search aim just unfortunately classification provided isngreat figured might give try thanks btw early demo code farlove opensource interested developer good luck sentiment enormously contextual tweeting culture makes problem worse arengiven context tweets whole point twitter can leverage huge amount shared real world context pack meaningful communication short message say video bad mean bad bad linguistics professor lecturing class one day english said double negative forms positive languages though russian double negative still negative however language wherein double positive can form negative voice back room piped yeah right kinds applicationsroll much code statistical classification task lucka suggested nltk perfect tool natural language manipulation python long goal doesninterfere non commercial nature license however suggest software packages modeling havenfound many strong advanced machine learning models available pythongoing suggest standalone binaries easily cooperate may interested toolkit advanced discriminative modeling can easily interfaced python used classification tasks various areas natural language processing also pick number different modelssuggest starting maximum entropy classification longalready familiar implementing naive bayes classifier may want look code one really get decent understanding statistical classification machine learning task university texas austin computational linguistics groups held classes projects coming used great tool can look course page computational linguisticsget idea make work previous applications served another great tool works vein mallet difference malletbit documentation models available decision treesjava opinion makes little slower weka whole suite different machine learning models one big package includes graphical stuffreally mostly meant pedagogical purposes isnreally somethingput production good luck task real difficult part will probably amount knowledge engineering required front classify seed set model will learn needs pretty sizeable depending whetherbinary classification happysad whole range emotions will require even make sure hold engineered data testing run tenfold remove one tests make sureactually good job predicting put fun best part nlpopinion thanks everyone suggestions indeed useful ended using naive bayesian classifier borrowed started feeding list good bad keywords added learn feature employing user feedback turned work pretty nice full details work blog post help useful thank constructed word list labeled sentiment can access new anew evaluation word list sentiment analysis microblogs article available homepage please note unicodeutf missing code paedagogic reasons lot research papers indicate good starting point sentiment analysis looking adjectives positive adjectives negative adjectives short block text pretty much sentence level analysis say tweets quite think best bet hunting one research papers trying get data set positively negatively oriented adjectives now said sentiment domain specific might find difficult get high level accuracy general purpose data set good luck think may find difficult findclosest thing know lingpipe sentiment analysis functionality available limited kind open source licence written java also sentiment analysis systems usually developed training system product movie review data significantly different average tweet going optimised text several sentences topic suspect better coming rule based system perhaps based lexicon sentiment terms like one university pittsburgh provide check feel fine implementation similar idea really beautiful interface twitrratr take look twitter sentiment analysis toolwritten python uses naive bayes classifier semi supervised machine learning source can found maybe textblob based nltk pattern right sentiment analysis tool came across natural language toolkit ago probably use starting point also lot modules addons maybe already something similar somewhat wacky thought try using twitter api download large set tweets classifying subset set using emoticons one positive groupetc another negative group etc crude classification search clues frequency ngram analysis something along lines may seem silly serious research done search sentiment analysis emoticon worth looktwitter sentiment api tweetfeel advanced linguistic analysis tweets can retrieve positive negative tweets see coursera course data science python code github part assignment link sentiments part afinn can find working solutions example addition afinn sentiment list simple implementation builing dynamic term list based frequency terms tweets pos neg score see trouble understanding difference one roc auc score auc scikit learn tying predict binary output imbalanced classes aroundsomebody can explain difference thought just calculating area roc curve might imbalanced dataset figure thanks auc always area curve roc curve area curve abstract area curve general thing auroc imbalanced classes may better find auc precision recall curve see sklearn source roc auc score can see first gets roc curve calls auc get area guess problem predict proba call normal predict outputs always changesometimes get different outputs predict returns one class compute roc results predict classifier three thresholds trial one class trivial class roc curve looks like meanwhile predict proba returns entire range probabilities now can put three thresholds data hence different areas usepred class labels already decided threshold useprob positive class probability open threshold roc curve help decide threshold first case using probabilitiesconsidering auc taking decision thresholdusing second case using prediction probabilities case use predict instead predict proba get result wondering classifiers handle nan null values scikit learn thought random forest regressor handles got error call predict can call predict scikit learn algorithm missing values edit now think makes senseissue training predict branch variable null maybe just split ways average result seems likenn work fine long distance function ignores nulls though edit older wiser gbm libraries xgboost use ternary tree instead binary tree precisely purpose children yes decision child missing decision sklearn using binary tree sometimes missing values simply applicable imputing meaningless cases use model can handle missing values scitkit learnmodels handle missing values xgboost can mentioned article scikit learndecision trees knn algorithms yet robust enough work missing values imputation doesnmake sense donkeep mind made example consider dataset rows cars danho diesel estal electric hesproc hybrid columns properties weight top speed acceleration power output sulfur dioxide emission range electric cars produce exhaust fumes sulfur dioxide emission estal electric nan value missing argue set electric cars produce sulfur dioxide imputing value will ruin predictions mentioned article scikit learndecision trees knn algorithms yet robust enough work missing values imputation doesnmake sense donmade example contains missing values training test sets just picked strategy replace missing data mean using simpleimputer class strategies using dataframe use fillna replaced missing data mean column nodata located edge geotiff image can obviously interpolated using average values neighbouring pixels masked lines code please note performed one bandband sentinel image first converted array performed random forest classification initial image following saving forget assign nodata value want write txt file neural network hyperparameters model architecture possible write object output file happensgetting none can see idea deal version keras python works outputs following lines file worked just get model summary string want write log understandalready accepted winnis answer since question title actually implies saving outputs string file following code might help others come page looking like code run using tensorflow comes keraspython yields string stumbled upon problem two possible workarounds use json method model case otherwise use ascii method keras diagrambest way one thing can redirect stdout see redirect print output file using python one option although exact replacement export modelconfiguration using docs returns dictionary containing configuration model model can reinstantiated config via problem pasaanswer useful thought post minimal examplereasonable assumption already keras model point example string useful matplotlib plot can use write summary model performance chart quick reference came find way log summary wanted share little twist ajb answer avoid info every line log file using fanders answer produces log filelooking applevision api documentation see couple classes relate text detection uiimages class vndetecttextrectanglesrequest class vntextobservation looks like can detect characters donsee means anything charactersgot characters detectedturning something can interpreted nslinguistictaggerpost brief overview vision thank readingfind complete project included trained model swiftocr just got swiftocr work small sets text vntextobservation swiftocr will post example using vntextobservation one connected opencv tesseract ocr tried use opencv tesseract got compile errors found swiftocr see also google vision ios note google vision text recognition android sdk text detection also ios cocoapod keep eye add text recognition ios eventually just tried android version sdk supports text detection can see textdetection added ios part cocoapod apple finally updated vision ocr open playground dump couple test images resources folder case called new class called vnrecognizetextrequest dump playground give whirldepth discussion wwdc adding progress anyone better solutionsuccessfully drawn region box character boxes screen vision api apple actually performant transform frame video image feed recognisermuch accurate feeding directly pixel buffer camera nowtrying actually reconize text apple doesnprovide built ocr model want use coremltrying convert tesseract trained data model coreml can find tesseract models can link tesseractios directly try feed region boxes character boxes get vision api thanks github user can test example result array bounding boxes detected character gathered visionsession think supposed use coreml detect actual chars recommended wwdc talk vision framework building corehavenfinished watching either look similar example called mnistvisionanother nifty app demonstrating use keras tensorflow training mnist model handwriting recognition using coreml githubusing googletesseract ocr engine convert images actual stringsadd xcode project using cocoapods although tesseract will perform ocr even simply feed image containing texts way make perform better faster use detected text rectangles feed pieces image actually contain text applevision framework comes handylink engine tesseract ocrlink current stage project text detection ocr already implemented loud camera speech hope can use good luck still looking solution wrote quick library uses vision api tesseract can used achieve task question describes one single method method will look text image return string found slice original image showing text found firebasekit ios android device vision api outperforms tesseract reading toc uses term batch instance without defined letsay want digit recognition mnist defined architecture network cnns now can start feeding images training data one one network get prediction till stepcalled inference compute loss compute gradient update parameters network proceed next image way training model sometimes called online learning want training faster gradients less noisy also take advantage power gpus efficient array operationsarrays specific instead feed say images time choice sizehyperparameter depends problem instance take look picture author martin gorner sincefeeding imagestime instead online training case batch size oftentimes called mini batch size simply mini batch also picture author martin gorner now matrix multiplication will just work perfectly fine will also taking advantage highly optimized array operations hence achieve faster training time observe picture doesnmatter much whether give batch size images long fits memory gpu hardwaresimply get many predictions please keep mind batch size influences training time error achieve gradient shifts etc general rule thumb batch size works best just try sizes pick one works best try use large batch sizes since will overfit data people commonly use mini batch sizes bonus get good grasp crazy canbatch size please give paper read weird trick parallelizing cnnsi using randomforestclassifier implemented python sklearn package build binary classification model results cross validations using price feature predict quality ordinal value cross validation training examples test examples apparently overfitting occurs parameters provided sklearn can used overcome problem found parameters quite understand tune thanks advance agree falconlikely main problem small size dataset possible best thing can get data data generally less likely overfit random patterns appear predictive start get drowned dataset size increases said look following params note work scientific use datasets training set separate development dataset tweak parameters test set tests final model optimal parameters change one parameter time evaluate result experiment sklearn gridsearch algorithm search across parameters adding late comment case helps others addition parameters mentionedestimators max features max depth min samples leaf consider setting min impurity decrease manually cumbersome use parameter grid find optimal parameters can use gini entropy criterion however recommend sticking gini default majority cases produce result entropy computational expensive compute max depth works intuitive way stop tree growing however just node less max depth doesnalways mean split information gained splitting addresses single misclassificationsplitting node may supporting overfitting may may find parameter useful depending size dataset feature space size complexity worth considering tuning parameters trained model classify images classes saved using code used successfully trained accuracy pretty good load test model new images used code outputs wouldngive actual name class someone still struggling make predictions images optimized code load saved model make predictions can use predict class single image follows doc example image loaded numpy array shape height width channels load model predict class returned real value range binary classification example keras predict classes docs outputs numpy array class predictions model case index neuron highest activation last softmax layer means model predicted test data class usually will passing multiple image result will look like must convert actual label cancer cancer binary encoding cancer cancer binary classification will interpret sequence output class label cancerre getting numeric value associated class example two classes cats dogs keras will associate numeric values get mapping classes associated numeric value can use now know mapping classes indices now can classes prediction dog else prediction cat forwarding example ritiekbeginnermaybe kind formatting will help see name instead just class calculate single number auc metric binary classifierlanguage simple english page auc better seems require knowing class labels example matlab donunderstandconfusedlanguage defined vector used function package proc can use function auc like example help page rocr package will calculate auc among statistics mentioned others can compute auc using rocr package rocr package can also plot roc curve lift curve model selection measures can compute auc directly without using package using fact auc equal probability true positive scored greater true negative example will give approximation auc can also estimate variance auc bootstrapping without additional packages found solutions slow confusing donhandle ties correctly wrotepackage mltools can learn auroc blog post miron kursa lettest auroc times faster proc auc computeauc auroc times faster mltools auc roc rocr performance combining code isl roc curves alongwonanswer question places following plots roc curve prints auc bottom right plot probs numeric vector predicted probabilities binary classification test label contains true labels test data gives plot like usually use function roc diagnosismed package like graph produces auc returned alongconfidence interval also mentioned graph along lines erikresponse also able calculate roc directly comparing possible pairs values certainly less efficient sample approach proc auc stable former requiring less installation latter related tried gave similar results procvalue exactly result closer sample approach highanyone ideas mightinterested currently top voted answer incorrect disregards ties positive negative scores equal auc corrected example calculating auc metrics package easy straightforward docs embedding layer keras say turns positive integers indexes dense vectors fixed sizebelieve also achieved encoding inputs one hot vectors length vocabulary size feeding dense layer embedding layer merely convenience two step process something fancier going hood embedding layer faster essentially equivalent dense layer makes simplifying assumptions imagine word embedding layer weights dense layer will treat like actual weights perform matrix multiplication embedding layer will simply treat weights list vectors vector representing one wordword vocabularystetc example use weights sentence naive dense based net needs convert sentence hot encoding matrix multiplication however embedding layer simply looks takes weights layer indices zero two one two immediately getresult just obtained hopefully faster way embedding layer limitations however none limitations matter just want convert integer encoded word embedding mathematically difference embedding layer performs select operation keras layer equivalent dense layer performs dot product operation plus optional activation can emulate embedding layer fully connected layer via one hot encoding whole point dense embedding avoid one hot representation nlp word vocabulary size can ordersometimes even million topoften needed process sequences words batch processing batch sequences word indices much efficient batch sequences one hot vectors addition gather operation faster matrix dot product forward backward pass want improve voted answer providing details use embedding layer generally reduce one hot input vectors sparse denser representations embedding layer much like table lookup table small fast table large table lookup much slower practice use dense layer dimension reducer reduce one hot input instead embedding layer casereading lot articles explain need initial set texts classified either positive negative sentiment analysis system will really work question anyone attempted just rudimentary check positive adjectivesnegative adjectives taking account simple negators avoid classing happy positive articles discuss just strategy isnrealistic classic paper peter turney explains method unsupervised sentiment analysis positive negative classification using words excellent poor seed set turney uses mutual information words two adjectives achieve accuracy haventried untrained sentiment analysis describing top headsayoversimplifying problem simply analyzing adjectives enough get good grasp sentiment text example consider word stupid alone classify negative product reviewproduct makes competitors look stupid thinking feature sentiment definitely positive greater context words appear definitely matters something like untrained bag words approach alone let alone even limited bag adjectives enough tackle problem adequately pre classified data training data helps problem shifts trying determine whether text positive negative sentiment scratch trying determine text similar positive texts negative texts classify way big point textual analyses sentiment analysis often affected greatly differences characteristics texts depending domain good set data train accurate data within domain working hopefully representative texts going classify important building good system classify exactly article hope helps paper turney mentioned larsmans good basic one newer researchintroduce approach using latent dirichlet allocation lda train model can classify articleoverall sentiment topic simultaneously totally unsupervised manner accuracy achieve tried several methods sentiment analysis opinion mining reviews worked best method described liu book liub compared many strategies discussed different papers sentiment analysis opinion mining although main goal extract features opinions implemented sentiment classifier detect positive negative classification features used nltk pre processing word tokenization pos tagging trigrams creation also used bayesian classifiers inside tookit compare strategies liu pinpointing one methods relies tagging pos neg every trigrram expressing information using classifier data method tried worked better around accuracy dataset calculating sum scores pmi punctual mutual information every word sentence words excellent poor seeds pos neg class tried spotting keywords using dictionary affect predict sentiment label sentence level given generality vocabulary non domain dependent results just paper available homepage somewhat improved version negation adverbs considered whole system named emolib available demo emolib regards davidsure helps may want look jacob perkinblog post using nltk sentiment analysis magic shortcuts sentiment analysis sort text analysis seeks discover underlying aboutness chunk text attempting short cut proven text analysis methods simplistic adjective checking similar approaches leads ambiguity incorrect classification etc end day give poor accuracy read sentiment terse source difficult problem run python program callsmethods calculate precisionscore output predicted sample predicted sample meansfp case recallzero scikilearn saysdefined definitionused scikilearn precision recall precision recall precisiontpve just said predictor doesnpredicts positive class precision recalltpcase predictor doesnpredict positive classrecall now dividing precision recallscore accuracy calculation wikipedia referencehow can calculate python cumulative distribution function cdf want calculate array points discrete distribution continuous distributions example scipy possible interpretation question wrong question get discrete pdf discrete cdf discrete array samples like know cdf sample can just sort array look sorted resultrealize smallest value represents largest value represents want know value distribution just look array element middle sorted array letcloser look simple example gives following plot right hand side plot traditional cumulative distribution function reflect cdf process behind points naturally long number points finite function easy invert depends application form need assuming know data distributed scipy support discrete data calculating cdfcan even print first values cdf show discrete method calculate cdf also works multiple dimensions usedata illustrate examples prior knowledge data normally distributed used multiple distributions scipy supports need know data distributed beforehand use functions donknow data distributed just use distribution calculate cdf likely will get incorrect results empirical cumulative distribution function cdf jumps exactly values data set cdf discrete distribution places mass values mass proportional frequency value since sum masses must constraints determine location height jump empirical cdf given array values compute empirical cdf first obtaining frequencies values numpy function unique helpful returns frequencies also values sorted order calculate cumulative distribution use cumsum function divide total sum following function returns values sorted order corresponding cumulative distribution plot empirical cdf can use matplotlibplot function option drawstyle steps post ensures jumps occur right place however need force jump smallest data valuenecessary insert additional element fronty example usages output calculating cdf array discerete numbers note return array pdf length bins bin edges length bins calculate cdf nothing area pdf distribution curve can simply calculate cumulative sum bin widths bins edges times pdf using numpy cumsum functionalternative pandas solution calculating empirical cdf using cumsum compute distribution example use function discretize distribution datapoints evenly spaced bins code follow class machine learningknow showcode error code think using newer version python please try pydotplus returns list try exactly issue turned hadninstalled graphviz started work alex sokolov case window downloaded install unzip following folder setup path windows environment variablesruncode works hope helpful install scikit learn via conda work firstly install libtool follow sklearn guide change python file code finally convert png terminal tried previous answers still got error running script therefore just used pydotplus install graphviz using worked added thanks previous contributors works following python donforget install pydot using anaconda prompt use anacondaworked run terminal run terminal add graphs numberestimators can also switch line one still work hope helps similar issue decided use pydot pydotplus rather graphviz modified barely code works wonders two numpy arrays want load tensorflow can classify using neural network can done shape numpy arrays need additional info images height width pixels alphanumeric characters sample image label array can uselink documentation method method purpose pack random image type update convert python object tensor can use can declare two placeholders use placeholdersy model cost etc modelwfinally run model cost feed numpy arrays using feed dict trying produce cnn using keras wrote following code want use kerasleakyrelu activation layer instead using activation relu however tried using leakyrelu alpha place activation layer keras get error using activation layer activation function can use leakyrelu example advanced activations keras including leakyrelu available layers activations therefore use sometimes just want drop replacement built activation layer add extra activation layers just purpose can use fact activation argument can callable object since layer also callable object also simply use now worksbetter solution avoids need use custom object loading christophorusreyhan mentionned can import function make code cleaner use like activation choose define alpha donforget add brackets leakyrelutrying build lstm autoencoder goal getting fixed sized vector sequence represents sequence good possible autoencoder consists two parts end encoder many one lstm decoder one many lstm image source andrej karpathy high level coding looks like similar described shape number training examples sequence length input dimension data array looks like problem sure proceed especially integrate lstm model get decoder generate sequence vector using keras tensorflow backend edit someone wants try procedure generate random sequences moving ones including padding models can way want understood right just want know create models lstm using lstms first define encoded vector looks like suppose want array elements dimension vector shape none size clear rule know ideal one input must three dimensional keras summaries error messages will shown none none represents batch size can vary time train predict many ways suppose want one lstm layer enough simple encoder resulting array elements can stack layers want letcreate model now decoder gets obscure donactual sequence anymore static meaningful vector may want use ltsms still will suppose vector sequence since input shape none must first reshape dimensional array order attach lstm layer next way will reshape entirely steps element step elements steps elements knowsimportant notice donsteps anymore wonable just enable return sequences output wantwork little acuallynecessary use return sequences even use lstms may since reshape timesteps intentionally willuse return sequences result will timesteps initial input work many ways simply creating cell lstm without returning sequences reshaping result model goes unite models code train autoencoder three models will weights can make encoder bring results just using predict method often see lstms generating sequences something like predicting next element take just elements sequence try find next element take another segment one step forward may helpful generating sequences can find simple sequence sequence autoencodercreate synthetic data consisting sequence idea looking sequences lens autoencoder words lowering dimension summarizing fixed length letdevice simple lstm build autoencoder representation sequencesiusing scikit learn custom pipeline conjunction randomizedsearchcv hyper parameter optimization works great now like insert keras model first step pipeline parameters model optimized computed fitted keras model used later pipeline steps think store model global variable pipeline steps can use right know keras offers wrappers scikit learn api problem wrappers already classification regression want compute keras model nothing else can done example method returns model method needs fixed parameters like file path etcy needed can ignored parameters model optimized number layers etc need wrap keras model scikit learn model first just proceed normalquick exampleomitted imports brevity full blog post one many examples scikit learn pipeline examples modification rbm example sklearn documentation sphx glr auto examples neural networks plot rbm logistic classificationneural network implemented keras tensorflow backendi canfind keras defines accuracy loss know can specify different metrics cross entropy keras prints standard accuracy defined likewise loss know can specify different types regularization loss ideallylike print equation used definesettle answer look can find definition available metrics including different types accuracy accuracy printed unless add list desired metrics compile model regularizers definition added loss example see add loss method layerclass update type accuracy determined based objective function see method scikit learn highly unbalanced data set even turned class weight feature auto know logistic regression possible know threshold value particular pair classes possible know threshold value oneclasses logisticregression method designs find anything documentation page default apply value threshold classes regardless parameter values little trick use instead using test data use test data use range values thresholds analyze effects prediction best yes sci kit learn using thresholdbinary classifications going build answers already posted two options check one simple option extract probabilities classification using output testsegment code along class predictions output testsegment code append class predictions probabilities test dataframe check another option one can graphically view precisionrecall various thresholds using following code logistic regression chooses class biggest probability case classes thresholdy obviouslyyy stands multiclass setting chooses class biggest probability seelectures bottom lines introducing special thresholds affects proportion false positives false negatives thus precision recall tradeoff parametermodel see also similar question can use wrapper follows think immensely helpful tensorflow community documented solution crucial task testing single new image model created convnet cifar tutorial may wrong critical step makes trained model usable practice seems lacking missing link tutorial script directly load single image array binary compare trained model return classification prior answers give partial solutions explain overall approach noneable implement successfully bits pieces can found unfortunately havenadded working solution kindly consider researchdone tagging duplicate already answered tensorflow save restore model restoring tensorflow model unable restore models tensorflowryansepassi yaroslavbulatov describe problem approach one needs manually construct graph identical node names use saver load weights although answers helpful apparent oneplugging cifar project fully functional solution highly desirable port single image classification problems several questions regard ask still full answer example load checkpoint evaluate single image tensorflow dnn hope can converge working script everyone use script yet functionalhappy hear can improved provide solution single image classification using cifartutorial trained model assume variables file names etc untouched original tutorial new file cifar eval hence will require retraining second method applicable user want modify model files instead wants use existing check point meta graph files code first approach follows script requires user creates two placeholders conditional execution statement work placeholders conditional execution statement added cifar inputs cifar model connected queue runner object multistage queue can prefetch data files parallel see nice animation queue runner queue runners efficient prefetching large dataset training overkill inference testing single file needed classified also bit involved modify maintain reason added placeholder training set false training shown another placeholder imgs holds tensor shape image will fed inference first dimension batch size one case modified cifar model acceptimages insteadoriginal cifar imagesfinally conditional statement feeds placeholder queue runner output graph training placeholder set false inference img placeholder fed numpy array numpy array reshaped dimensional vector conform input tensor inference function model model can inferred single user defined test data like shown script essentially read graph feed data graph nodes run graph get final output now second method approach hack call inference image file read pass logits eval modify eval evaluate logits separate script run method inference just run cifarran single image timeadmit seems bit hacky reuse getting scope helper function main part code runs single image time within loop alternative implementation using place holdersbit cleaner opinionleave example historical reasons got working output donworking codeafraidoften tackle problem production save graphdef disk using something like write graph use freeze graph load graphdef checkpoints save graphdef variables converted constants load graphdef something like label image classify image example overkill least suggest serializing graph original example graphdef loading script donduplicate code generating graph graph created able populate saverdef freeze graph script may help attempt split using multi class received error see tried split using binary works problem split method docs splity groups nonearray like shapesamples target variable supervised learning problems stratification done basedlabels simply invert order operations split first using intialtrain convert categorical afterwards call split like target variable continuous use simple kfold cross validation instead stratifiedkfold bumped problem found can check type target util function docstring labelencoder can transform classesarray numbers given target labelsarray categoricals object cased matrixalsomatrix shapeyusual full code example complementing desertnaut said order convert one hot encoding backarray will need will convert back initial representationusing ipython jupyter need change working directory folder downloaded can add tensorflow directory add files installed tensorflow pip osx current location anaconda lib python site packages tensorflow initfiles meant accessed directly tensorflow like sklearn datasets just supposeddirectory work example clear edit post dated letassume directory somepath tensorflow tutorial working directory need download inputassume file name invoke can just start running script will downloading next time old tutorial said import mnist data use will cause error new tutorial uses following code works using different version following install windows docker similar problem easy workaroundfound figure input case mentionned download manually case already used follwing linux commandgot files path will get existing paths hope can help found better option let know can start tutorial didndownload folder installed tensorflow pip similar problem workaround replace importusing tensorflow higher need install tensorflow datasets firstusing anaconda distribution command lineusing jupyter notebook will need install enable ipywidgets according docs using pipusing anaconda distribution install ipywidgets command line like anaconda distribution need enable extension conda handles import code able use without error follow instructions might kinda late tensorflow version might wanna use input mnist input data set tensorflow api mnist data changed placenow much easier way load mnist data tensorflow without download data using tensorflow tensorflow datasets get started make sure import tensorflow specifyversion load data dictionary using following code split data train test now can use data generators however like remove lines line will suffice note dataset available examples built keras will download dataset solve problem mnist input data builtjust individual moduleinside tensorflow module try mnist data set included part tensorflow examples tutorial want use tensorflow official website shown mnist data hosted use mnist dataset following command can used following steps work perfectly notebook step get python files github git clone append files python path import sys content tensorflow tensorflow examples tutorials mnist step load mnist data input data fonction import input data mnist input mnist data one hot trueconstructing tree random forest using bootstrapped samples terminal node selectvariables randomvariables find best splittotal number features data questions randomforestregressor max features correspondp something elsevariables selected random max features variables valuemax features correspondswant set equalregression default randomness setting different bagging thanks straight documentation max features size random subsets features consider splitting node max features callmax features autop feature subset selection performed trees random forest actually bagged ensemble ordinary regression trees docssay empirical good default values max featuresfeatures regression problems max features sqrtfeatures classification tasks setting max features differentlyget true random forest lynnyi max features number features considered per split level rather entire decision tree construction clear construction decision treewill still use featuresfeatures consider number max features features node splitting max features features randomly selected entire features confirm plotting one decision treemax features check nodes tree count number features involved max features basically number features selected random without replacement split suppose independent columns features max features will select random without replacement features every split working seq seq keras tensorflow model every time user inputs something model prints response perfectly fine however last line response get warning tensorflow input ran data interrupting training make sure dataset generator can generate least steps per epoch epochs batches case batches may need use repeat function building dataset last output user supposed type something new model works totally fine guess error ever good donquite get error says interrupting training however training anything program loads already trained model guess error stopping program case helps model looks like make sure least steps per epoch epochs batches set steps per epoch can see maximum number batches can take progress bar training interrupts maximum importantly keep mind default batch sizeusing can also add repeat method careful will loop indefinitely unless specify number also number models crash warnings trying train training dataset created using split created variable try run image using resnet number images dividing taking away epochs step loss accuracy val loss val accuracyepoch etaloss accuracywarning tensorflow input ran data interrupting training make sure dataset generator can generate least steps per epoch epochs batches case batches may need use repeat function building dataset might true generating dataset automatically handles extra data left example problem decreasing validation steps solved issue create dataset image dataset directory remove steps per epoch validation steps parameters can trying get steps number len problemsomething shape type input namely query case solved problem follows model takes inputs output warning tensorflow input ran data interrupting training make sure dataset generator can generate least steps per epoch epochs batches case batches may need use repeat function building dataset array dtype float solution output array dtype float understand completely fine firstly warning error secondly situation similar one data trained one epoch next epoch trains next data set epochs value high assuming data size fixed will approximately suppose data size now remaining epoch dondata left process hence warning result returns recent state last data trained hope helps let know concept misunderstood thanks try reducing steps per epoch value value currently set helped solve problem seeing issuecustom imagedatagenerator core issue appearskeras selecting correct data adapter select data adapter selecting generatordataadapter kerassequenceadapter updated following file work around issue better solution using float value determines much data want fit approach better ones batch size will always fit whole dataset change data amount value adjust also got training model google colab reason enough memory ram store amount data per batch using batch lower batch size ran perfectlyiusing scickit learn tune model hyper parametersusing pipeline chain preprocessing estimator simple version problem look like case preprocessing standardscale toy example time consumingtuning parameter execute example standardscaler executed times fit predictparameters every time standardscaler executed different value parameterreturns outputmuch efficient compute just run estimator part pipeline can manually split pipeline preprocessing hyper parameters tuned estimator apply preprocessing data provide training set implement splits manually use gridsearchcv simple standard way avoid repeating preprocessing using gridsearchcv update ideally answer used leads data leakage discussed comments answer gridsearchcv will tune hyperparameters data already preprocessed standardscaler correct conditions matter much algorithms sensitive scaling will give wrong results essentially gridsearchcv also estimator implementing fit predict methods used pipeline instead will call standardscalar one call instead multiple calls described edit changed refit true gridsearchcv used inside pipeline mentioned documentation refit boolean default true refit best estimator entire dataset false impossible make predictions using gridsearchcv instance fitting refit false will effect gridsearchcv object inside pipeline will reinitialized fit refit true gridsearchcv will refitted best scoring parameter combination whole data passed fit want make pipeline just see scores grid search refit false appropriate want call method refit true must used else fitted error will thrown stumbled upon little bit different problem suppose pipeline specifying parameters need include clf name used estimator parameters grid going possible current version scikit learn fix proposed github project weights appear getting set note actually setting none weights appear set values returned set weights layer keras numpy array values keras layer code can set weights ways model instance existing model can see expected length list array shapes using method get weights instances set weights method keras accepts list numpy arrays passed method seems like single array shape shape output get weights layercode worked returns updated weights calling get weights trying convert pytorch model keras model can also try pytorch keras converter supports base layers like convlinear activations element wise operations etc can follow pytorch keras ratio class calculate prediction error class rebalance weights accordingly sklearn random forest kind like following link breiman randomforestsbalance can pass sample weights argument random forest fit method sample weights none samples equally weighted splits create child nodes net zero negative weight ignored searching split node case classification splits also ignored result single class carrying negative weight either child node older version classes become uniformly distributed still internal still usable preprocessing weights module deprecated will removed future versions donknow exact reasons update clarification seems confused sample weight usage straightforward remember purpose balance target classes training datasetobservationsclasses labels lenlenlen sample wight element sample witghtarray represent weight corresponding observation label pair case class represented times class balance classes distributions use simple assigning weight instances weight instances see link bit crafty balance weights weights evaluation function really shame sklearnfit method allow specifying performance measure optimized one around seem understand question interestedactually going one calls fit method data sample solving classification task users scikit learn package silently left suggestion indirectly use crossvalidated grid search specific scoring method suitable unbalanced datasets hope stumble upon parameters metaparameters set produces appropriate aucscore think looks like fit method called hood time always optimizes accuracy end effect aim maximizescore gridsearchcv givesmodel bestmodesl best accuracy silly better directly optimize modelparameters maximalscore remember old good matlab anns package can set desired performance metric rmse mae whatever want given gradient calculating algo defined choosing performance metric silently omitted sklearn least simple option assign class instances weights automatically remedy unbalanced datasets issues calculate wights manually besides many machine learning books articles saw authors praising sklearnmanual awesome best sources information topic really unbalanced datasets problem obviously utter importance data scientists even covered nowhere docs address questions contributors sklearn read anyone knowing reasons welcome comment clear things update since scikit learn class weight balanced option can pass least classifiers balanced mode uses valuesautomatically adjust weights inversely proportional class frequencies input datasamplesclassesuse parameter class weight balanced sklearn documentation balanced mode uses valuesautomatically adjust weights inversely proportional class frequencies input datasamplesclassesmajority class minority class ratio sample weight array note invert following example dataclearly anomaly want perform specific action based tempted just try use knowledge particular domain detect anomalies instance figure distance mean value useful check based heuristics however thinkprobably better investigate general robust anomaly detection techniques theory behind since working knowledge mathematics limitedhoping find technique simple using standard deviation hopefully single dimensioned nature data will make quite common problem information scenario required please leave comment will give info edit thoughtadd information datatried case makes one answer correct another values positive non zero expect values will form normal distribution expectation based intuition domain rather analysis bad thing assume please let know terms clustering unlessalso standard algorithms choosevalue find hard provide valuemeans algorithm action want take outlier anomaly present user recommend data point basically removed data set wonget makes sense domain thus will used input another function far tried three sigma iqr outlier test limited data set iqr flags values extreme enough three sigma points instances better fit intuition domain information algorithms techniques links resources learn specific scenario valid welcome answers recommended anomaly detection technique simple one dimensional data check three sigma rule alternative method iqr outlier test test usually employed box plots indicated whiskers edit case simpleunivariate data think first answer suited however isnapplicable multivariate data smaclell suggested usingmeans find outliers beside fact mainly clustering algorithm really outlier detection technique problemmeans requires knowing advance good value number clustersbetter suited technique dbscan density based clustering algorithm basically grows regions sufficiently high density clusters will maximal set density connected points dbscan requires two parameters epsilon minpoints starts arbitrary point visited finds neighbor points within distance epsilon starting point number neighbors greater equal minpoints cluster formed starting point neighbors added cluster starting point marked visited algorithm repeats evaluation process neighbors recursively number neighbors less minpoints point marked noise cluster fully expanded points within reach visited algorithm proceeds iterate remaining unvisited points depleted finally set points marked noise considered outliers variety clustering techniques use try identify central tendencies within data one algorithm used heavily pattern recognition coursemeans allow identify whether one related sets data bimodal distribution require knowledge many clusters expect fairly efficient easy implement means try find point far means can define far however want recommend suggestions amro good starting point depth discussion clustering algorithms refer wikipedia entry clustering old topic still lacks information evidently can seen case univariate outlier detection approaches presented several pros cons weak spots think problem can solved lines python code like subsequently reject values certain threshold percentile distribution data case assumed normal distribution threshold translates entry rejected course one argue mad presented also assumes normal dist therefore argument small sample apply answer mad high breakdown point easy choose different threshold points different distributions come conclusion outlier three sigma rule iqr test often used couple simple algorithms detect anomalies iqr test want improve question update question can answered facts citations editing post closed years ago number hidden layers multilayer perceptron neural network way neural network behaves question number nodes hidden layers letsay want use neural network hand written character recognition case put pixel colour intensity values input nodes character classes output nodes choose number hidden layers nodes solve problem note answer correct time made since become outdated rare two hidden layers neural network number layers will usually parameter network will worry much although multi layer neural networks many layers can represent deep circuits training deep networks always seen somewhat challenge recently empirical studies often found deep networks generally performed better often worse neural networks one two hidden layers bengiolecunscaling learning algorithms towardslarge scale kernel machinescited paper good reference learning effect network depth recent progress teaching deep networks deep learning general general answer picking hyperparameters cross validate hold data train networks different configurations use one performs best held set problems seen solved hidden layers proven mlps one hidden layer universal function approximators hornikal hidden layers can make problem easier harder usually try different topologies heard add arbitrary number hidden layers want train mlp backprop gradient will become small first layers reference applications people used nine layers maybe interested standard benchmark problem solved different classifiers mlp topologies besides fact cross validation different model configurations hidden layers neurons per layer will lead choose better configuration one approach training model big deep possible use dropout regularization turn neurons reduce overfitting reference approach can seen paper hinton absps general rules following based paper approximating number hidden layer neurons multiple hidden layer bpnn architecture saurabh karsoliya general keep always mind need explore try lot different combinations also using gridsearch find best model parameters best size hidden one copy weights one model another backgroundtrying implement deepnetwork dqn atari games following dqn publication deepmind understanding implementation uses two networksq weightstrained using gradient descent weights copied periodicallys buildq call twice getq updatetargetmodel method attempt copying weights code runs fine overall dqn implementation failingreally just trying verify valid way copying weights one network anotheranother question discusses saving loading weights disk tensorflow copy weights issueaccepted answer also question loading weights individual layers copying weights one convlayer anotherwanting copy entire modelweights actuallydone much simply copying weights made two models identical time every time update one model second one also updated models weights variables want just copy weights simplest way command following tutorial learning tensorflow slim upon running following code inception seem getting set errors strange code official guide newhelp appreciated got problem using released make work without roll back previous version problem caused change api discussion helped find solution google group recent api changes tensorflow just update line able use models without problem still got error afterward wanting load pretrained weight seems slim module got several changed since made checkpoint file graph created code one present checkpoint file different note able use pretrain weights inception resnetadding convlayer biases initializer none explicitly writing name arguments solves problem instead use got error work found output shape code want concat outputs outputs get new shape api may allow train labels write can run found people answering wrong way just due change works following way net branch branch branch branch use following net values branch branch branch branch axis remember passing keyword arguments others following data set trying make plot datewearrate color wheel code follows works want put actual date labels edit plot currently looks shown however want see aug sep etcaxis want display ticks easiest way use scaledateabbreviated month nameyear without century description full possibilities see strftime using sklearn python clusteringtrained data code works new testing contentlike cluster existed clusterstrainedwondering save idf result can tfidf new testing content make sure result new testing content array length thanks advance update may need save transformer tfidf variable file txt others one contains trained idf result update example training data tfidf result will contains featuresctest see cluster already mademeans belongs tfidf will give result featuresd clusteringmeans will fall teste may problems store features list testing data even store file update solved see answers successfully saved feature list saving reuse countvectorizer decode error replace vocabulary codes works tfidf will feature length trained data instead using countvectorizer storing vocabulary vocabulary tfidfvectorizer can used directly training phase fit transform works using old vocabulary storing tfidf just used transform test data even transform new documents test data fit vocabulary vectorizer train exactly thing can storeuse tfidf vectorizer vocabulary want store features list testing data use future can simpler solution just use joblib libarary document said can vectorization tfidf transformation one stage fit transform training data use tfidf model transformi trying train simple layer fully connected neural net binary classification tensorflow keras split data training validation sets split using sklearntrain test split calltraintrain validation datavalval shows validation loss accuracy epochs trains just fine also try evaluate validation set output non zero can someone please explain facing loss accuracy error validation thanks help complete sample code mcve error usp sharing use keras instead even tried validation datatraintrain also gives zero accuracy demonstration definitely issue tensorflow implementation fit dug source seems part responsible validation data internally calls already established evaluate works fine realized culprit unpacky sample weight looked implementationcrazy just pass tuple instead list everything works fine due check inside unpacky sample weight labels missing step somehow data getting fixed inside evaluatetraining reasonable labels seems like bug documentation clearly states pass tuple following code gives correct validation accuracy loss seems bug just opened relevant issue tensorflow github repo categorical crossentropy loss binary crossentropy problem tried answer worked thing binary classification model output node multi classification model multiple output nodes loss binary crossentropy appropriate loss function case following data need split dataset training testing set based group data goes training set test set need training set look something like test set simplest way far know standard test train split function sklearn support splitting groups way can also indicate size split figured answer seems workexpected nothing wrong word index computed way matter many frequent words will use later may see will call transformative method tokenizer will use three common words time will keep counter words evenobvious will use later just add marcinanswer will keep counter words evenobvious will use later reason keeps counter words can call fit texts multiple times time will update internal counters transformations called will use top words based updated counters hope helps limiting num words small numbereffect fit texts outputs word index word counts word docs effect texts matrix resulting matrix will num words columns just add little bit farid khafizovanswer words sequence num words removed results texts sequencesndsentence disappeared respectively encoded categorical data using good systematic way figure start test data workmuch care works simply want quick answer skip bottom lines determinevalues parameter will determined automatically setvalues auto default alternatively can specify maximum value features int maximum value per feature array letassumeusing default following lines execute next feature indices parameter calculated feature indices merely cumulative sumvalues prepended next sparse data ones row indices column indices note coo matrix immediately converted facilitates fast conversion among sparse formats nowvalues auto sparse csr matrix compressed columns active features sparse csr matrix returned sparse true otherwise densified returning now letwork reverselike know recovergiven sparse matrix returned along onehotencoder features detailed letassume actually ran code instantiating new onehotencoder running fit transform datakey insight solving problem understanding relationship active features indices array contains column numbers data point however column numbers guaranteed sorted sort can use sorted indices method can see sorting indices actually reversed along rows words ordered last column first first column last evident first two elements corresponds first columnsince minimum element assigned first active column corresponds second columnsince first row occupies distinct columns minimum element second column gets index next smallest gets index third smallest gets index sorting indices ordered expect next look active features notice elements corresponds number distinct elements data one element repeated notice also arranged order features first columnfeatures second column simply summed corresponds looking back can see maximum column number one minus active features encoding little thought relationship shows indices can decode givescan get back original feature values subtracting offsets note will need original shapesimplysamplesfeatures given encoded data output shape original datasamplesfeature recover original datajust compute dot product encoded values key insight active features attribute ohe model represents original values binary column thus can decode binary encoded number simply computing dot product active features data pointjust single position original value use axis example since version scikit learn active features attribute onehotencoder class deprecated suggest rely categories attribute instead function can help recover original data matrix one hot encoded test created small data set includes ratings users given users building prediction model remember delete dependent variable case rating dataframe encode proceed encoding results encoding can reverse using reverse one hot function defined like givesfeatures dense like several number missed can mapping corresponding positions compromised simple method works easy reverse argmax see short answer encoder takes categorical data automagically transforms reasonable set numbers longer answer automatically provide explicit mapping usingvalues parameter though can probably implement decoding side see documentation hints might done said fairly strange question may want instead use dictvectorizer pandas approach convert categorical variables binary variables can find index value using can map list index according original datawager blog news site plenty articles blags whatever call want bottom suggest others seem related letassume little metadata item tags categories treat one big blob text including title author namefinding possibly related documentsrather interested actual algorithm ready solutions althoughok taking look something implemented ruby python relying mysql pgsql edit current answer pretty goodlike see maybe really bare example code thing two pretty big topic addition answers people come recommend tracking syllabi couple information retrieval classes checking textbooks papers assigned saidbrief overview grad school days simplest approach called bag words document reduced sparse vector word wordcount pairs can throw naivebayes classifier set vectors represents set documents compute similarity scores bag every bag callednearest neighbour classification knn fast lookup requiresn storage score matrix however blogisnlarge something size large newspaper knn rapidly becomes impractical fly classification algorithm sometimes better case might consider ranking support vector machine svms neat donconstrain linear similarity measures still quite fast stemming common preprocessing step bag words techniques involves reducing morphologically related words cat cats bob bobsimilar similarly roots computing bag words bunch different stemming algorithms wikipedia page links several implementations bag words similarity isngood enough can abstract layer baggrams similarity create vector represents document based pairs triples words can use tuples even larger tuples practice doesnhelp much disadvantage producing much larger vectors classification will accordingly take work matches get will much closer syntactically otoh probably donneed semantic similaritybetter stuff like plagiarism detection chunking reducing document lightweight parse trees can also used classification algorithms trees useful things like authorship problem given document unknown origin wrote perhaps useful use case concept mining involves mapping words concepts using thesaurus wordnet classifying documents based similarity concepts used often ends efficient word based similarity classification since mapping words concepts reductive preprocessing step can rather time consuming finallydiscourse parsing involves parsing documents semantic structure can run similarity classifiers discourse trees way can chunked documents pretty much involve generating metadata unstructured text direct comparisons raw blocks text intractable people preprocess documents metadata first read book programming collective intelligence building smart web applications isbn method code first ask whether want find direct similarities based word matches whether want show similar articles may directly relate current one belong cluster articles see cluster analysis partitional clustering simple theoretical slow method finding direct similarities preprocess find similar articles typical case document classification studied every class machine learning like statistics mathematics computer science recommend look unsupervised methods like kmeans bayesian methods lda particular bayesian methods pretty good looking problem slow unless run large site shouldnbother much practical less theoretical approach recommend look great code examples small vector space model search engine ruby basic idea two documents related contain words count occurrence words document compute cosine vectors terms fixed index appears index zero cosine will two documents terms common common terms can directly translate values definition array cosine left exercise reader deal nil values different lengths got array zip right btw example documents taken svd paper deerwester etal time ago implemented something similiar maybe idea now outdated hope can help ran asp website programming common tasks started principle user doubt will stay website long can find interesting content subject user arrived started asp session object recorded user navigation just like linked list take first link look next link incremented counter column like check related articles just list topnextpage entities ordered counter column descending wonder can set optional step classification problem may want try extratreesclassifier without pca transformation ahead practice might pipeline extra parameter specifying toggle pca step can optimize via gridsearch etc donsee implementation sklearn source work around furthermore since possible parameter values following step pipeline might depend parameters previous step valid values possible specify conditional dependency thank docs individual steps may also replaced parameters non final steps may ignored setting none pipeline steps currently made optional grid search wrap pca class optionalpca component boolean parameter turn pca requested quick workaround might want look hyperopt setup complex search spaces think good sklearn integration support kind patterns default find doc anymore maybe look talk dependent parameters problem gridsearchcv supports trees parameters handle case demonstratedexample trainmodel using code can use parameters found best iteration code predict output casemod predict method like dictionary output pred parametersmod missing important transformation step general purposehyperparameter optimisation purpose evaluate performance model building procedure basic train test split conceptually identical foldcustom size split contrasttrain sizefoldadvantage splitsget information estimate generalisation error info sense getting error stat uncertainty excellent discussion crossvalidated start links added question cover question formulated different way covers nested cross validation absolutely straightforward will wrap head around concept general will help various non trivial situations idea take away purposeevaluate performance model building procedure keeping idea mind one approach hyperparameter estimation general lightgbm can make step say additional hold set separated hyperparameter optimisation started way can evaluate chosen best model set measure final generalisation error however can make even step instead single test sample can outerloop bringsnested cross validation technically allows evaluate performancefold split fixed model parameters hyper parameter tuning will need run loop providing different parameters recoding averaged performance choose best parameter set loop complete interface different sklearn provides complete functionality hyperparameter optimisationloop personally recommend use sklearn api lightgbm just wrapper around native functionality thus slower allows use full stack sklearn toolkit thich makes life much easierhappyresults just use parameters call method like pho saidusually just param tuning donuse actualobject predictions useparameter optimization model performs folds use parameters train whole training set evaluate model external test setusing scikit learn machine learning library python machine learning project one algorithmsusing gaussian naive bayes implementation one attributes gaussiannb function following want alter class prior manually since data use skewed recall one classes important assigning high prior probability class recall increase however canfigure set attribute correctlyread topics already answers donwork can prior probabilities manually set naive bayes clf scikit learn know priorm giving sci kit learn naive bayes classifiers code figured correct syntax find class belongs place array playing values results remain unchanged also errors given correct way setting attributes gaussiannb algorithm scikit learn library link scikit documentation gaussiannb jianxunfact way set prior probabilities gaussiannbcalled priors available parameter see documentation parameters priors array like shapeclasses prior probabilities classes specified priors adjusted according data let give example changed prior probabilities will give different answer looking believe gaussiannb implemented scikit learn allow set class prior read online documentation see class prior attribute rather parameters fit gaussiannb can get access class prior attribute calculated simply counting number different labels training sample see estimator smart enough take account unbalanced weight issue donmanually specify priors dataframe time series want decompose first time series divida way can separate trend seasonal residual components found answer trying use following code however keep getting error can proceed works fine convert index datetimeindex access components via statsmodel will decompose series provide frequency usually time series index will contain frequencydaywise business days weekly shows error can remove error two ways depends index format can datetimeindex can periodindex stefan presented example datetimeindex example periodindex original dataframe multiindex index year first level month second level convert periodindex now ready used seasonal decompose make simple follow three steps done make column yyyyddmm yyyy using excel using pandas convert date formatdatedate decompose using finally try parsing date column using parse dates later mention index column classification scheme several steps including main parameters tuned scheme percentile hyperparameters svc wantgrid search tuning current solution builds partial pipeline including step scheme clf pipeline normal svc class weight auto breaks scheme two parts tune percentile features keep first grid searchscores will stored averaged fold partitions percentiles percentile bestscore returned purpose putting percentile loop inner loop allow fair competition training data including synthesized data across fold partitions percentiles determining percentile tune hyperparameters second grid search done similar way except tune hyperparamter svc rather percentile features select questions current solution involve clf kinda manually two nested loop described way include four steps pipeline whole process okay keep first nested loop possible simplify next nested loop using single pipeline simply use gridsearchcv clf parameter comb tuning please note smote fisher ranking criteria done training data fold partition much appreciated comment smote fisher shown smote returns synthesized data modified return original input data stacked synthesized data along labels synthesized ones scikit created functiontransformer part preprocessing class version can used similar manner davidimplementation class fisher answer less flexibility input output function configured properly transformer can implement fit transform fit transform methods function thus allow used scikit pipeline example input pipeline series transformer follows vectidf transformer clf classifier train training dataset series text input pipeline donknow smote fisher functions coming answer yes can definitely order will need write wrapper class around functions though easiest way inherit sklearnbaseestimator transformermixin classes see examplemaking sense post details least one functions library comes code wrote canedit apologize didnlook functions closely enough realize transform target addition training data pipeline support transformations target will prior originally reference look like write custom class fisher process work function need affect target variable actually can put functions single pipeline accepted answer david wrote functions transform target addition training data pipeline support transformations target will prior originally true sklearnpipeline support however imblearnpipeline supports imblearn pipeline just like sklearn allows call transformations separately training testing data via sample methods moreover sample methods actually designed can change datalabelsimportant many times want include smote pipeline want smote just training data testing data imblearn pipeline can call smote pipeline transform justtraintraintesttest can create imblearn pipeline smote sampler pre processing step svc details check stack overflow post machine learning mastery article issue warning comes always last iteration val acc calculated therefore modelcheckpoint never finds val acc code training cnn know frustrating things can val accuracy hope helps add accepted answer just struggled use full metric name must match modelcheckpoint earlystopping one set accuracy two set val accuracy work print metrics training one epoch like will print metrics defined model now replace metrics will work like charm hack given gentleman link thanks issuecomment issue even mentioning metric val accuracy work just changed metric val acc worked using validation steps steps per epochs function remove parameter validation losses accuracy will start appearing just include parameters possible using modelcheckpoint earlystopping case momitor metric like accuracy also earlystopping doesnsupport metrics tensorflow versions choose metricscommon best suits model still issue even changing argument monitor val acc monitor val accuracy can check link keras make sure keep arguments values passing removed extra arguments passing worked write name appears run probably using different metric instead accuracy metric section binaryaccuracy sparseaccuracy categoricalaccuracy etc example use binaryaccuracy binary accuracy written instead accuracy run section write monitor section monitor val loss checkpointing earlystopping callbacks worked may also find model metrics incrementing number appended first run can reset session run numbers arenappendedimplementing multilayer perceptron keras using scikit learn perform cross validation inspired code found issue cross validation keras studies neural networks learned knowledge representation neural network synaptic weights network tracing process weights updated thereby reduce network error rate improve performance caseusing supervised learning better training assessment neural network performance common method used cross validation returns partitions data set training evaluation model doubt define train evaluate new neural net generated partitions goal fine tune network entire dataset correct define single neural network train generated partitions piece code like understanding code works wrong theory goal fine tune network entire dataset clear mean fine tune even exactly purpose performing cross validationgeneralserves one following purposes since dondefine search grid hyperparameter selection code seem usingorder get expected performance model error accuracy etc anyway whatever reason usingfirst snippet correct one second snippet will train model sequentially different partitions continue training partition etc essentially just training whole data set certainly final stepoften implied frequently missed beginners satisfied chosen hyperparameters model performance givenprocedureback train model time entire available data can use wrappers scikit learn api keras models given inputsyexample repeated fold cross validation think many questions will answered read nested cross validation good way fine tune hyper parameters modelthread peeking circular logic essentially want make sure none data used assess model accuracy seen training one example might problematic running something like pca ica feature extraction something like must sure run pca training set apply transformation matrix training set test set main idea testing model performance perform following steps basically data finally test model mimic first data portionget client application apply modelcross validation powerful makes every data point whole dataset used simulation new data now answer question every cross validation follow following patternfirst train model use new data second approach treat mimicry training processneed evaluate procedure using kind schema commented functions make little less obvious idea keep track model performance iterate folds end provide either lower level performance metrics averaged global performance example train evaluate function ideally output accuracy score split combined end yes want create new model fold purpose exercise determine model designed performs segments data just one particular segment may may allow model perform type approach becomes particularly powerful applied along grid search hyperparameters approach train model varying hyperparameters using cross validation splits keep track performance splits overall end will able get much better idea hyperparameters allow model perform best much depth explanation see sklearn model selection pay particular attention sections cross validation grid search trying run following code brief machine learning algorithm piece code trying read dataset mnist original present lines code getting error particular line tried researching internet hardly help available expert help related solving error will much appreciated tia version sklearn deprecates fetch mldata function adds fetch openml instead download mnist dataset following code changes format though instance mnist target array string category labels floats looks like cached data corrupted try removing download takes moment specified differently data minst original downloaded dataset link path working directory files mldata worked sample code get mnist data ready use sklearn experienced issue found different file size worked since used import syntax shouldnprepend datasets use also getting fetch mldata ioerror read bytes error solution relevant lines code sure change data home preferred location directory script didngive data home program look yourprojectpath mldatarun fetch mldata internet connection took awhile download know interrupt process dataset corrupted error happened apart szymon mentioned can alternatively load dataset usingmnist original lowercasem training yolo model bounding boxes format need convert yolo format something like already calculated center pointy heightweightstill need away convert floating numbers mentioned looking reverse question yolo format normal bbox formatcode snipet python converty coordinates yolo format check sample program convert labelme annotation tool format yolo format use note converting yolo format requires image width height scaling yolo normalises image space runy directions converty coordinates yolov coordinates need transform datax xmaxy ymax xmax ymax maximum coordinates image array using depends image arrays oriented wayfunction perform conversion two potential solutions first understand first bounding box format coco pascal voc otherwise canright math formatting coco formatminmin width height pascal voc formatminminmaxmax python code can conversion converting coco yolo converting pascal voc yolo need additional conversions can check article mediumxformat two things needusing pytorch torchvision provides function can use conversion just reading answers also looking find informative know happening backend form source assumingyminymax bounding corners top left bottom right respectively need normalize means give proportion whole image simple divide value respective size values assumes top left origin will apply shift factor case answeri made simple module figure relationship input output numbers casex squared code python tried different number units adding layers even using relu activation function results always wrong works relationships likex problem making two basic mistakes certainly understood neural networks need complexity solve problems even simplex really shine fed large training datasets methodology trying solve function approximations just list possible inputs fed model along desired outputs remember nns learn examples symbolic reasoning examples better usually similar cases generate large number examples subsequently feed model training said rather simple demonstration layer neural network keras approximating functionx using input random numbers generated bad remember nns function approximators expect neither exactly reproduce functional relationship know results identical letgenerate new random data remember practical purposes unseen data model plot along original ones get general picture result arguably look like good approximation although get decent approximation even relatively simple model expect extrapolation details see answer deep learning bad fitting simple non linear functions outside training scope problemx different beastplease note usual neural network stacksfxtimes never multiplyingthereforenever get perfect reconstructionx unless setxx similar can get approximation range values presented training perhaps little bit extrapolation anywayrecommend work smaller range values will easier optimize problem philosophical note machine learning find useful think good bad rather correct wrong especially regression get result right unless exact model case nothing learn actuallyarchitectures multiplyingxx notably lstms highway networks even onexs bounded logistic sigmoid tanh thus unable modelx fully since misunderstanding expressed comments let emphasize points example result model single hidden layer units tanh activation trained sgd learning ratek iterations minimize mse data best five runs full code reproduce result unfortunately install kerascurrent environment hope pytorch code accessible answer bit different trivial casex can just write activation function takesoutputsx answers question buildcalcuatesx may violate spirit question mention sometimes want perform non trivial operation likeexpx sinh sqrt logx write activation function back propagation operation hellish impenetrable another developer suppose also want functionexpx cosh sqrt logx writing another stand alone activation function just wasteful reason might want build library activation functions atomic operations likez expsinhcoshsqrtlogactivation functions applied one time help auxiliary network layers consisting passthrough nodes spark dataframe mydataframe many columns trying run kmeans two columns lat long latitude longitude using simple values want extract clusters based just columns want attach cluster asignment original dataframetried getting error job aborted due stage failure task stage failed times recent failure lost task stage tid executor traceback recent call lasttried detachattach cluster result wrong since based another recent question guess first steps spark clustering even importing sqrt array without ever using probably like docs example let offer advice general level rather specific question asking hopefully also saving subsequently opening questions trying get cluster assignments back dataframe since data already dataframe want attach cluster membership back initial dataframe reason revert rdd use soon deprecated mllib package will job much easily elegantly efficiently using now recommendedpackage works directly dataframes step make toy data resembling step assemble features contrastpackages sparkrequires input features gathered single column dataframe usually named features provides specific method vectorassembler perhaps already guessed argument inputcols serves tell vectoeassembler particular columns dataframe used features step fit kmeans model select features serves tell algorithm column dataframe use clustering remember step original lat long features directly used step transform initial dataframe include cluster assignments last column transformed dataframe prediction shows cluster assignment toy case ended records cluster record cluster can manipulate transformed dataframe select statements even drop features column now fulfilled function may longer necessary hopefully much closer now actually wanted achieve first place extracting cluster statistics etc another recent answer mine might case whatever reason must stick mllib rdds causes error using toyselect columns dataframe convert rdd result rdd rows suitable input mllib kmeansneed map operation work code like following code running inside jupyter notebook code collects epochs history displays progress historycan make chart change training can see changes real time livelossplot python package live training loss plots jupyter notebook keras disclaimer author see work look source especially file wait true fair disclaimer interfere keras output keras comes callback tensorboard can easily add behaviour model just run tensorboard top logging data need notebook can also write callback get metrics training get training accuracy end current epoch printgood documentation around official keras site gives idea simplest codes sample output disease actually disease okay prediction disease actually disease okayfn research found ways like keeping higher learning rate one class using class weights ensemble learning specificity sensitivity etc achieved near desired result using class weights like class weight calling class weights class weight gave lowpretty hightrying reducemuch possible keepinglow struggling write custom loss function using keras will help penalize false negatives thanks helpbriefly introduce conceptstrying tackle positive many model predict positive positive model said positive since recall inversely proportionalimproving decreasesnegative many model predict negative negative model said negative since specificity inversely proportionalimproving decreasesnext searches whatever classification related activity perform knowing going give extra edge communication understanding two concepts mas figured already opposites means increasing one likely decrease since want priority recall donwant loose much specificity can combine attribute weights followingclearly explained answer notice recall weight spec weightweightsattributing metrics distribution convention always add specificity weight intention see proportion best suits needs keras loss functions must receivetruepred arguments letdefine wrapper onto usingweights added must total case recall specificity perfect score formula shall giveexample clearly got perfect scorewant loss equal currently performing multi class svm linear kernel using pythonscikit library sample training data testing data given model data want plot decision boundary visualize datasets can someone please help plot type data data given just mock data feel free change values helpful least suggest steps followed thanks advance choose features reason plotplot selecting features use visualization decision surface also written article source friends linkfddaf now next question ask can choose features lot ways univariatevalue feature ranking test see features variables important use plot also reduce dimensionality using pca exampleplot features using iris dataset edit apply pca reduce dimensionality edit aprilcan use mlxtendquite clean first pip install mlxtendtwo dimensional data matrixassociated vector training labels using recursive feature elimination cross validation rfecv feature selector randomforest classifier follows also performing gridsearchcv follows tune hyperparameters randomforestclassifier follows however clear merge feature selection rfecv gridsearchcv edit run answer suggested gambit got following error resolve issue using estimator param grid parameter list question now use selected features parameterstest verify model works fine unseen data can obtain best features train optimal hyperparameters happy provide details needed basically want fine tune hyper parameter classifier cross validation feature selection using recursive feature elimination cross validation pipeline object exactly meant purpose assembling data transformation applying estimator may use different model gradientboostingclassifier etc final classification possible following approach now can apply pipeline including feature selection test data can want prefixing names parameters want pass estimator estimator output fake data made just need pass recursive feature elimination estimator directly gridsearchcv object something like workletsay network following params now know loss calculated following manner binary cross entropy applied pixel image regards class essentially pixel will loss values happens step train network prints single loss value epoch many levels loss accumulation need happen produce single value happens clear docs code state different way losses different classes combined produce single loss value image explained docs helpful people multi class predictions keras regardless type network link start keras code one first passes loss function closest thing find explanation loss string name objective function objective function see losses model multiple outputs can use different loss output passing dictionary list losses loss value will minimized model will sum individual losses keras mean losses class image simply summed example code someone trybasic implementation borrowed kaggle modified multi label prediction actual bce dice loss function can found motivation question based code total validation loss network epochs however mean intersection union scores first classes last class clearly indicatingclass isnhowever loss accuracy isnreflected loss hence means individual losses sample combined way completely negates huge loss seeclass per sample losses combined batchstill really lowsure reconcile information although already mentioned part answer related answer letinspect source code step step details find answer concretely first letfeedforward call weighted loss function takestruepred sample weight mask inputs weighted loss actually element list contains augmented loss functions passed fit method augmented word mentioned importantcan see actual loss function wrapped another function called weighted masked objective defined follows nested function weighted actually calls real loss functionline score arrayy truepred now concrete case exampleprovidedbinary crossentropy therefore need take look definition binary crossentropy keras turn calls backend function case using tensorflow backend definition follows tensor shape logits componentwise logistic losses now letbackpropagate considering note output shapetruementionedtrue shape batch size img dim img dim num classes therefore axis applied tensor shape batch size img dim img dim num classes results output tensor shape batch size img dim img dim loss values classes averaged pixel image hence shape score array weighted function mentioned batch size img dim img dim one step return statement weighted function takes mean score array compute mean take look definition mean backend function find axis argument none default calls given axis none argument takes mean axes input tensor return one single value therefore mean whole tensor shape batch size img dim img dim computed translates taking average labels batch pixels returned one single scalar value represents loss value loss value reported back keras used optimization bonus model multiple output layers therefore multiple loss functions used remember first piece code mentioned answer can see variable used indexing array may guessed correctly actually part loop computes loss value output layer using designated loss function takes weighted sum loss values compute total loss pixels image pixels image individual class class losses combined exactly different pixel combinations happening summed averaged answer training batch images array consisting pixel values trained calculating non linear function loss optimizing updating weights loss calculated pixel value rather done image pixel valuestrain weights biasused sigmoid simplest example non linearity calculate predictedvalue alongtrain batch time used calculate loss optimized using one optimization methods like sgd momentum adam etc update weights biases answer non linearity operation pixel valuestrain combined weights dot product added bias form predicted target value batch may training examples belonging different classes corresponding target values class compared corresponding predicted values compute loss therefore perfectly fine sum losses really doesnmatter belong one class multiple classes long compare corresponding target correct class make sense need build classifier text nowusing tfidfvectorizer selectkbest selection features following want print selected features name text selectbest features way just need print selected feature names maybe use countvectorizer instead following work expand ogriselanswer returned list features ordervectorized code will give list top ranked features sorted according chi scores descending order along correspondingvalues need fit multivariate gaussian distributionobtain mean vector covariance matrix nearest multivariate gaussian given dataset audio features python audio features mfcc coefficientsx matrixaroundcan someone please outline packages technique fit gaussian data python use numpy package will need set rowvar calling pass transpose matrix function argument data numpy array data described mahout action normalization can slightly improve accuracy can anyone explain reason thanks normalization always required rarely hurts examplesmeansmeans clustering isotropic directions space therefore tends produce less round rather elongated clusters situation leaving variances unequal equivalent putting weight variables smaller variance example matlab fyi can detect dataset clustered unclustered distributed clustering comparative analysis shows distributed clustering results depend type normalization procedure artificial neural network inputs input variables combined linearly mlp rarely strictly necessary standardize inputs least theory reason rescaling input vector can effectively undone changing corresponding weights biases leaving exact outputs however variety practical reasons standardizing inputs can make training faster reduce chances getting stuck local optima also weight decay bayesian estimation can done conveniently standardized inputs artificial neural network inputs outputs things data answer depends standardizing either input target variables tends make training process better behaved improving numerical condition see ftp optimization problem ensuring various default values involved initialization termination appropriate standardizing targets can also affect objective function standardization cases approached caution discards information information irrelevant standardizing cases can quite helpful information important standardizing cases can disastrous interestingly changing measurement units may even lead one see different clustering structure kaufman leonard peterrousseeuw finding groups data introduction cluster analysis applications changing measurement units may even lead one see different clustering structure example age years height centimeters four imaginary people given table plotted figure appearsc two separated clusters hand height expressed feet one obtains table figure obvious clusters nowbpartition completely different first subject received another companion figure flattened even age measured days avoid dependence choice measurement units one option standardizing data converts original measurements unitless variables kaufmanal continues interesting considerations page philosophical point view standardization really solve problem indeed choice measurement units gives rise relative weights variables expressing variable smaller units will lead larger range variable will large effect resulting structure hand standardizing one attempts give variables equal weight hope achieving objectivity may used practitioner possesses prior knowledge however may variables intrinsically important others particular application assignment weights based subject matter knowledge see abrahamowicz hand attempts devise clustering techniques independent scale variables friedman rubin proposal hardy rasson search partition minimizes total volume convex hulls clusters principle method invariant respect linear transformations data unfortunately algorithm exists implementation except approximation restricted two dimensions therefore dilemma standardization appears unavoidable present programs described book leave choice user reason behind sometimes measurements different variables different nature variance results adjusted normalizing instance agevs weightcomparison set children age canone weight canpounds normalize graphic will produce two weird long oval shapes right graph since scales needform one normalizing give axis scale hecnce graphic will show meaningful clusters clustering makes use distance measure like euclidean forming clusters standardize normalization inputs performed ensure important inputs small magnitude donloose significance midway clustering process contributes hardly thing result hence input corresponding values considered futile model similarly classifiers also make use distance measure classification hencegood practice normalize input data classifiers normalization really helps intuitively important parameters small values build simple recommendation system movielensinspired apache spark als collaborative filtering results donmake sense using implicit training explicit implicit data gives reasonable results explicit training doesnok now curious update model current solution works like want flow like therefore must update model without completely recompute chance first way good batch processing like generating recommendations nightly batches second way good nearly live generating recommendations edit following worked implicit feedback ratings interesting ranking products new user details can actually get predictions new users using trained model without updating get predictions user model use latent representation vectorsizenumber factors multiplied product latent factor matrix matrix made latent representations products bunch vectors sizegives score product new users problem donaccess latent representation full representation sizenumber different products can use similarity function compute similar latent representation new user multiplying transpose product matrix user model get scoresv new user donlatent representation take full representation fullfullvv will approximate latent factors new users give reasonable recommendations model already gives reasonable recommendations existing users answer question training allows compute predictions new users without heavy computation model can now batch processing night can still make prediction new user day note mllib gives access matrixv seems like want kind online learningnotionactually updating model receiving data spark mllib limited streaming machine learning optionsstreaming linear regression streamingmeans many machine learning problems work just fine batch solutions perhaps retraining model every hours days probably strategies solving one option ensemble model combine results als another model helps make predictions unseen movies expect see lot previously unseen movies though collaborative filtering probably doesnwant new movies arenmodelway model know people watched liked better option might take different strategy try kind latent semantic analysis movies model concepts movie like genre themes way new movies various properties fit existing model ratings affect strongly properties interact using distance function can calculate distance words case one list containingnumber strings desired result calculate distance matrix clustering words just use pdist version accepts custom metric levensthein can use implementation rosettacode suggested tanu want full squared matrix just use squareform result code something like thisi question kkmeans function kernlab packagenew package please forgivemissing something obvious like assign new data point cluster set clusters created using kernelmeans function kkmeans regular clustering one calculating euclidian distance new data point cluster centroids choose cluster closest centroid kernelmeans one must feature space take example used kkmeans description say new data point like assign closest cluster createdtips help appreciated kernelmeans uses kernel function calculate similarity objects simplemeans loop centroids select one minimizes distance used metric given data point case kernel method default kernel function kkmeans radial basis function simply loop centroids select one maximizes kernel function value case rbf minimizes kernel induced distance kernel detailed description converting kernel distance measure provided general distance induced kernelcan calculatedbkbb case rbfxx can just maximizeb instead minimizing wholekbb get kernel function kkmeans object can use kernelf function example closest centroidsense used kernel userwarning input retrieved worker showing warning model starts training warning means something will affect training need worry just user warning will usually thrown try fetch inputs targets training timeout set queuing mechanism will specified inside dataworking directory use can done simply viar path google drive data dir path colab data dir notebook note will time new colab session created may may problem rahul asking think might helpful others face issue running training gpu warning will occur know two running progress fit generator running parallel tasks cpucompute lower gpus warning occurs just set batch size smaller upgrade cpu config make sure path data set given correct example train data dir content drive drive colab notebooks dataset faced issue training deep neural network machine using keras took figure images loading using lower resolution say trying convert apparently inbuilt support provided soon fixed output shape image returned imagedatagenerator warning vanished note figures just explanation can reduce number workers max queue size solve problems got warning training amount data samples smaller batch size training actually seem started get stuck even showing progress bar first epoch faced issue change keras version warning disappeared cuda cudnn can also work normally still resolved please additional referenceswin tensorflow version keras version python version cuda version cudnn version want implement classifier using sklearn library way save model convert file saved tensorflow file order convert tensorflow lite later replicate architecture tensorflow will pretty easy given scikit learn models usually rather simple can explicitly assign parameters learned scikit learn models tensorflow layers example logistic regression turned single dense layer always easy replicate scikit model tensorflow instance scitik lot fly imputation libraries will bit tricky implement tensorflowsome months ago used found convenient use didnkeep development tensorflow last months now project want use regressor control actual model provided dnnregressor far can see supported estimator api using modelparameter two estimators tensorflow api provide similar api nevertheless slightly different usage two different implementations reasons prefer one unfortunately canfind differences tensorflow documentation guide use actually working tensorflow tutorials produced lot warnings interfaces apparently changed insteady parameter inputparametercetera wondered give definitive answer educated guesses might help seems evolvedremoved yet existing code wonbreak now explicit statement docs note tensorflow also includes deprecated estimator class usemarked deprecated code add christophanswer distinction packages specifically mentioned tensorflow dev summit martin wicke distinction core contrib really core things donchange things backward compatible release nobodythinking right now something corestable use something contrib api may change depending needs may may want use can think experimental early preview classes already definitely use evenstated explicitly documentation can dropped next release tensorflow list graduated classes includes estimator dnnclassifier dnnregressor linearclassifier linearregressor dnnlinearcombinedclassifier dnnlinearcombinedregressor ported indeed christoph mentioned usage seems different can use canthing modelrequirement parameter different check error messages conclusion two estimator different thing anyway thinkdoc bad topic sinceusing scikitlabelencoder convert numerical values fed randomforestclassifier trainingfollows now testing prediction pass new data want transform data basedvalues present transform according label encoder otherwise assign new numerical value test file followsgetting following error valueerrorcontains new labels fix thanks update task use example training data predict high mod low values new banknum combinations model learn characteristics high given low given training dataset example high given multiple entries banknum different ids predict something likesomething like think error message clear test dataset contains labels included training data set items labelencoder can find suitable numeric value represent ways solve problem can either try balance data set sure label present test also training data otherwise can try follow one ideas presented one possibles solutions search data set beginning get list unique values train labelencoder list keep rest code just moment possible solution check test data labels seen training process new label set fallback value like unknown something like doin put new unknown ids one class items prediction will fail can use rest code now can try solution thing create dictionary classes map column fill new classes known value data label encoding special token reserved mapping cases onehot encoding onehot columns zeros cases usage fact known bug labelencoder bug fit transform basically fit transform will work fine suggestion keep dictionary encoders every column inverse transform able retrieve original categorical valuesable mentally process operations better dealing dataframes approach fits transforms labelencoder using training data uses series code defaults max trained encoder value found easy hack around issue assumingdataframe features first need create list dicts key iterable starting corresponding value pair categorical column name easily accomplish using enum cat cols enum list enumerate includecolumns idea create list label encoders whose dimension equal number qualitative categorical columns present dataframele labelencoder range len cat cols enum next last part fitting label encoders present list encoders unique values categorical columns present list dicts respectively cat cols enumfitvalue counts index now can transform labels respective encodings using error comes transform function getting new value labelencoder try encode training samples using fit transform specific value present corpus hack whether use unique values fit transform function sure new value will come try different encoding method suits problem statement like hashingencoder example new values will come testing also encountered exact error able fix used following code error occurred reason error true value array string type set boolean changed bool type string thus error fixed hope answer helpful hope helps someonerecent sklearn uses fit transform perform fit function transform function directing label encoding solve problemlabel throwing error unseen values use solves used able resolve issue fit transform need worry unknown values test splitsuppose matrixsize double represents number observations represents number features sigma covariance matrixd diagonal matrix whose diagonal elements eigenvalues sigma assume eigenvectors covariance matrix sigma following questions need select firsteigenvectors corresponding eigenvalues largest magnitude rank selected features final matrix namedcan matlab meaning selected eigenvectors seems size final matrixdouble calculatetime points observation information disappeared final matrixvalue matrixrepresent now also value matrixrepresent nowassuming determined eigenvectors eig function recommend future use eigs function computes eigenvalues eigenvectors will computelargest eigenvalues associated eigenvectors may save computational overhead doncompute eigenvalues associated eigenvectors matrix want subset simply supply covariance matrix data eigs returnslargest eigenvalues eigenvectors now back problem describing ultimately principal component analysis mechanics behind compute covariance matrix data find eigenvalues eigenvectors computed result known way recommended due numerical instability computing eigenvalues eigenvectors large matrices canonical way now via singular value decomposition concretely columnsmatrix give eigenvectors covariance matrix principal components associated eigenvalues square root singular values produced diagonals matrixsee informative post cross validated preferredthrow another link talks theory behind singular value decomposition used principal component analysisanswer question one time matlab generates eigenvalues corresponding ordering eigenvectors way unsorted wish select largesteigenvalues associated eigenvectors given output eig exampleneed sort eigenvalues descending order rearrange columns eigenvector matrix produced eig select firstvalues also note using eigs will guarantee sorted order will explicitly sort comes matlab described look something likegood thing note sorting absolute value eigenvalues scaled eigenvalues also eigenvalues scales also include negatives means component whose eigenvalue say good indication component significant meaning data sorted purely numbers gets placed near lower ranks first line code finds covariance matrixeven though saidalready stored sigma letmake reproducible next find eigenvalues covariance matrix associated eigenvectors take note column eigenvector matrix represents one eigenvector specifically ith column eigenvector corresponds ith eigenvalue seenhowever eigenvalues diagonal matrix extract diagonals diag command sort figure ordering rearrange respect ordering use second output sort tells position value unsorted result appear sorted result ordering need rearrange columns eigenvector matriximperative choose descend flag largest eigenvalue associated eigenvector appear first just like talked can pluck firstlargest vectors values viaknown fact eigenvectors covariance matrix equal principal components concretely first principal component gives direction maximum variability data principal component gives variability decreasing naturealso good note principal component orthogonalgood example wikipedia two dimensional data pulled image wikipedia article principal component analysis linked scatter plot samples distributed according bivariate gaussian distribution centred standard deviation roughly direction orthogonal direction component standard deviation first principal component one orthogonal second component vectors shown eigenvectors covariance matrix scaled square root corresponding eigenvalue shifted tails mean now letget back question reason take looklargest eigenvalues way performing dimensionality reduction essentially performing data compression take higher dimensional data project onto lower dimensional space principal components include projection will resemble original data actually begins taper certain point first principal components allow faithfully reconstruct data part great visual example performing pca svd rather data reconstruction found great quora post stumbled upon past means originally features dataset reduced dimensionality data consider matrix transformation original dimensionality feature reduced dimensionality use matrix conjunction reconstructing original data concretely give approximation original data looked like least amount error case donneed use principal components can create approximation data less information reconstruct data simple lettalk forward reverse operations first full data forward operation take original data reproject instead lower dimensionality will use components first need original data mean subtractedwill produce matrix feature every sample mean subtracted bsxfun allows subtraction two matrices unequal dimension provided can broadcast dimensions can match specifically will happen case mean column featurewill computed temporary replicated matrix will produced largesubtract original data replicated matrix effect will subtract every data point respective feature means thus decentralizing data mean feature operation project simply operation quite simple expressing samplefeature linear combination principal components example given first sample first row decentralized data first samplefeature projected domain dot product row vector pertains entire sample first principal component column vector first samplesecond feature projected domain weighted sum entire sample second component repeat samples principal components effect reprojecting data respect principal components orthogonal basis vectors transform data one representation another better description just talked can found look amroanswer matlab principal component analysis eigenvalues order nowbackwards simply inverse operation special property eigenvector matrix transpose get inverse get original data back undo operation add means back problem want get original data backsolvingrespect previous operation however inverse asort just transposehappening perform operation getting original data back data still decentralized get original data back must add means feature back data matrix get final resultre using another bsxfun call can samplefeature values ableback forth original domain projected domain two lines code now dimensionality reduction approximation original data comes play reverse operation need first project data onto bases principal components nowback original domain trying reconstruct data reduced number principal components simply replace asort codealso reduce amount featuresusing bproject concretely bprojectselectsfeatures projected domain data correspondinglargest eigenvectors interestingly just want representation data regards reduced dimensionality can just use bprojectll enough however wantforward compute approximation original data need compute reverse step code simply full dimensionality data useselectingfeatures bproject will give original data representedlargest eigenvectors eigenvalues matrixlike see awesome examplemimic quora post linked using another image consider grayscale image row sample column feature lettake cameraman imagepart image processing toolbox get imageimage means data points point featuresgoing convert image double precision computing covariance matrix nowgoing repeat code incrementally increasinggo thereforeintroducing principal components slowly start get reconstruction datarunnable code illustrates point can see majority code seendifferent loop valuesproject back onto original spacehighest eigenvectors show image get nice figure can see startingdoesnreallywouldnhurt add start increasing number components start get clearer picture original data looks likeactually can see cameraman looks like perfectly donneed components beyond seehappening talking regards data compression donneed work principal components get clear picturegoinglike end note referring chris taylorwonderful exposition topic principal components analysis code graphs great explanation boot got started pca quora post solidified knowledge matlab pca analysis reconstruction multi dimensional datai dataframe pandas contain training examples example generated using can see training set imbalanced samples class samples class like oversample training set specifically like duplicating training samples class training set balanced number samples class approximately number samples class can ideally like solution may generalize multiclass setting integer class column may can find maximum size group example equals group can sample replacement max size len group size elements way concat original dataframe sizes willkeep original rows can play max size len group maybe add noise will make group sizes equal saw help matlab provided example without explaining use parameters classregtree function help explain use classregtree parameters will appreciated documentation page function classregtree complete example illustrate process classregtree class made obsolete superseded classificationtree regressiontree classessee fitctree fitrtree functions newupdated example using new functions classes know libsvm allows oneone classification comes multi class svm however like tweak bit perform one classification tried perform one correct approach code might done mistakes like hear feedback thanks second part grapeot said need sum pooling voting simplified solution come final answer sure need help saw python file still sure need help code can see trying first turn labels classclass invoke libsvm training testing questions suggestions instead probability estimates can also use decision values follows achieve purpose just finished implementingtree fast nearest neighbor searchesinterested playing around different distance metrics euclidean distance understandingtree speedytree search guaranteed give exact searches metric non euclidean means might need implement new data structure search algorithm want try new metrics search two questions nearest neighbour search procedure described wikipedia page linked can certainly generalised distance metrics provided replace hypersphere equivalent geometrical object given metric test hyperplane crossings object example using manhattan distance instead hypersphere become multidimensional diamond easiest visualisecurrent nearest neighbour distancequery pointcloser neighbour behind different hyperplane must intersect diamond shape width heightcentredmight make hyperplane crossing test difficult code slower run however general principle still applies donthinktied euclidean distancerandom hacker says can probably use manhattan distancepretty suretied geometries can represented cartesian coordinates couldnusetree index metric space want override tensorflow gradient computation gradient method using registergradientwrong code want see zeros print instead getting need definewithin scope myop myopgrad also need map identity rather name myop new gradient full code output want use purposesure proper solution official documents says decorator used defining newtype means need define newwrittenwrappedfunctotally sure can apply groupop said however can also refer trick methods mentioned thread can define gradient tensorflow subgraph combine tfgradient override map togetherdefine gradients groups operations see answer note different questions might satisfactorily answered answer can anyone help getting error use google colab solve error size mismatchxx pytorch aten srcgeneric code trying run carec donexbatch sizefeaturescd featuresfeatures size mismatch first layer model expects dim input assume got valuesize mnist digits however trainset applies cropsregion center image thus input dimension actually summarize weka explorer gui foldgiven arff file weka explorer provides far can see average result foldsway get results fold instance need error rates incorrectly identified instances fold help appreciated think possible using wekagui need use experimenter though instead explorer steps weka explorer option give results individual folds using crossvalidation option workarounds explicitly donwant change code need manual fiddling think gives less want exactly equivalent fold crossvalidation though since pseudo folds make way might overlap alternative equivalent crossvalidation cumbersome make folds manually using unsupervised instance filter removefolds removerange generate save training sets test sets every fold load training set select supplied test set classify tab select appropriate test want fit linear regression line training data use line coefficients calculate test mse mean squared error residuals test data line fit case precise call mspe mean squared prediction error useful measure models aim prediction want model minimal mspe practice spare test data set can directly compute mspe however often donspare data statistics leave one cross validation estimate mspe training dataset also several statistics assessing prediction error like mallowsstatistictrying traindonwant use custom training loop like customize fit method overriding train accomplish reason want get benefit keras built functionality like fit callbacks donwant use custom training loop time want override train step reason likeelse can customize fit method still get leverage using built functions also know pros usingmajor cons usingcome default optional feature framework please run check following toy setupfound others also tried achieve ended issue one got workaroundmessy think better approach accepted answer fine works single strategy now like startbounty extend support multi gpu tpu mixed precision techniques complications see details yes possible customize fit method overriding train step without custom training loop following simple example will show train simple mnist classifier gradient accumulation outputs gradient accumulation mechanism split batch samples used training neural network several mini batches samples will run sequentiallycalculates loss gradients mini batch instead updating model parameters waits accumulates gradients consecutive batches can overcoming memory constraintsusing less memory training model like using large batch size example run gradient accumulation steps batch size images serves almost purpose running batch size images also parallel training usinge aggregate gradients multiple machines technique working widely used things consider using donthink called consturning machine sufficient memory batch size already large enough need use known large batch size will lead poor generalization will certainly run slower usingachieve batch size machinememory already can handle reference gradient accumulation deep learning thanks also observed using gradient accumulation wonspeed training sincegradients times forward pass compute gradients will speed convergence model found using mixed precision technique can really helpful details complete gistcreated xgboost classifier python train pandas dataframerows features columns target pandas series however training use classifier predict values entire results array number idea happening data clarification numerical features numerical targetalso tried randomforestregressor sklearn data give realistic predictions perhaps legitimate bug xgboost implementation question received several responses including thread similar issue xgboost lgbm solution increase size training dataset training local machine using random sample large sparse dataset rows columns enough local memory algorithm turned array predicted values just array average values target variable suggests model may underfitting one solution underfitting model train model data tried analysis machine memory issue resolved prediction array longer array average target values hand issue simply slice predicted values looking predicted training data little informationnantraining data little information seems reasonable predict average value target feature none suggested solutions came across helpful summarize suggested solutions included check gamma high make sure target labels included training dataset max depth may small one reasonsproviding high penalty parameter gamma compare mean value training response variable check prediction close yes model restricting much prediction keep train rmse val rmse close possible prediction simplest higher value gammaget simplest model prediction like mean training set prediction naive prediction wonmax depth smaller try get bigger default value remember correctly set silent can monitorerror epochs need post reproducible example real investigationentirely likely response target highly unbalanced training data super predictive thus always almost always get one class predicted looked predicted probabilities see variance just issue using proper cut classification labels since saidgave reasonable predictions useful see training parameters glancecurioususing regression objective function xgboost call though easily seeing poor performance trying changing objective binary logistic check inf values target try increase significantly min child weight xgboost min data leaf lightgbm actually may case overfitting masking underfitting happens instance zero inflated targets case insurance claims frequency models one solution increase representation coverage rare target levels tree leaf increasing hyperparameter controlling minimum leaf size rather large values specified example just problem managed fix problem training tree method gpu hist gave predictions set tree method auto works properly wayy longer runtimes set tree method gpu hist along base score worked think base score mean predicted variable tried solutions page none worked grouping time series certain frequencies created gaps data solved issue filling nanprobably hyper parameters use cause errors try using default values case problem solved removing subsample min child weight hyper parameters params searching hyperparameter tune package code written directly tensorflow keras tflearn make suggestion usually donneed hyperparameter optimisation logic coupled optimised model unless hyperparemeter optimisation logic specific kind model training case need tellbit several tools packages available task good paper topic practical blog post examples really real problem used hyperopt tensorflow didntook much effort api bit weird points documentation terribly thorough work seems active development optimization algorithms adaptations possibly coming however suggested previously linked blog post scikit optimize probably good sigopt looks quite easy use fitslike add one library jdehesalist applied research particularly tensorflowhyper engine apache licensed also implements gaussian process bayesian optimization techniques like learning curve prediction save lot time can try ray tune simple library scaling hyperparameter search mainly use tensorflow model trainingagnostic framework works seamlessly pytorch keras etcdocs page also donneed change code want run script cluster disclaimer work project let know feedbacksure also parameters want mentioned tensorflow hyperparameters guess can suggest try clone repository needed scripts git clone invoke command prompt run line pythonfound sci kit optimize simple use bayesian optimization hyperameters works tensorflow api estimator custom estimator core keras etc bayesian point cloud optimization space hyperparameter tuning much better tensorflow probability approachworking project isolate vocal parts audiousing dsd dataset testsusing dsd subset dataset use mixtures vocalsbasing work article first process audios extract spectrogram put list audios forming four lists trainmixed trainvocals testmixed testvocals like next build model run modelgetting result new topic thanks help provided advanceprobably issue specifying input data keras fit function recommend using like can also use functions like shuffle batchdatasets edit also seems like input shapes incorrect input shape specified first conv layer input batch tensor shape batch size whereasinputting shape batch sizeneed reshape probably cut inputs specified shape specify new shape basically matter define shape convdrequiresfeeding inputbatch row col channel example clarify convtlnow letelaborating codes line input layer defined shapelinereshapedshape matching shape however order feed inputinput layer convmust passone reasons using vowpal wabbit large size data file can calculate auc outside vowpal wabbit environment using output vowpal wabbit might problematic data file large currentlyreport auc worse optimize directly auc optimizing auc compatible online learning approximations auc suitable optimizing concerning question donneed store intermediate file raw predictions disk can pipe directly external evaluation tool perf case edit john langford confirmed auc can generally optimized changing ratio false positive false negative lossmeans setting different importance weight positive negative examples need tune optimal weight using hold set cross validation progressive validation loss one pass learning trying use multi layer neural network predict nth square following training data containing first squares code printsst squares right way following filip malczakseannysuggestions comments implemented neural network tensorflow check happens try teach predict interpolatesquare training continuous interval trained network interval taking points inside interval make continuous tested interval activation functions relu network hidden layers one size epochs result depicted figure basically inside also close interval fit quite perfect continues less linearly outside nice see least initially slope networkoutput tries match slopeincrease test interval two graphs diverge quite lot one can see figure training even numbers finally instead train network set even integers interval apply set integers even odd interval get training network produce image increased epochs get better accuracy rest parameters stayed unchanged seems interpolating inside training interval works quite maybe except area around fit bit worse code used first figure checked docs neurolab newff createssigmoid transfer function neurons default sigmoid value always range output will never leave range second square already range code doesnmatch problem try using functionspropose softplus relu work quite feed forward networks allow backpropagation training derivable whole domain values range just need also first param newff defines ranges input datausing matches training data doesnmatch valuestried testing since bigger change value something way bigger values test special meaning end rangepropose something like besides stated seanny comment donthinkgonna work current setup can sure good luck let know example comments succeeded last leasttrying extrapolation figuring values range based values rangebetter suited interpolation figuring values range based samples range supposed generalize data used training try teaching squares example everysquare testing asking squares rest example asking square want train multiple linearsvc models different random states prefer parallel mechanism supporting sklearn know gridsearch ensemble methods implicitly thing hood thing hood library joblib powers example multi processing gridsearchcv ensemble methodsparallel helper class handy swiss knife embarrassingly parallel loops example train multiple linearsvc models different random states parallel processes using joblib building image processing classifier line giving error input img resize input img error erroropencv modules imgproc src error function resize code obviously line input img data path dataset img returns empty array check whether image exists first reading better use string combination join file paths use pythonresolution zeronumber channels means finding image add following checking performing operations working several images example images may difficult identify image giving problems may also several others corrupt case code can useful filenames list contains names images facing problem image might read properly scanning make sure tat image loaded skips current image continue scan breaks two segments results follows hope helps region image properly identifiedone way can try will let manually select region image pic detected error can simply use code definitely runs resolves problem also facing error fixed first matrix arranged upside want arrange labels true positives set diagonal arrangementgoing find confusion matrices generated sklearn packages things sorted right direction can take page answer say take formulas sklearn docs precision recall put code since remove true positives define false positives negatives add donthink need summation last without summation method correct gives precision recall class intend calculate average precision recall two options micro macro average read given list grounthpredictionfollowing code snippet computes confusion matrix calculates precision recall hypothetical confusion matrixprecision recall class using map calculate list division please note classes precisions recalls agreeing gruangly euwern modified pabtorresolution accordingly generate precision recall per class also given use case ner model wrap array convert nan zero mathematical decision per use case functional decision handle never predicted never occuring classes simplernn like model summary says curious parameter number simple rnn someone answer question look headline table see title param number represents number trainable parameters weights biases respective layer case simplernn edit formula calculating weights follows recurrent weights input weights biases resp num features num units num units num units explanation num units equals number units rnn num features equals number features input now two things happening rnn first recurrent loop state fed recurrently model generate next step weights recurrent step recurrent weights num units num units secondly new input sequence step input weights num features num units usually last rnn state new input concatenated multiplied one single weight matrix nevertheless inputs last rnn state use different weights now weights missing biases every unit one bias biases num units finally formula recurrent weights input weights biases num units num units num features num units biases num features num units num units biases cases means trainable parameters hope understandable just tell can edit make clear might easier understand visually simple network like number weights number biases number units number input dimensions formula just like first answer num units num units input dim num units simply num units num units input dim yields parameters given question visualize simplernn add think figure can explain lot simplernn layernewbie canpost images directly need click link unrolled version simplernn layer can seen dense layer previous layer concatenation input current layer previous step number parameters simplernn can computed dense layer num para units pre units num bias units pre sum input neurons settings units see units number neurons settings current layer num bias number bias term current layer units plugging settings achieve num para fetches feed dict guaranteed execute fetches arguments order documentation doesnseem mention example run order execution matters trainwill update parameters affecting accuracy default tensorflow free evaluate operators order concurrency order may even change runs usually good thing means tensorflow may make optimal use available hardware can problematic code mutates state variables however reason wish control order evaluation general can use control dependencies enforce order operators control dependencies documented control dependencies hope helps posting discussion possible get objective function value training step noticed execution order undefined example consider code tensorflow environment variable cuda visible devices set one gpus prints set code prints unfortunately donsee anything documentation specifying execution order warning usersundefined trying apply decision tree decision tree takes care splitting node first node want split tree basis age force built option ctree easiest method hand simply learn tree age explanatory variable maxdepth creates single split split data using tree step create subtree left branch split data using tree step create subtree right branch want although typically wouldnrecommend use ctree implementation partykit can also merge three trees single tree visualizations predictions etc requires bit hacking still feasible will illustrate using iris data will force split variableused tree learning three trees easy note however important use formula assure variables model frame ordered exactly way trees next comes technical step need extract raw node structure three trees fix node ids proper sequence integrate everything single node finally set joint model frame containing data combine new joint tree information fitted nodes response added able turn tree constparty nice visualization predictions see vignette partykit package partykit backgrounddone can visualize combined tree forced first split every iteration decision tree will choose best variable splitting either based information gain gini index cart based chi square test conditional inference tree better predictor variable separates classes can done predictor age variable will chosen first think based requirement can following couple things unsupervised discretize age variable create bins etc per domain knowledge subset data age bins train separate decision tree segments supervised keep dropping predictor variables age chosen first now will get decision tree age chosen first variable use rules age age age created decision tree subset data parts parts learn full decision tree variables separately supervised ensemble can use randomforest classifier see important age variable can use rpart partykit combination achieve operation notice use ctree trainuse data party function extract data different node variables included extracted data set training variables case age use rpart first step train model selected variable way using rpart traincan keep variables extracted data set without putting variables training variables using method training variable age can convert rpart tree partykit extract data different node train desperately now two dataset split based age variables want use trainfuture can buildbased subsets however see fit use rpart ctree later can use partynode partysplit combo construct tree based training rules achieved hope looking want leverage machine learning model userintent potentially automate commonly performed tasks like access fire hose information user actions machine state end current thinking getting access stream windows messages probably way forward like much information possible filtering information pertinent like leave machine learning tool accomplished preferablyplease assume know manage use large influx data help gratefully appreciated can use setwindowshookex set low level hooks catch specific windows messages specifically hook ids might interesting monitoringcallwndproc installs hook procedure monitors messages system sends destination window procedure information see callwndproc hook procedurecallwndprocret installs hook procedure monitors messages processed destination window procedure information see callwndretproc hook proceduresinceimplemented exampleposted base class use hook specific messages exampleused global mousewheel trapper makes sure winforms apps behave internet explorer scroll control underneath cursor instead active control using code compare performance number models can use accuracy recall scoring will give accuracy sensitivity can create scorer gives specificity specificitytntntrue negative false positive values confusion matrix tried will worksplit get error calculation scorer indexerror index bounds axis size change recall score parameters binary classifier pos label get specificity default sensitivity pos label get specificity scikit can actually get fpr getting specificity just need subtract fpr fpr can calculated using roc curve work need calculatepred training model want use inside cross val score can make custom scorer like note codes will give correct results binary method modifies certain modules layers required behave differently training inference examples listed docs effect certain modules see documentations particular modules details behaviors training evaluation mode affected batchnorm etc exhaustive list modules affected addition info provided iacob searching site evaluation google appear following modules affected built tensorflow model uses dnnclassifier classify input two categories problem outcome occurs upwards time therefore tensorflow giving probabilities predictions trying predict outcome know machine learning general case worthwhile try upweight outcome however donknow tensorflow documentation alludes possible canfind examples actually look like anyone successfully done anyone know find example code thorough explanationusing python note seen exposed weights manipulated someone using fundamental parts tensorflow estimator maintenance reasons need using estimator weight column string numericcolumn created weights used weight boost examples training will multiplied loss example string used key fetch weight tensor features numericcolumn raw tensor fetched key weight weight updatecomplete working example using random forestscame across following situation output output first example set importance false second example true understanding affect resulting predictionalso indication behavior documentation according cross validated thread proximity importance influence predictions random forest importance flag influence predictions clearly example importance parameter randomforest method influencing performance model nice example demonstrating limits reproducibility short letsee equal change two experiments invalidates assumption expect reproducibility deterministic sense seeking may course still expect reproducibility statistical sense issue difference two cases present calculating feature importance really subtle see actually violates principle stated dig little documentation source code documentationimportance function already provides strong hint emphasis mine definitions variable importance measures first measure computed permuting oob data done permuting predictor variable may already started becoming suspicious data permutations normally performed random sense hence potentially invoking random number generator rng one extra process use importance true process absent importance false case words importance true case rng involved way absent importance false case first time thing happens program two cases stop deterministically comparable irrespectively common random seed point may strong hint still speculation principle permutations can performed deterministically hence rng smoking gun turns smoking gun exists indeed buried underlyingsource code used randomforestpackage relevant partfunction permuteoob can clearly see function unif rand invoked line snippet source code method called ask importance true opposite case arguably given factalgorithm randomness hence rng use enters many points enough evidence two cases present indeed expected identical since different use rng makes actual results diverge hand difference one single misclassification among samples provide enough reassurance two cases still statistically similar also apparent subtle implementation issue violate expectation two results equal want look implementation functions just see exactly things done started simple case ran searches source tree got okay presumably actual code apply gradient descent searched uses definitions training ops exist source file suggestive name entire content file hmm find file seems confirm files object code generated build process source code generated point give ask help can anyone familiar tensorflow code base point relevant source code implementation goes nativecodeapplygradientdescent gpu implementation core kernels training ops cpu implementation core kernels trainingcurious value field nodes decision tree produced graphviz used regression understand number samples class separated split using decision tree classificationsure means regression data dimensional input dimensional output example tree looks like regression problem produced using code visualized webgraphviz regression tree actually returns output mean value dependent variabletraining samples end respective terminal nodes leaves mean values shown lists named value picture length sincedimensional words using leftmost terminal node leaf tree example can confirm case predicting samples training test set doesnmatter checking dimensional result one value lists depicted terminal leaves additionally can confirm element value weighted averages children nodes equal respective element parent node using first element leftmost terminal nodes leaves get element parent node leftmost node intermediate level one example time first value elements intermediate nodes agrees first value element root node judging value list root node seems mean values elements dimensionalalmost zero can verify manually final confirmation wrap trying implement simple sequence sequence model using keras however keep seeing following valueerror questions like looking issue github suggests might something cross entropy loss function fail see wrong think problem want mention nightly build tensorflownightly two different sets problems code categorized syntactical architectural problems error raised related syntactical problems mostly address try give pointers architectural problems main cause syntactical problems using named inputs outputs model named inputs outputs keras mostly useful model multiple input output layers however model one input one output layer therefore may useful use named inputs outputsdecision explain done properly first keep mind using keras models data generated input pipeline whetherpython generator provided tuple input batch output batch input batch output batch sample weights said expected format everywhere keras dealing input pipelines even using named inputs outputs dictionaries example want use inputs outputs naming model two input layers named words importance also two output layers named output output formatted like can seetuple element tuple dictionary first element corresponds inputs model second element corresponds outputs model now according point letsee modifications done code sample generator return tuple dicts dict make dataset function input arguments signature prepare example body modified finally call method subclassed model one thing also put names corresponding input output layers using name argument constructing layers like dense name output however since using model sub classing define modelnecessary right resolve input output problems error related gradients gone however run code applying modifications still get error regarding incompatible shapes said earlier architectural issues model briefly address mentioned supposed seq seq model therefore output sequence one hot encoded vectors length vector equal target sequences vocabulary size result softmax classifier much units vocabulary size like note never model problem use softmax layer one unitwrong thinkwrong next thing consider fact dealingsequences therefore usingconvolutionpooling layers make sense can either usecounterparts replace something else like rnn layers result lambda layer removed also want use convolution pooling adjust number filters layer pool size properly convprobably optimal pool size make sense dense layer last layer one unit severely limit representational capacity model either increase number units remove thing reason one hot encoding labels dev set rather one hot encoded like labels training set therefore either training argument make generator removed entirely use case dev dataset created training true argument passed make dataset function finally changes model might work start fitting data batches passed might get incompatible shapes errorgenerating input data unknown dimension also use relaxed padding approach pad batch much needed none padded shapes resolve decide fixed input output dimension adjust architecture hyper parameters model conv padding pooling size adding layers etc padded shapes argument accordingly even like model support input output sequences variable length instead consider modelarchitecture hyper parameters also padded shapes argument since solution depends task desired design mind one fits solutions comment leave figure working solution may probably isnoptimal just give idea audio data set different length events audios want train test events placed randomly plus lengths different really hard build machine learning system using dataset thought fixing default size length build multilayerhowever lengthevents also different thought using cnn like used recognise patterns multiple humans image problem one really struggling try understand audio file questions anyone can give tips building machine learning system classifies different types defined events training dataset events randomly data contains events different different lenghts will appreciated anyone helps first need annotate events sound streams convert sounds sequences feature vectors using signal framing typical choices mfccs log mel filtebank features latter corresponds spectrogram sound done will convert sounds sequences fixed size feature vectors can fed classifier see better explanation since typical sounds longer duration analysis frame probably need stack several contiguous feature vectors using sliding window use stacked frames inputnow input dataannotations window analysis can try train dnn cnn rnn predict sound class window task known spotting suggest read sainathn paradaconvolutional neural networks small footprint keyword spotting proceedings interspeechfollow references details can use recurrent neural network rnn kind rnn available libraries like load libraries load churn data set librarycreatey variables use createfolds createfolds churntarget variable create traincontrol object mycontrol fit glmnet model model glmnet getting following error error lognetixy weights offset alpha nobsnan inf foreign function call arg addition warning message lognetixy weights offset alpha nobs nas introduced coercion checked missing values churnvariables anyone know answer problem model specification use caret train formula interface training will work however specifyy will work glmnet takesform model matrix supply formula caret will take care short answer using fixed issue initially fixed longer answer long problem passingmatrix using turns elements data frame coercible type columns happen factors data frame turns everything character fixed can handle factors ordered factor clear answer given group items solution based difflib basically search given item difflib can return similar word list can used grouping like reduce one idea tried item iterate list get close matches returns one match use keep word partly worked can suggest apple appel appel apple words simply switch places nothing change appreciate pointers names libraries etc note also terms performance list items get close matches seems bit slow anyone knowbased solution thanks note investigation revealed kmedoid right algorithm hierarchical clustering since kmedoid require centers takes uses data points centers points called medoids hence name word grouping case medoid representative element group cluster need normalize groups group pick one word coding represents group group words representative possible ways grouping words difficult though similarb similarc necessarily similarrepresentativeincluded grouprepresentative included going first alternative first encountered word example output decide closed matches words words want use may get first element list get close matches returning just use random function list get one element closed matches must sort rule now removeinitial listcan use levenshtein distance another version using affinity propagation algorithm distances converted similarities taking negative distance output another method using matrix factorization using svd first create word distance matrix wordsmatrix representating distance word words svd ran matrixresultingscan seen membership strength cluster code result selectionnumber clusters importantgives much better resultsinstance code also selects representative word cluster picking word whosecoordinate closest cluster centroid approach based medoids first install mlpy ubuntu output bigger word list usingsorry naivety donunderstand word embeddings resulttraining process word vec actually vectors embedding process dimension reduction training processreduces arrays words smaller size arrays process nothing applies vector arithmetic result got just arrays vectors think arrays vectors even though got vectors everyone depict vectors coming origin sorry question looks stupid embeddings word embedding collective name set language modeling feature learning techniques natural language processing nlp words phrases vocabulary mapped vectors real numbers conceptually involves mathematical embedding space one dimension per word continuous vector space much lower dimension source word vec word vec group related models used produce word embeddings models shallow two layer neural networks trained reconstruct linguistic contexts words word vec takes input large corpus text produces vector space typically several hundred dimensions unique word corpus assigned corresponding vector space word vectors positioned vector space words share common contexts corpus located close proximity one another space sourcearray computer science array data structure simply array data structure consisting collection elements values variables identified least one array index key array stored position element can computed index tuple mathematical formula simplest type data structure linear array also called one dimensional arrayvector vector space vector space also called linear space collection objects called vectors may added together multiplied scaled numbers called scalars scalars often taken real numbers also vector spaces scalar multiplication complex numbers rational numbers generally field operations vector addition scalar multiplication must satisfy certain requirements called axioms listed sourcedifference vectors arrays firstly vector word embeddings exactly programming language data structurearraysvectors introductory similarities differences programmatically word embedding vector sort array data structure real numbers mathematically element one dimension populated real numbers tensor vector single dimension scalars answerquestion word embedding actually vectors definition word embeddings vectors see represent words vectors real numbers learn differences words quantify difference manner imagine assign theses smart numbers words see distance fruit apple close samsung apple isncase single numerical feature word capable capturing information word meanings fully imagine two real number values word compute difference doneinformative returns vector canget definitive measure distance words can try vectorial tricks compute distance vectors now can see information apple can closer samsung orange samsung possiblyappleoccurs corpus frequently samsung orange big question comes get real numbers represent vector wordsword vec embedding training algorithms originally conceived bengio comes since adding real numbers vector representing words informative donjust add lot dimensions traditionally compute differences words computing word word matrices field distributional semantics distributed lexical semantics matrices become really sparse many zero values words donco occur another thus lot effort put dimensionality reduction computing wordoccurrence matrix imholike top view global relations words compressing matrix get smaller vector represent word deep learning word embedding creation comes another school thought starts randomly sometimes random initialized layer vectors word learning parameters weights vectors optimizing parameters weights minimizing loss function based defined properties sounds little vague concretely look word vec learning techniqueclearer seeresources read word embeddings word vectors process nothing applies vector arithmetic training process nothing vector arithmetic arrays produced turns pretty nice properties one can think word linear space example words embeddings closest given word space put differently words similar meaning form clouddsne representation another example distance man woman close distance uncle aunt result pretty much reasonable arithmeticfar fetched call vectors pictures wonderful post much recommend read word mapped pointdimension spaceusually though necessary thus called vector pointdim space nothing vectordim space points nice properties words similar meanings tend occur closer proximity measured using cosine distance word vectors famous word vec implementation cbow skip gram input cbow input word vector vector lengthn size vocabulary input word vectors together array sizexm length words now interesting graphic projection step forcelearn lower dimensional representation input space predict output correctly desired output original input lower dimensional representationconsists abstract features describing words adjective etc reality learned features really clear now features represent one view words like features can see high dimensional vectors want can use dimensionality reduction techniques display dimensional space details source graphic shows problem thinking now possible code uses older versionepochs writtenepoch last update code jan tried everything internet much including looking inside source code tensorflow keras hints just make clear donvariable called batch index inside code far looked inside different versionstensorflow tensorflow python keras engine training appears copyright start function fit loop model iteration probably update fit loop batch index variable can seen first function wonder going right direction point showing code explained variable first place inside code code function stock prediction gives error little clarification tried see versionkeraskeras shows different versions checked training function got error can see think problem statements lines batches empty list get error training set problem reason problem list batches empty batches reason blank number samples training data small divided batch size check data number samples reduce batch size point allows divide number samples batch size real result import correct libraries tensorflow keras directly apparently related different version issue keras error empty training data whether import keras directly tensorflow will error pass proper data error message might different per import version also make sure passing couple records data import keras tensorflow use error will raise valueerror empty training data valueerror empty training data directly message will error message given question one question though heard someonecan use extra packages extract decision rules implementedtry google thing python without luck help achieve thanks advance assuming use sklearn randomforestclassifier can find invididual decision trees estimators tree stores decision nodes number numpy arrays tree example code just prints node order array typical application one instead traverse following children example outout use something similar emlearn compile random forestcodetrying create new string attribute using wekajava appears way use constructorstuck pass attributevalues java complains protected objects put nullsyntax error put new fastvector becomes nominal attribute empty rather string create new object passargument returns null pointer cast null fastvector otherwise methods apply method signature good resource creating instances fly main problem wekadefinition null value null vector new type java editors imported earlystopping stops training soon val acc decreases however final model obtain best model namely one highest val acc rather model corresponding epoch namely one corresponding val acc just bit lower best one caused early stopping get best one tried use save best model using call back get results keras new argument called restore best weights introduced earlystopping callback set true defaults false restore weights epoch best monitored quantity restore best weights whether restore model weights epoch best value monitored quantity false model weights obtained last step training used like save highest accuracy set checkpoint monitor val acc will automatically save highest lowest loss might necessarily correspond highest accuracy can also set verbose see model saved trying use keras fit cnn model classify classes data imbalanced dataset want balance data donknow can use class weight balanced donwant change data creation process can use class weight fit generator can use dictionary set class weight observe fine tuning instance class weight used examples class examples class loss function calculate loss uniformly means class will problem set means loss function will give times weight class now therefore misclassification underrepresented data will take times punishment thus model can handle imbalanced data use class weight balanced model can make setting automatically suggestion create dictionary like class weight try different values can understand difference also can use undersampling methods imbalanced data instead using class weight check bootstrapping methods purposelearning deep learning keras trying compare results accuracy machine learning algorithms sklearnrandom forestneighbors seems kerasgetting worst resultsworking simple classification problem iris dataset keras code looks tired add layers change number units per layer change activation function relu seems result higher sklearn random forestneighborsgetting result dataset missing sklearn little effort got good results keras lot upgrades good sklearn results can get results keras short need detail first issue nowadays never use activation tanh intermediate network layers problems practically always use activation relu second issue build quite large keras model might case iris samples training set data effectively train large model try reducing drastically number layers number nodes per layer start simpler large neural networks really thrive lots data cases small datasets like expressiveness flexibility may become liability instead compared simpler algorithms likekthird issue contrast tree based models like random forests neural networks generally require normalizing data dontruth knn also requires normalized data special case since iris features scale affect performance negatively last least seem run keras model one epoch default value donspecify anything somewhat equivalent building random forest single tree btw still much better single decision tree following changes code everything else get can better use slightly training data stratify training epochs can get perfect accuracy test set details might differ due randomness imposed default experiments adding dropout might help improve accuracy see tensorflowdocumentation information essentially add dropout layer just similar added dense layers note parameter implies connections layer randomly omitted reduce interdependencies reduces overfittingtrying transfer learning using pretrained xception model newly added classifier model datasetusing oxford flowers taken directly tensorflow datasets dataset page problem selecting parameters either training accuracy shows suspiciously low valueserror need help specifying parameter oxford flowers dataset triedsure whether sparsecategoricalcrossentropy categoricalcrossentropy logits parameteralso sure whether choose definitely lacking theoretical knowledge right now just need work looking forward answers dataset divided training set validation set test set training set validation set consist images per class totaling images test set consists remaining images minimum per class checksee categories classes target comes integer different shapes input first keep integer target label use sparse categorical accuracy accuracy sparse categorical crossentropy loss function transform integer label one hot encoded vector use categorical accuracy accuracy categorical crossentropy loss function data set integer labels can choose sparse categorical can transform label one hot order use categorical second set outputs activation softmaxlast layer will get probabilities score set outputswill get logits set activations softmax use logit true example code followstheory third keras uses string identifier metrics acc optimizer adam case need bit specific mention loss function specific instead choose target integer target one hot encoded vector end end example note will transform integer labels one hot encoded vector right nowmatter preference also want probabilities logits last layer means logits false need choose following parameters training letcomplete whole code preprocess augmentation model okay additionally like use two metrics compute top top accuracy evaluatein docs predict proba selfbatch size verbose generates class probability predictions input samples batch batch returns numpy array probability predictions suppose model binary classification model outputprobability classprobability class situation different somehow misleading especially comparing predict proba method sklearn methods name keras sklearn wrappers method predict proba exactly predict method can even check binary classification case output get depends design network second method rarely used theorethical advantages using first method wanted inform just case depends specify output model targets can usually one binary classification output single value probability positive prediction one minus output probability negative prediction trying create autoencoder split train split trained weights make encoder make decoder make autoencoder now can use way want already referred posts donmark duplicate working binary classification problem dataset categorical numerical columns however categorical columns mix numeric string values nontheless indicate category name instance column called biz category values likec etc guess error thrown due values like therefore tried belowm convert category datatype still doesnwork data info looks like dtype conversion try smotenc get error results error shown typeerror traceback recent call last appdata roaming python python site packages sklearn utils unique python values return inverse uniques sorted uniques set missing typeerror supported instances str int handling exception another exception occurred typeerror traceback recent call lastusers sathap appdata local temp ipykernel smotencsmotenc categorical features cat index random state sampling strategy minoritytrain restrain restraintrain print oversampling shape trainformattrain appdata roaming python python site packages imblearn fit resample selfy outputyappdata roaming python python site packages imblearn sampling smote fit resample selfy input onehotencoder needs denseohex categorical elsecategorical appdata roaming python python site packages sklearn preprocessing fit transform selfy self validate keywords return super fit transformy def transform selfappdata roaming python python site packages sklearn fit transform selfy fit paramsnone fit method arity unsupervised transformation returnfit params transformelse fit method arity supervised transformation appdata roaming python python site packages sklearn preprocessing fit selfy self validate keywordshandle unknown force finite allow nan self compute drop idx return self appdata roaming python python site packages sklearn preprocessing fit selfhandle unknown force finitex list auto cats uniqueelse cats dtype appdata roaming python python site packages sklearn utils unique values return inverse object return unique python values return inverse return inverse numerical values return inverse return inverse appdata roaming python python site packages sklearn utils unique python values return inverse except typeerror types sorted typev values raise typeerror encoders require input uniformlystrings numbers got types typeerror encoders require input uniformly strings numbers got int str transformtrain categorical currently int help please smote requires values categorical numerical column uniform datatype essentially can mixed datatypes column case biz category column also merely casting column categorical type necessarily mean values column will uniform datatype one possible solution problemencode values columns mixed data types example use lableencoder think case simply changing dtype string also workgetting errors thinkdue pandas importinggreyed problem fixanacondausers nickd documents sklearn stocks recent call last fileusers nickd documents sklearn stocks line key stats fileusers nickd documents sklearn stocks line key statscolumns date unix tickerratio nameerror global name pandas defined process finished exit code imported calling either change edit error due missing imported pandaseither refer throughout removeimport plus never ever ever exceptswallow sorts errors never know arengoing handle doncatch code feature scaling using fit transform transform fit means fit pre processor data provided pre processor learns data transform means transform data produce outputs according fitted pre processor normally used test data unseen data general fit transform means fit pre processor data transform data according fitted pre processor calling fit transform convenience avoid needing call fit transform sequentially input course applicable training data calling fit transform test unseen data unfortunately common rookie mistakefollowed tensorflow poets tutorial replaced stock flower photos classes nowgotreading docs can find instructions create train deploy models withinengine donwant spend money training model googleservers need host model can call predictions anyone else run problem deploying locally trained model supported use case instructions essentially regardless trained deploy model versionneed tensorflow savedmodel saved google cloud storage can get model following cloudengine training steps train cloud training elsewhere exporting savedmodel unfortunately tensorflow poets show export savedmodelfiled feature request address meantime can write converter script like following alternatively end training instead saving untested code based codelab post want output use string labels instead integer indices make following change partial answer unfortunately able accomplish installed tensorflow calling trained model via http request works errors gunicorn mod wsgi surprised people tryinggeneral issue working binary classification using random forest trying shap explain model predictions however like convert shap local explanation plots values pandas dataframe instance one can help exporting shap local explanations pandas dataframe instance know shapash pandas method couldnfind anything like shap tried something like based post doesnhelp expect output something like negative sign indicates feature contribution class positive values indicates feature contribution class model like can decompose results like exactly equal want put results pandasalternatively wish everything arranged row wise trying apply idea sklearn roc extension multiclass dataset per class roc curve looks find straight line unline sklearnexample showing curvefluctuating give mwe show mean following function plots roc curve output kind straight line bending like see model performance different thresholds just one figure similar sklearnillustration classes shown pointusing predict rather predict proba decision function definehat means considering threshold vector defined number distinct valueshat see referencethresholds per class tpr fpr computed turn implies curves evaluated points indeed consider doc says passscores roc curve either prob estimates decision values example sklearn decision values used compute scores givenconsidering randomforestclassifier considering probability estimateshat ways point label binarizing output standard definition roc terms binary classification pass multiclass problem convert problem binary using onevsall approachn class number roc curves observe indeed svc handles multiclass problems ovo fashion default example force use ova applying onevsrestclassifier constructor randomforestclassifier donprobleminherently multiclass see reference terms switch predict probaseemuch sense label binarizing predictions eventually consider roc curve also drop intermediate parameter meant dropping suboptimal thresholds might useful know just update amiola answer issue non monotonic classes lead strange fuzzy results case little modification function will work use label binarize line need range function just use thanksanswer can check details want perform time series prediction future events using svr module scikit learn source code trying work dataset huge portion csv dataset included end interestedcolumn wanted predict valuescolumn increase decreases possible lookcolumn time series prediction help much appreciated thankssvm function problem second line win unused will cause error delete second donknow entire function reading csv ignore use pandas sample code will work intermediate steps clean imported data turn dataframe numpy array copycolumn regression fit delete training data rebuild new array must done fitting svr let know worked just took lines data table tried create neural network estimatex created fitting neural network gave samples input output tried build networkresult different expected following inputs following outputs used fitting tool network matrix rows training validation testing number hidden neurons two command lines wrote information netnetinputtest result command made error somewhere found stack overflow post neural network matlab contains problem like problem little difference differences problem ranges input output problem solution says need scale results can scale result right scaling mentioned linked answer neural network default scales input output range can seen network processing functions configuration second preprocessing function applied input output mapminmax following parameters map range prior training means trained network expects input values range outputs values also range want manually feed input network compute output scale data input reverse mapping output one last thing remember time train ann will get different weights want reproducible results need fix state random number generator initialize seed time read documentation functions like rng randstream also pay attention dividing data training testing validation sets must use split time probably also affected randomness aspect mentioned example illustrate idea adapted another post mine opted use mapminmax function done manually formula pretty simply linear mapping using opencv quite time decided check power machine learning lately ended implementing neural network face recognition summarize strategy face recognition predict test data using trained network everythingprediction stage using max responsed output unit classify face normally opencvsigmoid implementation give values range stated docs max closure class got nearly accuracy checked output responses class test data suprised values ind sigmoid applied get values wrong help understand matter ones wondering apply pca usem sharing code reading csv rolling images row row converting vector labels mat labels main note useds first class dataset thanks canberk bacicomment managed overcome sigmoid output discrepancy problem seems default parameters mlpcreate function takes alpha beta default given sigmoid function works stated docs neural network can predict something errors course results neural network modifying parameters like momentum etc without illumunation correction algorithm got accuracy dataset randomly sampled train test images first classes croppedyaleb opencv tutorials factors increase accuracy applied pca directly gave reduced dimension size may also reduce accuracy retained variance may worse free time will apply increase accuracy shared someone may wonder increase classification accuracyhope helps way can track issue explanation shows features contributing push model output base value average model output training dataset passed model output features pushing prediction higher shown red pushing prediction lower blue force plots introduced nature bme paper looks base valuetrain mean equals however case looking plot number actually even within tried log different basisassuming kind monotonic get base value raw space link identity need unwind class labels probabilities raw scores note default loss deviance raw inverse sigmoid relevant plotdata point raw space wish switch sigmoid probability space link logit relevant plotdata point probability space note probability base value shapperspective call baseline probability data available reasonable person define independent variables case full reproducible example outputtrying implement loss function using representations intermediate layers far know keras backend custom loss function accepts two input argumentsturepred can define loss function help appreciated simple workaround pass additional variables loss function case pass hidden output one layersoutput can used something inside loss function dummy operationworking really simple dataset missing values categorical numeric featurestrying use run following code get error valueerror convert string float private makes sense obviously canhandle categorical data try run onehotencoder throws error valueerror input contains nanprefer use knnimpute even categorical data feel likelosing accuracy just use columntransform impute numeric categorical data seperately way get onehotencoder ignore missing values using columntransform simpler imputer better way tackling problem thanks advance open issues prs handle missing values onehotencoderclear yet options interimmanual approach want implement adaboost model using scikit learn sklearn question similar another question totally far understand random state variable described documentation randomly splitting training testing sets according previous link understand correctly classification results dependent seeds correct worried classification results turn dependent random state variable classification scores will depend random state ujjwal rightly said used splitting data training test test just lot algorithms scikit learn use random state select subset features subsets samples determine initial weights etctree based estimators will use random state random selections features samples like decisiontreeclassifier randomforestclassifier clustering estimators like kmeans random state used initialize centers clusters svms use initial probability estimation mentioned documentation code relies random number generator never use functions like built random state argument passed class function read following questions answers better understanding matter training set differs trained state also changes different subset data can end classifier little different one trained subset hence use constant seed like another integer results reproducibleextremely new pythonrecently trying understand machine learning neural nets know trivial question seem problem importing data utils jupyter notebook can anyone please help note using keras following tutorial video also following video went issue searching link github tensorflow chatbot required files can download copy working directory python file directory now will able import based link provided video usinglink download files working directory files need download data utils seq seq model tutorial try tensorflow tutorials found tensorflow website get started library also new python recommend tutorial first since mentioned machine learning neural netsassumereferring kerasalso assume installed via case need uninstall first running clone githubdirectory run informationassuming using code tensorflowgithub case need download order follow case module called data util contains functions will called later data util function name let say data util python filedirectoryusers xxx modules run line code order python find modul call import data util using files just open seq seqarray input neural network like try something lstm requiresstructure input datacurrently using following code generatestructure needed super slow eta day better way numpy current code generate dataapproach using numpy strides vectorize creation outputsample run creates view input array memory wise efficient cases translate benefits performance operations involving letverify view indeed another sure shot way verify set values output check input neural nets regularization dropout commonly used reduce overfitting example plot shows typical lossepoch without dropout solid lines train dashed validation blue baseline dropout orange dropout plot courtesy tensorflow tutorials weight regularization behaves similarly regularization delays epoch validation loss starts increase regularization apparently decrease minimum value validation loss least models tutorial plot taken use early stopping stop training validation loss minimum avoid overfitting regularization delaying minimum validation loss pointdecreasing minimum validation loss value seems regularization result network greater generalization rather just slows training can regularization used reduce minimum validation loss improve model generalization opposed just delaying regularization delaying minimum validation loss reducing use generalizing single tutorial plot arguably good idea relevant plot original dropout paper clearly effect dropout delay convergence much use course work always plot clearly suggests hence used default arguably lesson like can get accuracy like training code single prediction code file structures like test set training set training set structure also test set update clarified comments looking probabilities class given one single test sample therefore can use predict method however note must first preprocess image way done training phase result probability given image belonging class one generator test data can use evaluate generator get loss accuracy metric set model test data example right fitting model can use evaluate generator test data generator way reload weights certain epoch best weights model checkpoint files created modelcheckpoint training trained trained epochs created checkpoint saved weights epoch final epochval categorical accuracy bit lower epoch know set save best true missed options thanks help advance implementation filepath doesncontain formatting options like epoch filepath will overwritten new better model casecanget weight specific epochg epoch option however choose formatting option modelcheckpoint callback training time will save model weightformat epoch different convenient way additionally choose save best true will save best weights way code example one end end working example reference will save model weights epoch convenient way formatting option will define filepath parameter follows will save model weight epoch will find every weight local disk however note used save best false set true get best weight way something like following datastored numpy array array much larger gets fed neural networkbinary ones zeroes means will ride taxi will ride taxi question stems sigmoid activation layer performs binary classification probability outputs expectings eventually assuming probability outputs created following much confusion lies binary classification neural network handle one gets pass input prediction binary classifier sigmoid activation last layer will give matrices row represents probability inputs class case score represents possibility sampletest class point order get class labels default api uses threshold consider score belong class class specifically score greater considered class course can tweak threshold one dummy example probabilities class labelsiworking binary classification problem situation used logistic regression support vector machine model imported sklearn two models fit imbalanced training data class weights adjusted achieved comparable performances used two pre trained models predict new datasetmodel svm models predicted similar number instances positives predicted instances share big overlap however looked probability scores classified positives distributionsvm starts around called function prediction data find instances predicted class function prediction data give probability scores classified neg pos assume default threshold error code idea svm predicted instances probability scores positives thoughts interpret situationknown fact sklearn comes binary classification problems svc reported instance github issues moreover also reported user guide said addition probability estimates may inconsistent scores argmax scores may argmax probabilities binary classification sample may labeled predict belonging positive class even output predict proba less similarly labeled negative even output predict proba directly within libsvm faq said letjust consider two class classification probability information obtained training prob decision value point one side predictions based decision function values decision value computed new instance positive predicted class positive class viceversa side stated within one github issuesaxisinconsistency comes terms order always consistency binary classification problems need classifier whose predictions based output predict proba btwget considering calibrators likealso suggest post topic want special tokens always available first attempt give tokenizer feels hacky refs seems useful standard tokens solution provided didnwork since bos token still none see code entirely understandtrying accomplish notes might helpdocumentation showsthree special tokensunk pad can also seetokenizer class definition confident originalmodel trained special tokens bos mask cls running will show three tokens extra tokens reason want tokens like bos edit answer comments really think benefit reading linked documentation huggingface point pretrained model take advantage already doneuse bos cls way seem imagining maybe can get work imo makes sense adapt task want solveapproachsep token already available understandmodel masking sake ignoring loss implemented using attention mask hand want fill blank extra used indicate model predict missing token semi supervised pretraining done see section training documentation bos similartrained use bos token documentation noteuses pad token decoder start token generation without using generate make sure start pad tokenuse cls token want classification finetune new task find corresponding one done pretraining finetuning model generate word words correspond classifications want documentation build model inputs sequence pair sequence sequence classification tasks concatenating adding special tokens sequence following format think correct please correctwrong left comment doc inspired answers tokenization utils feedback always welcomed trying create simple cnn classify images mnist dataset model achieved acceptable accuracy noticed model trained images epoch cause can fixed optimizer adam loss sparse categorical crossentropy metrics accuracy train images train labels epochs screenshot model colab screenshot trained modelproblem training model trained batches images images imagescan use adaboost random forest base classifier searched internet didnfind anyone like following code try run takes lot time tried gridsearchcv addedclassifier adaboost parameters use accuracy increase wonder actually seen anyone absurd bad idea trying build ensemble adaboost consists ensemble base classifiers rfs essentially ensemble squared wonder high computation time even practical good theoretical reasons quoting answer execution time adaboost svm base classifier adaboost similar ensemble methods conceived using decision trees base classifiers specifically decision stumps good reason still today donspecify explicitly base classifier argument assumes value decisiontreeclassifier max depth dts suitable ensembling essentially unstable classifiers case svms hence latter expected offer much used base classifiers top svms computationally much expensive decision trees let alone decision stumps reason long processing times observed argument holds rfs unstable classifiers hence reason actually expect performance improvements using base classifiers boosting algorithms like adaboost short answerimpossible donknowanything wrong theory tried accuracy increased long answer tried typical datasetrowsreal valued features label list lengthcase matters embeddings nodes graph obtained deepwalk algorithm nodes categorized two classes trained classification models data using fold cross validation measured common evaluation metrics precision recall auc etc models used svm logistic regression random forest layer perceptron adaboost random forest classifiers last model adaboost random forest classifiers yielded best results auc compared multilayer perceptronrandom forestsure now runtime increased factor letsaystill minsconstraintthought firstlyusing cross validationprobably overfitting flying radar secondly ensemble learning methods random forest bagging method wheras adaboost boosting technique perhapsstill different enough combination make sense playing around bit bit microsofts ell library compiler deploy simple learning algorithm micro controller knowledge regarding embedded development better past problem following ell creates llvmfileheader file cntk machine learning model purec files far good now can usetell llc make assembler object file desired target arm cortexcase end header file modelassembler file modelobject file now want include model header precompiled model embedded project developing use bosch xdk ide basically eclipse way can include precompiled model code yes correctly include eclipse steps also thought making static library object file experience tries end successfully far thanks kind help make static library object file linker will simply extract object file link unnecessary step can add object file linker command line directly alternatively addsource file project default build rules identify assembly language file invoke assembler rather compiler large amount data form matrix already clustered usingmeans clustering matlabwant exact coordinates centroid cluster formed possible using formula anything else want find centroid cluster whenever new data arrives matrix can compute distance centroid find cluster new data will belong data heterogeneous difficult find average data trying write code printing centroid location automatically matlab use instead per documentation idxkmeans returnscluster centroid locationsp matrixcentroid simply evaluated average value points coordinates assigned cluster assignments point cluster can easily evaluate centroid letsay given clusterpoints assigned points can evaluate centroid cluster using obviously can run process loop depending data structure common evaluation method map calculated quotes mentioned zisserman paper evaluation results page first overlap criterion defined intersection union greater considered detection matching madeboxes predicted boxes using greedy approach detections output method assigned ground truth objects satisfying overlap criterion order ranked decreasing confidence output multiple detections object image considered false detections counted correct detection false detections hence predicted box either true positive false positive ground truth box true positive true negatives average precision computed averaging precision values precision recall curve recall range precise consider slightly correctedcurve curve pointr different curve pointrpr replacemaximumpoints still unclear doneboxes never detected even confidence means certain recall values precision recall curve will never reach makes average precision computation undefined edit short answer region recall unreachable precision drops one way explain assume threshold confidence approaches infinite number predicted bounding boxes light image precision immediately goes since finite numberboxes recall keeps growing flat curve reach map mean average precision use different field information retrieval reference multi class classification object detection settings calculate object detection calculate average precision class data based model predictions average precision related area precision recall curve class taking mean average individual class precision gives mean average precision calculate average precision see detection common way determine one object proposal right intersection union ioutakes set proposed object pixels set true object pixelscalculates commonly iou means hit otherwise fail class one can calculate map mean average precision note one wants better proposals one increase iou higher value perfect one can denote mapp iou map means map calculated multiple thresholds averaged edit detailed information see coco evaluation metrics think important part linking object detection can considered standard information retrieval problems exists least one excellent description average precision output object detection algorithm set proposed bounding boxes one confidence classification scores one score per class letignore classification scores now use confidence input threshold binary classification intuitively average precision aggregation choices threshold cut value wait order calculate precision need know box correct gets confusing difficult opposed typical information retrieval problems actually extra level classification canexact matching boxes need classify bounding box correct solution essentially hard coded classification box dimensions check sufficiently overlaps ground truth considered correct threshold part chosen common sense dataset working will likely define threshold correct bounding box datasets just set iou leave recommend manual iou calculationshard get feel strict iou actually now actually defined means correct can just use process information retrieval find mean average precision map just stratify proposed boxes based maximum classification scores associated boxes average take mean average precisionclasses tldr make distinction determining bounding box prediction correct extra level classification evaluating box confidence informs correct bounding box prediction completely analogous information retrieval case typical descriptions map will make senseworth noting area precision recall curve thing average precision essentially approximating area trapezoidal right hand rule approximating integrals definition map mean average precision object detection contests many categories detect evaluation model performed one specific category time eval resultcategory every category evaluated mean aps calculated final result model map intersection union iou measure based jaccard index evaluates overlap two bounding boxes requires ground truth bounding box predicted bounding box applying iou can tell detection valid true positive false positive iou given overlapping area predicted bounding box ground truth bounding box divided area union shape tensor integer values know two methods tensor canget shape values integer int values examplecreatedtensor need get number rows columns int can call reshape create tensor shape num rows num cols however method returns values dimension type int get shape list ints list complete call try tensor tensor num rows num cols can directly tensor tensor first dimension can inferred another way solve like will return int value dimension object compatible answer tensorflowcan get dimensions shape tensor integer values shown code method using method usingtensor can get number rows columns int using following code another simple solution use map follows converts dimension objects int later versions tested tensorflownumpy like way get shape tensor can use software algorithm software tools primarily used programmers believe question topic another stack exchange site can leave comment explain question may able answered closed years ago lstm network understanding lstms input gate output gate use tanh intuition behind just nonlinear transformation can change another activation function relu sigmoid specifically used gating function three gates forget lstm since outputs value can either let flow complete flow information throughout gates hand overcome vanishing gradient problem need function whose second derivative can sustain long range going zero tanh good function property good neuron unit bounded easily differentiable monotonic good convex optimization easy handle consider qualities believe can use relu place tanh function since good alternatives making choice activation functions must know advantages disadvantages choice others shortly describing activation functions advantages sigmoid mathematical expression sigmoidexpfirst order derivative sigmoidexpexpadvantages tanh mathematical expression tanhexpexpexpexpfirst order derivative tanhexpexpexpexptanhadvantages hard tanh mathematical expression hardtanhzzfirst order derivative hardtanhz otherwise advantages relu mathematical expression relumaxfirst order derivative reluz otherwise advantages leaky relu mathematical expression leakymaxk dotk first order derivative reluzotherwise advantages paper explains fun activation function may consider read lstms manage internal state vector whose values able increase decrease add output function sigmoid output always non negative values state increase output tanh can positive negative allowing increases decreases statetanh used determine candidate values get added internal state gru cousin lstm doesnsecond tanh sense second one necessary check diagrams explanations chris olahunderstanding lstm networks related question sigmoids used lstms also answered based possible outputs function gating achieved multiplying number zero onesigmoids output arenreally meaningful differences derivatives sigmoid tanh tanh just rescaled shifted sigmoid see richard socherneural tips tricks second derivatives relevantlike know sort rule thumb use based data input size since pretty small dataset samples probably safe using batch size pretty standard wonmake huge difference problem unlesstraining hundreds thousands millions observations answer questions batch size epochs general larger batch sizes result faster progress training donalways converge fast smaller batch sizes train slower can converge fasterdefinitely problem dependent general models improve epochs training pointstart plateau accuracy converge try something like plot number epochsaxisaccuracyaxissee levels type shape data images just tabular data important detail great answers everyone gave good inputs ideally sequence batch sizes used use keras perform non linear regression speech data speech files gives features rows text file row containing real valued numbers use batch size epoch train sequential model keras hidden layer epochs training converges quite low val loss used keras perform non linear regression market mix modelling got best results batch size epochs training sequential model keras hidden layers generally batch size good epochs unless large dataset case large dataset canbatch size epochsw mentioned figures worked fine havenseen answer looking made research article said paper trying batch sizes performance models standard deviation means batch size didnsignificant influence performance final word find post useful please vote comment took time share thanks keras can make use rule thumb batch size learning rates high correlation achieve good performance high learning rate study means small learning rate case usually high batch size dataset million records example learning rate default adam optimizer however also use cyclical learning rate scheduler changes value fitting another topic paper compared performance cnn using different batch sizes different learning rates according results can conclude learning rate batch size significant impact performance network high correlation learning rate batch size learning rates high large batch size performs better small learning rates recommend choosing small batch size low learning rate practical terms determine optimum batch size recommend trying smaller batch sizes first usually also keeping mind small batch sizes require small learning rates number batch sizes power take full advantage gpus processing subsequently possible increase batch size value till satisfactory results obtained depending upon validation loss stops improving much batch size difference sparse categorical crossentropy categorical crossentropy one loss used opposed example losses suitable linear regression simply consider classification problem categories classes case cce one hot target may model may predict probably right case scce target index may model may predict consider now classification problem classes many categorical models produce scce output save space lose lot information exampleexample index also close generally prefer cce output model reliability number situations use scce including response one hot encoding comments one hot encoding used category feature input select specific category encoding allows model train efficiently training weight product category categories except given one cce scce model output cce probability array category totally scce shows likely category totally scce technically one hot array just like hammer used door stop still hammer purpose different cce one hot also confused one fortunately excellent keras documentation came rescue loss function ultimately thing difference representation true labels use crossentropy loss function two label classes expect labels provided one hot representation use crossentropy loss function two label classes expect labels provided integers one good example sparse categorical cross entropy fasion mnist dataset tensorflow source code sparse categorical crossentropy defined categorical crossentropy integer targets tensorflow source code categorical crossentropy defined categorical cross entropy output tensor target tensor meaning integer targets target labels form integer list shows index class example sparse categorical crossentropy class class targets class classification problem list basically targets integer form order call sparse categorical crossentropy called sparse since target representation requires much less space one hot encoding example batchtargetsclasses needsk space represented one hot whereas batchtargetsclasses needsspace represented integer form categorical crossentropy class class targets class classification problem list basically targets one hot form order call categorical crossentropy representation targets difference results since calculating categoricalandrewcoursera gives following one line octave solution cocktail party problem given audio sources recorded two spatially separated microphones bottom slide source sam roweis yair weiss eero simoncelli bottom earlier slide audio clips courtesywon lee video professorsays might look unsupervised learning like ask complicated implement seems like order build application seems like audio processing write ton code maybe link bunchjava libraries process audio seems like really complicated program audio separating audio turns algorithm just heard can done just one line code shown right take researchers long time come line codesaying easy problem turns use right programming environment many learning algorithms will really short programs separated audio results played video lecture perfect opinion amazing anyone insight one line code performs particular anyone know reference explains workwon lee sam roweis yair weiss eero simoncelli respect one line code update demonstrate algorithmsensitivity microphone separation distance following simulation octave separates tones two spatially separated tone generators minutes execution laptop computer simulation generates following three figures illustrating two isolated tones correct frequencies however setting microphone separation distance zero dmic causes simulation instead generate following three figures illustrating simulation isolate second tone confirmed single significant diagonal term returned svds matrix hoping microphone separation distance smartphone large enough produce good results setting microphone separation distance inches dmic meters causes simulation generate following less encouraging figures illustrating higher frequency components first isolated tone trying figure years later got answers hopefullyhelp someone need audio recordings can get audio examples roweiscodet original voice one channel microphonerepmat sumx sizexestimation power spectrumt althoughx intervals rows columns row represents time signal column frequency guess estimation simplification strict expression called spectrogram singular value decomposition spectrogram used factorize signal different components based spectrum information diagonal valuesmagnitude different spectrum components rowscolumnsorthogonal vectors map frequency component corresponding magnitudespace donvoice data test understanding means svd components fall similar orthogonal vectors hopefully clustered help unsupervised learning say first diagonal magnitudesclustereds newwill form one person voicenewexcept elements end end eliminated two articles sound formed matrix svd noticed something training models training set example around selected support vectors looked everywhere find good thing bad mean relation number support vectors classifiers performance read previous post performing parameter selection also sure attributes feature vectors ordered just need know relation thankss use linear kernel support vector machines optimization problem attempting find hyperplane divides two classes largest margin support vectors points fall within margineasiest understand build simple complex hard margin linear svm training set data linearly separable using hard margin slack allowed support vectors points lie along supporting hyperplanes hyperplanes parallel dividing hyperplane edges margin support vectors lie exactly margin regardless number dimensions size data set number support vectors little soft margin linear svm dataset isnlinearly separable introduce soft margin svm longer require datapoints lie outside margin allow amount stray line margin use slack parametercontrolnu svm giveswider margin greater error training dataset improves generalization allowsfind linear separation data linearly separable now number support vectors depends much slack allow distribution data allow large amount slack will large number support vectors allow little slack will support vectors accuracy depends finding right level slack data analyzed data will possible get high level accuracy must simply find best fit can non linear svm bringsnon linear svm still trying linearly divide data now trying higher dimensional space done via kernel function course set parameters translate back original feature space result non linear now number support vectors still depends much slack allow also depends complexity model twist turn final model input space requires one support vectors define ultimately output svm support vectors alpha essence defining much influence specific support vector final decision accuracy depends trade high complexity model may fit data large margin will incorrectly classify training data interest better generalization number support vectors can range every single data point completely fit data tradeoff controlled viachoice kernel kernel parameters assume said performance referring accuracy thought also speak performance terms computational complexity order test data point using svm model need compute dot product support vector test point therefore computational complexity model linear number support vectors fewer support vectors means faster classification test points good resource tutorial support vector machines pattern recognition basically tells svm needs use almost every single training sample encode training set basically tells isnmuch regularity data sounds like major issues enough training data also maybe think specific features separate data better number samples number attributes may influence number support vectors making model complex believe use words even ngrams attributes quite many natural language models complex support vectors samples seemalso pay attention karenucommentsnu parameters also large effect svs number get intuition recall svm main idea svm works multidimensional feature space tries find hyperplane separates given samples lot samples features dimensions data hyperplane may look like support vectors others behind thus donplay role note support vectors defined coordinates now imagine dimensional space thus support vectors defined coordinates meansone parameter coordinate adjusted adjustment may need samples find optimal hyperplane words worst case svm finds hyperplane coordinate per sample data structured several support vectors may needed others will stay behind text bad structured data svm best trying fit sample possible thus takes support vectors even samples drops increasing number samples anomaly reduced insignificant samples appear absolute number support vectors stays high svm classification linear number support vectors svs number svs worst case equal number training samples yet worst casestill pretty bad training documents small training set check happens scaledocuments things donimprove consider using linear svms trained liblinear document classification scale much better model size classification time linear number features independent number training samples confusion sources textbook islred instancedescribed boundary violation budget follows higherwill allow boundary violations support vectors svm implementationspython parameterimplemented violation penalty opposite will observe higher valuesfewer support necessarily better use hard margin svm soft margin svm expect soft margin svm better even training dataset linearly separable reason hard margin svm single outlier can determine boundary makes classifier overly sensitive noise data diagram single red outlier essentially determines boundary hallmark overfitting get sense soft margin svmbetter look dual formulation can see margin maximizing objective margin negative hard margin svm additional constraint lagrange multiplier associated support vector boundedessentially bounds influence single point decision boundary derivation see proposition cristianini shaw taylorintroduction support vector machines kernel based learning methods result soft margin svm choose decision boundary non zero training error even dataset linearly separable less likely overfitexample using libsvm synthetic problem circled points show support vectors can see decreasingcauses classifier sacrifice linear separability order gain stability sense influence single datapoint now boundedmeaning support vectors hard margin svm support vectors points margin picturepretty close hard margin svm can see circled points ones will touch margin margin almost pictureessentially separating hyperplane soft margin svmeaser explain terms dual variables support vector predictor terms dual variables following function alphasparameters found training proceduress training setnew datapoint support vectors datapoints training set included predictorones non zero alpha parameter opinion hard margin svm overfits particular dataset thus can generalize even linearly separable dataset shown diagram outliers within boundaries can influence margin soft margin svm versatility control choosing support vectors tweakingapplying transfer learning pre trained network using gpu version keras donunderstand define parameters max queue size workers use multiprocessing change parameters primarily speed learning unsure whether data still seen per epoch max queue size maximum size internal training queue used precache samples generator question refer many batches prepared cpu related workers define optimally workers number threads generating batches parallel batches computed parallel cpu passed fly onto gpu neural network computations question find many batches cpu can generate parallel use multiprocessing whether use process based threading question set parameter true change workers relate cpu usage related questions can found worker mean fit generator keras parameter maxsize used detailed example use data generators keras using fit generator follows specs machinequestion refer many batches prepared cpu related workers define optimally link posted can learn cpu keeps creating batches queue maximum queue size reaches stop want batches ready gpu take gpu doesnwait cpu ideal value queue size make large enough gpu always running near maximum never wait cpu prepare new batchesquestion find many batches cpu can generate parallel see gpu idling waiting batches try increase amount workers perhaps also queue sizeset parameter true change workers relate cpu usage practical analysis happens set true false recommendation set false prevent freezing setup true works fine without freezing perhaps someone else can increase understanding topic try sequential setup try enable cpu provide enough data gpu also create several questions next time easier answer mean mean resource allocation issues running titancudagpu tensorflow multiple memory allocators memory will used different ways behavior adaptive aspects particular case sinceusing gpu poolallocator cpu memory pre registered gpu fast dma tensor expected transferred cpu gpu will allocated pool poolallocators attempt amortize cost calling expensive underlying allocator keeping around pool allocated freed chunks eligible immediate reuse default behavior grow slowly eviction rate drops constant eviction rate proportion free calls return unused chunk pool underlying pool order exceed size limit log messages see raising pool size limit lines show pool size growing assuming program actually steady state behavior maximum size collection chunks needs pool will grow accommodate grow behaves way rather simply retaining chunks ever allocated sizes needed rarely program startup less likely retained pool messages cause concern run memory case log messages may help diagnose problem note also peak execution speed may attained memory pools grown proper sizedr oom try reducing size network training fewer models simultaneously play around batch size etcauc scores different cases model precision recallauc model precision recallauc main motive problem predict positive cases correctlyreduce false negative casesusescore choose model use auc choose model thanks rule thumb every time want compare roc aucf score think comparing model performance based note sensitivity recall exact metric now need understand specificity precision recall sensitivity intuitively specificity given following formula intuitively speaking specific model means miss true negative words false positives yet risk lot false negatives precision given following formula intuitively speaking precise model means catch true positive false positive recall given following formula intuitively speaking recall model means miss true positive words false negatives yet risk lot false positives can see three concepts close rule thumb cost false negative high want increase model sensitivity recall exact regard formula instance fraud detection sick patient detection donwant label predict fraudulent transaction true positive non fraudulent false negative also donwant label predict contagious sick patient true positive sick false negative consequences will worse false positive incorrectly labeling harmless transaction fraudulent non contagious patient contagious hand cost false positive high want increase model specificity precision instance email spam detection donwant label predict non spam email true negative spam false positive hand failing label spam email spam false negative less costlygiven following formulascore keeps balance precision recall use uneven class distribution precision recall may give misleading results usescore comparison indicator precision recall numbers compares sensitivityspecificity words compare true positive ratefalse positive rate bigger auroc greater distinction true positives true negatives general roc many different levels thresholds thus manyscore valuesscore applicable particular point roc curve may think measure precision recall particular threshold value whereas auc area roc curvescore high precision recall high consequently data imbalance positive negative samples always usescore roc averages possible thresholds read credit card fraud handling highly imbalance classes receiver operating characteristics curve roc curve used precision recall curve preferred highly imbalanced situations look definitions can aucscore optimize something together fraction sample labeled positive actually true positive something difference becomes important highly unbalanced skewed classes example many true negatives true positives suppose looking data general population find people rare disease far people negative positive trying optimize positive negative samples simultaneously using auc optimal want positive sample include positives possible donwant huge due high false positive rate case usescore conversely classes make dataset make sizable fraction care performance identifying class equally use auc optimizes classes positive negative just adding cents auc implicit weighting sampleslast use case comparing effectiveness drugs patientseasy learn drugs generally strong weak big question whether can hit outliers positives weak drug negatives strong drug answer specifically weigh outliers usingdonneed auc predict positive cases correctly one can rewrite bit goal get case really positive want classify positive probability eventpredicted label positive true label positive recall definition want maximize property modelchoose model july question years old still onedeeply interested time since machine learning rnncnngans etc new approaches cheap gpurisen enable new approaches thought fun revisit question see new approaches learning programming python algorithms trying work project find interesting created basic python scriptssure approach solution game trying buildgame will work users will given items value example will get chance choose combo like pears one orange output computer gets total value examplecurrently computer will try guess obviously wonable get correctly first turn next turn user can modify numbers total quantity percent may choseuse example prices fruit can change random total value may change based also simplicity changing fruit prices example using example day game user returns value dayexample hope tables show right manually space hopefullyjust screen doesnwork let knowtry upload screenshot trying see can figure quantities time assuming user will patience keep entering numbers know right now restriction total value within accuracy right now user will entering forever done farsolution far much basically take values figure possible combinations done part take possible combos put database dictionary example dictionary entry apple pears oranges apple pears oranges time get new number list possibilitiesm stuck using rules can figure best possible solution thinkneed fitness function automatically compares two days data removes possibilities variance previous days data questions question user changing total list probabilities approach need learn algorithms theories can use applicable help understand mistake can suggest rules can add make goal feasiblecurrent state thinking adding fruits saying must pick least etc also vague understanding genetic algorithms thought use something can useeager learn advice tips greatly appreciated just please dontell game impossible update getting feedback hard solve thoughtadd another condition game woninterfere player game stays everyday value fruits change price randomly make easier solve within movement certain fruit value changes combinations probable time day anything possible getting close enough range almost impossible prices fruits change user can choose change shouldntime range narrow narrow example prices volatile enough think brute force solution gave range guesstrying figureelegant solution solutions keep narrowing range time update reading asking around believe hidden markov viterbi problem tracks changes fruit prices total sum weighting last data point heaviestsure apply relationship though think case wrong leaststarting suspect type machine learning problem update created test case smaller numbers generator help automate user generated data trying create graph seelikelycode along total values comments users actually fruit quantitiescombine graph theory probabilityday build set feasible solutions denote solutions setsecond day can build solutions set now elementneed check can reached element giventolerance connectm canreached nodecan delete node basically building connected directed acyclic graph paths graph equally likely can find exact solution single edge node node sure nodes appear paths nodes probability node can directly deduced based number paths contains node assigning weight node equals number paths leads node need keep history previous day also look non negative values linear diphantine equations question asked ago accepted answer great way enumarte combos step disclaimer changed answer dramatically temporarily deleting answerreading question carefully misread critical parts question still referencing similar topics algorithms answer greatly improved attempted solve problemfirst like state see two main problems sheer number possible solutions knowing number items total value say example will yield lot possible solutions plus easy algorithm picking valid solution without inevitably trying invalid solutions total equal possible solutions found given dayone must find way eliminate potential solutions added information givendiletlay bases upcoming examples order solve easily took liberty change one constraint makes algorithm converge faster rule enablesrule solutions easily non tiny ranges renders backtracking algorithms still useless just like original problem rules humble opinion rule essence game facilitator enabling computer solve problem starters problem can solved using monte carlo algorithm find set potential solutions technique simple generate random numbers item values quantities within respective accepted range repeat process required number items verify whether solution acceptable means verifying items distinct values total equal target total say technique advantage easy implement drawbacks get around drawback less useful monte carlo algorithm since will enough valid solutions iterate reasonable time constraints around valid solutions constrained target total value monte carlo usable around need use monte carlo brute force loops will just fine believe problem call constraint satisfaction problem csp given fact problem cspahead call problem problem general dynamic csp dcsp dcsps useful original formulation problem altered way typically set constraints consider evolves environment dcsps viewed sequence static csps one transformation previous one variables constraints can added restriction removed relaxation one technique used csps might useful problem called constraint recording work need get new set possible solutions every day use either brute force monte carlo compare solutionsdi keep solutions can succeed previous days solutions without violating constraints will probably keep history solutions lead solutions probably directed graph constraint recording enables remember possible add remove quantities rejects solutions based lot steps taken improve solution ideas given try figure ranking system based occurrence solutions heuristics determine candidate solution problem impossible solve letsay know exactly ratio number items increased just maximum ratio userfruitsdays guessing day getnew variables totaln variables day can generate two equations one equation sumitem price based known ratio totalequations independentnn wrote program play game course automate human side believe way shouldninvalidate approach played real human approached machine learning perspective treated problem hidden markov model total price observation solution use particle filter solution written python using numpy scipy stated assumptions made either explicitly comments implicitly code also set additional constraints sake getting code run automated fashionparticularly optimized tried err side comprehensibility rather speed iteration outputs current true quantities guess just pipe output file can review easily interesting extension plot output graph eitherfruitsfruits able see particle filter hone solution update edited code include updated parameters tweaking included plotting calls using matplotlib via pylab plotting works linux gnome mileage may vary defaulted num fruits plotting support just comment pylab calls remove plotting able change num fruits anything good job estimating current fxn represented unknownquantitiesprices totalpricefruits linefruitsplane seems little data particle filter reliably hone correct quantities need little smarts top particle filter really bring together historical information try converting particle filterrd order updateplaying around code lot tried bunch things now present final programmaking starting burn idea changes particles now use floating points rather integers sure meaningful effect general solution rounding integers done making guess plotting shows true quantities green square current guess red square currently believed particles shown blue dots sized much believe makes really easy see algorithm working plotting also tested working win bit added parameters turning quantity changing price changing course interesting pretty dang good job notedreally tough problem getting exact answer hard turning change quantities produces simplest case can get appreciation difficulty problem running fruits change quantities see quickly hones correct answer see harder increase number fruit can also get perspective difficulty keeping change quantities adjusting max quantity change small values large values one situation struggles dimension one fruit quantity gets close zerousing average particles guess will always skew away hard boundary like zero general makes great particle filter tutorial initial rules school years say make abstraction changes everyday equation three unknown values sorry donknow maths vocabulary english values previous day day three equations three unknown values solution direct guess change day may forgotten values three elements different enough said will use approximations round numbers adapted rules many unknowns changing values case direct solution know trust lior approach looks fine limited range prices quantities realized answer getting quite lengthy moved code top probably people interested two things interested either topic please see rest code code finds possible solutions explain answer problem determined average case many possible solutions number grows least exponentially number days increases true original extended problem nevertheless can sort efficiently find solutionsnp hard donexpect much backtrackingexactly modern algorithm choice python can write recursive generator actually quite elegant approach essentially structures possible candidates large tree performs depth first search pruning whenever constraint violated whenever leaf node encountered yield result tree search general can parallelized scope will make solution less readable without much additional insight goes reducing constant overhead code working constraints continue iterator bounds variable less checks put full code example including simulator human side game bottom answer modern machine learning problem question years old still onedeeply interested time since machine learning rnncnngans etc new approaches cheap gpurisen enable new approaches thought fun revisit question see new approaches really like enthusiasm world deep neural networks unfortunately simply apply reasons game can uniquely solved part letconsider substitute problem first lift integer requirement basket human choicefruits given day can fractional fruits oranges total value constraint basket daily price total value limits possible solutions basket reduces problem one dimension freely pick amountsfruits can always find valueth fruit satisfy constraint seemschoices make day actuallycan make freely last one will fully determined previous choices day game goes need estimate additionalchoices variables might want enforce choices greater reduces interval can choose number open interval real numbers infinitely many numbers will never run options stillchoices make two days total basket volume basket changes percent previous day previous basket basket percent previous basket choices make given day will change basket percent previous day make sure never violate can freely makechoices pickth variable adding addingvariable fixed previous choices stays within percent note inequality constraint will reduce number choices equality basket changes exactly percent optimization theory known constraint active can think constraint choices greater argument remains simply changes interval can now freely choosevariablesdays leftchoices estimate first day change constraintn choices estimate following day unfortunately ran constraints reduce number number unknowns grows leastday essentially luka rahne meantnn will likely find many candidates equally probable exact food prices day donmatter long value will constrain one choices hence extend game way specify always chance infinitely many solutions regardless number days game can still uniquely solved part one constraint didnlook might help fix allow integer solutions choices problem integer constraints complex deal however main concern adding constraint will allowuniquely solve problem given enough days rather intuitive counter example suppose consecutive daysd day total value constraint allows one basket words know basket day day day knowtotal value within percent day day within percent day enough information always work basket day one example know values two days thanks total value constraint still wonallowwork exact composition basket day thus may possible work cases possible general adding days day doesnhelp figuring day might help narrowing options day will narrow options day already just choice left dayuse full code player selects combination will reduce number possibilities computer will win otherwise player can pick combination constraint total varying within certain percentage computer may neverallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago looking open source neural network library far looked fann weka opennn others look criteria course documentation examples ease use last update will update answer time neural networks quite popular research industry moment deep learning many research libraries available kind easy set integrate use although easy libraries mentioned provide leading edge functionality high performance gpus etc libraries also automatic differentiation can easily specify new architectures loss functions etc donspecify backpropagation manually performance comparison gpu accelerated libraries can found bit outdated unfortunately comparison gpus library versions can found inactive want flexibility defining network configurations like sharing parameters creating different types convolutional architectures look family torch librariesgone documentation torch yet documentation versions pretty decent code readable luacan use parallel resilient backpropagation nguyen widrow initialization algorithm deep belief networks restrictured boltzmann machines many neural network related items netlab commonly used matlab library free open source netlab toolbox designed provide central tools necessary simulation theoretically founded neural network algorithms related models use teaching research applications development extensively used msc research mathematics complex systems netlab library includes software implementations wide range data analysis techniques many yet available standard neural network simulation packages netlab works matlab version higher needs core matlab toolboxes required compatible earlier versions matlab number classes corresponding feature vectors run predict proba will get like get probability corresponds class page says ordered arithmetical ordersure means command like one two three just use classes attribute classifier recover mapping example gives thanks putting minimalistic reproduction script question makes answering really easy just copy pasting ipython rule attribute learner ends learned one caselooking can use dir function find attributes object queries source code way encode variable length data fixed length inputs still get generalization properties neural networks faced problem ann made fixed feature vector length many classifiers knn svm bayesian etc design problem however researchers opt adding zeros fill missing gap personally think good solution zeros unreal values will affect weights net will converge addition might real signal ending zeros ann classifier even better random forest classifier considered best among researchers uses small number random features creating hundreds decision trees using bootstrapping bagging might work number chosen features normally sqrt feature vector size features random decision tree converges solution using majority rules likely class will chosen another solution use dynamic time warping dtw even better use hidden markov models hmm another solution interpolation interpolate compensate missing values along small signal small signals size max signal interpolation methods include limited averagingspline distinctive time make fixed size method include pca lda etc another solution use feature selection normally feature extraction easy way select best features give best accuracynow non worked please contact usually extract features data feed network advisable take just data feed net practice pre processing choosing right features will decide success performance neural net unfortunately imho takes experience develop sensenothing one can learn book summing garbage garbage problems solved recurrent neural network example good calculating parity sequence inputs recurrent neural network calculating parity just one input feature bits fed time output also fed back hidden layer allows learn parity just two hidden units normal feed forward two layer neural network require sequence length hidden units represent parity limitation holds architecture just layers svm guess one way add temporal component input recurrent neural net stream input net chunk time basically creating neural network equivalent lexer parser allow input quite large disadvantage necessarily stop symbol seperate different sequences input equivalent period sentances use neural net images different sizes images often cropped scaled better fit input network know doesnreally answer question perhaps something similar possible types input using sort transformation function inputentirely suresay use maximum number inputs say word will longer characters longest word found dictionary according wikipedia shorter word encountered set inputs whitespace character binary data set problem approach input filled whitespace characters zeros whatever collides valid full length input much problem words numbersreading build ann pybrain say train network epochs usually set something like looked mean conclude use epoch data update weights choose train data epochs pybrain advice dataset will divided subsets wights will update times maximumfamiliar online training wights updated sample data feature vector question sure epochs will enough build model setting weights probably advantage way online training also term epoch used online training mean one feature vector one epoch consists one full training cycle training set every sample set seen start marking beginningepoch nothing batch online training perbatch means update end epoch every sample seen epoch updates online update sample samples epoch updates cansure epochs enough convergence since will vary data data can stop training error converges gets lower certain threshold also goes territory preventing overfitting can read early stopping cross validation regarding sorry reactivating thread new neural nets investigating impact mini batch training far understand epoch rundosrun saying use trainingset dataset dataset trainingset validationset mini batch training can sub divide trainingset small sets update weights inside epoch hopefully make network converge faster definitions neural networks outdated guess must redefined number epochs hyperparameter defines number times learning algorithm will work entire training dataset one epoch means sample training dataset opportunity update internal model parameters using regularization strength regularization applying penalty increasing magnitude parameter values order reduce overfitting train model logistic regression model choosing parameters give best fit data means minimizing error model predicts dependent variable given data compared dependent variable actually problem comes lot parameters lot independent variables much data case model will often tailor parameter values idiosyncrasies data means fits data almost perfectly however idiosyncrasies donappear future data see model predicts poorly solve minimizing error already discussed add minimized also minimize function penalizes large values parameters often functionconstant times sum squared parameter valueslarger less likely parameters will increased magnitude simply adjust small perturbations data case however rather specifying specifysave model keras differences output files saved file larger model significantly larger json yaml model architecture file restating size size something size size something efficient just load just load model differences save saves weights model structure single hdf file believe also includes things like optimizer state can use hdf file load reconstruct whole model including weights save weights saves weights hdf nothing else need extra code reconstruct model json file just add modelcheckpointoutputrelevant anyone else used callback model training can either save whole model just weights depending state save weights argument set true weights saved akin calling false default whole model saved calling adding answers model can saved formats using tensorflow savedmodel format older kerasformat recommended format savedmodel default called savehdf format use model save formatshape mean stddev dtype seed none name none outputs random values normal distribution shape mean stddev dtype seed none name none outputs random values truncated normal distribution tried googling truncated normal distribution didnunderstand much documentation says truncated normal distribution values drawn normal distribution specified mean standard deviation discardingdrawing samples two standard deviations mean probably easy understand difference plotting graph magic use jupyter notebook now point using truncated normal overcome saturation tome functions like sigmoid value big small neuron stops learning selects random numbers normal distribution whose mean close values close examplecalled truncated cutting tails normal distribution selects random numbers normal distribution whose mean close values can bit apart example machine learning practice usually want weights close api documentation describes function outputs random values truncated normal distribution generated values follow normal distribution specified mean standard deviation except values whose magnitude standard deviations mean droppedpickedtrying get agent learn mouse movements necessary best perform task reinforcement learning settinghoping uselearning techniquefound way extend method continuous state spaces canseem figure accommodate problem continuous action space just force mouse movement certain magnitude certain number different directions reasonable way making actions discrete yield huge action space since standardlearning requires agent evaluate possible actions approximation doesnsolve problem practical sense common way dealing problem actor critic methods naturally extend continuous action spaces basiclearning diverge working approximations however still want use can try combining self organizing map done applications self organising map reinforcement learning paper also contains references might find useful fast forward year folks deepmind proposes deep reinforcement learning actor critic method dealing continuous state action space based technique called deterministic policy gradient see paper continuous control deep reinforcement learning implementations numerous ways extend reinforcement learning continuous actions one way use actor critic methods another way use policy gradient methods rather extensive explanation different methods can found following paper available online reinforcement learning continuous state action spaces hado van hasselt marco wieringdonbelieve need work continuous action spaces although physical mouse moves continuous space internally cursor moves discrete steps usually pixel levels getting precision threshold seems like woneffect agentperformance state space still quite large finite discrete know post somewhat old variantlearning applied continuous action spaces proposed alternative actor critic methods called normalized advantage functions nafpaper continuous deeplearning model based acceleration another paper make list value based school input convex neural networks idea requires convex actions necessarily states solving argmaxinference reduced finding global optimum using convexity much faster exhaustive sweep easier implement value based approaches yet likely expense reduced representation power usual feedforward convolutional neural networkstrying evaluate multiple machine learning algorithms sklearn couple metrics accuracy recall precision maybe understood documentation source codeusing sklearn cross val score function receives one scorer execution calculating multiple scores implement time consuming error prone scorerexecuted multiple times code get outputs slow data can measure scores since time writing post scikit learn updated made answer obsolete see much cleaner solution can write scoring function capture three pieces information however scoring function cross validation must return single number scikit learn likely compatibility reasons example scores cross validation slice prints console returned value just sum three metrics want return valuesgoing make changes cross val score line cross score line file gives scikit learn solution becomes much easier gives ran problem created module can support multiple metrics cross val score order accomplish want module can write can check download module github hope helps want perform gridsearchcv svc model uses onestrategy latter part can just problem parameters letsay want try following values order perform gridsearchcv something like however execute get basically since svc inside onevsrestclassifierestimator send gridsearchcv svcparameters canaccessed order accomplish want see two solutionsyet find way mentioned alternatives knowway maybe suggest another way get result thanks use nested estimators grid search can scope parameters separator case svc model stored attribute named estimator inside onevsrestclassifier model yields python following code usedi know principal component analysis svd matrix generates eigen value matrix select principal components take first eigen values now decide number eigen values take eigen value matrix decide many eigenvalues eigenvectors keep consider reason pca first place reducing storage requirements reduce dimensionality classification algorithm reason donstrict constraints recommend plotting cumulative sum eigenvalues assuming descending order divide value total sum eigenvalues prior plotting plot will show fraction total variance retainednumber eigenvalues plot will provide good indication hit point diminishing returns little variance gained retaining additional eigenvalues correct answer somewherethink principal component street town never visited many streets take get know town obviously visit main street first component maybe big streets need visit every street know town enough probably know town perfectly visit streets visit say streets understanding town good enough basically select enough components explain enough variance comfortable others said doesnhurt plot explained variance use pca preprocessing step supervised learning task cross validate whole data processing pipeline treat number pca dimension hyperparameter select using grid search final supervised score cross validated grid search whole dataset costly try sub samples data second see come optimal value pca dimensions number heuristics use total variance however high dimensionality heuristics usually good depending situation may interesting define maximal allowed relative error projecting data ndim dimensions matlab example will illustrate small matlab example just skip code interested will first generate random matrixsamples rowsfeatures containing exactly non zero principal components image will look similar sample image one can calculate relative error made projecting input data ndim dimensions follows plotting relative error function number dimensions principal components results following graph based graph can decide many principal components need take account theoretical image taking components result exact image representation taking elements useless want example maximum error take principal components disclaimer obtained values valid artificial data use proposed values blindly situation perform analysis make trade error make number components need code reference highly recommend following paper gavish donoho optimal hard threshold singular values sqrt posted longer summary crossvalidated briefly obtain optimal procedure limit large matrices procedure simple require hand tuned parameters seems work practice nice code supplementseem many options deploying predictive models production surprising given explosion big data understand open source pmml can used export models xml specification can used database scoring prediction however seems make work need use pmml plugin zementis means solution truly open source easier open way map pmml sql scoring another option use json instead xml output model predictions casemodel sitassuming always need mapped options following list alternatives found far deploymodel production please note workflow use products varies significantly somehow oriented facilitate process exposing trainedmodel service answer really depends production environment big data hadoop can try relatively new open source pmml scoring engine called pattern otherwise choice short writing custom model specific code runserver use save save fitted models rdata files load run corresponding predict server bound slow can always try throw hardware really depends platform usually way add custom functions writtenterm udf user defined function hadoop can add functions pig can use rhadoop write simple map reduce code load model call predictdata hive can use hive transform call externalscript also vendor specific ways add functions writtenvarious sql databases look udf documentation instance postgresqlr can create restful apisscripts using plumber wrote blog post using deploying credit models example general recommend pmml packages used might support translation pmml common practice scoring new updated datasetmoving results ids scores probabilities necessary fields production environment data warehouse know limitations infrequent refreshes reliance upon data set size computing power restrictions may cutting edge answer many bosses looking many use cases works cost friendlyyears since question originally asked rapid prototyping argue easiest approach currently use jupyter kernel gateway allows add rest endpoints cell jupyter notebook workspython depending kernelusing means can easily callpython code web interface used conjunction docker lends microservices approach deploying scaling applicationarticle takes start finish quickly set jupyter notebook jupyter kernel gateway learn build machine learning services prototype real applications deploy work users moving solutions production leading approach use kubeflow kubeflow created maintained google makes scaling machine learningmodels deploying production simple possible website adapt configuration choose platforms services want use stageworkflow data preparation model training prediction serving service management can choose deploy workloads locally cloud environment elise yhat like ramnath leomentioned software allows putpython matter model directly production via rest api endpoints handle real time batch model testing versioning systems management associated process case studyauthored via sms might usefulthinking getmodels production data sci team recoding php prior using yhat cheers questions askingrecommend find tool library favorite site resource topic stack overflow tend attract opinionated answers spam instead describe problem done far solve closed years ago assume know student wants study machine learning natural language processing specific computer science subjects focus programming languages specifically designed solve types problems looking favorite subjects tools rather industry standards exampleguessing knowing prolog matlab might help also might want study discrete structures calculus statistics graphs trees functions properties recursive definitions solving recurrences relations properties equivalence partial order proof techniques inductive proof counting techniques discrete probability logic propositional calculus first order predicate calculus formal reasoning natural deduction resolution applications program correctness automatic reasoning introduction algebraic structures computing related stackoverflow question nice answers good starting points someone interested natural language processing big field prerequisites mostly consist probability statistics linear algebra basic computer science although natural language processing requires intensive computer science background start frequently covering basicregarding specific langauges lisp created afterthoughtresearch prologroots formal logic especially aimed natural language processing many courses will use prolog scheme matlabanother functional language suited kind analysis specific pointers machine learning stanfordmachine learning great includes everything including full videos lectures also itunes course notes problem sets etc taught andrewnote prerequisites students expected following background knowledge basic computer science principles skills level sufficient write reasonably non trivial computer program familiarity basic probability theory familiarity basic linear algebra course uses matlab octave also recommends following readings although course notes complete natural language processing nlp group stanford provides many good resources introductory course stanfordnatural language processing includes lectures online following prerequisites adequate experience programming formal structures programming projects will written java knowledge java willingness learn required knowledge standard concepts artificial intelligence computational linguistics basic familiarity logic vector spaces probability recommended texts prerequisite computational linguistics course requires basic computer programming data structures knowledge uses text books required articificial intelligence course also available online along lecture notes uses standard artificial intelligence text also worth reading usemachine learning really recommend suggest looking elements statistical learning full text available online free may want refer machine learning natural language processing views cran specific functionality recommendation either depending amount area interest oxford handbook computational linguistics source foundations statistical natural language processing introduction information retrieval string algorithms including suffix trees calculus linear algebra varying varieties statistics artificial intelligence optimization algorithms data clustering depending intend doesnreally matter language choose operate python instance nltk pretty nice free package tinkering computational linguistics say probabily statistics important prerequisite especially gaussian mixture models gmms hidden markov models hmms important machine learning natural language processing course subjects may part course introductory say basicknowledge also helpful example algorithms formal languages basic complexity theory stanfordnatural language processing course mentioned already includes also videos online addition course materials videos arenlinked course website many people may notice jurafsky martinspeech language processingpublished alsodecent programmernever early toy around nlp programs nltk comes mind python book can read free online published oreilly think markdown introduction parsing expression grammars peg posted cletus site cforcoding antlr seems like good place start natural language processingexpert though broad question certainly think knowledge finite state automata hidden markov models useful requires knowledge statistical learning bayesian parameter estimation entropy latent semantic indexing commonly yet recently used tool many machine learning problems methods rather easy understand bunch potential basic projects edit nonnegative matrix factorization nmf tool grown considerably popularity due simplicity effectivenesseasy understand currently research use nmf music information retrieval nmf shown useful latent semantic indexing text corpora one paper pdf prolog will help academically also limited logic constraints semantic nlp based work prolog yet industry friendly language yet practical real world matlab also academic based tool unless lot scientific quants based work wouldnreally much need start might want pick norvig book enter worldget grounding areas understand basic probability statistics databasesdatastructures likely understanding experience programming language need able provetechniques work donlook specific areas like machine learning nlp detail fact norvig book sources references every chapter already lot reading available lot reference material available internet books journal papers guidance donjust read book try build tools programming language extrapolate meaningful results learning algorithm actually learn expected didncase fixed need classify data hope nearest neighbour algorithmgoogled problem found lot libraries including pyml mlpy orangeunsure startimplementingnn using python particularly given techniquenearest neighbors mentionedstrongly recommend note answer posted lead developer project informed new homepage project features believe distinguish library others least pythonlibraries used extensive diagnostics testing library including plotting modules via matplotlib includes feature selection algorithms confusion matrix roc precision recall etc nice selection batteries included data sets including handwriting digits facial images etc particularly suitedtechniques extensive documentation nice surprise given project two years old including tutorials step step example code use supplied data sets without exception least can think moment pythonlibraries superb see pymvpa homepage list dozen popular pythonlibraries past months instance used ffnet mlp neurolab also mlp pybrainlearning neurolab mlp pymvpa svm available python package index vary significantlyrmaturity scope supplied infrastructure found high quality still best might instance aware pythonlibrary though solid example code tutorials none know integrate library research grade data sets diagnostic algorithms second given technique intend usenearest neighbor returns score classification returns class label detailed sample code using literally couldneasierunlike nearlytechniques cruxnearest neighbors coding working classifier builder rather difficult step building production gradenearest neighbor classifier regressor persistence storage fast retrieval data points nearest neighbors selected knn data storage layer know almost nothing apparently superiortree traditional data structurenn performance doesndegrade higher dimensional features space additionallynearest neighbors requires appropriate similarity metric euclidean distance usual choice though always best one libraries mentioned either scope pyml bayesian primarily libraries developers rather applications end users orange unusual difficult install dependencies mlpy requires gsl turn must built source leastmacx note developer committer possible train model xgboost multiple continuous outputs multi regression objective train model thanks advance suggestions suggestion use xgboost happens support probably easiest way regress multi dimension targets using xgboost need change part code using sklearn api originally however method leverage possible relation targets can try design customized objective function achieve multiple output regression now available nightly build xgboost will included xgboost see reg linear now deprecated favor reg squarederror update answer based comeongetmeplace comment lack reputation addition jesse anderson install recent version select top link prefix master make sure select one operating system use pip install install wheel pip installdefb ede cefdnone macosxrandom forest regressors related algorithms scikit learn produce multi output regression sure xgboost boosting regressor scikit allow multiple outputs people asked may necessary one example forecast multi steps time series head based discussion extended univariate xgboostlss multivariate framework called multi target xgboostlss regression models multiple targets dependencies probabilistic regression setting code follows given code exactly evaluating need define model can multiple metrics one model importantly mechanics behind scientific reference also appreciated order understand metricsgood start understanding loss function neural networks mostly trained using gradient methods iterative process decreasing loss function loss designed two crucial properties first smaller value better model fits data second differentiable knowing fully define metricfunction given predicted values ground truth values examples provides scalar measure fitness model data may see loss function metric opposite doesnalways hold understand differences letlook common examples metrics usage measure performance network using non differentiable functions even continuous directly optimize network use order choose model best accuracy obtain values different loss functions final loss combination letassume loss regularization term measures weights differ term measures fitness model case use metrics order separate track fitness model changes across epochs track measure respect donwant directly optimize model letassume solving multidimensional regression problem mostly concerned mse time interested cosine distance solution changing timebest use metrics hope explanation presented made obvious metrics used use multiple metrics one model now letsay words mechanics usage keras two ways computing training using metrics defined compilation directly asked case keras defining separate tensor metric defined computed training usually makes computation faster comes cost additional compilations fact metrics defined terms nice can use callbacks order compute metrics callback default attribute model compute variety metrics using makes possible compute epoch wise also batch wise training wise comes cost slower computations complicated logic need define metrics can find list available metrics example define keras metrics page described metric function used judge performance model metrics frequently used early stopping callback terminate training avoid overfitting reference keras metrics documentation given documentation page keras metrics metric judges performance model metrics argument compile method holds list metrics needs evaluated model training testing phases metrics like binary accuracy categorical accuracy sparse categorical accuracy topcategorical accuracy sparse topcategorical accuracy available metric functions supplied metrics parameter model compiled metric functions customizable multiple metrics need evaluated passed form dictionary list one important resource refer diving deep metrics can found implementation point view losses metrics actually identical functions keras loss helps find best solution model can produce metric actually tellsgood imagine found regression line least minimum squared error good enough solution metric will answer considering shape spread data ideally difference standardscaler normalizer donthingremove mean scale using deviation normalizer docs sample least one non zero component rescaled independently samples norml equals one standardscaler standardize features removing mean scaling unit variance words normalizer acts row wise standardscaler column wise normalizer remove mean scale deviation scales whole row unit norm visualization article ben helps lot illustrating idea standardscaler assumes data normally distributed within feature removing mean scaling unit variance can see picture now scale regardless original one addition excellent suggestion vincentlcy view article now example scikit learn documentation important difference normalizer applied sample row rather column may work certain datasets fit assumption similar types data column standardscaler standardizes features features person dataheight weight removing mean scaling unit variance unit variance unit variance means standard deviation sample variance will tend towards sample size tends towards infinity normalizer rescales sample example rescaling companystock price independently stocks expensive others account normalize normalizer will separately transform companystock price relative scale main difference standard scalar applied columns normalizer applied rows make sure reshape data normalizing standardscaler standardizes features removing mean scaling unit variance normalizer rescales sample perhaps helpful example normalizer seems default operation divide data point row norm row example given row norm normalized row first row example sklearn docs building answer terrencej code manually calculate normalizer transformed result example first sklearn documentation note reflects defaultnormalizationexploring xgboost packagewent several demos tutorials still confuses using optimal parameters get passed calculate ideal parameters nround based output looks like misunderstood parameter searching functionfolds cross validation nothing code change value param find best parameterss xgboost methods methods use mlr package mlr example code kaggleprudential challenge code regression classification far know mlogloss metric yet mlr package must code mlogloss measurement scratch cmiiw second method manually setting parameters repeat example find best minimum mlogloss min logloss minimum value mlogloss min logloss index index round must repeat process several times time change parameters manually mlr repeat finally get best global minimum min logloss note can loop iterations iteration set parameters value randomly way must save best parameters list min logloss min logloss index variables file note better set random seed reproducible result different random seed yields different result must save parameters list min logloss min logloss index seednumber variables file say finally get results iterations repeats must use third parameters global minimum min logloss best index nrounds get best parameters use training donthink need watchlist training done cross validation still want use watchlist just okay even better can use early stopping mlogloss value decreasing steps expect minimum mlogloss example code iterations loop random chosen parameters code run cross validation times time random parameters get best parameter set iteration minimum min logloss increase valuesmall early stopping need also change random parameter values limit based data characteristics iterations think want change verbose false side note example random method can adjust good hyperparameter script xgboost want addmanual method posted davut polat kaggle master kaggle forum edit know python sklearn can also use gridsearchcv along found helpful someone new xgboost like thank method randomize compared boundary inspiring good use good know now slight revise needed example depends application linear logistic objective eval metric parameters shall adjusted accordingly convenience anyone running regression slightly adjusted version code found siloanswer helpful addition approach random research may want use bayesian optimization facilitate process hyperparameter search following code rbayesianoptimization shuffle training data donlose temporal ordering training data still effective making predictions trained shuffled training data general shuffle training data set sequences shuffle order sequences fed rnn donshuffle ordering within individual sequences fine network stateless stateless case networkmemory persists duration sequence training sequencesequence doesnmatter networkmemory state persist across sequences hand stateful case networkmemory persists across sequences blindly shuffle data expect optimal results sequence fed network sequencecomeswant network evaluate sequencememory sequence canget dtypes match either loss wants long model wants float change tensors long shape tensorssure can change dtypes required model losssure dataloader required using variable didnwork either gives longtensor synonymous integer pytorch wonaccept floattensor categorical targettelling cast tensor longtensor change target dtype documented pytorch website definitely wonregret spending minute two reading page pytorch essentially defines nine cpu tensor types nine gpu tensor types started using sckikit learn work going tutorial gives standard procedure load datasets however convenience tried loading data following way however throws following error however use apparently similar method works without problem fact following also works completely confused missing something trivial difference two approaches sklearn package answer said succinctly import package variables functions classes initfile package directly visible sub packages modules datasets sub package sklearn happens however reason works load sub package datasets sklearn import datasets automatically added namespace package sklearn one lesser known traps python import system also note look initsklearn will see datasets member allows one last point note inspect either sklearn datasets will see although packages type module packages considered modules however modules packagesfit pipeline object randomizedsearchcv want access coef attribute best estimatorunabletried accessing coef code sgd randomized pipeline object attribute coef scikit learn docs say coef attribute sgdclassifier class base estimator wrong can always use names assigned making pipeline using named steps dict access attributes like coef intercept etc available corresponding fitted estimator formal attribute exposed pipeline specified documentation named steps dict read attribute access step parameter user given name keys step names values steps parameters think workfound one way chained indexing steps coef best practice another way short scikit learn two ways access estimators chained together pipline either retrieved index retrieved name way two flavours firstly user guide sklearn points pipline built using list key value pairs key string containing name want give step value estimator object indicates pipline constructed one multiple estimator objects order just like list estimator object name either appointed user key automatically set finaly can access estimators pipline either hope play around piplines like skilled default value states feature axis typically normalized case suppose surprisingfamiliar using something like standardscaler equivalent using axis normalize features individually reason samples individually normalized default keras opposed features edit example concretenesscommon transform data feature zero mean unit variance letjust consider zero mean part mock dataset row sample wouldnmake sense subtract axis mean opposed axis mean using axis units scales can completely different edit first equation section paper seems imply axis used calculating expectations variances feature individually assumingn shaped datasetnumber samplesnumber features edit another example wanted see dimensions means variances batchnormalization calculating toy dataset inputshape batchnormalization layer calculated means means operated axis batchnormalization default axis shouldnmeans confusion due meaning axis collapse dimension preserve dimensions example axis collapses axis vertical dimension data compute batchnormalization along axis preserve dimensions array normalize respect mean standard deviation every axisexample batchnormalization axis subtracting mean axis just expect know post old still answering confusion still lingers keras documentationcode figure mini batch matrix mxn normalization axis axis said want normalize every feature individually default axis keras used convolution layer dimensions figures dataset usually samples width height channal batch samples normalized long channal axis last axisreading decision trees cross validation understand concepts howevertrouble understanding cross validation pertains decision trees essentially cross validation allows alternate training testing dataset relatively small maximize error estimation simple algorithm goes something like problem canfigure endk decision trees slightly different might split way etc tree pick one idea pick one minimal errors although doesnmake optimal just performed best fold given maybe using stratification will help everythingread say helps little bit understand cross validation point compute node statistics can later used pruning really node tree will statistics calculated based test set givenimportant node stats averaging error merge stats within node acrosstrees tree vary choose split etcpoint calculating overall error across iterationsomething used pruning help little wrinkle much appreciated problem canfigure endk decision trees slightly different might split way etc tree pick purpose cross validation help select particular instance classifier decision tree whatever automatic learning application rather qualify model deviation relative average etc can useful asserting level precision one can expect application one things cross validation can help assert whether training data big enough regards selecting particular tree instead run yet another training training data available typically will produce better tree downside cross validation approach need divide typically little amount training data folds hint question can lead trees either overfit underfit particular data instances case decision treesure reference statistics gathered node used prune tree pertains maybe particular use cross validation related techniques first part like others pointed usually use entire dataset building final model use cross validationget better estimate generalization error new unseen data second part think confusingvalidation set used avoid overfitting tree pruning node function value computed validation set increase split cross validation isnused buliding pruning decision treeused estimate good tree built data will perform simulating arrival new data building tree without elements just wrote doesnreally make sense pick one trees generated model constrained data using might actually worse use tree new data tree built data choose usualy pruning usually done using heuristic elements node belongs class dongo information gain small main point using cross validation gives better estimate performance trained model used different data tree pick one option bulid new tree using data training set mentioned already purpose cross validation qualify model words cross validation provideerror accuracy estimation model generated selected parameters regardless used data corss validation process can repeated using deferent parameters untill satisfied performance can train model best parameters whole data currently facing problem think correct answer since concepts contradictorytrade model robustness model interpretation basically chose decision tree algorithm sake easy interpretability visualization straight forward hands application hand want proof robustness model using cross validation think will apply two step approach applyfold cross validation show robustness algorithm dataset use whole dataset final decision tree interpretable results also randomly choose tree set cross validation best performing tree loose information hold setnew machine learningpreparing data classification using scikit learn svm order select best features used following method since dataset consist negative values get following error can someone tell can transform data error message inputmust non negative says pearsonchi square test goodness fit apply negative valueslogical chi square test assumes frequencies distribution frequency cannegative number consequently min max mean median fft accelerometer signal many cases may quite safe simply shift feature make positive even normalize interval suggested edchum data transformation reason possible pick another statistic score features since whole point procedure prepare features another methodbig deal pick anyone end result usually closeworking particular binary classification problem highly unbalanced dataset wondering anyone tried implement specific techniques dealing unbalanced datasets smote classification problems using sparkmllibusing mllibrandom forest implementation already tried simplest approach randomly undersampling larger class didnwork expected appreciate feedback regarding experience similar issues thanks moment class weighting random forest algorithm still development seewilling try classifiers functionality already added logistic regression consider case positives label dataset theoretically want sample positive class logistic loss objective function treat negative class label higher weight example scala generating weight add new column dataframe record dataset create classier follow details watch predictive power labeltrying predict case sampling still low precision maybe nothing fact dataset imbalanced nature exploratory data analysis classifier doesnbetter random choice risk simply connection features class overfitting low error training set high error test set might indication overfit using overly flexible feature set bias variance check whether classifier suffers high bias high variance problem used solution serendipity can optimize balancedataset function avoid using udf also added ability change label column used version function ended create classifier stated wtih dbakr get answer biased prediction imbalanced dataset thoughsure original plan note first subsample majority class dataset ratioorder get unbaised predictions sparklogistic regression can either use rawprediction provided transform function adjust intercept logcan train regression weights using setweightcol classweightcol see article cited figure value must set weights want evaluate regression model build scikitlearn using cross validation getting confused two functions cross val score cross val predict use one option one usepredictions standardscore assume methods valid give similar results case smallfoldsroughly foldgets increasingly lower highervalues case first version using cross vall score second version mostly unaffected changing numbers folds behavior expected lack understanding regardingsklearn cross val score returns score test fold cross val predict returns predictedvalues test fold cross val score using average output will affected number folds may folds may high error fit correctly whereas cross val predict returns element input prediction obtained element test set note cross validation strategies assign elements test set exactly can used increasing number folds increases training data test element hence result may affected much edit comment please look following answer cross val predict works scikit learn cross val predict accuracy score calculated think cross val predict will overfit folds increase data will train less will test resultant label dependent training data also already told prediction one sample done may susceptible splitting data places tutorials recommend using cross val score analysis question also buggedmade good points didnanswer aspectss question true answer divergence scores increasingdue chosen metriccoefficient determination msle mae wondifference using cross val score cross val predict see definitionr mse ground truth prediction mse ground truth mean ground truth bold part explains score starts differ increasingsplits fewer samples test fold higher variance mean test fold conversely smallmean test fold wondiffer much full ground truth mean sample size still large enough small variance proof output will course another effect shown mentioned others increasingmodels trained samples validated fewer samples will effect final scores induced choice cross val score cross val predict think difference can made clear inspecting outputs consider snippet notice shapes see argumenttherefore single real value computed fold value score classifier given true labels predicted labels many answers predictor right particular fold caselabels given input used twice learn data evaluate performances classifier handshape dataset length input dataset means value score computed multiple values single value prediction classifier given input data labels prediction classifier specific example test set particular fold note know fold used output computed test data certain fold cantell output least case labels used just train classifierjob compare outputs true outputs compute score just average output scorejust average custom generator multi output model like node moment generating random numbers real training wish load json file contains bounding box coordinates images will need get file names generated using train method can load file parse json pass instead also necessary orderingvariable list file names get yes possible least version donknow earlier version instance imagedatagenerator flow directory attribute filenames list files order generator yields also attribute batch index can like every iteration generator can get corresponding filenames like will give filenames images current batch can make pretty minimal subclass returns image file path tuple inheriting directoryiterator init added attribute numpy version get batches transformed samples index array file paths index array can make generator like check least version can like get file path example works shuffle true also properly handles last batch make one pass code might help overriding flow directory check images file path returned needed exactly developed simple function works shuffle true shuffle false use follows using dropout neural network model keras little bit code like testing using preds model image testing dropout also participating predict score happen search lot disable dropout didnget hint yet anyone solution disable dropout testing keras keras default keras dropout disabled test mode can look code see use dropped input training actual input testing far know build training function layers specify training flag predict dropout problem case want gans use intermediate output training also train network whole due divergence generated training images generated test images previously stated dropout keras happens train time proportionate weight adjustment training learned weights appropriate prediction dropout disabled ideal cases wish use dropout nnet probabilistic predictor produces distribution asked predict inputs repeatedly words keras dropout layer designed give regularization train time mean function learned distribution predicting want retain dropout prediction can easily implement permanent dropout permadropout layer based suggestions madechollet github discussion area keras replacing dropout layer keras model permadropoutget probabilistic behavior prediction activate dropout inference timesimply specify training true layer interest dropout case training false training true default training set false full example usage droput inference time dropout removes certain neurons form play compensate usually take one two ways keras uses second form correction can see newer tensorflow versions usually eager can try things like will give predictions considering behavior desired phase custom training loops insteadimportant use never tested following non eager mode can also probably build new model using existing layers passing training false call functional api model dropout layer call argument named training use keras sets automatically argument true call model use model input keras sets argument false can use argument custom layers models control dropout manually see kerasofficial documentation information already know difference scikit learn like wrappers call prepare dmatrix pass corresponding objective function parameters end fit call simply boils means everything can done xgbregressor xgbclassifier doable via underlyingobviously true instance useful parameters maxim xgboost much differences donexist anymore find different evals result retrieved separately fit resulting dict different cantake advantage name evals watchlist watchlisttrain trainvalid valid opinion main difference training prediction speed reference will call native implementation sklearn wrapper made benchmarks dataset shape fit train time sklearn wrapper time seconds native implementation time seconds prediction time sklearn wrapper seconds native implementation milliseconds believe reasoned fact sklearn wrapper designed use pandas numpy objects input native implementation needs input data converted danil suggesting significant differences speed mohammad correctly points necessity convert data dmatrix structure tried replicate benchmark kaggle notebook environment results showed major training predicting speed difference among xgboost native sklearn wrapper cpu times user minsystotal minwall time mincpu times usersystotalwall timecpu times user minsystotal minwall time minxgbregressor base score booster gbtree callbacks none colsample bylevel colsample bynode colsample bytree early stopping rounds none enable categorical false eval metric none gamma gpu grow policy depthwise importance type none interaction constraints learning rate max bin max cat onehot max delta step max depth max leaves min child weight missing nan monotone constraintsestimatorsjobs num parallel tree predictor auto random state reg alpha reg lambda cpu times usersystotalwall time msthese questions calculate reduce overfitting machine learning think many new machine learning will questions tried clear examples questions hope answers can help others small sample textstrying predict values associatedused sklearn calculateidf insert regression model prediction gives samples features lot know inserting samples featuresassociated scoreslinearregression model gives good predictions obtained using leave one cross validation cross indices true pretty good using ngramsinstead unigramssimilar results occur obviously right words occur texts prediction fail doesnquestion might mean prediction model overfitting data know chose extreme value ngramsknow canproduce good results didnknowledge normally tell model fitting words reasonable measureused know good prediction result overfitmodel just working question best way preventing fitting situation sure prediction results good question leaveoneout cross validation used can model possibly fit good results fitting means prediction accuracy will suffer doesnsuffer prediction text left reason can thinkidf sparse matrix mainlystrong overlap texts many termsregression thinks texts correlate highly please answer questions even donknow thanks normally tell model fitting one useful rule thumb may overfitting modelperformance training set much better held validation set cross validation settingthough blog entry linked describes procedure testing overfit plot training set validation set error function training set size show stable gap right end plotprobably overfitting best way preventing fitting situation sure prediction results good use held test set evaluation setcompletely done model selection hyperparameter tuning dontrain donuse cross validation score get test set modelfinal evaluation show whetheraccidentally overfit validation setmachine learning conferences sometimes set like competition test set given researchersdelivered final model organisers meanwhile can use training set please leaveoneout cross validation used can model possibly fit good results can tune model much want cross validation setting performs nearly perfectlyextreme example supposeimplemented estimator essentially random number generator can keep trying random seeds hit model produces low error cross validation doesnve hit right model meansoverfit cross validation see also interesting warstory trained xgboostregressor model use trained model predicting new input predict function throws feature names mismatch error although input feature vector structure training data also order build feature vector structure training data lot inefficient processing adding new empty columns data exist rearranging data columns matches training structure better cleaner way formatting input matches training structure case order column names model building different order column names model scoring used following steps overcome error first load pickle file extraxt columns order used reorder pandas dataframe try converting data ndarray passing fit predicttrain data traintest data testuse code now fit model finally predict hope helps find predict function take dataframe sparse matrix input one bugs can found use matrix function case dataframe toarray case sparse matrix workaround till bug fixed feature implemented different manner also problem used pandas dataframe non sparse representation converted training testing data numpy ndarray got rid error came across problemsolved adding passing train dataframe column name test dataframe via adding following code check exception see two arrays one column names dataframepassing xgboost feature names length put side side excel spreadsheet will see order guess xgboost names written dictionary coincidence names two arrays order fix easy just reorder dataframe columns match xgboost namescontributing answer experienced problem putting fitted xgbregressor model production thus solution cases select column namestraining testing dataframe though may cross helpful model fit pandas dataframe attempting pass single row values reverse label encoded etc array numeric values got familiar error valueerror feature names mismatch followed list features followed list lengthf doubt direct solutions little time fixed problem names feature names result vector names iloc iloc transformation found selecting feature names models scikit learn implementation feature names attribute using get booster feature names found athar post check documentation learn hope helps creating dmatrix xgb passtraintest directly xgboostregressor needs columns features order try apply train test feature datasets also facing issue tried techniques failed using pima diabetes dataset model fit good comes manual testing using predict throwing errors missing features namestried something works columns basically independent variables columns dataset now will question time need try complex method just predict answer pickle model can easily pass test will problem can see complete code instead try issue actually just namings since xgboost internally converts wrong feature names correct ones trainingwondering calculate precision recall measures multiclass multilabel classification instance can multiple labels multi label classification two waysfirst consider following metrics computed per datapoint manner predicted label score computed scores aggregated datapoints metrics things done labels wise label metricsprecision recall computed label wise metrics aggregated hence case end computing precision recall label entire dataset binary classification label binary assignment aggregate easy way present general form just extension standard multi class equivalent macro averaged micro averaged true positive false positive true negative false negative counts respectively labelstands confusion matrix based metric case plug standard precision recall formulas macro average pass per label count sum micro average average counts first apply metric function might interested look code mult label metrics part package mldralso might interested look java multi label library mulan nice paper get different metrics review multi label learning algorithms answer compute precision recall class average togetherc precision recallexpert determined based following sources compute recall label can read values confusion matrix compute now letcompute precision label can read values confusion matrix compute just need remaining labelsc applies multi class classification problem full article talks compute precision recall multi class classification problem including examples python using sklearn numpy simple averaging will classes balanced otherwise recall real class needs weighted prevalence class precision predicted label needs weighted bias probability label either way get rand accuracy direct way make normalized contingency table dividetable adds combination label class add diagonal get rand accuracy classes arenbalanced bias remains chance corrected method kappa appropriate better still roc analysis chance correct measure informedness height chance line roc using scikit learn text classification want calculate information gain attribute respect class sparse document term matrix suggested formula information gain measure mutual information matches also definition wikipedia possible use specific setting mutual information scikit learn accomplish task can use scikit learnmutual info classif example will output dictionary attribute using pure python question appear programming within scope defined help center closed year ago know regular neural nets people use batch norm activation will reduce reliance good weight initialization wonder rnn lstm rnn use anyone experience use batch normalization recurrent neural network statistics computed per batch consider recurrent part network weights shared rnn activation response recurrent loop might completely different statistical properties techniques similar batch normalization take limitations account developed example layer normalization also reparametrizations lstm layer allow batch normalization used example described recurrent batch normalization coijmaansal batch normalization applied rnns similar batch normalization applied cnns compute statistics way recurrent convolutional properties layer still holdapplied cnns means computing relevant statistics just mini batch also two spatial dimensions words normalization applied channels dimension rnns means computing relevant statistics mini batch time step dimension normalization applied vector depths also means batch normalize transformed input vertical directionsxsince horizontal across time connections time dependent shouldnjust plainly averaged non recurrent network convnetlayer gets adjust incoming scale mean incoming distribution layer doesnkeep changing authorspaper claim advantageproblem recurrent outputs rnn parameters incoming distribution now shared timesteps effectively layers backpropagation time bptt distribution ends fixed across temporal layers bptt may make sense may structure data varies non random way across time series example time series sentence certain words much likely appear beginning end distribution fixed might reduce effectivenesscommonly used though found paper shows way use batch normalization input hidden hidden hidden transformations trains faster generalizes better problems answer yes yes according paper layer normalization section clearly indicates usagernns distribution output timestep stored calcualted conductimagine pad sequence input examples length predict case longer training cases time step mean std output distribution summarized sgd training procedure meanwhile least keras believelayer consider normalization vertical direction sequence output horizontal direction hidden status cell status normalized correct wrong multiple layer rnns may consider using layer normalization came across method using simple activation functions rectified linear unit relu instead classic smooth sigmoids relu function differentiable origin according understanding backpropagation algorithm bpa suitable training neural network relus since chain rule multivariable calculus refers smooth functions however none papers using relus read address issue relus seem effective seem used virtually everywhere causing unexpected behavior can somebody explain relus can trained via backpropagation algorithm understand backpropagation even possible functions like relu need understand important property derivative makes backpropagation algorithm works property treatactual value parameter moment can tell knowing value cost functionderivative cost function will behave change parameters little bit crucial thing backpropagation fact computing cost function crucial cost computation will need cost function satisfy property statedeasy check relu satisfy property everywhere except small neighbourhood problem relu fact use property close overcome may choose value relu derivative either hand researchers dontreat problem serious simply fact close relu computations relatively rare course pure mathematical point viewplausible use relu backpropagation algorithm hand practice usually doesnmake difference weird behaviour around tensorflow model one part model evaluates accuracy accuracy just another node tensorflow graph takes logits labels want plot training accuracy simple something like training loop something like also inside loop every say iterations want evaluate validation accuracy separate feed dict able evaluate validation accuracy nicely python however problem want make another summary validation accuracy using accuracy node clear though since accuracy node makes sense ableuse unsure exactly can also get validation accuracy written separate scalar can reuse accuracy node need use two different summarywriters one training runs one test data also assign scalar summary accuracy variable training loop normal training record summaries train writer addition run graph test setiteration record accuracy summary test writer can point tensorboard parent directory summaries dir will load data sets can also found tensorflow howtosimply attach two summary opssay want run accuracyvalidation test data want get summaries also remember can always pull raw scalar data protobuff summary str like logging tensor pictures like randomly selectlooking equivalent letsay want pictures torch equivalent implementation see discussion alternative indexing shuffled index random integers readincluding sampling without replacement size tensor following code works fairly fast takes aroundusing however taketry answer mentioned torch choice can use randint permutation instead following google cloud machine learning tutorial unable launch tensorboardfollowed steps tutorial also set environment using docker container typing command terminal terminal outputs prompt visit http browser see nothing server page located responding can someone please advice can launch tensor board problem morning solved navigated browser http localhost try will open socket listening network interfaces can connect local hostlocal networkmobile network faced problem used tensorboard inside docker container successful steps case docker run name tensorboard containertensorboard image bash tensorboard bind port logdir logs hope works case looks like port open machine can check command line tool netstat open specific port google cloud platform see answer using google cloud click icon placed upper left window solutions far check solve problem instead using http name port number use http localhost port number using chrome browser using firefox recommendedreally convenient can open linkname directly displayed executing tensorboard logdir logs command cmdhttp name port number will work name refersuser name donknowcase tensorboard visualization problems several browsers try connect http different browser example macbook safari doesnwork tensorboard use google chrome stated rodrigo silveira works just change name graph directory directory data directory logs typed command cmd window appeared window pop change port tensorboard port right toolbar gloud case port open opening port helped process done linux first checked port open can check code open port following code just change port number place solve pybrain python order predict next value sequenceread pybrain documentation clear example think also found question fail see works general case thereforeasking anyone work clear example predict next value sequence pybrain recurrent neural network give example say example sequence numbers range now given example start new sequence next valuequestion might seem lazy think lacks good decent example pybrain additionally can done feature present example say example several sequences sequence features range now given example start new sequences next valuefeel free use example long similar examples depth explanation issam laradjiworked predict sequence sequences except version pybrain required tuple unserperviseddataset object gives predict smaller sequences just train either sub sequences overlapping sequences overlapping shown gives create supervised dataset expects sample target arguments succeeding sample target labelpredecessorput number sample numbers features please note standard notations second half question better call feature feature sample sample sequence let features denote numbers sample create network initialize trainer run epochs make sure set recurrent argument true create test data created unsupervised dataset assumption donlabels targets predict test sample using trained network display values expected fourth run second case sequence can sample instead creating supervised dataset create sequential onesequentialdataset everytime get new sequence call add samples call features sequence using hope clear cut wish full code save trouble importing libraries please let hidden layers first tried implement way can see poor implementation think gets job done least way tried real outputs one hot true outputs activation functions used sigmoid function cost function used squared error cost function think called correctwrongtried using relu softmax activation functions cost function doesnwork figured donwork also tried sigmoid function cross entropy cost function also doesnwork iterations question activation function cost function can work learn network without changing parameters meaning without changingxquestion read stackoverflow post activation function selection depends problem cost functions can used anywhere mean standard cost function can used neural network right please correct also implemented gate different approach output one hot true can see trainmeansindex answer hope get used softmax activation function cross entropy cost function sigmoid function activation function fails miserably iteration question case cost function activation function can use understand type cost activation functions use standard way rule just experience try every cost activation function brute force manner found answer hoping elaborate explanation question noticed takes many iterations converge near accurate prediction think convergance rate depends learning rate using large will miss solution cost function correctwrong optimal way meaning fastest cost function converging correct solution will answer questions little bit order starting general answers finishing specific particular experiment activation functions different activation functions fact different properties letfirst consider activation function two layers neural network purpose activation function serve nonlinearity put activation function two layers two layers together will serve better one effect will still just linear transformation long people using sigmoid function tanh choosing pretty much arbitrarily sigmoid popular recently relu became dominant nonleniarity reason people use relu layers non saturating also faster compute think graph sigmoid function absolute valuelarge derivative sigmoid function small means propagate error backwards gradient error will vanish quicklyback layers relu derivative positive inputs gradient neurons fired will changed activation unit will slow gradient descent last layer network activation unit also depends task regression will want use sigmoid tanh activation want result classification will want one outputs one others zerosdifferentiable way achieve precisely will want use softmax approximate example now letlook example first example tries compute output following form notew will always converge value outputx equal outputx therefore model fittingx can take one three values want return casex casex since sigmoid function rather smooth will take large valuesb make output close desired small learning rate canget large values fast increasing learning rate first example will increase speed convergence second example converges better softmax function good making precisely one output equal others since precisely case converge quickly note sigmoid also eventually converge good values will take significantly iterations higher learning rate use now last question one choose activation cost functions use advices will work majority cases classification use softmax last layernonlinearity cross entropy cost function regression use sigmoid tanh last layernonlinearity squared error cost function use relu nonlienearity layers use better optimizers adamoptimizer adagradoptimizer instead gradientdescentoptimizer use momentum faster convergence cost function activation function play important role learning phase neural network activation function explained first answer gives possibility network learn non linear functions besides assuring small change output response small change input sigmoid activation function works assumptions activation functions may less computational expensive see activation functions completeness general sigmoid activation function avoid vanishing gradient problem cost functionplays crucial role speed learning neural network gradient based neural networks learn iterative way minimising cost function computing gradient cost function changing weights according quadratic cost function used means gradient respect weights proportional activation function first derivate now sigmoid activation function used implies output close derivate small can see image neurons learns slow cross entropy cost function allows avoid problem even using sigmoid function using cross entropy function cost function implies derivates respect weights proportional first derivate activation function happened quadratic function instead proportional output error implies prediction output far away target network learns quickly viceversa cross entropy cost function used always instead using quadratic cost function classification problem explained note neural networks cross entropy function always meaning cross entropy function meet probability used compare two probability distribution neural networks can true unique sigmoid output final layer want think probability distribution losses meaning multi sigmoid neurons final layer need code maximum likelihood estimator estimate mean variance toy data vector samples created data zero mean unit variance gaussian distribution checked wikipedia extra sources little bit confused since donstatistics background pseudo code maximum likelihood estimator get intuition mle figure start coding wiki says taking argmax log likelihood understand need calculate log likelihood using different parameterstake parameters gave maximum probability donget will find parameters first place randomly try different mean variance get high probability stop trying just came across know oldhoping someone else benefits although previous comments gave pretty good descriptionsoptimization one gave pseudo code implement python minimizer scipy willpseudo code linear regression works great granted just basics doesnprofile give cis parameter estimates start can also usetechniques find estimates say odes models describe know question old hopefullyfigured since hopefully someone else will benefit maximum likelihood calculations first step need take following assume distribution depends parameters since generate data even know parameters tell program assume gaussian distribution however dontell program parameters leave unknown priori compute afterwards now sample vector letcallelementsx process compute followingdenotes probability density function gaussian distribution can see given linkemploys two parameters greek letters now calculate values wayxx takes maximum possible valuedone maximum likelihood value mean maximum likelihood value standard deviation note donexplicitly tell compute values since quite mathematical procedure donhand probably understand just tell technique get values can applied distributions since want maximize original term can simply maximize logarithm original term saves dealing products transforms original term sum summands really want calculate can simplifications lead following term hope didnmess anything now find values beast maximal nontrivial task called nonlinear optimization one simplification try following fix one parameter try calculate saves dealing two variables time need numerical optimisation procedure sure anything implemented pythonnumpy scipy friends look things like nelder mead algorithm bfgs else fails use rpy callfunction optim functions work searching function space trying work maximum imagine trying find top hill fog might just try always heading steepest way send friends radios gps units bit surveying either method lead false summit often need times starting different points otherwise may think south summit highestmassive north summit overshadowing joran said maximum likelihood estimates normal distribution can calculated analytically answers found finding partial derivatives log likelihood function respect parameters setting zero solving equations simultaneously case normal distribution derive log likelihood respect meanderiving respect variance sigma get two equations equal zero solving equationssigmaget sample mean sample variance answers see wikipedia page details working signal classification problem like scale dataset matrix first dataformat batch length channels tried use scikit learn standard scalergot error message found array dim standardscaler expected think one solution split matrix channel multiplesmatrices scale separately put backformat wonder better solution thank much linefit store scaler channel want scale feature differently like standardscaler can use simply flattens features input giving sklearnstandardscaler reshapes back usage standardscaler prints arguments mean std directly passed standardscaler thus work expected copy false wonwork since reshaping happen inplaceinputs ndstandardscaler works like standardscaler prints just like sklearn example standardscaler elegant way using class inheritance follows usage used normalization scheme spatio temporal data shape samples timesteps features spatial locations following code can used normalization inverse also just reshaped data like zero padded use similar can use classdealing pipelines another simple way without using loops making functions methods just flattened given input array fit inside minmaxscaler later transformation convert original shape example implemented cifar dataset tensorflow implemented gradient descent algorithm minimize cost function order gain hypothesis determining whether image good quality octave idea somehow based algorithm machine learning class andrewtherefore valuescontains values valuespredict imagequality sadly algorithm seems fail iterations value theta small theta theta become nan linear regression curve strange theta zeros alpha iterations computation costfunction wondering seemingly complex looking loop can vectorized cramped single one line expression please read vectorized form theta theta alphaxthetagiven detailed explanation arrive vectorized expression using gradient descent algorithm gradient descent algorithm fine tune value assume following valuesy given whole objective machine learning minimize errors predictions based corollary errors matrixx vector matrix follows calculate new valueget summation errorsrows multiplied jth feature value training settake valuesindividually multiply jth feature corresponding training example add together will helpgetting new hopefully better valuerepeat processnumber features matrix form can written can simplified succinctly can written sinceb can also write original expression started vectorized theta may help somebody think computecost function wrong attendeds class last year following implementation vectorized rest implementation seems fine although also vectorize afterwards setting temporary thetas called theta theta correctly back real theta generally useful vectorize instead loops less annoying read debugusing least squares cost function try using normal equation instead gradient descentmuch simpler one line computationally faster normal equation tutorial explains use normal equation loop based computation gradient descent generate results example probably case gradient descent failing compute correct theta value alpha verified set cost gradient descent functions set data similar one described question theta ends nan values just iterations alpha however set alpha gradient descent works expected even iterations using vectors compact implementationgradient descent mathematica note course one assumesn matrixcontainingwork cleaner way vectorized also remember first pdf file gradient descent form machine learning course take care learning rate note mentioned pdf implementation note learning rate largetheta canverge blow resulting values large computer calculations situations octave matlab will tend return nans nan stands fornot number often caused undened operations involve infinitykneighborsclassifier answer says documentation kneighborsclassifier says metrics mentioned distancemetrics available distance metrics doninclude explicit cosine distance probablyreally distance supposedlypossible input function metric tried inputting scikit learn linear kernel kneighborsclassifier gives error function needs two arrays arguments anyone else tried cosine similarity generally definedyy outputs goes completely different definition technically metric canuse accelerating structures like balltrees force scikit learn use brute force approach able use distance pass custom distance metric object methods transforming cosine similarity valid distance metric like use ball trees can find one jsat library notice thoughyyxyeuclidean distance can equivalently written sqrt xtx yty xty normalize every datapoint giving kneighborsclassifiertx euclidean distance will degrade sqrttcompletely inputs get sqrt complete opposites sqrt clearly simple shape can get ordering cosine distance normalizing data using euclidean distance long use uniform weights option results will identical used correct cosine distance knn family class constructors parameter called metric can switch different distance metrics want use nearest neighbour model list available distance metrics can found want use cosine metric ranking classification problem can use norm euclidean distance normalized feature vector gives ranking classification predictions made argmax argmin operations resultsusing scikit learn sometimes need probabilities labels classes instead labels classes instead spam spam labels emails wish example probability given email spam purposeusing predict proba randomforestclassifier following got results second column class spam however two main issues results confident first issue results represent probabilities labels without affected size data second issue results show one digit specific cases probability different way get next digit example randomforestclassifier collection decisiontreeclassifiermatter big training set decision tree simply returns decision one class probability classes probability randomforest simply votes among results predict proba returns number votes class tree forest makes decision chooses exactly one class divided number trees forest hence precision exactlyestimators want precision add estimators want see variationdigit will need estimators excessive normally donwant estimators often many get one digit results sure due dataset example using small dataset yield simple decision trees simple probabilities otherwise may display shows one digit try print predictions sure understand mean probabilities arenaffected size data concern donwant predictmany spams usually done use thresholdpredict proba labelway can use threshold balance predictions example limit global probabilty spams want globally analyse model usually compute area curve auc receiver operating characteristic roc curve see wikipedia article basically roc curve description predictions depending thresholdhope helps afraid top voted answer isncorrect least latest sklearn implementation according docs probability prediction computed mean predicted class probabilities trees forest class probability single tree fraction samples class leaf words since random forest collection decision trees predicts probability new sample averaging trees single tree calculates probability looking distribution different classes within leaf look image single decision tree understand means different classes within leaf right leafchild split yellow prediction probability class yellow will scenario mentioned top voted answer will occur every leaf trees data points belonging one class references reverse mapping step example data frame contains columns string values type like convert numerical values possibly translate back later can use apply need factorize column separately need string value numeric one need apply function columns use subset solution factorize translate back possible via map dict need remove duplicates drop duplicates also found answer quite helpful listaddresses named srcip map numerical values new column named example solution result like redirect answer want keep categories consistent across resulting dataframe using replace performs slightly worse example jezrael easier read also might escalate better bigger datasets can proper testing anyone value returned scikit learn metricsscore can negative docs say unlike scoresscore may negative need actually square quantityhowever wikipedia articlementionssquared quantity perhaps uses absolute differences instead square differences really ideascikit learn essentially described wikipedia article coefficient determination grep general definition residual sum square total sum squares big difference classical stats setting usually try machine learning machine learning evaluate score unseen data can lead results outside applydata used fit model will lie within see also similar question sincerss tss case rss tss happens model even worse worst model assumed absolute mean model rss sum squares difference actual valuespredicted valuestss sum squares difference actual valuesmean value applying regression can imagine tss representing best actual model rss best model worst absolute mean model caseget rss tss model even worse worst mean model case rss tss since difference actual observation mean value difference predicted value actual observation check better intuition visual representationtrained tree modelcaretnow trying generate confusion matrix keep getting following error error predictionstree testdata catgeory data reference factors must number levels error occurs generating confusion matrix levels objects figure problem structure levels given help greatly appreciated making cracked try use worked maybe model predicting certain factor use table function instead confusionmatrix see problem try specifying change data frame use confusionmatrix function issue went ahead changed reading data file like data data thanks pointer might missing values testdata add following line predictionstree predict treefit testdata remove nas error now works length problemrunning probably due presence nas training set either drop cases complete impute missing values make sure installed package dependencies data contains nas sometimes will considered factor level omit nas initially model fit predicting incorrect level better use tables just ran problem solved usingordered factor dataconsider multivariate regression problem response variables latitude longitude currently machine learning model implementations like support vector regression goal tune parameters svr response single variable multiple perform operation follows however responsetrain dimensional need use multioutputregressor top svr can modify code enable gridsearchcv operation possible better alternative use without pipeline put estimator parameters just found working solution case nested estimators parameters inner estimator can accessed estimator thank marco adding answer short illustrative example randomized search applied multi ouput gradientboostingregressorlooking way produce non linear preferably quadratic curve baseddata set predictive purposes right nowusing implementation ordinary least squares ols produce linear trend trends much suited curve model dataanalysing system load timeequationusing produce linear coefficientslook either provide interpolation instead regression use code just doesnwork way anyone know free open source libs code samples can produce coefficients curve used calculated coefficients output matches quadratic results wolfram alpha edit get fit want try following initializationdatadata produces following coefficients lowest power highestcode pretty good ported present version optimized code size performance instancealso available github gist donthink want non linear regression even using quadratic function still called linear regression want called multivariate regression want quadratic just addsquared term dependent variables take look abnormal termination lnsrch information dictionary get warning every time sometimes get convergence norm projected gradient pgtol convergence rel reductionfactr epsmch know means minimum can reached iteration googled problem someone said occurs often objective gradient functions match provide gradient function using approx grad possible reasons investigate mean rounding error dominate computation also find log likelihood monotonically increase usually start decrease second third iteration even abnormal termination lnsrch occurs know whether problem related previous one scipy calls originalbfgsimplementation fortran old beautiful superfast code problem descent direction actually going problem starts line link code bottom words tellinghill going hill code tries something called line search total times descent direction provide realizes tellingdownhill uphill times guy wrote jorge nocedal way smart guy put pretty muchenough machine epsilonthink actually little much money people problem gradient match function now also rounding errors dominate computation means function flat surface increases order machine epsilon case perhaps rescale function now thiking maybe third option function weird oscillations see something like sin fraccausing kind problemsmart guy donassumethird case thinks solution function flat look fortran codeline search want seesake pointed answer wilmerhenao problem probably gradient since using approx grad true gradient calculated numerically case reducing value epsilon step size used numerically calculating gradient can help also got error abnormal termination lnsrch usingbfgsoptimizer gradient function pointed right direction rescaled actual gradient functionnorm removing adding another appropriate type rescaling worked guess gradient large went bounds immediately problemunbounded read correctly will certainly help problem setting however googling error abnormal termination lnsrch yields page one first results might help provide gradient function approx grad false cost function gradient consistent double checked optimization actually works time get abnormal termination lnsrch solution optimal even close even subjective point view can overcome issue modifying maxls argument increasing maxls helps solve issue finally get optimal solution however noted sometimes smaller maxls one produces abnormal termination lnsrch results converging solution dataframe summarizes results surprised observe expected reducing maxls improve result reason tried read paper describing line search algorithm trouble understand line search algorithm generates sequence nested intervalssequence iteratesik min max according procedure understand say maxls argument specifies length sequence end maxls iterations less algorithm terminates fewer iterations line search stops final trial point generated within final interval imaxls say formula guarantee get maxls respects two update conditions minimum decrease curvature especially interval still wide guess case iterations generated interval trial point respects conditions even though smaller still containing acceptable points finally iterations interval small generatedrespects update conditions understanding explanation accurate surprised maxls since generated acceptable chosen case instead pragmatically recommend try higher maxls getting abnormal termination lnsrchnew keras trained model like predict images stored subfolders like training testing want predict images classes subfolders test generator sees images get predictions mistake thanks lot can change value batch size flow directory default value batch size batch size set steps predict generator total number test images something like default batch size generator want make prediction every sample totalsamples devidesamples batch size thus batch size need steps images problem inclusionsamples predict generator creating batches images use fit predict tensorflow now supports methods generators just incase someone finds future wondering accuracy score gotten using inputs targets single items inputs targets lists basically crawling data set one sample item time pass generator get maxsize default thought purpose using generator batch data sets reasonable chunks additional queue simply defines maximum size internal training queue used precache samples generator used generation queues words thread filling queue given maximum capacity directly generator example training routine consumes elements sometimes waits completion default particular reason like defaults simply makes sense use different values construction like suggests authors thought expensive data generators might take time execture example consider downloading data network generator call makes sense precache next batches download next ones parallel sake efficiency robust network errors etc might want pay attention using maxsize combination fit generator fact batch size declare use generator function will considered one single input case batch size images maxsize will result real maxsizeimages healthy memory reason sometimes keras model never stop getting increased memory training process crashesi want use flow directory method imagedatagenerator generate training data regression model target value can float value flow directory class mode parameter description class mode one categorical binary sparse none default categorical determines type label arrays returned categorical willone hot encoded labels binary willbinary labels sparse willinteger labels values take none seems really allowing flow images directory regression problems store images folder load dataframe containing one column image ids column regression score labels set class mode flow dataframe can find example images image dir dataframe image ids regression scores loaded pandas train file think organizing data differently using dataframe without necessarily moving images new locations will allow run regression model short create columns dataframe containing file path image target value allows generator keep regression values images properly synced even shuffle data epoch example showing link images binomial targets multinomial targets regression targets just show target target target model might change describe great detail examples newest version keras januaryflow directory work following manner need directories structured following manner can see used classification case options provided documentation specify way class provided classifier neat hack make flow directory useful regression task need structure directory following manner also need list list valuesvaluevalue generator defined following mannercrucial flow directory gen class mode sparse make work course little bit cumbersome works used solutionjust one glitch accepted answer like point code fails error message likearray fix simple method generate list values can found correct better way preprocess data correct standardized way preprocess data normalize mean either standardization linear scaling techniques normalize data pca example consider following situation create data setknown correlation matrixnow perform pca correctly find principal components rows weights vector oriented angle coordinate axes now scale first feature data set intuitively think principal components shouldnchange however now find principal components aligned coordinate axes resolve two options first rescale data weird bsxfun notation used vector matrix arithmetic matlabsubtracting mean dividing standard deviation feature now get sensible results pcaslightly different pca original datanow guaranteed features unit standard deviation wasncase originally option perform pca using correlation matrix data instead outer product fact completely equivalent standardizing data subtracting mean dividing standard deviationjust convenient opinion always unless good reason need normalize data first always otherwise pca techniques used reduce dimensions will give different results normalize data first actuallypackages useful perform pca analysis normalize data automatically performing pca variables different units describe different characteristics mandatory normalize answeroption pca normalize pca output whole data will completely different standard normalize dataset pca will accuarate got another reason pca objective function may see detail link enter link description assumingmatrix normalized pca saw tutorialw autoplot plotted loadings loading labels scikit learn pandas data analysis however donknow add can plot vectorsmatplotlibreading recovering features names explained variance ratio pca sklearn havenfigured yetplot python something like following creating biplot function nice article source friends linkbfc aff fedfbresult try pca library will plot explained variance create biplot found answer teddyrolandlike add generic solution topic careful research existing solutions including pythondatasets especially biological omic datasets figured following python solution advantages scale scores samples loadings features properly make visually pleasing one plot pointed relative scales samples features mathematical meaning relative directions however making similarly sized can facilitate exploration can handle high dimensional data many features one afford visualize top several features arrows drive variance data involves explicit selection scaling top features example final output using moving pictures classical dataset research field preparation will use iris dataset samples features comes critical part scale features arrows properly match samples points following code scales maximum absolute value samples axis another way discussed seraloukanswer scale range max min will make arrows larger points plot points arrows compare resultsolution can see quite consistent note known pcasscikit learn opposite axes can flip one make directions consistent will use digits dataset samples features now will find topfeatures best explain data method find toparrows appear longest furthest origin visible plot method find topfeatures drive variance visible pcs now new problem feature number large topfeatures small portion features contribution data variance tiny thus will look tiny plot solve came following code rationale features sum square loadings always persmall portion features bring sum square loadings also method tested working generates nice plots will scale arrows match samples discussed now can render biplot hope answer useful community plot pca loadings loading labels biplot using matplotlib scikit learn can follow steps fitting pca model using retrieve loadings matrix using components attribute model loadings matrix matrix loadings original feature principal component determine length loadings matrix create list tick labels using names original features normalize loadings matrix length loading vector will make easier visualize loadings biplot plot loadings arrows biplot using add loading labels biplot using set font size color using font size color parameters plot data points biplot using trying use scikit learn anaconda multilabel classification problem code data looks like training test get error mean full stacktrace fix need change format data xtrain ytrain fail makey suitable fit function edit tried now get binarizeneed convertdimension float documentation gives example recommended use pickle cpickle save keras model however need pickling keras model stems hyperparameter optimization using sklearnrandomizedsearchcv hyperparameter optimizersessential save results file since script can executed remotely detached session etc essentially want now keras models pickle able still recommend using save model disk works like charmproblems due raised typeerror json serializable obj due circular reference error swallowed code somehow hence resulting pickle function running forever look link unable save dataframe hdf object header message large can pickle keras neural network using deploymodule can installed via pip full training deployment kera neural network using deploywrapper looks like pickled file contains model metrics testing list variable names order inputted version keras python used scaler used will also stored file documentation loading using file done following appreciate training can bit restrictive deploysupports importing modellearnstill working support keras howeverfound can create deployneuralnetworkbase object define keras neural network outside deployassign deploymodel attribute works just fine dealing highly imbalanced data set idea obtain values feature weights libsvm model nowlinear kernel can obtain feature weights using rbf poly fail reach objective using sklearn modeleasy obtain feature weights linear kernel using coef can anyone help thing rbf polytried far given impossible stated documentation weights asigned features coefficients primal problem available case linear kernel also doesnmake sense linear svm resulting separating plane space input features therefore coefficients can viewed weights inputdimensions kernels separating plane exists another space result kernel transformation original space coefficients directly related input space fact rbf kernel transformed space infinite dimensional can get starting point wikipedia course stuck similar problem different reason objective compute inference using built assuming like compute predictions trained models using algebra now formula linear inference easy collectively called weights makes matters super easy side note sum multiplications exactly dot two vectors reshape input vector needed conform expected predict input shape course kernels complicated formula previous answers pre compute weights since tied together nowgot stuckgot help friend discovered documentation page says know equation becomes easy now know value one thing left calculate kernel function depends type kernel polynomial kerneldegree default degree poly svm scikit roughly translatesnow letcombine everythinglearned code snippet runsee assertions passing woo hoo now can predict results using predict hope may help question asked since now can adjust dual coefficients way wanted adjust weights please pay attention use gamma also remove manual calculations since will just break otherwise also example inference polynomial kernel kernels inference function adjusted accordingly see documentationwant improve question update question focuses one problem editing post closed years ago want create dataset format cifar data set use tensorflow images labelslike able take cifar code different images labels run code first need understand format cifar data set refer kriz specifically binary version section see first byte label first image number range next bytes values pixels image first bytes red channel values next green final blue values stored row major order first bytes red channel values first row image intuitively need store data format can next sort baseline experiment first get images exactly size number classes cifar put format means images sizex classes can successfully run canfactor cases like single channels different size inputs different classes mean change many variables parts code slowly work waymidst working general module code will see many flags can changed accommodate needs admitcryptic now havencleaned readable works willing spend time taking rough look will figure something probably easy way run data set cifar course just copy neural network definition implement reader input format batching etc want running fast just tune inputs fit cifar edit really really basic code hope help convert image byte file ready use cifar multiple images just keep concatenating arrays stated format check format correct specifically askeruse case get file size bytes assuming pictures rgb values range verifyset run tensorflow use tensorboard perhaps visualize one image just guarantee correctness edit per askerquestion comments really wanna work need study function calls cifar code cifar input batches hardcoded edit line code fit name bin file just distribute images bin files evenly didnfind answers wanted made solution can found github can try like multiple input images computer vision algorithm want tune using isnthing trying optimize will convert odd number roughly one parameter window size pixels parameter threshold value worth using fresh build scipy git repo anyone know tell scipy use specific step size parameter way can roll gradient function scipy flag help aware done simple parameter sweep eventually like apply code much larger sets parameters code dead simple output looks like can see repeating lot runs getting anywhere minimization assuming function minimize arbitrarily complex nonlinear hard problem general guaranteed solved optimal unless try every possible option know integer constrained nonlinear optimizer somewhat doubt will assume know nelder mead work fine contiguous function edit considering comment dougal will just add set coarse fine grid search first feel like trying nelder mead works converges faster points may unfortunately scipybuilt optimization tools doneasily allow never fear sounds like convex problem able find unique optimum even wonmathematically pretty two optionsimplemented different problems creating custom gradient descent algorithm using bisection series univariate problemscross validation tuning loss function unfortunately wonsmooth noise cross validation different datasets will generally convex implement gradient descent numerically without analytical method evaluating gradient choose test point second point delta away test point dimensions evaluating loss function two points can allow numerically compute local subgradient important delta large enough steps outside local minima created cross validation noise slower potentially robust alternative implement bisection parametertesting know problem jointly convex two parametersparameters can separateunivariate optimization problems write bisection algorithm recursively hones optimal parameters can help handle types quasiconvexity convex another region requires good guess bounds initial iteration simply snap requestedvalues integer grid without fixing xtol map gridsize risk solver request two points within grid cell receiving output value concluding minimum easy answer unfortunately snap floatsy threshold integer grid inside function like nelder mead will see function values grid give near integerycare post code someplacelooking test cases nelder mead restarts nelder mead minimize method now specify initial simplex vertex points able set simplex points far apart simplex will flop around find minimum converge simplex size drops optimize minimize neldermead problem algorithm gets stuck trying shrinksimplexhighly recommend anyone new concept learn geographical shape simplex figure input parameters relate points simplex get grasp note different defininggoes nelder meaddedicated options example higher dimensional problem also note initial simplexpoints case case examplegets ignored definition initial simplex useful option high dimensional problems adaptive option takes number parameters acount trying set models operational coefficientsreflection expansion contraction shrink respectively havenalreadyalso recommend familiarizing steps algorithm now reason problem happening method gets good results expansion keeps shrinking simplex smaller smaller trying find better solution may maypolynomial features works quite one feature whenever add multiple features also outputs values array besides values raised power degreesarray try outputsefeaturesc default polynomial features sklearn degreeccbcex simple way polynomialfeatures can create new features good reference course disadvantages overfitting using polynomialfeatures see edit careful using polynomial features formula calculating number polynomial featuresncdn number featuresdegree polynomialbinomial coefficient combination case numbernumber features degree height polynomial features becomes many example case may need apply regularization penalize weights quite possible algorithm will start suffer curse dimensionality also nice discussion polynomialfeatures generates new matrix polynomial combinations features given degree like will converted degree can visualize input transformed matrix generated polynomialfeatures output can see matrix generated form observe polynomial features scatter plot letuse number output changing degree get general way check features caseecorrespondccterms correspondingly dimensional data following code generates poly features degree can also generated following code according scikitdocs far back polynomialfeatures will generate new feature matrix consisting polynomial combinations features degree less equal specified degree example input sample two dimensional formdegree polynomial featuresabtrying create cnn classify data datan datafeatures want create neural net capable classifying problem concerning input shape convkeras back end want repeat filter let say features keep weights next ten features data convolutional layer createfeatures new neurones can put input shape advice thank try reshapeshapeexamplesfeatures edit convdesigned sequence analysis convolutional filters matter part sequence second dimension called features dimension vector multiple features timesteps one may think sequence dimension spatial dimensions feature dimension channel dimension color dimension convputonspectacles mentioned comment may set sequence dimension none order make network input length invariant marcinanswer might work might suggestion given documentation using layer first layer model provide input shape argument tuple integers none sequences vectors dimensional vectors none variable length sequences dimensional vectors note since input datadatafeatures set number examples unspecified none strides argument controls size timesteps case input usual feature table data shape nrows ncols convkeras following steps needed example taking first features iris dataset see usual format shape output shows usual format shape following code alters format output code data format shape works convkeras input shape needed trying train neural networksusing package nnet following information training data truncated information run following get following error try changing weights argument like get following error mistake making avoid correct error maybe problem understanding weights either increase maxnwts something will accommodate size model reduce size make model smaller probably also want think exactly variables include model just looking data provided name factor levelsgoing get anything sensible observations city might useful levels something complex neural net likely marginal increase maxnwts option something larger option set increase number weights allowed network maxnwts weights set specify weights sample increase maxnwts parameter passing directlyi trying merge sequential models keras code error log file nicshome dsawant anaconda lib python site packages keras backend tensorflow line keras tensor raise valueerror unexpectedly found instance type str typevalueerror unexpectedly found instance type class expected symbolic tensor instance log valueerror layer merge called input isnsymbolic tensor received type class full input inputs layer tensors can merge sequential models use different window sizes apply functions like max sum etc using functional api brings possibilities using functional api need keep track inputs outputs instead just defining layers define layer call layer input tensor get output tensor models layers can called exactly way merge layer prefer using merge layers intuitive add multiply concatenate instance idea apply following layers keep updating output tensor giving layer getting new output interested creating branches use different var output interest keep track now created pathtime create model creating model just like telling input tensors starts ends notice since model two inputs train two differenttraining vars list now suppose wanted one input model model take input functional api allows quite easily creating input tensor feeding models call models layers case model consider inputusing keras predict time series standardusing epochs want check model learning predicting one epochs usinggetting one prediction among epochs sure keras selects want predictions least best anyone know help think bit confusion epoch used training neural network training stops caseepoch weights correspond ones computed last epoch keras prints current loss values validation set training epoch weights epoch saved lost can save weights epoch modelcheckpoint callback load back load weights model can compute predictions training epoch implementing appropriate callback subclassing callback calling predict model inside epoch end function use instantiate callback make list use keyword argument callbacks case want make predictions test data every epoch training going can try need mention callbackseen use softmax layer output activation function normally hidden units use sigmoid tanh relu function activation function using softmax function far know work mathematically havenfound publications using softmax activation hidden layer best idea except quora question probably already read will try explain best idea use case variables independence lot regularization effort put keep variables independent uncorrelated quite sparse use softmax layer hidden layer will keep nodes hidden variables linearly dependent may result many problems poor generalization training issues try imagine make network working better make part activations hidden layer little bit lower automaticaly making rest mean activation higher level might fact increase error harm training phase mathematical issues creating constrains activations model decrease expressive power model without logical explaination strive activations worth opinion batch normalization better one may consider fact constant mean output network may useful training hand technique called batch normalization already proven work better whereas reported setting softmax activation function hidden layer may decrease accuracy speed learning softmax layers can used within neural networks neural turing machines ntm improvement differentiable neural computer dnc summarize architectures rnns lstms modified contain differentiable neural memory matrix possible write access time steps quickly explained softmax function enables normalization fetch memory similar quirks content based addressing memory really liked article illustrates operations ntm recent rnn architectures interactive figures moreover softmax used attention mechanisms say machine translation paper softmax enables normalization places attention distributed order softly retain maximal place pay attention also pay little bit attention elsewhere soft manner however considered like mini neural network deals attention within big one explained paper therefore debated whether softmax used end neural networks hope helps edit recentlyeven possible see neural machine translation nmt models attention softmax used without rnn cnn usually output layercan also intermediate layer say multinomial latent variablementioned thread outputssumlinear dependency intentional layer additional layers may provide desired sparsity feature independence downstream page deep learning goodfellow bengio courville time wish represent probability distribution discrete variablepossible values may use softmax function can seen generalization sigmoid function used represent probability distribution binary variable softmax functions often used output classifier represent probability distributiondifferent classes rarely softmax functions can used inside model wish model choose onedifferent options internal variable softmax function used output layer least cases ensure sum components output vector equal clarity see formula softmax cost function also implies probability occurrence component class output hence sum probabilities output components equal softmax function one important output function used deep learning within neural networks see understanding softmax minute uniqtech softmax function apply three classes outcomes softmax formula takesraised exponent score value score devide sumraised exponent scores values example know logit scores four classes order obtain probabilities outputs softmax function can apply follows import numpydef softmaxprint softmax scores output probabilitiessum probabilitiescan try substitute value know scores will get different values sum values probabilities will equal onemakes sense sum probability equal one thereby turning logit scores probability scores can predict better finally softmax output can helpunderstand interpret multinomial logit model like thoughts please leave comments imported nltk python calculate bleu score ubuntu understand sentence level bleu score works donunderstand corpus level bleu score work code corpus level bleu score reason bleu score code expecting corpus level bleu score least code sentence level bleu score sentence level bleu score expect taking account brevity penalty missing word however donunderstand corpus level bleu score work help appreciateddr note pull latest version nltk develop branch order get stable version bleu score implementation long actuallyone reference one hypothesis whole corpus corpus bleu sentence bleu return value shown example code see sentence bleu actually duck type corpus bleu look parameters sentence bleu input sentence bleureferences list list str sentence string cat tokenized get list strings cat since allows multiple references list list string feline input sentence bleu comes corpus bleu list references parameterbasically list whatever sentence bleu takes references look doctest within nltk translate bleu can also take look unittest nltk test unit translate test bleu since sentence bleu imported bleuusing code lettake lookbetter position understand description algorithm wontry explain docstring clear things enough take look source find locally want improve question update question focuses one problem editing post closed days ago community reviewed whether reopen question days ago left closed original close reasonresolved classification problem like test available algorithms test performance tackling problem know classification algorithm listed please list answers provide full list classifiers listed may want look following question list scikit learn classifiers support predict proba accepted answer shows method get estimators scikit support predict probas method just iterate print names without checking condition get estimators classifiers regressors cluster etc classifiers modify like check classes implement classifiermixin versions use instead check respective reference docs using another alternative use moduleexample importing classifierscolaboratory code working code shaheer akram answer deprecated can get actual import code sklearn output output estimators trying use train loss standard optimizers worklonger answer will solve problems optimizers lack support optimizers requiregetting random forest trees sklearn want inspect trees python can dump trees list strings dump file nice formatting want make model predicts future response input signal architecture network questions thinkclear step back discuss role bias unit meant playbias unit meant allow units net learn appropriate threshold start sending positive activation since normally positive total input means positive activation example bias unit weight neuronneuronwill provide positive activation input adds greater background answers want parallelize single examples batch example situation cpus tried get bug losses gradient separate processes entirely ruins attempt still want essential multiproessing happens can optimizer step get around made totally self contained example error sure want seems works question line need work properly multiple cpus current issue cpu parallel job slower serially running one cpus available want know set python parallel cpus choose number even heursitics rough related links research torch will use multiple cpu parallelize operations serial maybe using multi core vectorization take simple example code used parallelize however cpus default configuration can use parallelizing operations cost unableimplementation details can run quick experiment shows overhead using multiple threads operations tends run faster parallelism take total cpu time multiplying number threads see single thread version efficient able parallelize experiment higher level running independent processes try single core process otherwise process will try use cpus will run slowly system overloaded modified hyperparameters example scripts intentionally way weights favor multi process remove line using ddp single node seems particularly advantageous unless model lot work particularly handled pytorch intraop parallelism large batches preferrably models less parameters operations meaning less gradients synchronize instead vectorized operations trying use adaboostclassifier base learner decisiontree tried svm kneighborsclassifier get errors classifiers can used adaboostclassifiersystematic method find base learners supported adaboostclassifier compatible base learnerfit method needs support sample weight can obtained running following code results following output classifier doesnimplement predict proba will set adaboostclassifier parameter algorithm samme shouldnot use svm adaboost adaboost use weak classifier using classifiers like svm will result overfitting classifier supports passing sample weights work svc one classifier specific error message traceback get can provide minimalistic reproduction case error text classification taskobtain document term matrix size million non zero entries less entries now want reduce dimensionality utilizing pca principal component analysis unfortunatelyhandle huge matrix store sparse matrix file matrix market format hoping use techniques pca anyone give hints useful libraries whatever programming language pca large scale matrix ease longhand pca words calculate covariance matrix first calculate eigenvalues eigenvectors covariance matrix want calculate pcs choose toppcs accounts variance obviously case give threshold priori set tiny variance values covariance matrix otherwise covariance matrix will sparse size impossible handle one single machine also loadings eigenvectors will extremely large stored sparse format thanks much help note using machineram cpu cores python toolkit scikit learn pca variants randomizedpca can handle sparse matrices formats supported never tried though disclaimerscikit learn development team edit sparse matrix support randomizedpca deprecated scikit learn truncatedsvd used stead see documentation details instead running pca try latent dirichlet allocation lda decomposes document word matrix document topic topic word matrix linkimplementation though google lda need specify fixed number topics similar principle components advance potentially better alternative hdp lda ywteh research npbayes learns number topics form good representation corpus can fit dataset memory seems like can also shouldnproblem running lda code number people scicomp forum pointed need computeprinciple components algorithms like lda algorithms will converge minimum description length representation data given number topics specifiedtechnique can handle large sparse matrix result shows simple pca outperfoms word vec intends simple pca outperforms lda suppose wouldnable compute principle components still can obtain reduced dimension version dataset matriximplemented simple routine matlab can easily replicated python compute covariance matrix input dataset convert dense matrix assuminginput sparse matrix like apply eigs function covariance matrix obtain firstdominant eigenvectors obtain pcs projecting zero centered matrix eigenvectorsreduced dimension versiond like implement gaussian kernel python just exerciseusing kernel kernel really donunderstand going expect function kernel called columnsmatrix parameters instead got calledx arguments looking examples things clearer missing code reading answer questions sites put together gaussian kernel call kernel precomputed compute gram matrix often abbreviateduse gram matrix first argument fit start following code calls svmtrain fit gram matrix computation used parameter fit done gaussiankernelgrammatrix uses gaussiankernel get radial basis function kernelx measure similarity based gaussian distribution centeredsigma model trained custom kernel predict custom kernel test data training data short use custom svm gaussian kernel can use snippet efficiency reasons svc assumes kernel function accepting two matrices samplesy will use two identical ones training return matrixk point level kernel function either implement gaussian kernel works generic way add proxy function like use like using gbm functiongbm package fit stochastic gradient boosting models multiclass classification simply trying obtain importance predictor separately class like picture hastie book elements statistical learninghowever function importance averaged classes anyone know get relative importance values think short answer page hastie mentions uses mart appears available splus agree gbm package doesnseem allow seeing separate relative influencesomethinginterested mutliclass problem probably get something pretty similar building onegbm classes getting importance measures models say classescmodelrest get importance model modelvs rest get importance model etc hopefully function helps example used data elemstatlearn package function figures classes column splits data classes runs gbm function class plots bar plots models digging gbm package calculates importance based errorreduction contained trees element result can accessed relative influence obtained taking sum errorreduction trees variable multiclass problem actually real use features give option specify number features plot also couldnuse faceting wanted plots sorted separately class used gridextra seems give results built classification specific svm particular high dimensional input results get quite satisfactory dimensional data can visualized along algorithmresults can get hanggoing idea aproach problem data dimensions intuitively playing around parameters really sure attack data answer nothing svms designed handle high dimensional dataworking research problem right now involves supervised classification using svms along finding sources internet experiments impact dimensionality reduction prior classification preprocessing features using pca lda significantly increase classification accuracy svm totally makes sense way svms work letm dimensional feature vector letaxrxmmx projected onto space lower dimension classesy linearly separablen corresponding classesx linearly separablem therefore original subspaces least separable projections onto lower dimensions pca help theory one discussion debates use pca svm link can change svm parameters example libsvm link parametersgamma crucially important classification success libsvm faq particularly entry link contains helpful tips among edit let just add data point recently another large scale experiment using svm pca preprocessing four exclusive data sets pca improve classification results choice reduced dimensionality original data simple diagonal scaling feature subtract mean divide standard deviation performed bettermaking broad conclusion just sharing one experiment maybe different data pca can help suggestions project data just visualization lower dimensional space using pca mds whatever makes sense data try understand learning fails think overfits think enough data possible isnenough information features solve task trying solve ways answer questions without visualizing data also telltask svm output may specific suggestions people make can try reducing dimensionality problem pca similar technique beware pca two important points assumes data applied normally distributed resulting data looses natural meaning resulting blackbox can live try another option try several parameter selection algorithms since svmalready mentioned might try approach changfeature ranking using linear svm used linear svm pre select interesting features used rbf based svm selected features familiar orange python data mining library will able code method less hour note greedy approach due greediness might fail cases input variables highly correlated case solve problem pca see might wantheuristic methods try select best possible combinations predictors main pitfall kind approaches high potential overfitting make sure bunch virgin data seen entire process model building test model data sure model ready fail donuse data validate another model will find new data set otherwise wonsure didnoverfit list selected papers parameter selection feature selection high dimensional genomic microarray dataone thing svm svm black box better figure mechanism generate data model mechanism data hand possible probably wouldnasking question wouldnbitter overfitting list selected papers parameter selection approach problem follows mean results get quite satisfactory classification rate training data unsatisfactory implies either classification rate test data unsatisfactory implies model overfits data course may mixture elements blind methods attack problem order gain insight problem may use visualization methods projecting data lower dimensions look models suited better problem domain understand example know data normally distributed can use gmms model datawrong trying see parameters svm gives best result problem model curve fitting worked similar problem couple years ago tons libraries algos used newton raphsonalgorithm variation genetic algorithm fit curve generate guess get result hoping real world experiment simple classification just compare output svm algos mentioned earlier reiterates process till result model svm case somewhat matches expected values note process take time based problem data size took months node beowulf cluster choosenewton raphsonmight good place start dataset reviews class label positive negative applying naive bayes reviews dataset firstly converting bag words sorted data text reviews final counts sparse matrix splitting data train test dataset applying naive bayes algorithm followstest test dataset pred variable giveswhether vectortest positive negative classtest shape rows dimensions length pred question want get words highest probability vector can get know words predicted positive negative class therefore get words highest probability vector can get importantance word fit model using coefs feature log prob attributes example prints top predictive words classes trouble maybe datascience exchange forum want post since achieved good result first stands positive class stands negative classstands proability going build odds ratio can demostrated equalwordword let know need demostration guys ratio greater means word likely occur positive texts negative text priors naive bayes model create dataframe storing words important words will hive ratio example odds ratio negative word damn means word twice likely occur comment class negative comparison positive class try use google colab get error randomly sometimes works sometimes error occur interface google drive solutions bug faq google drive operations can time number files subfolders folder grows large thousands items directly contained top level drive folder mounting drive will likely time repeated attempts may eventually succeed failed attempts cache partial state locally timing encounter problem try moving files folders directly contained drive sub folders similar problem can occur reading folders accessing items folder containing many items can cause errors like oserror errno input output error python ioerror errno input output error python can fix problem moving directly contained items sub folders ran error using little window bottom left corner colab notebook popped saying timeout occurred colab pro tried switching runtime hardware accelerator gpu runtime shape high ram fixed problem might one options together sure problem top answer might need simple functionality colab like order efficiently move files create sub folders achieve reduced folder contents caneven listfolder without timeout error occurring may just need upgrade colab pro gain advanced runtime options powerful computing environment another possible solution save files different new folder directory think bob smithsolution one best solutions problem just showing variation original solution worked face almost regularly along dialogue google drive timeout occurred recentlyinfo sometimes run code cell three times error doesnoccur anymore sometimes run cell much times successfully execute problem always happens data loading expected data loading cell usually splitting item transforms batch transforms defined add extra time cost running cell multiple times instead running data loading cell multiple times runcommand bash using method different cell usually look file known file name training directory pass pattern grep pipedlike cell executes successfullynumber tries shows desired filename output data loading cell runs successfully time can begin training important note runningentire training directory without grep will always fail training directory sometimesfiles ugly hack works every letcallo number elements belonging classes spreadplane example two classes linearly separable possible draw straight line perfectly dividesos side line determine general whether two classes linearly separable interested algorithm assumptions made regarding number elements distribution algorithm lowest computational complexity course preferred found convex hullpointspoints separately just need check whether segments hulls intersected whether either hull enclosed two hulls found totally disjoint two data sets geometrically separable since hulls convex definition separator straight line efficient algorithms can used find convex hull qhull algorithm basednlogquickhull approach think perform line line intersection tests set segments sweeplinenlogoverall seems efficientnlogalgorithm possible type approach also generalise generalway separation testsgroups objects forming convex hull performing intersection tests group also work higher dimensions although intersection tests start become python octave julia etc letsay set pointsminimize following conditions matrix set points minimizing effectively means donneed actually optimize objective function necessary find sets linearly separable end defining separating plane case interested working examplemath details checkve algorithmquite sure will work shows problemcomplete another post claims wouldnsurprised can done efficiently separating line exists will possible move rotate hits twoes oneonetherefore can simply look possible lines intersect twoes oneonesee dividing linesn pairs iterateelements seees one sides total time complexityn linear perceptron guaranteed find separation one exists seesure computational complexity formal terms technique successfully applied large problems covering wide range domains computing linear svm determining side computed plane optimal marginals point lies will tell points linearly separable overkill need quick one solution many existing svm libraries will mentioned elkamina linear perceptron guaranteed find solution one exists approach efficient large dimensions computationally effective way decide whether two sets points linearly separable applying linear programming code example solve using perceptron matlab general problemhard good approximate solutions likemeans clustering perceptron svm support vector machines can tell two data sets separable linearly svm can find optimal hiperplane separability besides can workdimensional vectors points used applications face recognition recomenddeep topic trying use ordinary least squares multivariable regression says attribute ols statsmodels formula api library following code lecture udemy code follows error follows just completeness code look like use import tried mentioned methods import works run next piece code gives error typeerror ufunc isfinite supported input types inputs safely coerced supported types according casting rule safe getting mentioned error can solve specifying dtype worked working solution tried today use import rest fix mentioned work work josef mentions comment use ols instead ols ols truly existbrief description problem plot roc graphs several classifiers present great auc meaning classification good however test classifier computemeasure get really low value know issue caused class skewness dataset now discover two options deal went first option solved issuemeasure satisfactory now question methods preferable differencess using python scikit learn library weighting cost sensitive thresholding valid forms cost sensitive learning briefest terms can think two follows essentially one asserting cost misclassifying rare class worse misclassifying common class applied algorithmic level algorithms svm ann random forest limitations consist whether algorithm can deal weights furthermore many applications trying address idea making serious misclassification circumstances know want make sure classify specific classes even imbalanced settings ideally want optimize cost parameters model parameter algorithm returns probabilities score thresholding can applied model built essentially change classification threshold appropriate trade level typically can optimized generated curve evaluation metric limitation making absolute trade offs modification cutoff will turn decrease accuracy predicting class exceedingly high probabilities majority common classes likely success method also algorithm independent provided algorithm returns probabilities sampling another common option applied imbalanced datasets bring balance class distributions essentially two fundamental approaches sampling extract smaller set majority instances keep minority will result smaller dataset distribution classes closer however discarded data may valuable also beneficial large amount data sampling increase number minority instances replicating will result larger dataset retains original data may introduce bias increase size however may begin impact computational performance advanced methods additional methods sophisticated help address potential bias include methods smote smoteboost easyensemble referenced prior question regarding imbalanced datasets csl one note regarding building models imbalanced data keep mind model metric example metricsmeasures dontake account true negative rate therefore often recommended imbalanced settings use metrics cohenkappa metric trying solve problem think cdetermananswer covers thoroughlybest first define measures apart one metrics like cohenkappa find extremely useful just compute common metrics precision recallmeasure per classes problem scikit learnclassification report quite conveniently want visual output can use one deepchecks built checks disclosureone maintainers using per class metrics alerted beginning model performing certain classes ones running using cost sensitive learning let know managed balance performance classes created simple neural network python theano estimate persons age based spending history selection different stores unfortunately particularly accurate accuracy might hurt fact network knowledge ordinality network relationship age classifications currently selecting age highest probability softmax output layer considered changing output classification average weighted probability ageg given age probabilities age age age solution feels sub optimal better implement ordinal classification neural networks better machine learning method can implementedg logistic regression problem came previous kaggle competition thread references paper mentioned comments idea say age groups instead one hot encoding using softmax objective function can encodeclasses use sigmoid objective example encodings net will learn orderingsfeeding dynamic shaped tensor usingshape none vector size need turn list tensors shape vector size usinglistraises valueerror length first dimension knownnonetrying get around using another situation another function can also turn variable feed list tensors thanks advance donthink can unpack tensor argument num unspecified non inferrable documentation says raises valueerror num unspecified inferred something tensorflowinternal design operations like unpack tread yaroslav bulatov explained operations like unpack compile tensor tensor ops graph construction time hence tensorflow needs know specific value num pass compiling althoughtry get around using tensorarray see following code illustration tensorarray class wrapping dynamically sized arrays tensors initialize tensorarray object application tensorarr dynamic size true infer shape false set dynamic size true infer shape false since shape placeholderpartly defined access unpacked element evaluation time note trying access unpacked element index value boundable pass compilingget error runtime suggesting index bound additionally shape unpacked tensor tensorshape none since shapepartially determined evaluated probably requires static number output tensors can establish maximum number tensors can use outputs followingtrying solve issue couldnm trying run code every format can imagine arcgis pro softwarecanfind error message issue similar issues seems data files missing get error also tried arcgis pro got make sure pyproj error rather geopandas runtime error can sure error due pyproj just conda remove pyproj install pip least works today july resintalled miniconda conda remove pyproj work instead pip uninstall pyproj pip install pyproj makes everything fine problem problably within pyproj instalation anaconda windows platform just like stephen said solution edit path located lib site packages pyproj correct path anaconda library share make sure full path complete may contain username etc also needed change change worked yes change necesary restart spyder whatever use initial crs defined ran problem passed epsg command epsg show init epsg first step transforming gdf init epsg working arcgis also check properties whether initial epsg definedusing pycharm use combination stone shiremark dorregarayaccording stone shi provespyproj err used pycharm settings reinstalled pyprojpyproj err pycharm settings reinstalling pyproj help editedanaconda lib site packages pyproj dorregaraytest runtime error test upgrading pyproj geopandas fixed issue using geopandas try work redefine geodataframe define initial geo referential finally convert good one donforget drop nan came across error working python version geopandas version solved using following insteadinit epsg can force reinstall pyproj pip directly using pip install upgrade force reinstall pyproj instead uninstalling reinstall will also uninstall dependent librariesiusing scikit learngridsearchcv iterate parameter space tune model specificallyusing test different hyperparameters neural network grid follows problem end running redundant models hidden num hidden layers set will run model hidden layers units another units another units models equivalent since hidden layer highly inefficient means need write code remove redundancy results way prevent parameter combinations perhaps passing tuple parameters sklearn documentation suggests two parameter grids something like gridsearchcv allows pass list dictionaries params param grid dict list dictionaries dictionary parameters names string keys lists parameter settings try values list dictionaries case grids spanned dictionary list explored enables searching sequence parameter settings can specify dictionaries certain subdictionaries original dictionary thus avoid irrelevant combinations splitted training dataset train validation data created dataloaders shown however want limit modeltraining thought splitting datamaybe folds performing cross validation however know combine datasets dataloader splitting just wrote cross validation function work dataloader dataset code hope helpful order give intuition correctness see output take look cross validation mnist dataset pytorch sklearn question asker implemented kfold crossvalidation take especially look answer answered nov doesnrely random split use subsetrandomsampler way sampler dataloader will always sample train valid indices generated kfold function randomly trying build model takes multiple inputs multiple outputs using functional api followed create code shapes input data follows train data new train data train labels new target labels code runs steps raises error jupyter notebook complete code provide validation data correct format like train pass input data verb predicate object example sentence like going seminar nlp sxsw austin next month can extract following meaningful sub sentences sentence going seminar going seminar nlp going seminar nlp sxsw going seminar sxsw going seminar austin going seminar nlp next month etc please note deduced sentences will nlp seminar sxsw next month although true donneed part problem generated sentences strictly part given sentence can approach solving problem thinking creating annotated training data set legal sub sentences sentence training data set write supervised learning algorithmgenerate model quite new nlp machine learning great guys suggest ways solve problem can use dependency parser provided stanford corenlp collapsed output sentence will look like last sentence output optional can remove one parts essential sentence optional parts belong prepositional modifierg prep prep advmod tmod etc see stanford dependency manual example remove modifier output will get going seminar nlp sxsw austinpaper titled using discourse commitments recognize textual entailment hicklal discusses extraction discourse commitments sub sentences paper includes description algorithm level operates rules used rte may minimal levels deduction output text simplification maybe related area look following paper rgemulla publications text simplification see online demo subsentences likely suffer data sparsity also doubtful write really clean unambiguous definition subsentence candefine canget annotators annotate want check loss values training time can observe loss iteration far havenfound easy way scikit learn give history loss values find functionality already within scikit plot loss way plotgreat simply fetch final loss values end aware fact solutions closed formusing several classifiers analytical solutions logistic regression svm anyone suggestions couldnfind good documentation directly fetching loss values per iteration hope will help someone future code will take normal sgdclassifier just linear classifier intercept verbose flag will split get loss verbose printing obviously slower will giveloss print use best way proceed will need hacky stuff parsetrue documentation doesnmention anything attribute check source code may notice one mlpclassifier base classes basemultilayerperceptron actually defines attribute loss curve stores values iterarion get values list plotting trivial using library notice attribute present using stochastic solver just adapted updated answer oneraynyday using context manager way elegant defining context manager usage wrote following code test small datayx matrixx numpy arrays small data algorithm works give right results run program hours stuck way laptop specsmemory coresvm training can arbitrary long depends dozens parameters general basic smo algorithmn case datapoints run number operations proportional realy huge number options know visualize tensorflow graph training tensorboard now possible visualize just forward part graph training operator defined reasonaskinggetting errorlike inspect graph find gradient tensor flow pun intended broken yes can visualize graph try simple scriptsee can simply create session just write graph filewriter anything using regression algorithms random forest extra trees adaboost bagging scikit learn compare interpret use feature importance though bagging decision tree look available question anybody know get feature importances list bagging greetings kornee talking baggingclassifier can used many base estimators feature importances implemented model independent methods computing feature importances see scikit learn doesnuse case decision trees base estimators can compute feature importances yourselvesjust average randomforestclassifer computation internally extending charlesg postedsolution overloading baggingregressor work baggingclassifier correctly handles max features though suppose wonwork exactly bootstrap features true supposesklearn evolved lot since couldnget work constructor doesnseem entirely necessary reason pre specify feature importances attribute none however shouldneven exist fit called anyway encountered problem average feature importance interested furthermore needed feature importance attribute exposed bagging classifier object necessary used another scikit learn algorithm chose overload baggingclassifier gain direct access mean feature importance coef parameter base estimators little confused use insert batchnorm layer models see several different approaches instance batchnorm layer followed immediately scale layer cifar example provided caffe batchnorm used without scale following batch norm param use global scale changed train test phase one use batchnorm layer caffe follow original paper batch normalization followed scale bias layers bias can included via scale although makes bias parameters inaccessible use global stats also changed training false testing deployment true default behavior note first example give prototxt deployment correct set truesure shared parameters made pull request improve documents batch normalization closed wanted modify never got back note thinkmult batchnorm longer required perhaps allowed althoughfinding correspondingnow batchnorm add scale layer caffe reason caffe batchnorm layer subtracts mean input data divides variance include parameters respectively scale shift normalized distribution conversely keras batchnormalization layer includes applies parameters mentioned using scale layer parameter bias term set true caffe provides safe trick reproduce exact behavior keras version trees depth top extra trees use ridge regression trained model several hours pickled trained model entire class object later use however size saved trained model bigway reduce size saved model configuration pickle helpful alternative pickle can try using joblib compression parameter compress higher value means compression also slower read write times using value often good compromise can use python standard compression modules zlib gziplzmause can just specify format specific extension example information see link best case binary trees will nodesassuming one node cost byte store thinkpretty decent size comparisionclassification using rparttree model trained accuracy tree model read tutorial prune tree cross validation accuracy rate pruned tree still want knowwrong pruned tree can prune tree model using cross validationthanks used minimum cross validated error tree alternative use smallest tree within standard error best tree one selecting reason givenestimates error smallest tree within standard error just good job prediction best lowesterror tree yet fewer terms plot cost complexitytree sizepruned tree via find tree left one minimum error whosevalue lies within error bar one minimum error many reasons pruning affecting fitted tree example best tree one algorithm stopped according stopping rules specified order select stop words example built functioncountvectorizervectorized corpus returns list term frequency pairs distinct term corpus countvectorizer extracted little asarray ravel dance needed work around quirks built found faster way based ando saabasanswer outputi model fit based historic information last month now like predict using model current month try invoke following code get following error notes predict generic function will invoke specific predict function based first input argument case will fit modelinfo label random forest therefore predict method invoked will caret documentation info summary source code generating model invoking note execution time generating model hours save object reusing data set training model following structure now testdata will following structure variable structure just factor variables different levels variable new values example acuity model levels testing data levels donupfront way know possible level variables advice david think found stats package use namespace notation invoking functions caret package recommendation creating user packages equivalent predict function caret package internal function invoked external application way invoke function using generic predict function stats package based class first input argument predicted predict fit testdata readmit identifies particular predict function will invoked particular case class function train call actually function method used example etc explained detail caret documentation section extracting predictions class probabilities therefore notation works functions package particular one predict cases necessary explicitly load library internally can invoke solution just adding following line invoking predict function error disappears based answer david leal tried loading library caret calling predict function help trying bit realized load library contains model case call library kenlab support vectors trying use higher library meta learning issues understanding copy initial weights mean docs say copy initial weights true weights patched module copied form initial weights patched module thus part gradient tape unrolling patched module set false actual module weights will initial weights patched module useful maml example doesnmake much sense following example weights patched module copied form initial weights patched module doesnmake sense context manager initiated patched module exist yet unclear copying copying something want also unrolling patched module make sense usually unroll computaiton graph caused loop patched module just neural net modified library unrolling ambiguous also isntechnical definition gradient tape also describing false sayinguseful maml isnactually useful doesneven hintuseful maml overallimpossible use context manager explanations examples flag precise terms really valuable related short version call fmodel diffopt expected inner loop fmodel will iteratively receive input compute output loss loss will called time timenew tensor computed using previous ones full graph allowing compute gradients process point user calls backward tensor regular pytorch gradient computation accumulation will start way allowing gradients propagateparametersmomentum passed tensors requiring gradients creation time version fmodelparameters time copy original model parameters copy initial weights true provided default time will clone detachversion modelparameters will severe connections original model copy initial weights false provided time will cloneversion modelparameters thus will allow gradients propagate original modelparameters see pytorch doc clone terminology clarifications gradient tape referring graph pytorch usescomputations propagate gradients leaf tensors requiring gradients point cut link leaf tensor requiring parameters copy initial weights true case original wongradient tape anymore meta computation unrolling patched module refers part meta computation pytorch going timestarting latest ending earliest higher doesncontrol process just regular pytorch gradient computation higher just charge new timeparameters created previous ones time long version letstart beginning main functionality functionality really higher library unrolling modelparameter optimization differentiable manner can come either form directly using differentiable optimizer stateless model fmodel existing model gives optimizer diffopt fmodel summarized difference training model original part instead time fmodel use new ones next step previous ones still preserved time available called timeinclusive notice time doesnchange process just every time fmodel applied input will use latest version parameters currently now exactly time created depends copy initial weights copy initial weights true time clonedetachparameters model otherwise clonedetachmeans meta optimization step original modelparameters will actually accumulate gradients copy initial weights false maml want optimize modelstarting weights actually need get gradients meta optimization step think one issues higher lack simpler toy examples demonstrate going instead rushing show serious things examples let try fill gap demonstrate going using simplest toy example come model weight multiplies input weight produces output thinkless clear means now firstlike make notation clear specially respect indices wrt inner time step outer time step also known episodes beginning training neural net params held insidemodule sake explanation specific tensor base model will denoted will updated place operation important sinceplaceholderouter outer step values normal meta learning outer optimizer want emphasizetensor normal pytorch neural net base model changing place outer optimizer like adam effectively training initialization outer optimizer will use gradients wrt tensor update whole unrolled inner loop process say copy initial weights false mean will gradient path directlywhatever value currently usually context manager done inner loop outer step donewillouter current step particular code one copy initial weight false might look confusingfamiliar clonemaking copy current weightunusual thing clone also remembers gradient history tensor came clone identitymain use add extra layer safety user dangerous place opsdifferentiable optimizer assuming user never anything crazy place ops one theory remove clone reason confusing imho copying pytorch clinging automatically block gradient flows real copy totally separate tensor clone copy initial weights copy initial weights true really happens weights cloned detached see code eventually runs runs copy tensor assuming safe copy note detach allocate new memory shares memory original tensor clone neededsafe usually wrt place ops copy initial weights copying detaching current valueusuallyouterusual meta learning inner adaptation loop intended semantics copy initial weight initial weight simply meanimportant thing note intermediate tensors net inner loop denoted notationinner also things usually meta learningw gets update place outer optimizer note outer optimizerplacefreeing graphs never take derivate gradrespect initial valuesomething initially thoughtstarting dive deploying predictive model web app using flask unfortunately getting stuck starting gate pickled model created per tutorial also made templates running gives error pickler main module program getting involved neuralnetwork modelconfused adding class definition class neuralnetwork object pass specific exceptiongetting refers attributes mainmostly red herringpretty sure issue actually dumped instance pickle dump actual code classes functions names includes name module one defined can find dump class defined modulerunning script will dump name main module name sincepython uses name main module seen name main boilerplate code run class will saved main neuralnetwork rather python will look class main module sincepickle data tells lookgetting exception attributes main solve probably want changedumping data instead running probably run module import model get modulenormal name suppose main blocksuper ugly awkward probably also need avoid recreating dumping instance unconditionally model imported since needs happen load pickle file assume whole point pickle avoid recreating instance scratch remove dumping logic bottom add new file like dump neuralnetwork using script will correctly identify model module class defined loading code will able import module make instance class correctly current fix issue defining empty neuralnetwork class main module loading object probably bad solution instance get loading pickle file will instance new class original one will loaded attributes old instance wonmethods class variables set isnissue classshown probably will kind objectcomplicated using keras library build neural network pickle will work pickle works fine model built using scikit libraries save neural network model using json keras provides ability describe model using json format json function can saved file later loaded via model json function will create new model json specification reading self organizing maps understand algorithm think however something still eludes interpret trained network actually use say classification task done clustering training data material seem find printed digital focuses training algorithm believe may missing something crucial regards soms mainly dimensionality reduction algorithm classification tool used dimensionality reduction just like pca similar methods trained can check neuron activated input use neuronposition value actual difference ability preserve given topology output representation som actually producing mapping input spacereduced spacecommonlattice makingdimensional space perform actual classification transform data mapping run classificational model svm neural network decision tree etc words soms used finding representation data representation easy analyzis humans mostly dimensional can plotted easy classification models great method visualizing highly dimensional data analyzing going classes grouped geometricaly etc confused neural models like artificial neural networks even growing neural gas similar concept yet giving direct data clustering serve different purpose course one can use soms directly classification modification original idea requires data representation general work using classifier top edit least ways visualizing trained som trying implement following softplus functiontried math numpy float data type whenevergets large result inf can assist successfully handle function large numbers tldr explanation relation one can use safe implementation mathematically sound works math numpy functions use sincelog explog expx simple stable implementation fact log expimplementation makes errors smallernever overflows particularerror approximation will much smaller float resolution impossible even measure computer use code work arrayscurrently using slightly inefficient clean vectorizedusing tensorflow can simply use data represents position movement facial features sample additional sub sequences smaller length dataset order add redundancy dataset reduce overfitting case know starting ending frame sub sequences order train model batches time series need length according many papers literature padding affect performance network example original sequence subsequences considering network trying anticipate action meaning soonaction threshold goest tmax will predict action will matter padding goes option zerossubstitute original values option zeros end moreover time series missing number frames known ones meaning frames donknow whether taken secondsetc need padded subsequences even taken best practice padding case thank advance powerful attribute lstms rnns general parameters shared along time frames parameters recur time frames parameter sharing relies upon assumption parameters can used different time stepsparagraph short padding zeros end theoretically change accuracy model used adverb theoretically time step lstmdecision depends cell state among factors cell state kind short summary past frames far understood past frames may missing case think little trade rather pad zeros end doesncompletely conflict underlying assumption rnnsconvenient implement keep track implementation side know tensorflow calculates loss function give sequences actual sequence size sample assumingimplementing option donknow whether implementation option though betterpadding zeroes beginning paper suggests effects padding lstms cnns though post padding model peakedefficiency epochs started overfitaccuracy way less pre padding check table accuracy pre padding padding zeroes beginning around post padding padding zeroes end around case sequences variable length pytorch provides utility function torch will limit rnn inspecting actual sequence stop padded tokentrying use tensorflow backend yesterday can use today use show error messagetrying import kerascode shows error therefore using tensorflow version keras version yesterday can run today seems canwrong version import keras tensorflow today edit use tensorflow import keras output want using tensorflow backend doesnshow load import segmentation modelsshows error use import keras like solution problemtested colab donneed install specific version tensorflow keras versionok runtf however colab need restart kernel see effect run kaggle kernel donneed restart kernel see colab will auto restart kernel restarting run following code new cell kaggle kernel specifying importing segmentation models alone worked colab tried lot answers none worked reason error attributeerror module attribute strategy supports merge call case tensorflow keras installed device just match versions worked getting error message upgrading tensorflow downgrading temporary working fix pip install tensorflow network two time series inputs one input fixed vector repeating every time step elegant way load fixed vector model just use computation can create static input using tensor argument described jdehesa however tensor keras tensorflow variable can create follows edit apparently answer work nowadays anyway see creating constant value keras related answer looking source havenable find reference docs looks like can just use input pass constant theano tensorflow tensor will wrap tensor actually like extend metadata can use keras layer something add come compile model need give constant input input otherwise graph disconnects train can just feed data donneed constant layer anymore found matter tryusually easier just use custom layer take advantage power numpy edit corresponding github issueusing tensorflow python interface implementlearning agent function approximation trained using stochastic gradient descent iteration experiment step function agent called updates parameters approximator based new reward activation chooses new action perform problem reinforcement learning jargon way can without reinforcement learning jargon courseconsidered obvious solutions just hardcode gradients easy really simple approximatorsusing now really inconvenient experimenting different filters activation functions big convolutional networkreally like use optimizer class possible call environment simulation within agent system make mine complicated remove lot modularity structure donwantread api whitepaper several times canseem come solution trying come way feed target graph calculate gradients couldncome way build graph automatically turns isnpossible tensorflow yet think complicated implement new operator havenusedcouple years tensorflow source looks little intimidating better switching something like torch imperative differentiation autograd instead symbolic differentiation thanks taking time help trying make concise edit searching came across previously asked questionlittle different mine trying avoid updating lstm network twice every iteration torch doesnanswers yet code helps right now want difficult tensorflow best bet bite bullet call run multiple times cost recomputing activations however aware issue internally prototype partial run solution works timeline completion right now since truly satisfactory answer might require modifying tensorflow also make github issue see anyone else anything say edit experimental support partial run nowtrying run keras first time installed modules tried run versions using can get keras run tensorflow issue kerasprobably using import statements can resolve issue details check see keras backend documentation information using tensorflow use say astonishment seems takes categorical data uses continuous data features categorical example can see following tree please note first featurepossible values found class uses tree class binary tree limitation sklearn anyone knows way missing use tree categorically know better task need categories currently using one hot vectors data sample original data looks likef encoded strings integers sklearn accept strings surprised turns sklearndecision tree handle categorical data indeed github issue june still open update now closed continued issue still resolved problem coding categorical variables integers done imposes order may may meaningful depending case example encode low medium high since low medium high call categorical variables ordinal although still implicitly making additional possibly undesired assumption distance low medium distance medium high impact decision trees importance approach fails completely cases like say red green blue male female since claim meaningful relative order non ordinal categorical variables way properly encode use sklearndecision tree use onehotencoder module encoding categorical features section userguide might also helpful time series data followed like add simple way linear trend intercept onto graph also like compute trend conditional data sayfound answers include statsmodels first answers might date pandas improved now includes ols component second statsmodels appears estimate individual fixed effect time period instead linear trend suppose recalculate running quarter variable comfortable way simplest way possible estimate trend add predicted values column data framequick example using general create matplotlib figure axes object ahead time explicitly plot dataframe still axes object around use directly plot line understand random state used various sklearn algorithms break tie different predictors trees metric value say example gradientboosting documentation clarify detail like else seeds used random number generation say randomforestclassifier random number can used find set random features build predictor algorithms use sub sampling can use random numbers get different sub samples can seed random state playing role multiple random number generations mainly concerned far reaching effect random state variable can value make big difference prediction classification regression yes kind data sets care stability quality results can make big difference best choose random state difficult one gridsearch without intuition specially data set onecan take hour motive steady result evaluation models cross validation scores across repeated runs effect setuse algorithms use random state none say using random state value gradientboosted classifier cross validating find goodness model scoring validation set every time satisfied will train model whole training set apply test set now full training set instances smaller training sets cross validation random state value can now result completely different behavior choice features individual predictors compared happening withinloop similarly things like min samples leaf etc can also result inferior model now settings approach safeguard yes choice random seeds will impact prediction results pointed fourth question impact really predictable common way guard predictions happen good bad just chance train several models based different random states average predictions meaningful way similarly can see cross validation way estimate true performance model averaging performance multiple training test data splits else seeds used random number generation say randomforestclassifier random number can used find set random features build predictor algorithms use sub sampling can use random numbers get different sub samples can seed random state playing role multiple random number generations random state used wherever randomness needed code relies random number generator never use functions like built random state argument passed class function far reaching effect random state variable can value make big difference prediction classification regression yes kind data sets care stability quality results good problems depend much random state can make big difference best choose random state difficult one gridsearch without intuition specially data set onecan take hour choose instead try optimize aspects classification achieve good results regardless random state motive steady result evaluation models cross validation scores across repeated runs effect setuse algorithms use random state none use control random number generation scikit learnused sklearn need control set instead say using random state value gradientboosted classifier cross validating find goodness model scoring validation set every time satisfied will train model whole training set apply test set now full training set instances smaller training sets cross validation random state value can now result completely different behavior choice features individual predictors compared happening withinloop similarly things like min samples leaf etc can also result inferior model now settings approach safeguard can know training data enough machine learninganswers mostly state data better lot model selection maybe sacred can help among things sets can log random seed evaluation experiment tune reproducibility fix temporarily random state repeat experiment different random states take mean results production system remove random state setting nonei svmnow like plot classification space machine found examples internet canseem make sensescript follows get plot command work like graph something like isnsupported secondly function seems need data frame input working vectors can use kernlab packageusing logisticregression model train estimator scikit learn features use mostly categorical labels therefore use dictvectorizer labelencoder respectively encode values properly training part fairly straightforwardproblems test part simple thing use predict method trained model get predicted label however processing need afterwards need probability possible label class particular instance decided use predict proba method however get different results test instance whether use method instance accompanied others next code reproduces problem following output obtained can seen values obtained predict proba instancetest change instance otherstest alsotest just reproducestest adds one instance equal lasttest probability values change happen also find really strange probabilitiestest shouldnsum now instead using predict proba use decision function get consistency values obtained need problem get negative coefficients even positives ones greater use values predict proba change way understanding correctly values mean thanks advance help give update suggested changed code also print encodedtesttesttest shapes doesnappear problem encoding consistant instances test sets indicated questioncomments error caused bug implementation version scikit learn using problem solved updating recent stable version implement neural network cost function matlab symbols representproblems nested sums bias nodes general complexity equationalso struggling matrices weights one connecting inputs hidden layer one connecting hidden layer outputsattempt far define variables hypothesis using weights struggling just keep writing things like realisingwrong can life work nested sums include input matrixcomplicated create equation matlab thank much note code strange colours stackoverflow doesnknow programing matlab also wrote code straight stackoverflow may syntax errors interested general idearather just code copy paste reason havenbothered semi colonsimplemented neural networks using error function onementioned unfortunately havenworked matlab quite timefairly proficient octave hopefully can still find useful since many functions octave similar matlab sashkello provided good snippet code computing cost function however code written loop structure like offer vectorized implementation order evaluate current theta values need perform feed forward forward propagation throughout networkassuming know write feed forward code sinceconcernedtheta errors let vector representing results forward propagationve performed feedforwardneed carry equation noteimplementing vectorized manner will compute part summation concerning now must add regularization term typically arbitrary number theta matrices case can just perform several sums get notice sumworking second column rest first column will correspond theta values trained bias unitsvectorized implementation computationhope helps think hthetaarray note need add biasforward cost function calculation showed array dimensions step assumption two nodes input hidden output layers comments code understand question nothing neural networks basically asking make nested sum matlab donreally want type whole equation first part first sum will look like jtheta result works number hidden layers following extremely simplified dataframe represents much larger dataframe containing medical diagnoses problem machine learning need randomly split dataframe three subframes following way works dataframes windy solution using train test split stratified splittingdataframe featuressingle columned dataframe labels python function splits pandas dataframe train validation test dataframes stratified sampling performs split calling scikit learnfunction train test split twice complete working example consider dataset label upon want perform stratification label distribution original dataset say foo bar baz now letsplit dataset train validation test subsets using ratio split retains distribution labels see illustration example dataset now letcall split stratified train val test function get train validation test dataframes following ratio three dataframestrainvaltest contain original rows sizes will follow ratio three splits will distribution label namely foo bar baz split train validation test ratioplaying onelogistic regression classifier using scikit learn sklearn large dataset slow run onealso like study learning curve training proceeds like use batch gradient descent train classifier batches say samples way using sklearn abandon sklearn roll far yes realize better evaluate new data just quick smoke test havengotten far creating learning curves can one simply run fit repeatedly subsequent subsets training data function train batches documentation google fairly silent matter thanks want batch gradient descent stochastic gradient descent batch learning means learning entire training set onedescribe properly called minibatch learningimplemented fits logistic regression model give option loss log sgdclassifier like logisticregressionneed wrap estimator onevsrestclassifier onetraining box train minibatches use partial fit method instead fit first time around feed list classes classes may present minibatchpassing classes minibatch isnnecessary doesnhurt either makes code shorter trying build sentiment analyzer using scikit learn pandas building evaluating model works attempting classify new sample text code errorsure issue classify method create brand new vectorizer process text want classify separate vectorizer used create training test data model thanksfitted vectorizer throw away doesnexist past lifetime vectorize function instead save model vectorizetransformed classify function doncreate new vectorizer instead use onefitted training data save vectorizer pickle joblib file load want predict can save model vectorizer use later working image segmentation machine learning project like test google colab training dataset images mostlyneed upload python numpy array project also thousands corresponding mask files upload currently exist variety subfolders google drive unable upload google colab use project far attempted using google fuse seems slow upload speeds pydrive given variety authentication errors using google colabexample code partpydrive waycode somewhere uploading folder structure many files time can put data google drive mount drive done let explain steps step transfer data google drive step run following code mount google drive step run following line check can see desired data mounted drive step now load data numpy array follows exel files traintest data edit downloading data drive colab notebook environment can run following code steps upload large dataset google colab openload etc used dropboxcan compress dataset zip rar file later unizp downloading google colab using command zip file first upload google drive see simple command unzip example step mount drive running following command will output link click link hit allow copy authorization code paste box present colab cell text enter authorization code written top process just giving permission colab access google drive step upload folder zipped unzipped depending size folder google drive step now work way drive directories files locate uploaded folder zipped file process may look something like current working directory colab start will content just make sure run following command cell will show current directory pwd stands print working directory use commands like list directories files directory command move directories locate uploaded folder uploaded zip file just like ready get hands dirty machine learning model hopefully simple steps will prevent spending much unnecessary time figuring colab works actually spending majority time figuring machine learning model hyperparameters local machine google drive github need click mount drive option pane left side notebookget access files stored drive select file right click copy path refer use python import methods import files path example importing multiple files onemay need write function many ways might want push data github repository google colab code cell can run git clone repo git can upload data google drive code cell content drive use can visit see worksbeginner keras just write toy example reports typeerror code error follows code error can deal input rnn layer shape num timesteps num features number timesteps variable unknown number features fixed specified beginning therefore need change shape input layer consistent rnn layer example also need change shape input data consistent input shape specified num samples num timesteps num features side note define rnn layer simply using simplernn layer directly think todayanswer clear however complete key thing input doesncontain num features make embedding layer next input use also works simple python code machine learning project relatively big database spontaneous speech started train speech model sincehuge database let work overnight morning woke saw mysterious killed line terminal nothing else error message something work code run hours whole process really donunderstand went wrong killed fixfrustrating lose hours computingmacos mojave betamatter thank advance faced issue updated macversion catalina big sur trying run binary facing killed issue able resolve issue following steps referred apple stackexchange post steps try change node version case two data sets training testing one column contains text interest job hand usedpackageprocess text column training data set removing white spaces punctuation stop words stemmed corpus finally created document term matrix grams containing frequency count words document took pre determined cut say kept terms count greater following train say glmnet model using dtm dependent variable present training data everything runs smooth easy till now however proceed want score predict model testing data new data might come future specifically trying find create exact dtm new data new data set similar words original training data terms count zero fine want able replicate exact dtm terms structure new corpus ideas thoughtsmany understand correctly made dtm want make new dtm new documents columnsterms first dtmcase matter sub setting second dtm terms first perhaps something like first set reproducible now keep terms testing data present training structure training documentscolumns though many containschaunw notes along lines want trying apply random projections method sparse dataset found papers tutorials johnson lindenstrauss method every one full equations makes meaningful explanation example document johnson lindenstrauss unfortunately document can get idea implementation steps algorithmlong shot anyone can tell plain english version simple pseudo code algorithm can start dig equations suggestions example understand algorithm reading paper concerning johnson lindenstrauss far understand first need constructmatrix fill entries randomly probability edit okay think started get matrix mxn want reducemxk need construct matrixnxk dimension fill respect probability constructingll simply matrix multiplication axr find reduced matrixdonneed full matrix multiplication elementdonneed calculation simply skip face just add columnjust subtract calculationsimply use summation rather multiplication findmakes method fast turned neat algorithm although feel stupid get idea idea right however understand random project rows matrixunit length believeapproximately normalizing sqrtnormalize away factunit vectors isnprojectionnearly projections rows arenorthonormal within much higher dimensional space quite nearly fact dot product two vectors choose will pretty close generally good approximation actually finding proper basis projection mapping high dimensional data low dimensional datagiven statement theorem latter paper simply scalar multiplication followed matrix multiplication data vectors rows matricesauthor points section donneed use full matrix multiplication algorithm dataset sparse sparse random projections will work options option step apply structured dense random projection called fast hadamard transform typically used special projection fast compute otherwise properties normal dense random projection step apply sparse projection densified data sparse random projections useful dense data optionapply svd sparse data data sparse structure svd better random projection preserves distances points svd preserves better distances dense regions practice meaningful also people use random projections compute svd huge datasets random projections gives efficiency necessarily best quality embedding low dimension data structure use random projections optiondata points svd little error use svd rest points use random projection optionuse random projection based data points easy understand going looks something like still looking solve problem write message can give pseudocode way think random projection just random pattern dot product data point pattern gives overlap two data points overlap many random patterns points similar therefore random projections preserve similarity using less space also add random fluctuations pairwise similarities jlt tells make fluctuations eps need logdimensions good luckpackage perform random projection using johnson lindenstrauss lemma randproas may know many things changed opencv comparision opencv old first version old days train svm one use third version api cvsvmparams cvsvm surprisingly documentation page svm tells everything really use least make moreover looks like one internet uses svm opencvcurrently managed get following can please provide information rewrite actual training opencv opencvdefinitely different difficult porting code opencvissue unfortunately api changes since answer posted like update accordingly know old post came across looking solution tutorial extremely helpful update question can answered facts citations editing post closed years ago set books objects classs book defined following title title book example javascript dummies taglist list tags example javascript jquery web dev said set books talking different things biology history book title set tags describing classify automaticaly books separated sets topic example books history books biology books guys know classification algorithm method apply kind problems solution use external api define category text problem books different languages french spanish english looks like reasonably straightforward keyword based classification task sinceusing java good packages consider classifierweka lucene mahout classifierclassifiersupports classification using naive bayes vector space model seen source code snippet training scoring using naive bayes classifier package reasonably easy usealso distributed liberal apache software license weka weka popular tool data mining advantage usingable readily experiment using numerous different machine learning models categorize books topics including naive bayes decision trees support vector machinesnearest neighbor logistic regression even rule set based learnerfind tutorial using weka text categorization weka however distributed gpl wonable use closed source software want distribute still use back web service lucene mahout mahout designed machine learning large datasetsbuilt top apache hadoop supports supervised classification using naive bayesfind tutorial covering use mahout text classification like classifiermahout distributed liberal apache software license want something simple now will return books happens real life edit sounds like might want take look vector space model apply classification categories either lucene classifieroffer framework might want look fuzzy matching algorithms soundex word char analyzer way combine vectorizers use one analyzer can pass callable analyzer argument get full control tokenization featureunion combining feature extractors case probably less efficient larsmans solution might easier use tried following importations machine learning project got error message please help tried everything nothing worked tried solutions importerror dll load failedmodulecifi est introuvable importerror dll load failed specified module found line points scipy pip uninstall scipy pip install scipy enjoy reinstallation scipy numpy scikit learn packages fixed error case openpython lib site packages sklearn utils edit contents two specific changes make first copy paste contentspython lib site packages sklearn utils second replace lineversionversion background info detail available great answer user dsm install numpy library instead one use gohlke pythonlibs numpy assume intel math kernal libary installedfound silly solution similar saggy ones iteratively run script command line compare dll error look package module library wattelapesca name pip uninstall thatpackageinstall pseudocode uninstalling scipy conda env reinstalling using pip works uninstall conda remove force scipy install pip install scipy dll missing can happen wide range reasons case seems mismatch sklearn dependencies maybe different bit bit installation packages different answers point different packages general way find dependencies using output name scikit learn version summary set python modules machine learning data mining home page none author email none license new bsd locationusers username appdata local programs python python lib site packages requires joblib numpy threadpoolctl scipyprobable root problem returns one requires packages way error lines also can point package causes error try reinstalling packages solve problem creating model keras want compute metric perplexity requires using unnormalized probabilities logits however keras model returns softmax probabilties keras faq solution get output intermediate layers another solution given however answers store intermediate outputs different model need want use logits custom metric custom metric included functionevaluated displayed training donneed output dense layer separated different model part original model short questions defining custom metric outlined using def custom metrictruepredpred contain logits normalized probabilities contains normalized probabilities can get unnormalized probabilities think found solution first change activation layer linear receive logits outlined loannis nasios second still get sparse categorical crossentropy loss function define loss function setting logits parameter true try change last activation softmax linear can make model training another predictions training can use functional api model simply take part existing model leaving activation aside since got one model part another will share weights thought batch size performance bigger batch images computed time train net realized change batch size net accuracy gets better understand batch size can someone explain batch size caffe trained using stochastic gradient descend sgd iteration computes stochastic gradient parameters change parameters direction gradient now write equations gradientnotice order compute gradient exactly need evaluate training data iteration prohibitively time consuming especially training data gets bigger bigger order overcome sgd approximates exact gradient stochastic manner sampling small portion training data iteration small portion batch thus larger batch size accurate gradient estimate iterationdr batch size affect accuracy estimated gradient iteration changing batch size therefore affect path optimization takes may change results training process update iclr conference interesting work presented samuelsmith pieter jan kindermans chris ying quocle dondecay learning rate increase batch size work basically relates effect changing batch size learning rate looking multi output regression last view weeks working scikit learn package machine learning problem input features needs predict two output variablesmodels sklearn package support multioutput regression nativly models support sklearn multioutput regression algorithm can used convert multioutput class fits one regressor per target first question divided two parts first part answer written documentation linked also user guide topic states explicitly multioutputregressor fits one regressor per target can take advantage correlations targets second part first question asks algorithms support can look inherently multiclass part user guide inherently multi class means donuse onerest oneone strategy able handle multi class ovo ovr uses multiple models fit multiple classes may use relationship targets inherently multi class means can structure multi class setting single model lists following try replacing classifier end regressor see documentation fit method example lettake see supportsarray targetsmay able use correlation underlying relationship targets now second question using neural network depends personal preference type problem amount type data training iterations want maybe can try multiple algorithms choose gives best output data problem subclass model code following result want see layers mobilenet tried extract layers mobilenet put model resule changed tried extract one layer insert model change either confused find parameter dense layer changed know happend ioannisanswer perfectly fine unfortunately drops keras model subclassing structure present question just like want keep model subclassing still show layers summary can branch individual layers complex model using loop can directly build model call summary order able view backbonelayersconstruct new model using fit linearsvc predict really familiar datatypes scikit learn yet also thinking splitting samples multiple arrays familiar numpy arrays scikit learn data structures will easier put split samples chunks train combine trained set back later work edit scenario say million files training sample set want distribute processing tfidfvectorizer several processors split samples case will two categories say samples train server coreswant split topics number chunks process tfidfvectorizer like testing sample set decide make sense thanksplease close think using sgdclassifier instead linearsvc kind data good idea much faster vectorization suggest look hash transformermultiprocessing can distribute data sets across cores partial fit get weight vectors average distribute estimators partial fit parallel gradient descent area active research ready made solution many classes data btw class separate will trained automatically nearly many classes cores might better much easier just one class per core specifyingjobs sgdclassifier linear models linearsvc sgdclassifier can chunk data train independent models chunk build aggregate linear model sticking average values coef intercept attributes predict method linearsvc sgdclassifier perceptron compute function linear prediction using dot product intercept threshold onemulticlass support specific model class use holding average coefficient important however previously said tricky point parallelizing feature extraction current scikit learn version provide way easily edit scikit learn now hashing vectorizer anyone know can add new image classes pre trained inceptionmodel example wanted train tensorflow multitude national flags need make sure can still recognize images imagenet hierarchy realize way wipe top layer inception completely retrain model classes limiting time consuming also way output entire hierarchy containing tag image receives wish able see specifically inception tags image want see broad synsets imagenet example instead just seeing output toy poodle interested animal domesticated animal dog poodle toy poodle responses greatly appreciated output layer softmax means predefined number neurons one defined one specific class technically perform network surgery one neuron output layer will represent new class will perform additional training network updates weights order account new class bad news take since update will affect whole network network giant good news change pretrained existing network will faster learning everything scratch makes think hierarchy exists canknow anything internal representation data sure course can inspect activations neurons functions even visualizefind hierarchy expect see sum understanding ann represents data internally easy task actually extremely difficult one suggested reading explanations repo link example finetuning recently something similar case patogenic plant leaveshealthy plant leavesinception already trained will transfer learning transfer learning technique shortcuts lot work taking fully trained model set categories like imagenet retrains existing weights new classes link image retraining youtube video tutorial hvass laboratories great video resource rectify questions need compute information gain scoresfeaturesdocuments text classification code works fine full dataset slow takes hour laptop dataset newsgroup using scikit learn chi function provided scikit works extremely fast idea compute information gain faster dataset edit merged internal functions ran cprofiler dataset limitedfeaturesdocuments result top tottime looks time spent get row slice entirely sure first row looks covers whole block provided though donknow big gap first line totime second one tottime difference spent possible check cprofile basically looks problem sparse matrix operations slicing getting elements solution probably calculate information gain using matrix algebra like chi implemented scikit idea express calculation terms matrices donknow whether still helps since year passed now happen faced task text classificationrewritten code using nonzero function provided sparse matrix just scancount correspondingvalue calculate entropy following code needs seconds run news dataset loaded using libsvm sparse matrix format version uses matrix operationsfeature mean class specific scores dataset instances unique features implementation faster one without matrix operations code feature set indices feature range feature set indices takes time try change set operationhow get dependency parse syntax tree output syntaxnet see description dependency get dependency parse output syntaxnet specifically parsey mcparseface model even dependency parsing box passing arg prefix brain parser parserexample first pass tags words second pass resolves dependencies generates following outputimplementing pca using eigenvalue decomposition sparse data know matlab pca implemented helps understand technicalities write codefollowing guidancegetting different results comparison built function princomp anybody look point right directioncodeexample compare princomp function statistics toolbox might also interested related post performing pca svd found piece code chapter section deep deep learning python follow see modelinput donraw datashape information embedding layer input lstm output embedding variable length sequence want know additional information order explain lstm unit donknow call just show image provided recurrent layers inherit base implementation includes option return sequences defaults false means default recurrent layers will consume variable length inputs ultimately produce layeroutput final sequential step result problem using none specify variable length input sequence dimension however wanted layer return full sequence outputdeal variable size output next layer accept variable sized input punt problem later network eventually either must calculate loss function variable length thing else calculate fixed length representation continuing later layers depending model requiring fixed length sequences possibly padding end sequences special sentinel values merely indicate empty sequence item purely padding length separately embedding layer special layer built handle variable length inputs output shape will different embedding vector token input sequence shape batch size sequence length embedding dimension since next layer lstm problem will happily consume variable length sequences mentioned documentation embedding wantdirectly embedding non variable length representation must supply fixed sequence length part layer finally note express dimensionality lstm layer lstm describing dimensionality output space layer order avoid inefficiency batch size one tactic sort input training data sequence length example group batches based common sequence length custom keras datagenerator advantage allowing large batch sizes especially model may need something like batch normalization involves gpu intensive training even just benefit less noisy estimate gradient batch updates still work input training data set different batch lengths different examples importantly though also big advantage manage padding ensure common sequence lengths input deal units units totally independend length nothing special done length increases recurrent steps recurrent steps use always cells number cells fixed defined user deal variable length using scikit learnlinearsvc classifier text miningvalue labelvalue tfidfvectorizer text document use pipeline like prediction like get confidence score probability data point classified range currently use decision function feature however returns positive negative values seem indicate confidence sure mean either however way get values range example output decision function data points canhowever can use linear probability true may run longer can get probabilities classifier using predict proba method insist using linearsvc class can wrap shows probabilities class data looked apis donsee anyone built package top scikit learn theory polynomial regression special case linear regression main idea select features looking multivariate regression variablesx linear regression will look likexnow want polynomial regression letmake degree polynomial will create additional featuresxx will get linear regression nicely shows important concept curse dimensionality number new features grows much faster linearly growth degree polynomial can take look concept practice scikit learn need scikit polynomial regression already available version check update either use support vector regression see install latest master version sklearn use recently added see ols ridge top want setup environment deep learning using anaconda python system nvidia get force windows installed now want ubuntuvb can install cuda cudnn librariesbased ubuntuone can help can use gpu virtual box virtual box pass host gpu however can use windows version python can use gpu windows machine installation procedure windows installing cuda cudnn anaconda just usedexpect observe donunderstand code update found sites report issue tried following suggested solutions without success far acc loss still different fit generator evaluate generator even using exact data generated generator training validation tried please let know solutions around missing now managed evaluation metrics changed following managed similar accuracy loss fit generator evaluate generator also using data training testing now results similar metrics reasons remaining differences provided keras documentation set use multiprocessing false fit generator level fixes problem cost slowing training significantly better still imperfect workround set use multiprocessing false validation generator code modified keras fit generator function training one epoch might informative enough case also train test data may exactly since setting random seed flow directory method look maybe can set seed remove augmentations save trained model weights load laterallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago sentence want predict missing word using nlp model nlp model shall use thanks try properly can use masked language model bert algorithm truly understand need cls mask segment tensors please read paper carefullylazy can read nice blogpost lilian weng lot models can perform task filling blank look models pytorch pretrained bert repository importantly dive deeper task language modeling bidirectional rnns like bidirectional lstm can get hint advised bidirectional rnns expensive train depending problem solve highly advice use pre trained model good luck want implement following algorithm taken book section donunderstand implement update rule pytorch rulequite similar theta far know torch requires loss form seem apply quoted algorithmstill certain correct way implementing update rules pytorch greatly appreciate code snippetweights updated givensoutput neural net parameterizededit chris holland suggested way implement implemented converge cartpole wonder something wrong critic converge solution function gammann happens sum series gamma gamma gamma inf meaning gamma diverges gamma converges gamma converges regardless actor policy code edit chris hollandsolution works problem originated bug code caused line always get called thus expected rewardnever zero thus stopping condition specified bellman equation recursion reward engineering gamma lambda single hidden layer size actor critic converged rather stable optimal policy within episodes even faster gamma graph shows best discounted episode reward big thank chris holland gave try gonna give try backward need loss function just needs differentiable scalar output approximates gradient respect model parameters letjust look first case update value function one gradient appearingcan approximate gradient givesgradientdimension model parameters assuming already calculated parameter updates can calculate actual optimizer update can use update model parameters adjusted gradient following evaluation metrics test set running models binary classification problem following questions briefly links parts already discussed elsewhere can model best terms logloss logloss closest since performs worst terms accuracy mean although loss proxy accuracy vice versa reliable one matter closer look specific mechanics accuracy loss may useful consider following threads disclaimer answers mine elaborate little assuming sample true labelprobabilistic prediction classifierdecision threshold classify otherwise contribution sample accuracyloss now assume another sample truenow probabilistic predictioncontribution accuracy will loss now will two samples correctly classified rather huge difference corresponding shouldndifficult imagine situation many sampleswill around areahence giving relatively low loss zero contribution accuracy model better accuracy mean one easier according experience leastpractitioners think auc score measures something different actually common unfortunate use just like higher better metric like accuracy may naturally lead puzzles like one express truth roughly speaking auc measures performance binary classifier averaged across possible decision thresholds auc actually measure performance particular deployed model includes chosen decision threshold averaged performance family models across thresholds vast majority course interest will never used reason auc started receiving serious criticism literature donmisread analysis roc curve highly informative useful wikipedia entry references provided therein highly recommended reading thus practical value auc measure called question raising possibility auc may actually introduce uncertainty machine learning classification accuracy comparisons resolution one recent explanation problem roc auc reducing roc curve single number ignores fact tradeoffs different systems performance points plotted performance individual system emphasis mine see also dangers donuse way say models best depends exact definition best best means best business problem trying solve irrational definitionpractitioner one performs better according business metric appropriate problem defined can never auc normally also many deep architectures use batch normalization training batch normalization mathematically way help training process batch normalization used training special layer inserted model need normalize layer suppose used batched normalization training affect test time model replace batch normalization equivalent layer operation deploy network question batch normalization covers part question aiming hoping detailed answer specifically like know training batch normalization affect test time prediction deploy network test phase net batch normalization layers can suffer deleterious drift math simple find mean variance component apply standard transformation convert values correspondingscores subtract mean divide standard deviation ensures component ranges similarchance affect training deltas back propusing network pure testing training simply delete layersdone jobtraining testing predicting classifying leave place operations wonharm results barely slow forward computations caffe specificsreally nothing particular caffe computation basic stats process algebra framework granted will optimizations hardware supports vector matrix math consist simply taking advantage chipbuilt operations response comment can afford little extra training time yeswant normalize every layer practice inserting less frequently say every inceptions will work just fine can ignore deploymentalready done jobback propagationdrift weights also model handles one instance batchscore always every input exactly mean batch entire batch complement pruneanswer testing batch normalization layer will use average mean variance scale shift values different training iterations normalize input subtract mean divide standard deviation original googlebatch normalization paper said moving average method thorough explanation provided though caffe tensorflow use exponential moving average method experience simple moving average method usually better exponential moving average method far validation accuracy maybe need experiments compare can refer tried two moving average methods implementations channel wiselayer compared batch norm layer bvlc caffeworth link example using batchnorm layers cifar classification net specifically splits layer train test phases batch normalization solves problem called internal covariate shift understand helpsneed first understand covariate shift actually covariates just another name input features often writtencovariate shift means distribution features different different parts training test data breaking training samples one age group want classify something coming another age group finance due changing market conditions internal covariate shift refers covariate shift occurring within neural network say layer layer happens network learns weights updated distribution outputs specific layer network changes forces higher layers adapt drift slows learninghelps making data flowing intermediate layers network look like whitened data means can use higher learning rate sinceregularizing effect also means can often remove dropout helpful dropout usually slows trainingnew machine learning tried create model predict number even used code changed needs problem circa success equal random know make work neural networks arengood figuring number even least input representation just integer neural networks good figuring combining linear decision boundaries case natural numbers infinite number decision boundaries check number even however getwork subset numbers make work however essentially need one neuron per number want able test input layerneed thousand neurons input layerreally great example neural network change representation inputs binary representation numbermuch easier time detecting number evencan see now rather simple problem solve basically inverse last binary digit example preprocessing inputs create problem easier neural net solve created model keras classify odd even numbers python just uses neuron first hidden layer inputs output layer just neurons one hot encoding predictions thinkgood idea read perceptron xor problem understand single perceptron works limitation predicting number even binary classification problem one dimensional input classification problem neural network trained separate classes via boundary one way thinking problem map one dimensional input two dimensional input adding input number added dimension see even odd vectors look like scatter diagram run following code jupyter notebook will see something like following image can see first figurereally possible come boundary even odd vectors map second dimension number equivalent negative number drawing boundary two classes even odd number vectors easy result transform input data two dimensions negate second dimension value based even odd neural network can learn separate even odd vector classes can try something like following code will see network will learn converge almost accuracy note transforming number negative space based even odd will work one dimension easier demonstrate scatter diagram two dimension vectors suprised doesnwork neural networks doesnwork like get better feeling passing input neural network passing number meaning means one number greater another cause something like age money dependancy looking odd number meaning abstract honestly think input independent string values maybe please try take input check whether network will understand second value greater zero number odd keep reading get better feeeling milano full code will look isnstrangest application neural networksever seen closest example compositional neural network solution prime number testing back used neural networks solve complex number theory problem result research trainedsuggest try using similar construction paper concludes better solutions kind problem goal machine learning predict labelsdata features patternsissuegrowing list particular pattern sequence explanationtrying ask statistical algorithm explain full random things impossible try beginning machine learning titanic dataset kaggle reference platformload via pandas try algorithmwill every features like class age sex etcsurvived value lived will trying determine lived thanks pattern age sex machine learning courses will explain everything really accessible beginners fun relatively new machine learning currently almost experiencing developing question training evaluating cifar dataset tensorflow tutorial wondering one test sample images train evaluate imagenet tutorial caffe machine learning framework relatively easy use trained model custom applications using python api help appreciated isnanswer questionsimilar way solving based mnisttraining example suggested comments question based tensorflow begginer mnist tutorial thanks tutorial way training using neural network custom data please note similar done tutorials cifar yaroslav bulatov mentioned comments image conditioning digits completely dark white background bettertraining accuracy please check advanced mnist tutorial tensorflowtutorialmentioned example mnist tutorial simple xor example note train test methods declare keep globally weights biases session test method redefine shape input reuse weights biases session refined training recommend taking look basic mnist tutorial tensorflow website looks like define function generates type output want run session passing evaluation function correct prediction dictionary containing whatever arguments requirey defined trained network takes inputgenerates responsebased inputs know expected responses testing setmay able print every response testing set something like just modification done tutorial instead trying print response determine percent correct responses also note tutorial uses one hot vectors predictionactual valueorder return associated numeral find index vectors equal oneedit general define something graph can output later run graph say define something determines result softmax function output logits can output run timetrying cluster data kdd cup dataset output file looks like thousand different records format cleaned data removed text keeping numbers output looks like now created comma delimited file excel saved csv file created data source csv file matlab tryed running fcm toolbox matlab findcluster outputs data types expected columns clusters however donlook like clusters accepting working way need anyone help finding clusters new matlab donexperiencealso new clustering methodtrying achievegetting since new machine learning data mining shouldntackle advanced problems data working used competition kdd cup donexpect easy besides data intended classification task supervised learning goal predict correct class bad good connection seem interested clustering unsupervised learning generally difficult sort dataset requires lot preprocessing clever feature extraction people usually employ domain knowledge network intrusion detection obtain better features raw data directly applying simple algorithms likemeans will generally yield poor results starters need normalize attributes scale computing euclidean distance part step method features values will dominate features small values thus disrupting result another point remember many attributes can bad thing curse dimensionality thus look feature selection dimensionality reduction techniques finally suggest familiarize simpler port roc curve obtain auc area curve binary classification result ipython need probabilities create roc curve example code scikit learn examples question appear specific programming problem software algorithm software tools primarily used programmers believe question topic another stack exchange site can leave comment explain question may able answered closed years ago want use nvidia smi monitor gpu machine learningprojects however run nvidia smi cmd git bash powershell get following results column gpu memory usage showsevery single process also lot processes listed found examples internet reason running nvidia gtx asuswindows pro perform following nvidia smiwill see following available wddm driver model wddm stand windows display driver model can switch tcc obtain information command nvidia smihowever operation can performed display attached gpumostly donworry high memory usage tensorflow reserve much gpu memory can speed processes prefer finer grained control memory taken use following may slow little bit computations can create dual boot ubuntu just forget non batched reinforcement learning basically defined suttonbook model trains woohoo though element confuses background environment duration rewarded like pole balancing rewards say per step episode sending arraytrain step standard discounting normalization get returns discount rewards usual method gist curious array rewards becomes array returns given basic background can ask question positive returns enforced negative returns discouraged optimize step matter length episode roughly first half actions will encouraged latter half will discouraged true misunderstanding something true love understand got wrong true donunderstand model trains since even good performing episode will latter half actions discouraged reiterate non batched learning returns relative returns another episode training step episode model trains trains hoping makes sense short enough feel like proper clear question background increase decrease rewards good bad equally nothing changes really optimizer tries minimize loss maximize reward meansinterested delta values gradient absolute value sign reinforcement learning letsay graph looks something like losses individual classes get scaled weights caserewards loss linear function reward gradient stays monotonic linear transformation reward normalization agent performs rather badly receives much bad rewards good rewards normalization makes gradient steeper puts weight good rewards shallower puts less weight bad rewards agent performs rather goodway round questions positive returns enforced negative returns discouraged optimize stepsign absolute value delta relative values matter length episode roughly first half actions will encouraged latter half will discouraged either much high much low reward values smaller half steeper gradient weight larger half shallower gradient less weight true donunderstand model trains since even good performing episode will latter half actions discouraged loss value actually expected stay constant point measure progress running program lookingnormalized rewards reference see example network googlet bad thing howeverjust loss less normalized network keeps improving anyway looking gradient training step classification problems usually global loss keeps falling time optimizers keep history gradient adapt learning rate effectively scaling gradient means internally also kinda normalize gradient thus doncare either want learn behind scenes gradient scaling suggest taking look non batched learning returns relative returns another episode training step episode model trains trains larger batch size stable distribution rewards reliable normalization even normalize rewards across multiple episodes opinion accepted answer wrong read thought plausible stopped worrying gradient normalization checked something else much later notice precisely gradient normalization breaking training process first reward normalization doesnmess sign gradient just plain wrong obviously subtract meanflip signs yes reward normalization affect sign gradient second everyday words measurement many plausible optionschoosing select actions randomly cross entropy high always select exact item cross entropy low choices irrelevant statistically never take line actually reward positive will minimize cross entropy meaning will increase chancewill take exact action sees similar situation future reward negative will maximize cross entropy meaning will makechoose randomly sees similar situation futurepurpose reward normalization yes normalization half items trajectory positive sign half negative sign basically saying things worked try something random things leads actionable advice model behaving randomly make sure enough positive rewards normalization model always exploring make sure enough negative rewards normalization givendimensionssamplessequencesfeatureslabels dimensionssamples suppose want train stateful lstm going keras definition stateful true means cell states reset sequences per sample please correctwrong states supposed reset per epoch basis per sample basis example summary sure reset states sequence epochsamples trainedadvice much appreciated use stateful true typically reset state end epoch every couple samples want reset state sample equivalent just using stateful false regarding loops provided note dimensionexactly dimension actually hence supposed inner loop now regarding loop since enumeration batches done keras automatically donimplement loop unless want reset states every couple samples want reset end epoch need external loop example architecture taken blog post alternatively seems possible custom callback avoids calling fit loop costly something similar tensorflow lstm gru reset states per epoch new batchi csv rowscolumns trying pca produce rowscolumns matrix csvlarge currentlyrun code program killed csv stepable get around spliting csv sets reading callingbetter way really love use data machine learning application wanted use incremental pca suggested answer canfind good examples online try divide data load batches script fit pca incremetal pcapartial fit method every batch useful link pca needs compute correlation matrixdata stored doublesgb willing bet macbookram pca transformation matrix likely nearly reasonably sized random subset like study optimal tradeoff bias variance model tuningusing caretallows plot performance metric auc hyperparameters model mtry lambda etc automatically chooses max typically returns good model want dig choose different bias variance tradeoff need learning curve performance curve sake simplicity letsay model random forest just one hyperparameter mtry like plot learning curves training test sets something like red curve test setaxis put error metric number misclassified examples something likeaxis mtry alternatively training set size questions caret functionality iteratively train models based training set folds different size code hand can want put hyperparameteraxis need models trained caret train just final model one maximum performance gotdiscarded model still available train caret will iteratively test lotsmodels set traincontrol function parameters using tunegrid passed control options train function specifics tunegrid parameters ntree will different model type yes final trainfit model will contain error rate however specified foldsspecifycode approached issue plotting learning curveusing caret package train model use motor trend car road testsillustrative purposes begin randomize split mtcars dataset training test sets records training records test set response feature mpg example output plot shown point probably question asked caret package added learning curve dat function helps assess model performance across range training set sizes example function documentation performance metricfound training size saved lda data along data variable resampling training optionally testing link function documentation answers first part question second part note least august typo caret package code documentation function call learing curve dat corrected learning curve datupdated answer reflect change make sure using recent version caret packageusing python theano mingwx installedwin cuda installed seems everythingok saying gpu working just keeps tell error hypot declared help appreciated error building python file using mingw opened file saysmingw lib gccw mingw includecmath changed line adding line just problem solved knowbasic solution one find answer posted comments originally keep original mingw cmath header otherwise libpng build commented define hypot hypot pyconfigline worked use combination answers guess incomplete information arencompilingmode arenpicking hypot example want add new instance dataraw far know use instance thanks advance let start highlights instancevalue addstringvalue string new denseinstance instancevalue complete running example output following currently using trigram assigns probability occurrence given sentence limited context words lstmcan build lstm model assigns probability occurrence given sentence just coded simple example showing one might compute probability occurrence sentence lstm model full code can found suppose want predict probability occurrence sentence following dataset rhyme published mother goosemelody london around first letuse model will take sequence words input context will output conditional probability distribution word vocabulary given context end prepare training data padding sequences sliding windows decided slide windows separately verse done differently next define train simple lstm model keras model consists embedding layer lstm layer dense layer softmax activation uses output last timestep lstm produce probability word vocabulary given context joint probabilitywn occurrence sentencewcan computed using rule conditional probabilitywnwwpnnconditional probabilities given lstm model note might small sensible work log space order avoid numerical instability issues putting together note small toy dataset might overfitting update bigger datasets likelyrun memory process entire dataset case recommend using generator train model please see gist modified version uses data generatortraining textual sentiment classification model multiple output layers kerasfunctional api using tensorflow backend model takes input numpy array hashed values produced keras preprocessing apihashing trick function uses list numpy arrays binary one hot labels targets per keras specifications training model multiple outputs see fitdocumentationmodel sans preprocessing stepsgist error trace training model produces valueerror error checking target expected dense shape got array shape numpy arrays inputs outputs contain batch dimension labels currently shape can reshape include batch dimension follows used loss categorical crossentropy optimizer adam metrics accuracy insted optimizer adam loss sparse categorical crossentropy metrics accuracy changed loss worked using python keras running imagedatagenerator using flow directory problematic image files can use data generator order handle read errors getting valid jpg file small portion images like treat without code crashing one solution modify imagedatagenerator code put error handling mechanism however one alternative wrap generator inside another generator use try except disadvantage solution throws away whole generated batch even one single image corrupted batch may mean possible samples may used training another disadvantage solution since need specify number steps generator considering batch may thrown away step new batch fetched instead step may end training samples epoch may may significant effects depending many batches include corrupted images nothing worried much finally note may want use newer keras data generator problem previous approach still present approach since also need implement len method essentially equivalent steps per epoch argument although opinion approach superior approach course put aside fact may need write code fewer side effects since can discard single image whole batch namesreferring several placeholders want access outside functions without passing reference assumption placeholders holding given names exist can get reference graph construction runtime second question can get variables hold given name matter scope example weights namemany scopes want get list want add one manually can done biases say want histogram first can get placeholder using example assuming working default graph secondly use following function get variables given name matter scope using roc auc score function scikit learn evaluate model performances howver get differents values whether use predict predict proba advise please thanks advance first look difference predict predict proba former predicts class feature set latter predicts probabilities various classes seeing effect rounding error implicit binary formattest predictedtest predicted comprisedspred comprised floating point values roc auc score routine varies threshold value generates true positive rate false positive rate score looks quite different consider case note roc curve generated considering cutoff thresholds now consider thresholdtest predicted case gives can probably see two points different area two curves will quite different really understand suggest looking roc curves help understand difference hope helps need mape function however able find standard packages implementation function donlikesuper optimal terms speed rewrite code pythonic way boost speedone vectorized approach masking probably faster one masking division computation runtime test another similar way using masked arrays mask division zero studying flann library approximate nearest neighbors search lsh method represent object point search space array unsigned int sure represent point simply double array represent point multi dimensional vector space maybe lsh used binary features can someone share possible use unsigned int case unsigned int need feature thanks please note will refer latest flann release point search space array unsigned int wrong lshindex class includes buildindeximpl method implements lsh indexing since lsh basically collection hash tables effective indexing occurs lshtable class elementary indexing method aka descriptor point time note buildindeximpl method uses alternative version simply iterates features call method can see method arguments pair descriptor look implementation can see first step consists hashing descriptor value obtain related bucket key identifier slot pointing bucket descriptor will stored practice getkey hashing function implemented binary descriptors maybe lsh used binary features yes stated flann lsh implementation works hamming space binary descriptors use descriptors real valuesd refer original paper includes details convert feature vectors binary strings use hamming space hash functions can someone share possible use unsigned int case unsigned int need feature see unsigned int value used store related feature vector created classifier weka saved hard disk now want use classifier eclipse using weka api can please guide output great beginers resource weka api serializationusing keras pre trained model vgg following link keras vggtrying decode prediction output wordimage full error valueerror decode predictions expects batch predictionsarray shape samples found array shape comments suggestion highly appreciated thank change first line without line model producing feature maps sizepixels reason behind error just add correct answer marcinejko applies available models must always include top three layers studying flann library approximate nearest neighbors search lsh method represent object point search space array unsigned int sure represent point simply double array represent point multi dimensional vector space maybe lsh used binary features can someone share possible use unsigned int case unsigned int need feature thanks please note will refer latest flann release point search space array unsigned int wrong lshindex class includes buildindeximpl method implements lsh indexing since lsh basically collection hash tables effective indexing occurs lshtable class elementary indexing method aka descriptor point time note buildindeximpl method uses alternative version simply iterates features call method can see method arguments pair descriptor look implementation can see first step consists hashing descriptor value obtain related bucket key identifier slot pointing bucket descriptor will stored practice getkey hashing function implemented binary descriptors maybe lsh used binary features yes stated flann lsh implementation works hamming space binary descriptors use descriptors real valuesd refer original paper includes details convert feature vectors binary strings use hamming space hash functions can someone share possible use unsigned int case unsigned int need feature see unsigned int value used store related feature vector using lstm time series data features time series time dependent imagine company stocks series stuff like company location non time series features usecase idea example letjust predict next value time series simple example however just sure specify initial state list correctly get can see causedbatch dimension tried using flatten permutation resize layers donbelieve correct missing can connect layers first problem lstm layer expects two initial statesc dimension nonemeans error message one initial state dense maybe can switch gru requirescan transform feature input two initial states second problemc shape batch size dense shape batch size timesteps need deal time dimension using dense initial states maybe can change input shape take average timesteps globalaveragepoolingworking example macos sierra installation xgboost openmp enabled always failstriedmake makefails llvm support openmp failslibrary found lomp related question install xgboost maclibrary found clang omp goes boneyard discontinue llvmopenmp supportdrilledoption solved llvm installation miss symbolic link case solved adding following linker flag addition lomp lpath llib case used version clang came homebrewllvm instead one came laptop factory workedtrying build simple lstm autoencoder pytorch always train data built model following link code running errorspred converge code source code using init hidden encoder init hidden decoder functions zero hidden states recurrent units every forward pass pytorch doninitial hidden state passed rnn cell lstm gru rnn ones currently available default pytorch implicitly fed zeroes obtain code initial solution simplifies next parts will scrap unneeded parts leavesmodel seen donneed superfluous dimensions like actuallyclue results equal furthermore left input reshape network opinion network fed input ready processed separate strictly tasks input preparation model approach givesfollowing setup code training loop whole network identical now except succinct readable provided keras code indicates want actually correctly obtain last hiddden state encoder encodes entire sequence decode sequence state obtain original one btw approach called sequence sequence seq seq short often used tasks like language translation maybe variation approach classify anyway pytorch provideslast hidden state separate return variable rnns family advise encoded reason bidirectional multilayered approach say wanted sum bidirectional output mean code along linesline last hidden input used actually mistake side last part output shapes predictions targets shapes provided mseloss default uses argument size average true yes averages targets output essentially calculates loss average tensor around beginning average target network converges correctly targets wrong provide mseloss argument reduction sum thoughreally temporary works accidentally network first will try get outputs equal sum first semi random outputs will converge want reasons want identity function easiest choice even summation input data really simple just pass appropriate shapes loss function case final part look like target one dimensional batch size output squeezing unnecessary dimensions changed adamparameters defaults converges faster way brevity code results resultssteps stucksteps actually may want improve optimization play around hidden size better results additionallyloss may get better results case tuning correct batching network left hopefun now get idearepeat entire shape input sequencegeneral approach work batches dimensions valueerror input data numpyarrayiterator rank passed array shape reference code per follow forth dimension number samples batch look letuse goodiris dataset reproduce fit several classifiers plot respective confusion matrices plot confusion matrix set way compare matrices simple sight creating set subplots plot confusion matrix expects input plot individual confusion matrices desired output way see multiple confusion matrices confusion matrix side side confusionmatrixdisplay note paste test train data names function thought adding new module will center pooling looking tensorflow code file named genmaxpool avgpool etc parameters required computation want centre pooling selects center element window code ready matlabversions need know add new module tensorflow computation also set backpropogation code custom pooling layer probably implementedseeneed letsee implementation lives python wrapper function automatically generated genappearsregistration opskernel registration kernels maxpooling maxpoolwithargmaxgrad placesfair amount work add newsee tutorial complete guide hopefully pointers can helptried build sequence sequence model predict sensor signal time based first inputs see figure model workswant spice things try add attention layer two lstm layers model codelooked documentationbit lost help adding attention layer comments current model appreciated update googeling aroundstarting think got wrong rewrote codetrying migrate seq seq modelfound github repository repository code problem demonstrated predicting randomly generated sine wave baed early samples similar problemtrying change code fit needs differences hyper params encoder code decoder code model summary trying fit model get following error wrong attention layer keras trainable layer unless use scale parameter computes matrix operation opinion layer can result mistakes applied directly time series let proceedclassical application attention enc dec structure nlp followingimplementation attention layer need query value key tensorformat obtain values directly recurrent layer specifically utilize sequence output hidden state need build attention mechanism query output sequence batch dim time step features value hidden state batch dim features add temporal dimension matrix operation batch dim features key utilize hidden state key value definition implementation found problems example reason time series attention propose solution query output sequence batch dim time step features value hidden state batch dim features add temporal dimension matrix operation batch dim features weights calculated softmax scale dot sequence hidden scale parameter scalar value can used scale weights applying softmax operation softmax calculated correctly time dimension attention output weighted product input sequence scores use scalar parameter fixed value can tuned insert learnable weight custom layer scale parameter keras attention term network implementation two possibilities available conclusion donknow much added value introduction attention layer simple problems can short sequences suggest leave reported answer express considerationsaccept comment consideration possible mistakes misunderstandings model solutions can embedded way answer edited question first call fit decoder inputs tensor canuse fit model author code cited use array zeros dummy example secondly look output layer model decoder input must feature dimension reported set initial parameters define encoder define decoder feature dimension input define model dummy data shapes pay attention decoder zero inputs dimensionarray zeros fitting prediction validationi try retrieve row containing nan values indices corresponding columnsalready done following want ideally name column get list like hope can find way without row test columnlooking pandas way able deal huge dataset thanks advance efficient use scipy coordinate format sparse matrix retrieve coordinates null values notecalling nonzero method order just output coordinates nonzero entries underlying sparse matrix since doncare actual values true another way extract rows nan gets way may enough although may easier work series though donthink need another simpler way subset get integer index can iterate row dataframe create mask null values output index try use returns series boolean values indicates columns nan values index column names retrieve nan columnusingi trying predict sales demand using recurrent neural networks modeled example data row seperate product columns demand products time used code error hovers around improvement numbers decimal poiint integer part errordoeslower look like method working just wanted check pybrainexpert see anything wrong correction apparently copying pdf file data got corrupted correct data shared repeat data bad correct datacode also shared will start error rate graduallysorry confusion might caused try plotting train error iteration method worksstep also tried adding bias get error one reported trainer error training set suffer high bias things help trying code output one gave first set data using fit transform vectorizer gave feature names likeeducationfootballgravityimporatantmoviesport applied another train set vectorizer gave feature names use fit fit transform want know update features vectorizer without overwriting previous oncs use fit transform previous features will get overwritten want update feature list vectorizer want something likeeducationfootballgravityimporatantmoviesportaimscollegecricketfilmtransformers can get sklearn terminology called partial fit cantfidfvectorizer two ways around example first approach output found question googling issueraised like mbatchkarov said scikit learntfidfvectorizer doesnnatively support partial fitting hashingvectorizer usually great alternative really depends use case specifically care much representing infrequent terms precisely collisions will hurt performance went ahead wrote implementation partial fit tfidfvectorizer countvectorizer see hopeuseful people reaching post note kind partial fitting change dimension output vector given vectorizer since whole point update vocabulary take account using pipeline listy pairs every pair represents pointspace want find closest point list specific pointyq best performance critical algorithm problem lisp points going change means need perform insertion deletion want just find nearest neighbor targetyq point set edit thanks stephan guessed correctly want repeatedly like function list necessarily sorted fact understand can sorted like table primary key columnshelps will sort will construct data structure based list one time will use generated data structure function process relevant thank jacob seemstree data structure good candidate answer feel will update get relevant results edit found problem named nearest neighbor edit first title search algorithm spatial querying spatial indexing nearest neighbor chose new title best performance critical algorithm solving nearest neighbor since want perform insertion deletion operation initial data want just nearest one new point going inserted chose currently workingtrees thanks stephan noted plan find closest match one point use tree recommendtree whose implementation can easily found several packages like opencv implement one edit asked questiontree implementations might useful edittrees widely used successfullysearches alsowilling accept approximate matches can use fast library approximate nearest neigbor flann flann implementation present opencv donwant approximate answers can tweak flann parameters search entire tree query pointyq varies list doesnneed calculate voronoi diagram list points will give set polygons cells infinite polygon corresponds point original list called site cell point lies entirely inside one polygon closer site polygon sites original list point boundary two polygons lies equally distant sitegotten far need easy way figure polygonknown point location problem really really good book kind thing computational geometry algorithms applications discuss voronoi diagram calculation trapezoidal slab method point location detail donwant code shouldntry get library like cgal will work probably appliestree answer donspecifically know need spatial index roll can lot worse pickingtree quad tree algorithmsquadtree simple spatial structure dimensions generally recommend quadtree insteadtree simpler faster downside memory consumption number dimensions high case dimensions difference significant nice optimization trick coordinates floating point typed query first will find leaf node contains point near point asked willtree root leaf iteration deciding child node step store identifiers addresses child nodes sized array node structure digitize point coordinates query algorithm will able find proper sub node just indexing array proper bits digitized point coordinates digitizing fast implement simple static cast first implement quadtree without optimization easy make bug bit operations even without optimization still will fastest solution iterate every point using distance formula find minimum distancexqhowever havengiven enough information performance critical answer examplecommon point might want calculate distancestore point second example huge number points might organize points sections start points section adjacent sections section containingtrying cluster products based users behaviors reach end clusters different number observations checkedmeans clustering parameters able find parameter controls minimum maximum number observations per cluster example number observations distributed across different clusters deal issue still looking answer found good module module deal kind problem use pip install size constrained clustering pip install git starting scikit learn trying transform set documents format apply clustering classification seen details vectorization methods tfidf transformations load files index vocabularies however extra metadata documents authors division responsible list topics etc can add features document vector generated vectorizing function use dictvectorizer extra categorical data use correct documentation actually obscure honest sure usefulness letreplicate example documentation iris data asking get realize exactly array represents useful look tree visualization also available docs reproduced convenience can see tree nodes looking closer see value node actually element make long story short clarify last point example consider second element array corresponds orange colored node says node end samples class zero samples two classestrying replicate results fully convolutional network fcn semantic segmentation using tensorflowstuck feeding training images computation graph fully convolutional network used voc pascal dataset training however training images dataset varied sizes just want ask preprocessed training images make size preprocessed images just feed batches images different sizes fcn possible feed images different sizes one batch computation graph tensorflow possible using queue input rather placeholderpossible feed images different size single input batch every batch can undefined number samplesbatch size usually noted none every sample must dimensions train fully convolutional network train like network fully connected layers end every input image input batch must widht height depth resize difference fully connected layers output single output vector every sample input batch shape none num classes fully convolutional outputs probability map classes train input images dimensions equals network input dimensions output will probability map shape none num classes can remove dimensions size output tensor using feed network images dimensions greater input output will probability map size nonen num classes simple machine learning codevalues featurescolumnvalue simple classification label considering using financial data like lookback pastvalues order predictvalue make algorithm use past rows inputy valuerelatively new machine learning spent much time looking online solution problem yet find anything simple case ideas typically done recurrent neural networks rnn retain memory previous input next input received breif explanation goes plenty sources internet better wrap understanding work break simple example say samples features data want two stagger data rows instead data assuming stock oldest price value first can think row day week use lstm keras data needsvs currentstructure now notation diminsion samples timesteps features currently samples features need augment data notice data staggered dimensional now just make lstm networkremainssince many one structure however need clip first value just brief example get moving many different setups will work including using rnn need find correct one data seems time series type task start looking recurrent neural networks keras want keep using modeling recommend time series may want transform data set kind weighted average last observations rows way new data setobservations function previous way information present classification can use something like column want runing sum alternately pivot current data set row actual numbers adddimension count columns populate previous observationdata whether possible practical depends shape data set simple thorough way make sure observation data think will make good prediction need aware thingssure considerations make optimal suggesting use dedicated rnn aware djk already pointed rnnposting answer accepted pers requestusing sklearnrandom foresttried compare several models noticed random forest giving different results even seed tried ways use random forest built random state cases get non repeatable results ideas thanks edit adding complete version code editquite think using randomstate might solve problem didntest yetreadingworth shot also generally preferable use randomstate instead first make sure latest versions needed modules numpy etc type use numpy generator use random state parameter inside randomforestclassifier several options int randomstate instance none docs int random state seed used random number generator randomstate instance random state random number generator none random number generator randomstate instance used numpy generator cases get reproducible results results cases check results results writing code image classification two classes using keras tensorflow backend images stored folder computer want give images input keras model load img takes one input image use either flowy flow directory directory flowy need also provide labels length task using flow directory directory images variable sizes like none none input shape none none channel last color images fchollet mention useful flatten layer model consist convolution flatten layers post moi suggest try different batches every batch images size possible group images sizes data scatter decidedbatch size write following code now getting following error sure img dim ordering backend checkedplease help correct code help can give variable size images input model can train variable sizes long dontry put variable sizes numpy array layers support variable sizes flatten oneimpossible train models containing flatten layers variable sizes can try though replace flatten layer either globalmaxpoolingglobalaveragepoolinglayer layers may condense much information small data might necessary add convolutions channels must make sure generator will produce batches containing images size though generator will fail trying put two images different sizes numpy array see answerchange input end add globalaveragepoolingtry something like unfortunately cantrain neural network various size images resize images given size fortunately donhard drive permanently keras hte fly inside flow directory define target size like also can whatever batch size want really confused calculate precision recall supervised machine learning algorithm usingclassifier say example two classesdocuments goes training sample set class classnow basis training sample set classify rest documents usingclassifier now classifying documents goes class documents goes classnow calculate precision recall please help thanksdivide results four groups true classcorrectly classified class false classincorrectly classified class true classtb correctly classified classfalse classfb incorrectly classified classprecisiontarecalltamight also need accuracymeasure accuracytbtbfbmeasure precision recall precision recall definition classification context let explain bit clarity suppose dogs cats video image processing algorithm tells dogs scene actually dogs true positives cats false positives precision tellsitems classified dogs many actually dogs precision true positives true positives false positives recall tells total number dogs many dogs actually found recall true positives total number true positive true positive false negative find precision recall class classclass true positive number class documents classified class documents false positive number classdocuments classified class documents can find precision recall true positive total number class documents used testing repeat classfind precision recall problem connection convolution layer lstm layer data shape timestepsdata points time step want convolutionget new convolveddata feed data lstm layer however work shape output convolution layer number filters need therefore shape convolution layer output input needed lstm layer just take first filter error comes can add reshape layer make dimensions compatible reshape dims reshape output certain shape input shape arbitrary although dimensions input shaped must fixed use keyword argument input shape tuple integers include samples axis using layer first layer model output shape batch size dims arguments dims target shape tuple integers include samples dimension batch size getting started find writing custom transformers typical preprocessing tasks order use pipeline examples work wondering pattern antipattern transformers good way work pipeline api necessary implement equivalent functionality provided somewhere elsesay primarily opinion based although looks unnecessarily verbose python transformers donintegrate rest pipeline api also worth pointing everything can easily achieved sqltransformer example little bit effort can use sqlalchemy hive dialect avoid handwritten however outputs sparse matrixcertain make sense can anyone advise best print decision path specific sample visualize outputsparse matrix type stored elements compressed sparse row format array dtype int found code scikit learn documentation modified fit problem randomforestclassifier collection decisiontreeclassifier can iterate different trees retrieve decision path sample one hope helps printing different trees random forest can just iterate estimators way output first trees randomforestclassifier sample just curious know pytorch track operations tensors requires grad set true later calculate gradients automatically please help understand idea behind autograd thanksgreat question generally idea automatic differentiation autodiff based multivariable chain rule means can express derivativerespectvia proxy variablefact allows break almost operation bunch simpler atomic operations can chained together now autodiff packages like autograd simply store derivative atomic operation block division multiplication etc runtime provided forward pass formula consisting multiple blocks can easily turned exact derivative likewise can also provide derivatives operations think autodiff exactly want advantage autodiff derivative approximations like finite differences simply exact solution interested works internally highly recommend autodidact project aims simplify internals automatic differentiator since usually also lot code optimization involved also set slides lecture took really helpful understanding trying sample dataframe now used get dummies convert string column integer conversion columns age name alex name bob name clarke country india country srilanka country usa now model trained prediction let say want predict target giving name country like alex usa used obviously will work suggest use sklearn label encoders one hot encoder packages instead now save onehotencoder dict label encoder dict use later encoding using svc classifier linear kernel train model train data records takes hours train model something wrong also can done improve time thanks advance several possibilities speed svm training letnumber recordsembedding dimensionality assume use scikit learn reducing training set size quoting docs fit time complexity quadratic number samples makes hard scale dataset couple samplesn complexity will likely dominate factors sampling fewer records training will thus largest impact time besides random sampling also try instance selection methods example principal sample analysis proposed recently reducing dimensionality others hinted comments embedding dimension also impacts runtime computing inner products linear kerneld dimensionality reduction can therefore also reduce runtime another question latent semantic indexing suggested specificallyidf representations different classifier may tryimilar svc parameter kernel linear implemented terms liblinear rather libsvm flexibility choice penalties loss functions scale better large numbers samples moreover scikit learn dev suggested kernel approximation module similar question issue scaling data solved problem can try using accelerated implementations algorithms scikit learn intelex changed following response way fasterbefore tensorflow neural network starts training following warning prints warning tensorflow layer model casting input tensor dtype float layerdtype float new behavior tensorflow layer dtype floatdtype defaults floatx intended run layer float can safely ignore warning doubt warning likely issue porting tensorflowmodel tensorflow change layers dtype float default call float change just layer pass dtype float layer constructor author layer can disable autocasting passing autocast false base layer constructor now based error message able silence error message setting backend float like get bottom set right dtypes manually full codedr avoid cast input float numpy explanation default tensorflow uses floatx defaults float standard deep learning can verify input provided iris dataset dtype float mismatch tensorflowdefault dtype weights input tensorflow doesnlike casting changing dtype costly tensorflow will generally throw error manipulating tensors different dtypes comparing float logits float labels new behaviortalking layer model casting input tensor dtype float layerdtype float new behavior tensorflow will automatically cast input dtype float tensorflowprobably threw exception situation although cansayever used trying evaluate multiple linear regression model data set like data set rows columns need predict ground truth value articles will add multiple linear model articlesamantadinecommon code multiple linear regression problem extract data dataframey variables codeconvert dataframe type structure can help appreciated can turn dataframe matrix using method matrix directly dataframe object might need specify columns interesteddfxmatrix differents column namesvariables can usedf ground truth values get array example randomly generated data calling matrixreturns might get warning saying futurewarning method matrix will removed future version use values instead fix use values instead matrix shown belowilike normalize training set passinginstead manually subtract mean divide std tried amazed results got running results unfortunately docs donexplainhappening hood can please explain use kind normalization expect actually uses hood normalize given data usingnorms example default case normalize data usingnormalization can either use function donwant mean std normalization manually can use standardscaler sklearn even minmaxscaler anyone know update subset weights used forward propagation guess might able applying compute gradients followsexample doubles values position see easiest way pull numpy array using npvar tfvar perform operation npvar can upload modified data back tensorflow using npvar obviously slow really useful training work constructed decision tree using rpart dataset divided data parts training dataset test dataset tree constructed dataset using training data want calculate accuracy predictions based model created code shown now want calculate accuracy predictions generated model comparing results actual values train test data however facing error code shown get error message states errorpredcomparison types implemented addition warning message incompatible methods checking typepred found type integer however documentation states predict method must return vector unable understand type variable integer list made mistake can fix try calculating confusion matrix first now can calculate accuracy dividing sum diagonal matrix correct predictions total sum matrix response similar mtotoone bitwrong way maybe canonical way problem two dataframe like merge without extra column without erasing existing infos example existing dataframedataframe mergelike updatedf columns corresponds result solution thinkreally good one anyone better way thanks yes can done without merge can try use gridsearchcv scikit learn library find best model will final model returns said set hyper parameters train numbersay models way will function return best model models best setting parameters gridsearchcv will return object quite lot information return model performs best left data best estimator estimator dict estimator chosen search highest score smallest loss specified left data available refit false note modeltrained entire data means confident model want will need retrain model entire data ref refitted estimator made available best estimator attribute permits using predict directly gridsearchcv instance donneed fit model can directly get best model best estimator attributewe donallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed last year book one start domain spiking neural networks know gerstnerspiking neuron models published recent book maybe suitable one background maths artificial neural networks good articles overviews domain also add list thanks later edit karelanswer depends mean spiking neural networks least several basic points view gerstner represents first one focused modelling biological neurons book really good starting point understanding bio physical models neuron past possible find book also html hand spiking neuron computer science context usually meant srmo model spike response model can used also alternative classical percepron based networks model described works wolfgang maass focused computational power model compares srm model percepron rbf unit want use model network recommend works sander bohte sbohte derived spikeprop algorithm personally derived variant spikeprop fast enough used real word applications spiking neural networks snns pulsed neural networks pnns artificial neural networks anns closely emulate behaviours natural neural mechanisms like advise following fundamental books personally derived variant remote supervised method resume better learning rate morphological advantages compared resume introduced filip ponulak meantime like list simulator tools dealing snns played based python please take account might others based languages donforget bindsnet best choice trendingusing sklearns orthogonalmatchingpursuit get sparse coding signal using dictionary learned ksvd algorithm however fit get following runtimewarning cases results indeed satisfactory donget point warning common sparse coding overcomplete dictionary thus also linear dependency within issue omp fact warning also raised dictionary square matrix might warning also point issues application problem data vectorcontained numbers small magnitude normalized fit works expected pca logistic data accuracy reduced shocked see result can anybody explain gone wrong guarantee pca will ever help harm learning process particular use pca reduce amount dimensions removing information data thus everything can happen removed data redundant will probably get better scores important part problem will get worse even without dropping dimensions just rotating input space pca can beneift harm process one must remember pca just heuristic comes supervised learning guarantee pca consequtive dimension will explain less less variance best affine transformation terms explaining variance firstdimensionscan completely unrelated actual problem pca consider labels given dataset pca will transform way depends positions points labelings consistent general shape data might help many others complex patterns labels will destroy previously detectable relations futhermore pca leads change scalings might need different hyperparameters classifier regularization strengthnow getting back problem say case problem bug code drop accuracy significantly accuracy means using opposite classifier give just answering false says true way around even though pca might help might even harm described case error code sure pca reducing number features care class labels thing cares preserving maximum variance may always optimal classification taskreg hand pushes features towards zero much correlation class labels hencereg strives reduce number features also getting good classification performanceregularization preferred pca reduced number features avoid fitting can always hyper parameter tuning find best lambda want kmeans clustering dataset namely sample data three variables columns typical way scaling columns determining number clusters will use functionpreference variables mean suppose variable column important two variables can insert weights model thank use kmeans weighted clustering like one presented flexclust package hard competitive learning neural gas data matrix weights optional vector weights used fitting process works combination hard competitive learning toy example using iris data can see output cclust also using competitive learning family always kmenas difference related cluster assignment training phase method kmeans classic kmeans algorithm given macqueen used works repeatedly moving cluster centers mean respective voronoi sets hardcl line updates used aka hard competitive learning work randomly drawing observationmoving closest center towards point ripley weights parameter just sequence numbers general use number minimum weight maximum weight problem answer satisfying wanted observation weightedmeans clusteringgood readable example question link standardmeans algorithm hard competitive learning algorithm difference described package description looked many sites find solution packageorder use perform standardmeans algorithm weighted observations also wondering flexclust package explicitly support weights standardmeans algorithm anyone explanation please feel free share basically two options first rewrite flexclust algorithm enable weights within standard approach second can estimate weighted cluster centroids starting centroids perform standardmeans algorithm one iteration compute new weighted cluster centroids performmeans one iteration reach convergence used second alternativec easier way used hope familiar want increase weight variable column just multiply constants trivial show increases weight ssq optimization objective question regarding random forests imagine data users interacting items number items large around output random forest items user likely interact like recommender system user want use feature describes items user interacted past however mapping categorical product feature one hot encoding seems memory inefficient user interacts couple hundred items sometimes littleconstructing random forest one input features categorical variable possible values output categorical variable possible values use catboost features categorical use one hot encoding think xgboost catboost better also try entity embeddings reduce hundreds boolean features vectors small dimension similar word embedings categorical features practical terms define embedding discrete space features vector space low dimension can enhance results save memory downside need train neural network model define embedding hand check article information xgboost doesnsupport categorical features directly need preprocessing use catfeatures example one hot encoding one hot encoding usually works frequent values cat feature catboost categorical features support one hot encoding calculation different statistics categorical features use one hot encoding need enable one hot max size parameter default statistics calculated statistics usually work better categorical features many values assuming enough domain expertise create new categorical column existing columncolumn values awarec similaresimilarh similar new column random forest model removing previous column include new column transforming features like loose explainabilityaskedtrained lstm model predict binary class batches samples featuresshape datam number batches data target model code training stage model stateful predictingusing stateful model iterating data outputting probability sample looking probability end batch exactly value get predicting entire batch one one howeverexpected probability will always continue right direction new samples arrive actually happens probability output can spike wrong class arbitrary sample see two samples sample batches time prediction label label way achieve want avoid extreme spikes predicting probability given fact explanation advice appreciated update thanks today advicetried training network hidden state output input time step using return sequence true last lstm layer now labels look like shape model summary however get exception need fix note just idea might wrong try like appreciate feedback way achieve want avoid extreme spikes predicting probability given fact can experiment set return sequences argument last lstm layer true replicate labels sample much length sample example sample length label create new label sample consists zeros can probably easily using numpy function like retrain new model test new samples afterwards sure expect monotonically increasing decreasing probability graphs time update error mentioned caused fact labelsarray look output shape last layer model summary use assumingtrain shape num samples actually tried experiment suggested imdb dataset using simple model one lstm layer one time used one label per sample original approach shlomi time replicated labels one label per timestep sample suggested code like try can create stateful replicas training models run test data compare results actually first sampletest label second sampletest label letfirst see stateful prediction test model two samples look like result correct label end spiky fluctuating now letcompare stateful predictions rep test model result correct label prediction end time much smoother monotonic trend expected note just example demonstration therefore used simple model just one lstm layer attempt tune guess better tuning model number units layer activation functions used optimizer type parameters etc might get far better results experiment three time series datasets different characteristics experiment whose format following first column timestamp reproducibility reasons sharing data column wanted read current row compare value previous row greater keep comparing current value smaller previous rowvalue want divide current value smaller previous value larger accordingly code produces following three points one dataset shared can see points plots based code given data pretty consistent whose value around data will two quotients whose values will concentrate either around values data concentrated around two values either around way given new data point quotient quotient times want know cluster belongs building dataset stacking two transformed features quotient quotient times trying kmeans clustering following giving error valueerrorsamplesclusters can fix error update samlpe quotient data array quotient variable now one single sample get different error message probably due different python scikit learn version essence gives following error despite different wording different essentially says data look like single sample following first advice column resolves issue please try code brief explanationdone first built dataset sample quotient times quotientstandardized become easier cluster followingapplied dbscan multiple hyperparameters eps min samplesfound one separated points better finallyplotted data respective labels since working dimensional dataeasy visualize good clustering trying make clusters testing iris data set started hidden nodes worked lowered number nodes hidden layer expecting fail surprised see accuracy went set experiment azurejust validate wasncode thing accuracy single hidden node can anyone explain happening first established variety classification models yield incredibly good results iris iris predictable see example secondly can observe relatively features iris dataset moreover look dataset description can see two features highly correlated class outcomes correlation values linear single feature correlations indicates one can likely apply linear model observe good results neural nets highly nonlinear become complex capture greater greater nonlinear feature combinations number hidden nodes hidden layers increased taking facts account features beginhigh linear correlations class point less complex linear function appropriate predictive model using single hidden node nearly using linear model can also noted absence hidden layer just input output nodes logistic transfer function used equivalent logistic regression just adding dmlashgood answer iris data set can even predicted high accuracy using just three simple rules one attribute general neural networks black boxes never really know learning case back engineering easy conceivable learnt something like rules found using onerallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago researching natural language processing algorithms read piece text text seems trying suggest meeting request sets meeting automatically example email text reads letmeet tomorrow someplace downtownalgorithm able detect time date place event someone know already existing nlp algorithms use purpose researching nlp resources like nltk toolsmuch success thanks application information extraction can solved specifically sequence segmentation algorithms like hidden markov models hmms conditional random fields crfs software implementation might want start mallet toolkit umass amherstpopular library implements crfs information extraction treat token sentence something labeled fields interestednone function word features like part speech capitalization dictionary membership etc something like will need provide hand labeled training data first though look tried jupyter notebook output problem still headlines today still looking algorithm solutions using antlr parser generator large choice programming languagescjs java open source referencestrying perform object detection rcnn dataset following tutorial matlab webpage based picturesupposed put image paths first column bounding box object following columns images one object kind example vehicles one image deal create separate row instance vehicle image example found website finds pixel neighbourhood largest score draws bounding box around region image multiple objects now complicates things two approaches can use facilitate finding multiple objects alternative approach choose valuedisplay topbounding boxes associatedhighest scores course requires know valuehand will always assume found object image like second approach addition logic approach state need create separate row instance vehicle image correct means multiple candidates object single image need introduce one row per instance keeping image filename therefore example vehicles one image need create rows table filename single bounding box specification distinct object image done assuming already trainedcnn detector want use original code detect objects following referencing website works one object highest score wanted multiple objects use score output detect method find locations either accommodate situation situation situation modify look like following notestored original bounding boxes labels scores original variables subset ones surpassed threshold separate variables case want cross reference two wanted accommodate situation code remains situation exception defining threshold code now change end result will multiple bounding boxes detected objects image one annotation per detected object think actually put coordinates image single entry training data table see matlab tutorial details load training data matlab locally check vehicledataset variable will actually see sorry score high enough include images directly answers summarize training data table make sure one unique entry image put however many bounding boxes corresponding category matrix row formaty width height learned essays tomas better way forming vector sentence concatenate word vector due clumsy mathematics still sure details example supposing dimension word vectorsentencewords will correct result concatenating operation row vectormmatrixxleast three common ways combine embedding vectors summingsumming averagingconcatenating case concatenating givem vector number sentences cases vector length stays seeconcatmean allows use three options keep getting error attributeerror module xgboost attribute xgbregressor code error python anacondasolve probably problem solved telling python explicitly find xgboost library reason one scripts name find definition xgbregressor command used path xgboost python package since dir call missing basically everything suspicion whereverstarting script xgboost subfolder empty initfound first import case solve problem pretty easily using xgboost import xgbregressor probably many files name check working directory seefiles name change name something else exact problem python anaconda windows bits fall creator update get work uninstall xgboost within anaconda chosen environement manually deleted xgboost directoryprogramdata anaconda downloaded xgboost page anaconda launch command prompt environment want xgboost coursedirectory downloaded whl file type pip install xgboostcpwin exact name file downloaded steps xgboost worked properly make sure follow download instructions xgboost website installing compiling forgot run python package installationireading imagesnetwork also need associated labels along tried follow answer labels output donactually match imagesgetting every batch names images format dir just extract label image file name something wrong slice input producer actually ensure input tensors synced aside also noticed get batch elements batch adjacent original list gave batch order isnoriginal order example data dir dir dir dir dir dir may get batch batch size dir dir batch dir dir last one makes hard even just use fifo queue labels since order wonmatch batch order complete runnable example reproduces problem prints basically eval call runs operation another time adding batching make difference just prints batches first filenames followed next labels workaround see correctly prints nothing violation principle least surprise edit yet another waymuch better way however results warningcjenkins home workspace release win device cpuwindows tensorflow core kernels queue input producer input producer fraction full fraction full skipping cancelled enqueue attempt queue closed see thisi tried pass gridsearchcv scoring metrics like balanced accuracy binary classification instead default accuracy got error valueerror balanced accuracy valid scoring value valid options accuracy adjusted mutual info score adjusted rand score average precision completeness score explained variancef macromicrosamplesweighted fowlkes mallows score homogeneity score mutual info score neg log loss neg mean absolute error neg mean squared error neg mean squared log error neg median absolute error normalized mutual info score precision precision macro precision micro precision samples precision weightedrecall recall macro recall micro recall samples recall weighted roc aucmeasure score strange balanced accuracy valid without defining balanced accuracy code works fine also scoring metrics error seems different ones document ideas thank much scikit learn version update sklearn latest version want use balanced accuracy can see documentation balanced accuracy valid scoring metric added neural network takes inputs list actors plot summary movie features movie reviews title tries predict sequence movie genres neural network use embeddings layer global max pooling layers however recently discovered recurrent layers attention interesting topic days machine learning translation wondered use one layers plot summary input note donml translation rather text classification neural network current state will see structure input layers embedding layers apply bidirectional layer lstm plot summary input however current bidirectional approach plot summary got following error problem can utilize attention text classification solve error doncomment solution error question suggesting ways create recurrent layer attention plot summary input also hesitate write comments article might help achieving keras remain disposal additional information required regarding structure neural network find neural network complicated can make simple version however original neural network want proposals basededit find colab notebook code want execute code included two answers one proposed comments already answered question written official answer question first approach proposed marcocerliani works although like also second approach work approach allohvk approaches implemented runtime cell attached colab latter work moment latest error get valueerror input layer globalmaxpooling plot summary layer incompatible layer expected ndim found ndim full shape received none solved latest error edit removing globalmaxpooling plot summary layer neuralnetwork structure let summarize intent want add attention code sequence classification task seq seq translator really care much way donedebugging error just need working piece code main input movie reviews consistingwords want add attention assume embed reviews pass lstm layer now want attend hidden states lstm layer generate classification instead just using last hidden state encoder attention layer needs inserted barebones implementation look like now call attention layer lstm dense output layer can build top seem want use features apart movie reviews come final sentiment attention largely applies please refer recall class recall class came following code sure calculate true positive class seems will usey create tensor shapetrue values sayedit based marcincomments wanted create custom metric based callback keras browsing issues keras came across following codemetric callback returning accuracy wanted implement unweighted recall recall class recall class can think following code appreciate help complete edit model keras version mean problem two classes actually one dimension output now two classes actually element output callback version callback can use lambdacallback manually print store results recall function usinginsteadepsilon float eps epsilon eps looking can help understand image mean image stdnoticenecessary quantized example see rough thoughts pixels frequently represented colors using range exactly middle range every pixel color adjusted input normalization common technique machine learning specific model trained input value range normalize inference input range achieve best result give intuition willwrong input isnnormalized range can arbitrary often used point normalization applied training inference trying use deep neural network architecture classify binary label value code tensorflow output get run donunderstand values getting correct real dearth non mnist binary classification examples accuracy nothing like expected expecting percentage instead large value also somewhat unsure theory behind machine learning cantell correctness approach using tensorflow can someone please tell approach towards binary classification correct also accuracy part code correct binary label value assuming values traintestactually going work chosen loss function sigmoid cross entropy logits assumes negativevalues causing mayhem however loss function choice good binary classification suggest changevalues addition technically output network final prediction loss function sigmoid cross entropy logits designed work network sigmoid transfer function output layer although got right loss function applied done training code appears correctsure personally logit output prediction value output can get high confident predictions probably explains high values later due missing sigmoid function add prediction tensor represents probability confidence example positive class can use calculate accuracy accuracy calculation basederror sum correct values closer code commented appears multiclass classification comparison true false binary classification need threshold predictions compare true labels something like accuracy value want percentage just multiply course class minority class class majority class since lot data planning oversample minority class balance classes become split wondering oversampling done splitting data train test sets generally seen done splitting online examples like however wouldnmean test data will likely duplicated samples training set oversampled training set means testing performance wouldnnecessarily new unseen data fine like know considered good practice thank wondering oversampling done splitting data train test sets certainly done splitting validation test ones see also related answer generally seen done splitting online examples like code snippet show obvious done splitting claim depends exactly train variable product train test split oversampling takes place splitting indeed however wouldnmean test data will likely duplicated samples training set oversampled training set means testing performance wouldnnecessarily new unseen data exactly reason oversampling done splitting train test witnessed case modeller struggling understand getting test accuracy much higher training one turned initial dataset full duplicates class imbalance idea similar several duplicates naturally ended test set split without course new unseen fine shouldnexperience bad practice mentioned test data contain unseen samples overfit give better evaluation training process need increase sample sizes think data transformation possibilities symmetric can double sample size mirroring imagestrying fit machine learning model takes audiofile wav predicts emotion multi label classificationtrying read sample rate signal file calling read filenamegetting valueerror incomplete wav chunktried switching output signal sample rate reason librosa takes exponentially longer time scipy impractical tasktriedy open filenamesuggested availtried looking files checking might cause wav files good scipy managed read bad raised error couldnseem find thing pointing makes file pass fail nonethelessweird result files taken dataset originheard people saying justexport files wav using software work didntry donaudio processing software seems like overkillwant understand actual problem rather put bandaid assume filenames subset audio files containinggoodbadgood actual file gets processedbad actual file raises error using vlc seems codecs supported either case files codecweird doncodec good file codec bad file donknowread file might invalid chunk readers simply ignore note even read good file warning wavfilewarning chunk non data understood skipping generated can read fearful song strong dogs actusing wavio source code github wavio package created wraps pythonstandard wave library functions understand numpy arrays solve problem changing number file condition code len chunk just intuition good luck now wonder works possible reasons keras documentation steps per epoch total number steps batches samples yield generator declaring one epoch finished starting next epoch typically equal number unique samples dataset divided batch size samples set steps per epochwork slowly set steps per epochwork faster thought batch works compared much video memory allocated first second cases notice big difference use simple fit function difference largereal speed just process examples instead parameter necessary can speed training generator code steps per epoch parameter number batches samples will take complete one full epoch dependent batch size batch size set initialize training data examplebatch size specified batch size parameter said samples steps per epoch equivalent total number samples divided batch size process implementing keras available two videos reason set steps per epoch generator designed run indefinitely see docs generator expected loop data indefinitely implemented setting since fit generator supposed run epochstimes method must know next epoch begins within indefinitely loop hence data drawn beginning using followingcode produce confusion matrix comparing true labels data output neural network however sometimes neural network doesnpredict certain class table isnsquare example levels levels nnetpredict factor want make table square adding factor levels necessary setting counts zeroexample can see table rows columns factor levels whereasfactor levels want pad table zeros row labels column labels matrix square example produce reason need two fold edit roundaddress additional details question deleted first answer since wasnrelevant anymore produced desired output test casesgiven definitely advise testing thoroughly real data approach find full list levels inputs table set full list levels generating table two test cases stuck dataset contains categrotical features high cardinality like item description read trick called hashing main idea still blurry incomprehensible also read library called feature engine didnreally find something might solve issue suggestions please options use target encoding target encoding syllabus section feature preprocessing generation respect modelsvideouse entity embeddings short technique represent category vector training obtain characteristics category tutorial iii use catboost extra hashing trick technique might also helpfulcee look category encoders many different encoders can use encode columns high cardinality single column among known bayesian encoders use information target variable transform given feature instance targetencoder uses bayesian principles replace categorical feature expected value target given values category takes similar leaveoneout may also check catboost based catboostencoder common choice feature encoding variables like item description essence text variables check paper corresponding python package simply search online dirty categorical variables doubt article package gal varoquaux one main developers example error sure can use ragged tensors like examples found embedding layer lstm donwant create additional embedding layer recommend use input layer rather inputlayer often need use inputlayer anyway probelm shape input lstm layer input shape wrong modification made comments using shap libraryinterpretability better understandmeans segmentation algorithm clusters nutshell make blogs usemeans cluster take clusters label xgboost try predict clusters signle label multi class classification problem pictures make sense class base value shouldnasked ago similar question time set already link logit link logit seem right multiclasssuitable binary output see probabilities summing letstreamline code see expected values base scores raw space multi class raw scores can converted probabilities softmax link logit doesnmake sense multiclass seems impossible switch raw probability still maintain additivity softmaxy softmaxsoftmaxwish analyze data probability space try kernelexplainer summary plot now additive shap values probability space align base probabilities see predicted probabilitiesdatapoint computer following software installed anaconda tensorflow gpu keras two anaconda virtual environments one tensorflow python one gpu version installed accordinginstructions cpu version tensorflow installed previously separate environmentdeleted run following check nvidia smi shows mib gpu memory usage python looks like gpu used calculations ideas can going wrong good way debug problems check operations allocated devices can check passing configuration parameter session run app will see output indicating devices used can find information summary check tensorflow gpu working use code check list available cpus gpus use code install tensorflow gpu windows using cuda cudnn guide overview guide complete details make sure hope helpful reason gpu wasnrunning broken installation cudnn precisely libraries source came different versions cudnn fixed following piece advice slippery problemalmost computer will use possible excuse revert back cpu ensure tensoflow keras pytorch currently used see obtained trained tensorflow model freeze graph function suppose simplicity like change sigmoid activations model tanh activations letdiscuss whether good idea can done access frozen graphfile without possibility retrain model aware graph editor library able kind job wasnable figure simple way documentation solution use import graph def wrote post can try graph load graph filename graph def relunode graphtanh graph def path savfrozn altered false please let know worksfile contains savedmodel protocol buffer able load using savedmodel loader can also inpsect savedmodel cli full documentation savedmodels something along lines work tfidfvectorizer takes much memory vectorizingk documents takesgo million documents will fitramhashingvectorizer still need know distribute hashing strongly recommend use hashingvectorizer fitting models large dataset hashingvectorizer data independent parameters important hencepickling hashingvectorizer instance fast vocabulary based vectorizers better suited exploratory analysis small datasets one way overcome inability hashingvectorizer account idf index data elasticsearch lucene retrieve termvectors using can calculateidfgetting error valueerror error checking input expected sequence dimensions got array shape codesusing outputrows code insights two things convlayer expects input shape batch sizefilters case need reshape input layer add another axis size change anything data trying use multiple inputs sequential api best choice recommend using functional api edit regarding comment sure wrong working version code fake data reshape outputreading convolutional netsprogrammed models see visual diagrams models shows layer smaller deeper last ones layers three dimensions likex third number assume first two numbers number nodes donknow depth many articles posts explaining convolution layers worktry answer question without going many details just focusing shapes assuming workingconvolution layers input output will three dimensional without considering batch correspondshape convolution layer input willhhc depending frameworknumber channelswidth inputwidth can seechannel hxw image intuitive example input input first convolution layer convolutional neural network likely image size hxwchannels examplegreyscales important pixels input values channel gives additional information pixel three channels will give pixel pixel positioninput space richer content single since pixel will encoded three values three channelssingle one one channel kind intuition channels represent can extrapolated higher number channels said input canchannels now going back convolution layers good visualization imaginechannel input convolution layer consisting singlefilter now keep mind dimension output will depend stride padding convolution layer shape output shape filter necessarily take input shape convolution settings end shape different filter shape also something note input one channel shapehfilter number channels channel input convolve channel filter results averaged singlefeature map intermediate outputaveraging channels leaveresult considering convolution single filter however many input channels output will always single channel can assemble multiple filters layer means define layerx filters layer consistsfilters computation output idea simple one filter gives feature mapfilters will givefeature maps maps stacked will channel dimension ultimatelyleft output shapelethw kernel height kernel width respectivelyw height width one outputted feature map back question layers dimensions likex third number assume first two numbers number nodes donknow depth convolution layers four dimensions one imposed input channel count can choose size convolution kernel number filters number will determine number channels outputseems extremely high likely correspond output shape feature map hand number channels output layer shapes example take vgg neural network deep convolutional networks large scale image recognition input shape vgg knowing result first convolution shape can determine total filters layer turns kernel size vggquestion knowing single bias parameter per filter many total parameters vggfirst convolution layer sorry short answer digital image dimensions often colors convolutional filter looks parts picture lower height width dimensions much depth channels case get information fed neural network learn created example pytorch demonstrate outputreal tensor inside may help can play lot convolution parameters need keep trackscores tuningsigma svm example following code keeps track accuracy need changescore able seen following two links retraining cross validation libsvm fold cross validation one svm using libsvm understand first find bestgamma sigma parameters training data use two values leave one crossvalidation classification experiment want now first grid search tuningsigma please prefer use matlab svm libsvm code leave one crossvalidation classification changed code making mistakes getting errors put loop varies boxconstraint rbf sigma parameters uses crossval outputscore iterations combination parameters can use single loop exactly like libsvm code example numel probably faster nested loopuse nested loop approaches now just define function fun docs say fun fun function handle function two inputs training subsetxtrain test subsetxtest follows testval fun xtrain xtest time called fun use xtrain fit model return criterion testval computed xtest using fitted model fun needsnotice fun cantake extra parameterswrapped anonymous function can pass currents values fun stuffjust trick convert six parameter fun parameter one required crossval found problem target trainidxrow vector just replaced target trainidx target trainidx column vector training dataset text particular category say cancer want train svm classifier class weka try creating folder cancer putting training files folder run code get following error handle unary class want classifier finds document related cancer says class name correctly fed non cancer document say something like unknown get behavior smo algorithm weka binary classification two classes sequential minimal optimization specific algorithm solving svm weka basic implementation algorithm examples cancer binary perhaps havenlabeled correctly however using training data examples cancer want tell whether future example fits pattern attempting one class svm aka outlier detection libsvm weka can handle one class svm unlike weka smo implementation libsvm standalone program interfaced weka incorporates many different variants svm post wekalist explains use libsvm weka developed time series model lstm canuse predicting stock price future days want use predicting stock price next year plot use forecasting stock price future next year one way feed forecasts back model inputs step update input sequence dropping oldest value adding latest forecast recent value schematically illustratedlength input sequencelength time series code shows implement approach lstm model plot enrollment user gives single image training however can add use images given user authentication reason want add images training user environment restricted different lighting conditions different distance camera differentcameras relief pose almost frontal think problem similar face tagging app widely available can anyone suggest method use available images adaptively smartly thanks make classifier robust need use condition independent features example use face color since depends lighting conditions state person however can use distance eyes since independent changes suggest building model independent features retrain classifier time person starts authentication session best model can think active appearance model one implementations recommend give som self organizing maps close look think contains solutions problems constraints mentioned can employ single image per person problem also using multiple som face strategy can adapt cases additional images available training pretty neat whole concept new face encountered new one rather whole original database neededlearned links might find helpful along way wiki interesting research paper demonstrates mentioned technique good luckrecently came across parameter layer caffe seems like layer exposes internal parameter blob top layer using can give usage example layer introduced pull request following description layer simply holds parameter blob user defined shape shares single top exactly expected introduced context issue basically proposes treat parameters like normal bottom blobs show can useful consider following example taken issue longjon inner product layer calculatesbtop blob outputbottom blob must parameter blob restrictive makes impossible use inner product layer multiplying inner product two bottom blobs suggests make fundamental change make parameters independent layer instead treat like normal bottom blob first step direction parameter layer introduced allows define new parameter can feed bottom another layer counterpart method feeding parameters layer bottom blob proposed pull request isnmerged yet jan though merged yet can still use parameter layer define new learnable parameters feed layers bottom blob trying predict using learnedfile learning model follows wrote form input follows thought shape correct following error occurred valueerror error checking expected dense input shape got array shape shapeobviously error doesndisappear data csv file form value value value class can solve problem shapeobviously error continues rightkeras expects expects shape convention axis denotes batch size axis denotes features first dense layer accepts featurescomplains sees just one solution simply transposeprepared two different arff files two different datasets one testing training equal instances different features changing dimensionality feature vector file cross validation files working perfectly shows arff files properly prepared donerror now use train file less dimensionality compared test file evaluation get following error test file weka requires less number features train code evaluation test file weka requires less number features train code evaluation number features necessary may need insert class attribute according weka architect mark hall compatible header information two sets instances needs number attributes names order furthermore nominal attributes must values declared order sets instances unknown class values test set just set value missingaccording wekawiki number features needs training test sets also type features nominal numeric etc needs also assume didnapply weka filters either datasets datasets often become incompatible apply filters separately dataset even filter divide dataset training test set can use removepercentage filter package explorer just following training set load full dataset select removepercentage filter preprocess panel set correct percentage split apply filter save generated data new file test set load full dataset just use undo revert changes dataset select removepercentage filter yet selected set invertselection property true apply filter save generated data new filei trying cross validation running error says found input variables inconsistent numbers samples using different columns pandas data framefeatures last column label derived machine learning repositoryirvine importing cross validation package used past getting error may depreciated going running decision tree svmnn code help great cross validation module deprecated new module model selection taken place everything cross validation now available model selection code becomes now far declaringy concerned wrapping list just use like can simply use code without changing anything last question folds cross validation multiple classes sklearn depending upon task please look contains fold iterators remember present model selection package items feature list pandas series donneed list feature list like done just need pass single table example looks like bank dataset work thing notice xis dataframe columns underlying data numpy ndarray list series single matrix correctly understood significance loss function model directs model trained based minimizing loss value example want model trained order least mean absolute error use mae loss function example sometimes see someone wanting achieve best accuracy possible building model minimize another completely different function example come model trained givebest acc sincetraining will try minimize another function mse know already trained metric model will givebest acc found training doubt shouldnfocus modeltraining maximize acc minimize acc instead minimizing mse done way wouldnmodel giveeven higher accuracy since knows maximizetraining start code snippet used example actually invalid although keras will produce error warning simple elementary reason mse valid loss regression problems problems accuracy meaningless meaningful classification problems mse valid loss function details including code example see answer function defines accuracy keras loss mean squared error mse similar situation scikit learn see answer thread continuing general question regression settings usually donneed separate performance metric normally use just loss function purpose mse redundant really needed sometimes people use something like show also performance mean absolute error mae addition mse now question shouldnfocus model training maximize acc minimize acc instead minimizing mse indeed valid least principle save reference mse classification problems roughly speaking situation follows use vast arsenal convex optimization methods order directly maximize accuracy accuracy differentiable function need proxy differentiable function use loss common example loss function suitable classification problems cross entropy rather unsurprisingly question pops time time albeit slight variations context see example answers interplay loss accuracy special case binary classification may find answers following threads useful wrote code multivariate polynomial regression used polynomial features transformation function sklearn possible make multivariate logarithmic regression sklearn kind logarithmic transformation like polynomial features can write multivariate logarithmic regression python code multivariate polynomial features want fit logarithms features one option box cox transform ols can apply sklearn using powertransformermllib following example given bunch sentences want give input train model sure model takes sentences just takes words sequence string input try train word vec model input work word vec take sentences input input correct however word vec will automatically remove words occur minimum number times vocabulary sentences combined default value case highly likely word occurs times data use change minimum required word occurrences use setmincount example min count lettake look simple class fairly straight forward pytorch module creates simple sequential dense network check hidden parameters see following expected result now lettry generalize bit turns number parameters within module longer believe understand happening bigger question overcome problem second generalized method example will sent gpu properly will trained optimizer problem generalized version stored regular pythonic list pytorch know look wish store need use specialized pytorch containers instance use example work fine btw need pytorch know members also functions moving gpu cpu setting mode eval training etc following shortened code trying run supposed happen iterating file training occasionally want calculate cost accuracy dev set data file inner loop finishes reading file obviously triggers exception causes code leave outer loop exception inner loop simply handled exception outer loop finishing reading file want code continue training file outer loop removed details like num epochs train etc simplify readibility code one suggestion regarding solve problem bit new thank advance solved apparently using queue runners right way tensorflow documentation indicates dataset api used instead took time understand code trying previously sharing case people may need put additional training code although found similar problem can vectorize list using sklearn dictvectorizer solution overly simplified like fit features logistic regression model predict chinese non chinese raw name will extract get two features just last name list substring last name example chan will giveha seems dictvectorizer doesntake list type part dictionary link try create function list dict successfully return dict elements idea incorporate dict applying dictvectorizer output sample data understood correctly want way encode list values order feature dictionary dictvectorizer use one year late something like can used depending case output another thing donrecommend donwant create many features values lists something like first one means canduplicate values probably donmake good features especially need fine tuned detailed ones also reduce possibility two rows combination two letter combinations thus classification probably wonoutput training lda model pyspark spark customers review dataset now based model want predict topics new unseen text using following code make model now dataframe column new customer reviews want predict topic cluster belong searched answers mostly following way recommended spark mllib lda infer topics distribution new unseen document however get following error ldamodel object attribute tolocal neither topicdistribution attribute attributes supported spark way infer topics unseen datagoing need pre process new data can just pass trained lda function need bow corpus want csv try hope helps possible duplicates optimalk means algorithm determineusingmeans clustering depending statistical measures can decidelike standard deviation mean variance etc simple method choosek means algorithm thanks advance navin explicitly want usemeans study article describingmeans using implementationmeans difference comparedmeans rather specifying singlespecify rangebest choice wrt measure range will part outputmeans can also look mean shift clustering algorithm computationally feasible given data possibly using sampling yura suggests clustering variouss evalute quality resulting clusters using standard cluster validity measures classic measures described measures doug correctmeans determines optimalnumber clusters cluster assignments startmeans differsmeans instead randomly choosing initialcentroids chooses one initial centroid randomly successively chooses centerschosen initial completely random choice data points chosen new centroid probability determined potential function depends datapointdistance already chosen centers standard referencemeansmeans advantages careful seeding arthur vassilvitskii also donthink general choosingnumber principal components will improve clustering imagine data points three dimensional space lying plane passing origo will get principal components natural clustering points number clusters unfortunately isnprincipled statistical method simple complex can set rightheuristics rules thumb sometimes work sometimes donsituation general many clustering methods type parameters two practical solutions problem intelligent selection number centroidscommon use first pca data output pca principal components eigenvectors cumulate contribution variation observed data obviously suggests optimal number centroids variability data explained first three principal componentswise choicemeans second commonly used practical solution intelligently estimaterevised implementationmeans algorithm calledmeans essencemeans just differs originalmeans additional pre processing step step number initial position centroids estimated algorithmmeans relies straightforward understand implement code good source post lingpipe blog offers excellent explanationmeans includes citation original paper first introduced technique aside providing optimal choicek means apparently superior originalmeans performance roughly processing time comparedmeans one published comparison accuracy three orders magnitude improvement error comparison study bayesianmeans may solution donknow number clustersrelated paper given website corresponding matlab code also given best solution unkown statistical paramters model etcproblem sample data find parameters thet best sub problem use full problem case select bestdata using keras create lstm model training getting error valueerror error checking target expected dense shape got array shape model model summary calling fit usingtrain one hot encoded label shapetrain shape sure model looking shape can see dense dense output shape nonefound issue posting answer can help others also facing issue layer configuration wrong loss function using sparse categorical crossentropy loss labels must shape batch size dtype int int changed categorical crossentropy expect label batch size num classes error message thrown keras like replace groupbykey reducebykey sure worried performance now relevant minified code notice println newcentroids will give mapeeprintln closest mappartitionsrdd map relevant question using reducebykey apache spark scala documentation def reducebykey funcvrddv merge values key using associative reduce function def reducebykey funcvnumpartitions int rddv merge values key using associative reduce function def reducebykey partitioner partitioner funcvrddv merge values key using associative reduce function def groupbykey rdditerablegroup values key rdd single sequence use aggregatebykey bit natural reducebykey like compute newcentroids work will need compute dimensionality data need probably use something like val dim validation training loss mse decrease training loss drops faster though resulting overfitting final model decided use dropout avoid overfitting using dropout validation training loss decrease first epoch remain constant epochs loss functions decrease way without dropout resulting overfitting final loss value range without dropout seems like dropout really working switchregularization though iam able avoid overfitting rather use dropout regularizer now iam wondering anyone experienced kind behaviour use dropout dense block bottleneck layer transition block dropout rate without regularization validation training loss mse decrease training loss drops faster though resulting overfitting final model overfitting overfitting starts validation loss starts increasing training loss continues decreasing telltale signature image adapted wikipedia entry overfitting diferent things may lie horizontal axis number neural net fitting iterations etc generally expected difference training validation loss something completely different called generalization gap important concept understanding generalization generalization gap difference modelperformance training data performance unseen data drawn distribution practically speaking validation data unseen data indeed seems like dropout really working can case dropout expected work always every problem interesting problem recommend plotting validation loss training loss see really overfitting see validation loss didnchange training loss dropped will also probably see large gap overfitting overfitting try reduce number layers number nodes also play little dropout rate reducing number epochs also helpful like use different method instead dropout recommend using gaussian noise layer keras tensorflow cnn code hands machine learning scikit learn keras tensorflow runcode windows run code chapter step kernel crashed prompting cuda gpu drivers successfully installed windows system instance running can see windows task manager gpu running calculationtakes seconds calculationtakes minutes happy announce solved issue searching many solutions finally weeks problem solved simply installing zlib cudnn please see details tested updated versiongot error using torch librarym mac using mps used wrong input size seem like torch throws error using mps instead ipy kernel crashes use cpu device instead throws error message likeml algorithms gives following error obviously reference sparkcontext inside apply classifier function code similar suggested previous question asked still havenfound solution looking tried using flatmap instead map get nonetype object iterable also like pass broadcasted dataset dataframe parameter inside apply classifier function finally possible trying alternatives possible trying apache spark doesnsupport form nesting distributed operations can initialized driver includes access distributed data structures like spark dataframe alternatives depends many factors like size data amount available resources choice algorithms general three options use spark task management tool train local non distributed models looks like explored path extent already advanced implementation approach can check spark sklearn general approach particularly useful data relatively small advantage competition multiple jobs use standard multithreading tools submit multiple independent jobs single context can use example threading joblib approach possible wouldnrecommend practice spark components thread safe pretty careful avoid unexpected behaviors also gives little control resource allocation parametrize spark application use external pipeline manager apache airflow luigi toil submit jobs approach drawbacks will require saving data persistent storage also universal robust gives lot control resource allocation six different sequnstial keras models desire concatenate like following output dimensions models input dimensions models different code will run completely without error now problem training model will try run following code train model one data instance dimension subarray equal input dimension corresponding model however following error valueerror failed convert numpy array tensor unsupported object type list found related post solve problem far can tell canjust pass variable size inputs together fit multi input model way pass training pairs model surely unable unpack concern input layers related post mentioned also important fact consider however tensorflow can use discussed sure workaround possible converting ragged tensor probably possible single input layer takes different length input sequence read fit methodtraining pairs input see keras expectsparamer follows case option pretty convenient choose passing dictionary mapped input names training pairs one way can first set names input layer model set model model etc now build whole final model also set last layer name set target concatenate dataset sample data provided legal model training mentioned firstly list numpy secondly multi input variable size convenient pass separately call fit will pass datasets dict mapping modelinput output names corresponding array letcheck get names composed model great now can pass training paris follow conveniently fit onerest works testing following code outputs means sample correctly predicted class quite obvious since used also training letgive look decision functions svm ova generate three classifiers three lines first separates class classclass second separates class classclass third separates class classclass original goal exactly understand decision function values mean knew positive values mean sample right side plane viceversa larger value larger distance sample hyperplane line case larger confidence sample belongs class however something clearly wrong since two decision function values positive supposed just correct class report positive decision function since predicted value also training sample reason tried plot separating lines obtained surprise indeed separating lines represent hyperplanes ovo oneone strategy computed indeed can notice lines separate class class class class class classalso tried add class happens vector representing decision functions length equals accordingly ova strategy lines generated implemented ovo strategy final questions decision function values represent even applying ova strategyn hyperplanes generated insteadones point default svm implement ovo strategy see reference svc nusvc implement one versus one approach multi class classification time default even though case made explicit decision function shape set ovr provide consistent interface classifiers decision function shape option allows monotonically transform results one versus one classifiers onerest decision function shapesamplesclasses reason ovo strategy implemented svm algos scale poorly size training set ovo strategy classifier trained part training set corresponds classes distinguish principle can force svm classifier implement ova strategy via instance onevsrestclassifierwant calculate group fairness metrics using aif sample dataset model gender protected attribute income target throws similar error disparate impact ratio seems data needs entered differently able figure can done transforming data standarddataset followed calling fair metrics function returns correct results image ref removetruepred characters function call retry one can see documentationwithin function prototype stands arbitrary number arguments see post logical guess wordstruepred keyword arguments passed names keyword arguments expressed kwargs within function prototype problempred default array type whole dataset dataframe convertpred default dataframe will lose order values result will show nan values new dataset converted dataset numpy array concatpred default array convert dataframe also change column names first now numbers exactly want dataframevalues correspondingpredicted values order count spd metricgot class classification problem letdefine classes case class important whatever gets classified class irrelevantrelevant however accuracy precision recall error rate classes like define accuracy metric looks subsection data relates gives measure model training asking code accuracyprecision recallfound can implementasking code can help select subsection categories perform metrics visually confusion matrix given like perform accuracy measure training following subset possible idea concatenate categorized argmaxedpred argmaxedtrue drop instances appearsunravel back one hot array simple binary accuracy remains edittried exclude class code doesnmake sense category gets effectively wrapped category true positives end labeled still looking help can anybody help please ashwin geetsahi working key point analysis task shared ibm link given dataset one rows text anyone can please tell can convert text columns tensors assign dataframe columns data facing problem never seen kind data like multiple text columns can convert columns tensors apply model time data like one text column columns label example movie reviews toxic comment classification got question right will sth like following will convert sentences token arrays trying build machine learning model predicts single number series numbers using lstm model tensorflow can imagine dataset look something like easily said just want model predict numberdata sequence numbersdata example likey datadata created numpy arraytrain want use train network using lstm networktrain shape samples time steps features reshapedtrain array shaped like samples length contain single numberdata created similarly shape samples contain single number desiredoutput current model attempt model summary looks like model compiled loss mse optimizer adam loss function simply mean squared error optimizerusing adam current results training model works fine can see loss validation loss decreases epochs actual problem occurs want predict dataverify dataverify training finished determine model trained following example simply used data used training determine model trained know overfitting verifying training set right way problem want demonstrate right following graph can seedata provided model blue orange line result callingverifyverify shapetrain also calculated mean absolute percentage error mape prediction actual data came around bad trained epochs result still helpful can see graph curves match question going using incorrect loss function seem like model tries predict single value samples rather predicting different value samples likesupposed ideally predictiondata provided curves look less ideas thanks back forth commentsgive best estimation questions going complex many layers deep model little data trained epochs non normalized data credit muhammad answer biggest issue far can tell number training epochs using incorrect loss function mse appropriate loss function regression task seem like model tries predict single value samples rather predicting different value samples likesupposed ideally predictiondata provided curves look less ideas training epochs biggest contributor far can tell based collab notebook luca shared epochs normalization way target flat predictions though canreproduce flat predictions luca posted epochs normalization worse epochs normalization okay now predictions least ballpark epochs normalization now model seems starting figure things likehope given training samples cobbled together notebooknaturally going overfitjust happy see learn something epochs normalization different loss never afraid try different losses may better suited others knowing domain taskjust trying mean absolute error instead mean squared error caution doncompare loss values different lossesscale epochs normalization larger learning rate okaytaking long time learn can nudge along little faster sure learning rate optimizergetgoing faster factor even employ learning rate scheduler starts big slowly diminishes course epochs hope helps notebook seems scaling data normalize standardize data training model first current result absolutely happy finally able achieve wanted least extent steps take achieve result end thought data better huge misconception able achieve results time steps per sampleglad just gave shot thank much answers will try imroved model suggestions think helpful change loss huber loss even change optimizer sgd first try define best learning rate based callback learning rate schedule cause small dataset even normalize standardize data training model want write naive base text classificator sklearn accept text form features transforming using tfidfvectorizer successfully able create classificatory using transformed data features code looks like everything works intended problems want add another featureflag indicating weather given text contains certain keyword tried multiple things properly transform url feature combine transformed feature another boolean feature unsuccessfully tips done assuming pandas frame containing two features url want transform contains keyword flag solution failed looks like produces rows containing boolean flag list wrong input sklearn model idea properly transform grateful help test data url splitted domain taken dns query target target class classification ads keyword flag indicating weather url contains ads word want transform url using tfidfvectorizer use transformed data together ads keyword possibly features future features used train naive bayes model demo showing union features tune hyperparameters using gridsearchcv unfortunately sample data set tiny train real cloudml code also makes predictions offline now trying use cloudmake predictions problems deploy model followed tutorial now code generates tfrecords via apache command looks like get errors exception running graph expected serialized scalar got shape seems like expect data different format found format specs json couldnfind tfrecords update output saved model cli show dir export model need make sure batchable outer dimension input placeholder shape none may require reworking graph bit instance see shape output hard coded outermost dimension none may happen automatically fix placeholder may require changes given name output probabilities also expect innermost dimension something like none num classes song genre classification classes song chopped small framesgenerate mfcc input features neural network frame associated song genre label data looks like following know can randomly pick say songs small frames training data rest testing now way writetrain frame frame level biney cross entropy loss function defined frame level wondering can customize loss function minimized aggregation frame level prediction currently also feed training testing data keras corresponding name data lost keeping data name lebel feature separate pandas dataframe matching back prediction keras good practice good alternatives thanks advance customized loss function usually needed genre classification combined model song split multiple prediction windows can setup multiple instance learning mil mil supervised learning approach label independent sample instances instead bag unordered set instances case instance second window mfcc features bag entire song keras use timedistributed layer execute model windows combine result using globalaveragepoolingeffectively implementing mean voting across windows easily differentiable majority voting runnable example example outputs inner combined model summaries shape feature vector fed model songs windows mfcc bands frames window fifth dimension sized make kerastrying make categorical cross entropy loss function better understand intuition behind far implementation looks like however understand function behave return correct value regardingpred digging keras backend source code binary crossentropy categorical crossentropy get can clearly see functions clipping operation output order avoid infinities logarithmspred will never exactly underlying calculations handling similar frameworks regardingtrue issue involved respective terms set according mathematical definition going omniglot maml example saw top testing code seems like mistake since means stats task meta testing shared however whenever eval instead get maml model diverges though test mini imagenet note related tldr use since uses batch statistics inference will deterministic anymore probably wonwant use meta learningintended behaviour likely donsee divergence testing just make sure use since uses batch statistics either new running stats cheat arensaved used can see variables write can get vector indices variables actually used can look structure object using str function looking see different places extract variables used make tree model one example edit since specifically asked indices can just match back variable names dataset although may always order havenused tree package cansay editright try thinklooking fit rpart species data iris setdiff levels fit frame var leaf quite since using package rpart instead tree think brian ripleysolution used rpart coded rpart printcp still interest goes like willing switch similar package rpart can get used variables ordered importance directly fiti working fraud analytics project need help boosting previously used sas enterprise miner learn boosting ensemble techniques learned boosting can help improve performance model currently group completed following models python naive bayes random forest neural network want use xgboost makescore better sure possible since come across tutorials xgboost naive bayes looking tutorial will show create naive bayes model use boosting can compare metrics without boosting see improved relatively new machine learning wrong concept thought replacing values xgboost sure one change can even work way naive bayes xgboost theory boosting base classifier easy straightforward scikit learnadaboostclassifier practice never use naive bayes neural nets base classifiers boosting let alone random forests ensemble method adaboost similar boosting methods derived afterwards like gbm xgboost conceived using decision trees dts base classifiers specifically decision stumps good reason still today donspecify explicitly base classifier argument scikit learnadaboostclassifier assumes value decisiontreeclassifier max depth case algorithms mentioned hence latter expected offer anything used base classifiers boosting result get anyone explain can use general formula channels kernel width kernel height channels num channels first example second addition number channels bias finished train model decided compare confusion matrix looks like shuffle dataset labels shuffled line awarelabel two testing sets related training sets confusion matrix shuffling phase confusion matrix without shuffling phase can see precision reports significantly different can explain gap two reports data shuffling never hurts performance often helps reason breaks possible biases data preparation can clearly see dataset prepared way first samples label next label last label try perform fold cross validation dataset without shufflingfind folds containing single label try foldfolds will include one labeljust theoretical possibility actually happened sincedifficult know beforehand bias may exist dataset always shuffle said never hurts just safe sideshuffling standard procedure machine learning pipelines even situation obviously depends details data donknow behavior surprising contrary totally expected number class class confusion matrix one need make sure mistake matching data class label trying create simple cnn classify images mnist dataset model achieved acceptable accuracy noticed model trained images epoch cause can fixed optimizer adam loss sparse categorical crossentropy metrics accuracy train images train labels epochs screenshot model colab screenshot trained modelproblem training model trained batches images images imageswanted take something like create hive udaf create aggregate function returns data type guess spark something like already built useful new wide datasets explore data helpfulwhole dataset one can decide get quite often want save parquet table providing correct data types make parquet space effiecient probably query time performant better parquet bloom filters just storing everything string varchar spark something like already built partially tools spark ecosystem perform schema inference like spark csv pyspark csv category inference categoricalnumerical like vectorindexer far good problem schema inference limited applicability easy task general can introduce hard diagnose problems can quite expensive depending data representation can impossible determine correct data type inferred type can lead information loss automatic schema inference can mask different problems input data supported additional tools can highlight possible issues can dangerous moreover mistakes data loading cleaning can propagated complete data processing pipeline arguably develop good understanding input data even start think possible representation encoding schema inference category inference may require full data scan large lookup tables can expensive even feasible large datasets edit looks like schema inference capabilities csv files added directly spark sql see csvinferschema try solve common problem medicine combination prediction model sourcesexpert opinion sometimes heavily emphysised medicine called superdoc predictor post solved stack model logistic regression enters expert opinion described page paper afsharmohammadi plataniotisoikonomou benalihandcrafted deep learning based cancer radiomics challenges opportunities ieee signal process mag availabletried without considering overfitting apply fold predictions lower learner example data stacked models without considering fold predictions now like consider fold predictions using mlr package family according helpful post tuning stacked learner created reprex packagethink mlr mlr pipelines suited task appears missing mainly pipeopselectselect extract features based name properties makes use selector objects code probably look something like looks like train evaluate model need create task objects model can now trained can used prediction quality prediction can evaluated works best turn ensemble learner get prediction test set prediction made task can used directly measure performance ground truth measure two notes trained tflite model faces tried implement android line got error detector inputs parameter change work problem java retrain model update problem seems tensorflow library mismatch input output map hope anyone knows eliminate mismatch debug variables given error line input output map update first installed demo app get started can detect many objects person cat laptop trained model usp sharing following link original model tensors shapecopy shape matches copy object shape try apply model shapecopy raises exception shape mismatch used custom model outputs differs used example update app changed model investigate new custom model determine input output shapes prefer use netron app open custom tflite model change input output data buffers application match corresponding inputs outputs model example use matches input output changed see near resultlabel new float map integer object outputmap new hashmap resultlabel new machine learning deep learning like clarify doubt related train test split training data set size belongs class belongs class like perform classification using lstm since sequence data can split data set training since classes equal distribution sets option consider whole data classes shuffle train test split proceed training option split class data set equally class class shuffle train test split proceed training will better way splitting training can get better results terms loss reduction accuracy prediction options rather options kindly recommend based comment section include part datatrain shape row every corresponds time step finally rows corresponds time steps milli secondsy train shape reference can seetrain data large include complete set entiretrain data provide one segment data better understanding data looks like segmentx train shape remaining will less looks like tldr try however stumbled upon problem handling imbalanced datasets came across techniques overbalancing underbalancing recommend using library imblearn will find various techniques handle cases one classes outnumbers one personally used smote lot relatively better success cases splits class mentioned test size working project experimenting credit dataset imbalanced dataset containing minority class majority class fraud detection using different sampling method found smote gives better results imbalanced datasets smote synthetic minority oversampling technique powerful sampling method goes beyond simple oversampling algorithm creates new instances minority class creating convex combinations neighbouring instances used smote sampling methods alongfold cross validation cross validation technique assures model gets correct patterns data getting much noise case imbalanced dataset accuracy score sampling algorithm yields accuracy seems impressive minority class totally ignored case imbalanced datasets used matthew coefficient correlation scorescore measuring algorithm addition accuracy performance measurement imbalanced dataset code referencesusing kobe bryant dataset wish predict shot made flag knnregressorused game date extract year month features wish use season year month features give weight distance function events closer date current event will closer neighbors still maintain reasonable distances potential datapoints example donwish event withing day closest neighbor just date featurestake account features shot range etc give weighttried use metric argument custom distance function arguments function just numpy array without column information pandassure can implementtrying edit using larger weights date features find optimalcv runningruns really slow idea make faster idea weighted features find neighbors close data point date avoid data leakagefinding optimalfirst prepare numpyweight array specifying weight feature something like can use kobe data year month features dataframe replaceline now define distance function guideline take twonumpy array initialize kneighborsregressor edit make things efficient can precompute distance matrix reuse knn bring significant speedup reducing calls dist since non vectorized custom python distance function quite slow now couldntest let know something isnalright just add shihabanswer regarding distance computation can use scipy pdist suggested post faster may may accurate depending surrounding context first tag sentence use pos tag additional parameter input lemmatization detailed walkthrough pos tag necessary see can use pywsd tokenizer lemmatizer wrapper nltkwordnetlemmatizer install code clarificationsrunning tensorflowcompiled source gpu support macbook nvidia geforcemgpuattempted train like initial clarificationslooking update thanks farooqhelpful notes tweaked version code prints prediction consoleran like finally got prediction great one tutorial warns dataset size accuracyprediction yaaay full execution took seconds example python train training data rnn tutorial data eval data rnn tutorial data classes file rnn tutorial data will simply read files folder download data files one one create tfrecord prediction certainly creation code mostly picked another file tensorflow guys create function along also modified code get inputcan find code changemerged yet note also modify modeladd lines additions comment compute current predictions thing left figure generating strokes data can take one existing tfrecord file read extract stroke read operation write javascript webpage generate strokesierror problem ran script jupyter notebook base root environment log said gensim library installed run command pip install gensim import still can imported error said modulenotfounderror module named gensim anyone can help problem will really appreciate help will help thesis work thank attention may jupyter lab maybe running base kernel kernel virtual environment check following notebook got result get instead meansusing wrong kernel can solve creating new ipython kernel new environment read running python classification script server using following code save gridsearchcv object using pickle can test classifiers smaller datasets local machine running great want evaluate best estimator validation setactually like gridsearchcv include original data arguably absurd data includes bookkeeping parameters tried perfold best estimator returned thing needed apply model new data encountered say like dig deeper details full results returnedresults attribute adapting example documentation knn classifier knn parameters grid removingjobs affects fitting speedreal hyperparameter algorithm keepingsimplicity said last result tells need know apply algorithm new data validation test deployment etc also may find actually removingjobs entry knn parameters grid asking insteadjobs gridsearchcv object results much fasterprocedure nevertheless want usejobs final model can easily manipulate best estimator actually answers second question since can similarly manipulate best estimator change hyperparameters found best model people stop reason want dig details whole grid search process detailed results returnedresults attribute can even import pandas dataframe easier inspection exampleresults dataframe includes column rank test score name clearly implies contains rank parameter combination means best can readily see one combinations ranked fact one best models although probably due relative simplicity used iris dataset reason principle happen real case cases returned best estimator just first occurrences combination number can easily see parameters best estimator now can inspect best models simply case results less models total models tried can fact select among choices even use additional criteria say standard deviation returned score less better although minimum value instead relying simply maximum mean score automatic procedure will return hopefully will enough get bug canseem find probably staring right face first tried examples mnist data trying replicate sign function trying replicate xor gate every time regardless epochs always produces output output neurons regardless many may roughly value cost function seems going using batch gradient descent done using vectors loop training example even implememented gradient checking values different thought try replacing back propagation updates approx gradient checking values gave results causing doubt even gradient checking code values produced training xor gate back prop grad grad approx cost training training epochs output different examples training question obvious problem back propagation gradient checking usual problems ann shows symptoms outputs roughly cost goingproficient reading python code gradient list xor contains elements corresponding weights assume two inputs one bias single neuron true network can learn xor minimuncan learn xor need two hidden neurons one output unit now looking feedforward functiondot product two vectors sigmoid scalar will always correspond output one neuron donsee way can add neurons layers code following advice useful debug newly implementeddonstart mnist even xor perfectly good implementation may fail learn xor can easily fell local minima spent lot time hunting non existent error good starting point will function can learned single neuron check forward computation pass manually computing results examples easy small number weights try train numerical gradient fails either numerical gradient wrong check hand training procedure wrong can fail work set large learning rate otherwise training must converge since error surface convex can train numerical grad debug analytical gradients check gradient per neuron gradient individual weights can computed manually compared see upon completion step everything worksadd one hidden layer repeat steps function everything works can move xor function complicated tasks procedure may seems time consuming almost aways results workingendthis example keras code want convert pytorch input dataset two dimensions labels dataset includes samples sample contains one row features thinking use dcnn regressionhyper parameter kernel size stride padding adjusted based dataset welcome pytorch really glad decide switch keras pytorch important step understand nns work detail specific questions code isnworking please let know name torch versionarticle helpful code seems changed little current standardsleaving vmware image using command downloading package got error traceback recent call last file line ioerror errno file directory tmp pip ggsbuild complete output command python traceback recent call last file line ioerror errno file directory tmp pip ggsbuild using pip python ubuntu lts vmware image can anyone please help solve error full try installing ubuntu vmware use discriminative algorithm letsay input datawant classify data labelsgenerative model learns joint probability distributionxdiscriminative model learns conditional probability distributionyread probabilitygivens really simple example suppose following data formyxpx take minutes stare two matrices will understand difference two probability distributions distributionynatural distribution classifying given exampleclassalgorithms model directly called discriminative algorithms generative algorithms modelxcan transformedyapplying bayes rule used classification however distributionxcan also used purposes example usexgenerate likelyy pairs description might thinking generative models generally useful therefore bettersimple paper popular reference subject discriminativegenerative classifierspretty heavy going overall gist discriminative models generally outperform generative models classification tasks generative algorithm models data generated order categorize signal asks question based generation assumptions category likely generate signal discriminative algorithm care data generated simply categorizes given signal imagine task classify speech language can either first one generative approach second one discriminative approach check reference details srihari cse models used follows discriminative models predict labeltraining examplemust evaluate merely chooses likely classconsiderings like trying model decision boundary classes behavior clear neural networks computed weights can seen complexly shaped curve isolating elements class space now using bayes rule letreplace equation since just interested arg max can wipe denominator will everyleft equation use generative models first case conditional probability distributionymodeled boundary classes second joint probability distributionxsincexppy explicitly models actual distribution class joint probability distribution function givencan calculate generate respectivereason called generative modelsimportant part lecture notesandrewrelated topic really helps understand difference discriminative generative learning algorithms suppose two classes animals elephantdogx feature vector animals given training set algorithm like logistic regression perceptron algorithm basically tries find straight line decision boundary separates elephants dogs classify new animal either elephant dog checks side decision boundary falls makes prediction accordingly call discriminative learning algorithmdifferent approach first looking elephants can build model elephants look like looking dogs can build separate model dogs look like finally classify new animal can match new animal elephant model match dog model see whether new animal looks like elephants like dogs seen training set call generative learning algorithm different models summed table image source supervised learning cheatsheet stanfordmachine learning generally practice machine learning community learn something donwant example consider classification problem onegoal assignlabels giveninput use generative model modelx irrelevant task hand practical limitations like data sparseness will forcemodelx weak independence assumptions therefore intuitively use discriminative models classification many answers rely widely used mathematical definition although useful narrow definition assumes supervised setting less handy examining unsupervised semi supervised methods also doesnapply many contemporary approaches deep generative modeling example now implicit generative models gans sampling based doneven explicitly model probability densityx instead learning divergence measure via discriminator network call generative models since used generate high dimensional samples broader fundamental definition seems equally fitting general question image source even question implies somewhat false dichotomy generative discriminative dichotomy fact spectrum can even smoothly interpolate consequence distinction gets arbitrary confusing especially many popular models neatly fall one fact hybrid models combinations classically discriminative generative models neverthelessstill highly useful common distinction make can list clear cut examples generative discriminative models canonical recent also lot interesting work deeply examining generative discriminative divide spectrum even transforming discriminative models generative models end definitions constantly evolving especially rapidly growing fieldbest take pinch salt maybe even redefine others addition informative point goes answer stompchicken fundamental difference discriminative models generative models discriminative models learn hard soft boundary classes generative models model distribution individual classes edit generative model one can generate data models features class modelxcan use probability distribution generate data points hence algorithms modelingxgenerativegenerative models naive bayes modelscdc classfeature vector alsocppc hence naive bayes form modelscbayes net markov nets discriminative model one can used discriminate classify data points require modelycasesdiscriminative models logistic regression neural networks conditional random fields general generative models need model much discriminative models hence sometimes effective matter fact sure unsupervised learning algorithms like clustering etc can called generative since modeld classesps part answer taken source generative algorithm model will learn completely training data will predict response discriminative algorithm job just classify differentiate outcomes previous answers greatlike plug one point generative algorithm models can derive distribution can obtain conditional distributionydiscriminative algorithm models can say useful discriminatings labelcalled discriminative model discriminative model doesnassumes independent givenx perpy hence usually powerful calculating conditional distribution two cents discriminative approaches highlight differences generative approaches focus differences try build model representative class overlap two ideally approaches used one will useful find similarities will useful find dis similarities article helped lot understanding concept summary good reading material conditional probability joint pdfis rule thumb set examples determine use genetic algorithms opposed neural networks vice versa solve problem know cases can methods mixed looking high level comparison two methods wikipedia genetic algorithmsearch technique used computing find exact approximate solutions optimization search problems neural networks non linear statistical data modeling tools can used model complex relationships inputs outputs find patterns data problem can quantify worth solution genetic algorithm can perform directed search solution space number items different classes neural network can learn classify items seen voice recognition execution times must also considered genetic algorithm takes long time find acceptable solution neural network takes long time learn can almost instantly classify new inputs genetic algorithm despite sexy name purposes optimization technique primarily boils number variables wanting find best combination values variables just borrows techniques natural evolution get neural networks useful recognizing patterns follow simplistic model brain changing number weights attempt predict outputs based inputs two fundamentally different entities sometimes problems capable solving overlap gas generate new patterns structure define nns classify recognize existing patterns based training data provide gas perform efficiently searching large state space solutions converging one good solutions necessarily best solution nns can learn recognize patterns via training notoriously difficult figure learned reuse knowledge noncomparing two totally different things neural networks used regression classification given sety examples want regress unknowngivengenetic algorithms optimization technique given functionx want determineminimizes maximizesx many similarities will try outline differences able analyze online patterns change time generally time varying sample needs matched predicted examples used can code attributes think may contribute specific non changing problem emphasis able code attributes sometimes know problem large degree unchanging otherwise evolutions donconverge examples can use genetic algorithms alternative backpropagation algorithm update weights neural networks example refer usually work discrete data enums integer ranges etc typical application gas searching discrete space good enough solution available alternative brute force search evaluating combinations neural networks hand usually work continuous data floats etc typical application nns function approximationgot setinputs setrelated outputs analytical functionxcourse thousands variants line somewhat blurred rule thumb many cases can formulate problem make use either machine learning still active area research learning model use can debatables take sexy languages evolutionwaiting computer stumble upon solution random process study data make good assumptions try know want pick approach can make good use first choice gives poor results know improve algorithm pick better update question focuses one problem editing post closed years ago expectation maximizationkind probabilistic method classify data please correct wrong classifier intuitive explanationtechnique expectation maximized note code behind answer can found suppose data sampled two different groups red blue can see data point belongs red blue group makes easy find parameters characterise group example mean red group around mean blue group around find exact means wanted generally speaking known maximum likelihood estimation given data compute value parameter parameters best explains data now imagine see value sampled group everything looks purpleknowledge two groups values donknow group particular value belongs can still estimate means red group blue group best fit data yes often can expectation maximisation givesway general idea behind algorithm steps need explanationwalk problem describeduse python example code fairly easy understandfamiliar language suppose two groups red blue values distributed image specifically group contains value drawn normal distribution following parameters image red blue groups save scroll can see colour pointeasy estimate mean standard deviation group just pass red blue values builtin functions numpy example cansee colours points instead red blue every point coloured purple try recover mean standard deviation parameters red blue groups can use expectation maximisation first step step guess parameter values groupmean standard deviation donguess intelligently can pick numbers like parameter estimates produce bell curves look like bad estimates means vertical dotted lines look far kind middle sensible groups points instance want improve estimates next step step compute likelihood data point appearing current parameter guesses simply put data point probability density function normal distribution using current guesses mean standard deviation red blue tellsexample current guesses data point much likely red blue data point can turn two likelihood values weights step sum follows current estimates newly computed weights can now compute new estimates mean standard deviation red blue groups step twice compute mean standard deviation using data points different weightings red weights blue weights key bit intuition greater weight colour data point data point influences next estimates colourparameters effect pulling parameters right direction new estimates parameters improve can jump back step repeat process estimates converge number iterations performed step data first five iterations process look like recent iterations stronger appearance see means already converging values shapes curves governed standard deviation also becoming stable continue iterations end followingprocess converged following values turn close actual values can see colours hidden variables code may noticed new estimation standard deviation computed using previous iterationestimate mean ultimately matter compute new value mean first just finding weighted variance values around central point will still see estimates parameters convergealgorithm maximizing likelihood function variables model unobserved might fairly askjust trying maximize function donjust use existing machinery maximizing function try maximize taking derivatives setting zero find many cases first order conditions donsolutionchicken egg problem solve model parameters need know distribution unobserved data distribution unobserved data function model parametersm tries get around iteratively guessing distribution unobserved data estimating model parameters maximizing something lower bound actual likelihood function repeating convergencealgorithm start guess values model parametersstep datapoint missing values use model equation solve distribution missing data given current guess model parameters given observed data note solving distribution missing value expected value now distribution missing value can calculate expectation likelihood function respect unobserved variables guess model parameter correct expected likelihood will actual likelihood observed data parameters correct will just lower boundstep nowgot expected likelihood function unobserved variables maximize function fully observed case get new estimate model parameters repeat convergence straight forward recipe understand expectation maximisation algorithm readtutorial paper batzoglou may question marks head look explanations maths stack exchange page look code wrote python explains exampletutorial paper item warning code may messy suboptimal since python developer job technically termbit underspecified assume refer gaussian mixture modelling cluster analysis technique instance generalprinciple actuallycluster analysis classifier know people consider clustering unsupervised classification actually cluster analysis something quite different key difference big misunderstanding classification people always cluster analysis cluster analaysis correct solution knowledge discovery method actually meant find something new makes evaluation tricky often evaluated using known classification reference always appropriate classification may may reflect data let give example large data set customers including gender data method splits data set male female optimal compare existing classes prediction way thinking good new users now predict gender knowledge discovery way thinking actually bad wanted discover new structure data method excellent clustering result age wasngiven now backessentially assumes data composed multiple multivariate normal distributions note strong assumption particular fix number clusters tries find local optimal model alternatingly improving model object assignment model best results classification context choose number clusters larger number classes even apply clustering single classes find whether structure within class say want train classifier tell apart cars bikes trucks little use assuming data consist exactly normal distributions however may assume one type cars trucks bikes instead training classifier three classes cluster cars trucks bikes clusters maybe cars trucks bikes whatever train classifier tell apart classes merge class result back original classes may also discover one cluster particularly hard classify example trikessomewhat cars somewhat bikes delivery trucks like oversized cars trucks answers good will try provide another perspective tackle intuitive part questionexpectation maximization algorithm variant class iterative algorithms using duality excerpt emphasis mine mathematics duality generally speaking translates concepts theorems mathematical structures concepts theorems structures one one fashion often always means involution operation dualdualinvolutions sometimes fixed points dual usually dualobject related way preserves symmetry compatibility exampleconst examples iterative algorithms employing duality previous sense similar fashionalgorithm can also seen two dual maximization stepsseen maximizing joint function parameters distribution unobserved variablesstep maximizes function respect distribution unobserved variablesstep respect parameters iterative algorithm using duality explicit implicit assumption equilibrium fixed point convergenceproved using jenseninequality outline algorithms note algorithm converges global optimum found configuration best sensesx domain parametersdomain parameters however algorithm can just find local optimum global optimum say intuitive description outline algorithm statistical arguments applications answers given good explanations check also references answer accepted answer references chuongpaper decent job explainingalso youtube video explains paper detail recap scenario case first trialquestion intuitivelythinkgenerated since proportion heads matchess bias cansure mind like thinksolution like may oversimplification even fundamentally wrong levels hope helps intuitive levelused maximize likelihood modellatent variabless iterative optimizationstep given current estimationcalculate expected loglikelihood functionstep find theta maximizesgmm examplestep estimate label assignments datapoint given current gmm parameter estimationstep maximize new theta given new label assigmentsmeans alsoalgorithm lot explaining animationsmeans using article batzoglou cited zhubarbanswer implementedproblem java comments answer show algorithm gets stuck local optimum also occurs implementation parameters thetaa thetab standard output code showing convergence parameters java implementationsolve problem batzoglou core part implementation loop runparameters converge entire codereading paper trouble understanding concept negative sampling please idea word vec maximise similarity dot product vectors words appear close together context text minimise similarity words equation paper link ignore exponentiation moment numerator basically similarity wordscontexttarget word denominator computes similarity contextstarget wordmaximising ratio ensures words appear closer together text similar vectors words however computing can slow many contextsnegative sampling one ways addressing problem just select couple contextsrandom end result cat appears context food vector food similar vector cat measures dot product vectors several randomly chosen words greed freddy instead words language makes word vec much much faster train computing softmax function determine words similar current target word expensive since requires summing wordsdenominator generally large can done different strategies proposed approximate softmax approaches can grouped softmax based sampling based approaches softmax based approaches methods keep softmax layer intact modify architecture improve efficiencyg hierarchical softmax sampling based approaches hand completely away softmax layer instead optimise loss function approximates softmax approximating normalization denominator softmax loss cheap compute like negative sampling loss function word vec something like logarithm can decompose mathematic gradient formula see details converted see converted binary classification taskpositive classnegative class need labels perform binary classification task designate context wordstrue labelspositive samplerandomly selected corpora false labelsnegative sample look following paragraph assume target word word vec window context words widely popular algorithm developed context words consider positive labels also need negative labels randomly pick words corpus produce software collobert margin based probabilistic consider negative samples technique picked randomly example corpus called negative sampling reference wrote tutorial article negative sampling use negative sampling reduce computational cost cost function vanilla skip gramskip gram negative sampling sgns looks like notenumber vocabs equivalentwordsv probability distributionwjtcomputedvocabs corpuscan easily exceed tens thousand training skip gram model probability needs computedtimes making computationally expensive furthermore normalization factor denominator requires extracomputations hand probability distribution sgns computedpos word vector positive wordneg word vectorsnegative samples output weight matrix sgns probability needs computedtimestypically furthermore extra iterations necessary compute normalization factor denominator sgns fraction weights updated training sample whereasupdates millions weights training sample sgns achieve transforming multi classification task binary classification task sgns word vectors longer learned predicting context words center word learns differentiate actual context words positive randomly drawn words negative noise distribution real life donusually observe regression random words like gangnam style pimples idea model can distinguish likely positive pairsunlikely negative pairs good word vectors will learned figure current positive word context pair drilling engineernegative samples randomly drawn noise distribution minimized primary concerns led page model iterates training samples weights optimized probability positive pair will outputdc pos probability negative pairs will outputdc neg know bidirectional lstms forward backward pass advantage unidirectional lstm better suited lstm core preserves information inputs already passed using hidden state unidirectional lstm preserves information past inputs seen past using bidirectional will run inputs two ways one past future one future past differs approach unidirectional lstm runs backwards preserve information future using two hidden states combined able point time preserve information past future suited complicated question bilstms show good results can understand context better will try explain example say try predict next word sentence high level unidirectional lstm will see boys went bidirectional lstm will able see information road example forward lstm boys went backward lstm got pool can see using information future easier network understand next word adding bluesummeranswer implement bidirectional lstm scratch without calling bilstm module might better contrast difference uni directionaldirectional lstms see merge two lstms create bidirectional lstm can merge outputs forward backward lstms using either sum mul concat ave comparison lstm blstm bilstm two networks one access pastinformation forward direction another access future reverse direction wiki new class bidirectional added per official doc complete example using imdb data will like like predicting electric consumption household however can also use lstm bidirectional lstm will also better jobtrying use deep learning predict income self reported attributes dating sitegetting rather odd results validation data getting better accuracy lower loss training data consistent across different sizes hidden layers model example accuracy lossestried remove regularization dropout expected ended overfitting training acceven tried decrease learning rate drastically similiar results anyone seen similar results happens use dropout since behaviour training testing different training percentage features set zero case since using dropout testing features used scaled appropriately model test time robust can lead higher testing accuracies can check keras faq especially section training loss much higher testing loss also suggest take time read good article regarding sanity checks always take consideration buildingaddition whenever possible check results make sense example caseclass classification categorical cross entropy loss first epochn apart specific case believe apart dropout dataset split may sometimes result situation especially dataset split random case temporal spatial patterns exist validation set may fundamentally differentless noise less variance train thus easier predict leading higher accuracy validation set training moreover validation set small compared training random model fits better validation set training indicates presence high bias dataset underfitting solutions issue probably network struggling fit training data hence try little bit bigger network try different deep neural network mean say change architecture bit train longer time try using advanced optimization algorithms actually pretty often situation much variance dataset behaviour like find explaination might happen number reasons can validation test validation set small adequately represent probability distribution data training set small enough data adequately train model also model basic may adequate cover complexity data drop high limited model try using established model like mobilenet version will adequate even complex data relationships works can confident data build model wish fact validation loss accuracy real meaning training accuracy gets reasonably high say solved simply increasing number epochs adding dropout model gives generalization doesncause data unbalanced biasthink donthink drop layer problem think related number images dataset point working large training set small validation test set latter way easy computed try data augmentation technique get dataset bigger agree anas answer situation might solved increase epoch times everythingsometimes just coincidence initialized model exhibits better performance validation test dataset compared training update question focuses one problem editing post closed years agoworking document classification tasks java algorithms came highly recommended benefits disadvantages commonly used literature natural language processing tasks basics major difference porter lancaster stemming algorithms lancaster stemmer significantly aggressive porter stemmer three major stemming algorithms use today porter snowball porter lancaster paice husk aggressiveness continuum basically following along lines porter least aggressive algorithm specifics algorithm actually fairly lengthy technical break though porter commonly used stemmer without doubt also one gentle stemmers one stemmers actually java support plus though also computationally intensive algorithms granted significant margin also oldest stemming algorithm large margin porter nearly universally regarded improvement porter good reason porter fact admits better original algorithm slightly faster computation time porter fairly large community around lancaster aggressive stemming algorithm sometimes fault porter snowball stemmed representations usually fairly intuitive reader lancaster many shorter words will become totally obfuscated fastest algorithm will reduce working set words hugely want distinction tool want honestly feel snowball usually waycertain circumstances lancaster will hugely trim working set can useful however marginal speed increase snowball opinion worth lack precision porter implementations though usually defaultalgorithm can use snowball snowball small string processing language designed creating stemming algorithms use information retrieval snowball compiler translates snowball script another language currently isocjava javascript object pascal python rust supported since effectively provides suffix stripper grammar toyed idea calling strippergram good sense prevailed snowball named tribute snobol excellent string handling language messrs farber griswold poage polonskymartin porter stemmers implemented snowball language sometimes simply referred snowball stemmers example see natural language toolkit feature selection mostly filtering useless wordsgotten test accuracy training accuracy significantly better random want bettertried implementing adaboostappear give appreciably better results literature seems split papers say adaboostdoesngive better results others know extensionsmay possibly give better accuracy experience properly trained naive bayes classifiers usually astonishingly accurate fast train noticeably faster classifier builder everused want improve classifier prediction can look several places tune classifier adjusting classifiertunable paramaters apply sort classifier combination techniqueensembling boosting bagging can look data fed classifier either add data improve basic parsing refine features select datarnaive bayesian classifiers parameter tuning limited recommend focus dataquality pre processing feature selection data parsing pre processing assume raw data something like string raw text data point series processing steps transform string structured vectorarray data point offset corresponds one feature usually word value offset corresponds frequency stemming either manually using stemming library popular open source ones porter lancaster snowball instance terms programmer program progamming programmed given data point stemmer will reduce single stem probably program term vector data point will value feature program probably want synonym finding idea stemming fold related words single word synonym finder can identify developer programmer coder software engineer roll single term neutral words words similar frequencies across classes make poor featuresfeature selection consider prototypical use case nbcs filtering spam can quickly see fails just quickly can see improve instance average spam filters nuanced features like frequency words caps frequency words title occurrence exclamation point title addition best features often single words pairs words larger word groups iii specific classifier optimizations instead classes use one many scheme words begin two class classifier class else results else class returned algorithm classification classelse etc fisher method probably common way optimize naive bayes classifier think fisher normalizing correctly standardizing input probabilities nbc uses feature probabilities construct whole document probability fisher method calculates probability category feature document combines feature probabilities compares combined probability probability random set features suggest using sgdclassifier tune terms regularization strength also try tune formula tfidfusing tuning parameters tfifvectorizer usually see text classification problems svm logistic regressioin trained one versus outperformscan see nice article stanford people longer documents svm outperformscode paper uses combination svmnbsvm second tune tfidf formula smooth idf normalize samplesl normalization default tfidfvectorization compensates different document lengths multilayer perceptron usually gets better resultssvm non linearity introduced inherent many text classification problems implemented highly parallel one using theano lasagne easy use downloadable try tunel elasticnet regularization makes huge difference sgdclassifier svm logistic regression try usegrams configurable tfidfvectorizer documents structure consider using different features different parts example add title word document word happens title document consider using length document feature consider using meta information document author name url document etc recently facebook published fasttext classification code performs across many tasks sure try using laplacian correction along adaboost adaboost first weight assigned data tuple training dataset intial weights set using init weights method initializes weightd size training data set generate classifiers method called runstimes creatinginstancesve bayes classifier classifiers weighted test data run classifier sum weighted votes classifiers constitutes final classification change probability space log probability space since calculate probability multiplying probabilities result will small change log probability features can tackle runs problem naive byes works based assumption independence correlation features means one feature depends others assumption will fail correlation can found naive bayes require less data logistic regression since needs data understand probabilistic relationship attribute isolation output variable interactions test data set zero frequency issue apply smoothing techniques laplace correction predict class test data set described following posts please refer posts keepingsize small also makegive high accuracy result coresize increase accuracy degrade select features less correlation try using different combination features call fit method multiple times differenty data happens fit model data like justinstantiated model keep accounts data already fitted previous call fit trying linearregression also looking source code seems every time call fit fits scratch ignoring result previous call method wonder true general can rely behavior models pipelines scikit learn will executetraintrain second timeoverwrite previously fitted coefficients weights intercept bias etc want fit just portion data set improve model fitting new data can use estimators supporting incremental learning implement partial fit method can use term fit train word interchangeably machine learning based classification model instantiated may clf gbnaivebayes clf svc model uses specified machine learning technique soon call features train label train model starts training using features labels passed can use features test predict will call features train label train will start training using passed data will remove previous results model will reset following inside model can use partial fit method want previous calculated stuff stay additionally train using next data beware model passed kind reference model will overwritten returns avoid usei playing ann part udacity deeplearning course assignment involves introducing generalization network one hidden relu layer usingloss wonder properly introduce weights penalized weights output layer code network without generalization bottom post code actually run training scope question obvious way introducingreplace loss calculation something like beta case will take account values output layerweights sure properly penalize weights come hidden relu layer needed introducing penalization output layer will somehow keep hidden weights check also shorter scalable way basically sumsloss trainable variables also make dictionary specify variables want add cost use second line can add lossl softmax cross entropy value order calculate total loss edit mentioned piotr dabkowski code will also regularise biases can avoided adding statement second line can used exclude variables hidden weights hidden biases weights biases model parameters creating can addregularization parameters follows note keight johnson regularize bias fact usually regularize bias terms interceptspenalizing intercept term intercept addedvalues will result changingvalues adding constantintercepts will change results takes computationswhen load whole dataset memory train network keras using following code generates progress bar per epoch metrics like eta accuracy loss etc train network batchesusing following code will generate progress bar batch instead epoch possible generate progress bar epoch batchwise training change verbose mentioned documentation verbose logging stdout progress bar logging one log line per epochshow output want show progress bar completion epochs keep verbose shuts logging stdout implement following manner output will follows want show loss everybatches can use though havenever tried example taken keras github issue show loss everybatches can also follow demo nbatchlogger can also use progbar progressprint progress batchwise tqdm version also just added built support keras turns keras progress verbose uses tqdm instead callback verbose means separate progressbars epochs batches means clear batch bars done means show epochs never show batch bars can set verbose set callbacks will update progress end fitting example model checkpoints set callback remotemonitori currently trying understand architecture behind word vec neural net learning algorithm representing words vectors based context reading tomas mikolov paper came across defines projection layer even though term widely used referred word vec couldnfind precise definition actually neural net context question neural net context projection layer name given hidden layer whose links previous nodes share weights units actually activation function kind another resource also refers broadly problem can found tutorial also refers projection layer around page find previous answers bit overcomplicated projection layer just simple matrix multiplication contextregular dense linear layer without non linear activation end sigmoid tanh relu etc idea projectdimensions discrete vector dimensions continuous vector chose numbers randomly mileage may vary exact matrix parameters learned training process happens already depends model contextasks practice wouldneven bother matrix multiplication multiplying hot vector word indexeverywhere else treat trained matrix lookout tablerow column depends define projection matrix projection layer maps discrete word indicesgram context continuous vector space explained thesis projection layer shared contexts containing word multiple times set weights applied form part projection vector organization effectively increases amount data available training projection layer weights since word context training pattern individually contributes changes weight values figure shows trivial topology output projection layer can efficiently assembled copying columns projection layer weights matrix now hidden layer hidden layer processes output projection layer also created number neurons specified topology configuration file edit explanation happening diagram neuron projection layer represented number weights equal size vocabulary projection layer differs hidden output layers using non linear activation function purpose simply provide efficient means projecting givengram context onto reduced continuous vector space subsequent processing hidden output layers trained classify vectors given one zero nature input vector elements output particular word index simply ith column trained matrix projection layer weights row matrix represents weights single neuron continuous bag words used predict single word given prior future entries thus contextual result inputs computed weights prior future entries given new weights identically thus complexity features count model much smaller manyarchitecturesprojection layer paper cited non linear hidden layer removed projection layer shared words just projection matrix thus words get projected position vectors averaged projection layer single set shared weights activation function indicated note weight matrix input projection layer shared word positions way nnlm hidden layer fact represented single set shared weights correctly implied identical across input nodes want know learning curve machine learning standard way plotting meany axis plot usually refers plot prediction accuracy errortraining set sizebetter model get predicting target increase number instances used train usually training test validation performance plotted together can diagnose bias variance tradeoffdetermine benefit adding training data assess model complexity controlling regularization number features just want leave brief note old question point learning curve roc curve synonymous indicated answers question learning curve conventionally depicts improvement performance vertical axis changes another parameter horizontal axis training set size machine learning iteration time machine biological learning one salient point many parameters model changing different points plot answers done great job illustrating learning curves also another meaning learning curve industrial manufacturing originating observationnumber labor hours needed produce individual unit decreases uniform rate quantity units manufactured doubles isnreally relevant worth noting completeness avoid confusion web searches contrast receiver operating characteristic curve roc curve show learning shows performance roc curve graphical depiction classifier performance shows trade increasing true positive rates vertical axis increasing false positive rates horizontal axis discrimination threshold classifier varied thus single parameter decision discrimination threshold associated model changing different points plot roc curve wikipedia shows performance three different classifiers learning depicted rather performance respect two different classes success error classifierdecision threshold made lenient strict looking area curve can see overall indication ability classifier distinguish classes area curve metric insensitive number members two classes may reflect actual performance class membership unbalanced roc curve many subtitles interested readers might check fawcett tom roc graphs notes practical considerations researchers machine learning swets john robyndawes john monahan better decisions science scientific american people use learning curve refer error iterative procedure function iteration number illustrates convergence utility function example plot mean square error mse least mean square lms algorithm function iteration number illustrates quickly lms learns case channel impulse response basically machine learning curve allows find point algorithm starts learn take curve slice slope tangent derivative point starts reach constant starts build learning ability dependingy axis mapped one axis will start approach constant value axisvalues will keep increasing start seeing learning whole curve pretty much allows measure rate algorithm able learn maximum point usually slope starts recede can take number derivative measures maximum minimum point examples can see curve gradually tending towards constant value initially starts harness learning training examples slope widens maximum mimimum point tends approach closer closer towards constant state point able pick new examples test data find new unique results datay axis measures epochserror andrewmachine learning class learning curve plot training cross validation error versus sample size learning curve can used detect whether model high bias high variance model suffers high bias problem sample size increases training error will increase cross validation error will decrease last will close still high error rate training classification error increasing sample size will help much high bias problem model suffers high variance keep increasing sample size training error will keep increasing cross validation error will keep decreasing will end low training cross validation error rate samples will help improve model prediction performance model suffer high variance can determine given model whether training points will helpful useful diagnostic learning curves plot prediction accuracy errortraining set size better model get predicting target increase number instances used train learning curve conventionally depicts improvement performance vertical axis changes another parameter horizontal axis training set size machine learning iteration time learning curve often useful plot algorithmic sanity checking improving performance learning curve plotting can help diagnose problems algorithm will suffering personally two links helped understand better concept learning curve sklearn learning curve use code plot note history graph compares performance model preparing testing data changing number training instances generally utilized analytic instrument machine learning calculations learn training dataset incrementally allowsverify model learning much can data three kinds expectations learning curves absorb information simple terms learning curve plot number instances metric loss accuracy plot shows journey learning gain experience hence named learning curve learning curves widely used machine learning algorithms learn optimize internal parameters incrementally time deep learning neural networks examplelevelsalaryy regression gives accuracy state line polynomial gives accuracy curvei running tensorflow happen something yielding nanlike know know main issue normal procedural program just write print statement just operation executed issue tensorflow first declare define graph adding print statements graph definition help rules advice heuristics anything track might causing nan case know precisely line look following line present returns nan declared summary writers way least explore valuesquare rooted specific example posted triedsuccess printed nothing actually donunderstand want print tensor need pass seems bizarre looking function doesnsay use plus docs seem super helpful anyone know use sincecomments addressing data might bad using standard mnist however computing quantity positive pair wise eucledian distance square rooting thus wouldnsee data specifically issue couple reasons can get nan result often high learning rate plenty reasons possible like example corrupt data input queue log calculation anyhow debugging print describe done simple print result printing tensor information inside graph print actual values however use graph gets executed will get actual values printed good exercise watch values debug understand behavior net however using print statement entirely correct mannerneed pass tensor request result tensor need work later executing graph otherwisegoing executed printing occurs try used findmuch tougher pinpoint nans infs may occur fix bug complementary scaianswerlike add points debug module can imported much better print assert can just add debug function changing wrapper sessionprompt command line interface enter runinf nanf inf nan find nans infs first one first place catastrophe occurs variable name can trace origin code reference tensorflow shipped builtin debugger called tfdbg optimizes workflow debugging type bad numerical value issues like inf nan documentation think will add check floating point operations sessions run function can add check operation check first need check input data properly cases reason always course usually use tensorboard see happening training can see values step also can simply eval print current value tensorflow injectxnan code will throw invalidargument error xhas values number nan infinity infnext person finding huntingnan issue case turned exploding gradient gradient gotquite nan yet adding variable turned big diagnosis revealed overly large numbers running exact network cpu worked fine failed gtxworkstation thus making cuda numerical stability issue likely root cause since occurred sometimes duct taped whole thing going will just clip exploding gradients sane value network gradients always high wouldnhelp since magnitudes high sporadically fixed problem now network trains nicely also gpu nans occurring forward process one thing occurring backward process another make sure extreme inputs nan inputs negative labels prepared dataset using numpy tools instance assertswitch cpu environment get detailed traceback test forward pass loss loss calculating gradients see can run several batches errors error occurs several types potential bugs methods everything goes remove loss loss asidealways helpful make sure shape every tensor desired can try input fixed sized batches drop remainders reshape feature tensors graph receives data dataset expect otherwise first dimension none sometimes print shape tensor graph fixed numbers recipe training neural networks andrej karpathy great article training debugging neural networks current implementation huge list tensors displayed sorted order execution possible hack find first appearance nans dump tensors temporary directory inspect afterwards quick dirty example assuming nans appear first runs able fix nan issues getting rid dropout layers network model suspected maybe reason unit neuron network lost many input connections zero dropout information fed value nan donsee happen dropout layers hundred units problem probably fixed different reason either way commenting dropout layers fixed issue edit oops realized added dropout layer final output layer consists three units now makes sense dondonallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago can get corpus documents already classified positive negative sentiment corporate domain want large corpus documents provide reviews companies like reviews companies provided analysts media find corpora reviews products movies corpus business domain including reviews companies match language business smileys likeliteratureinterested specific subtasks like negation sentiment scope etc get focus companies might pair method topic detection cheaply just lot mentions given company get data annotated mechanical turkers list wrote weeks ago blog datasets recently included nltk python platform opinion lexicon bing liu mpqa subjectivity lexicon sentiwordnet harvard general inquirer linguistic inquiry word counts liwc vader lexicon mpqa datasets notes gnu public license sentiment tweets sts gold tweets customer review dataset product reviews included nltk python platform pros cons dataset pros cons sentences included nltk python platform comparative sentences reviews included nltk python platform sanders analytics twitter sentiment corpus tweets hand classified tweets wrt different topics twittertos small python script included download tweets sentiment classifications provided free charge without restrictions may used commercial products may redistributed may modified spanish tweets tweets semeval tweets mustdistribute tweets annotations corpus obtained readme file various datasets reviews various datasets reviews references media channels blogs etc domain want explore can create corpus python creating corpus hard work pre processing checking tagging etc benefits preparing model specific domain many times increasing accuracy can get already prepared corpus justahead sentiment analysisaware corpus freely available try unsupervised method unlabeled dataset can get large select online reviews datafiniti reviews come rating data provide granularity sentiment positive negativelist businesses reviewslist products reviews can life figure switch image ordering images readx format theano requiresx format tried changing order img range guess gets job done ugly canfigure reverse get original image back agree qualiacomment source destination easier understand job can use considering batch size dimensionusing keras might want change configuration define per layer theano doesnrequire anythingusing keras keras can configured channels first channels last besides allowing define every individual layer donchange data find users yourusername keras keras dependingchange image data format channels last channels first vice versa wish usually working channels last less troublesome great amount non convolutional functions work last axis keras documentation information parameters layers including data format parameterlooking fastest optiontransposeeven faster found trying plot decision boundarynn classifier unable getting typeerror slice none none none invalid key got running sure means think getting issue try using iloc loc will resolve issue need use iloc loc accestry adding ilocissue following added values property worked without problem fixed converting pandas dataframe numpy array got help trying fetch dataset using pandas use code issue using solved calling values function method output iloc importing datasets use values change try run code code writed library use load dataset used pandas library load dataset need add index based selection iloc function data frame order access values used numpy library load dataset can access values directly array create arrayminmaxminmaxminmaxminmax present dataframe first convert dataframe array suggest changing input numpy moving ahead use values access dataframe values example hope will help can use case according needsiworking cnn several hundred gbs imagescreated training function biteschunks images calls fit piecesworriedtraining last piece entire dataset effectively pseudo code looks like know api keras forums say will train entire dataset canintuitively understand network wouldnrelearn just last training chunk help understanding much appreciated best joe question raised keras github repository issue quick question can model fit multiple times closed fran ois chollet following statement yes successive calls fit will incrementally train model yes can call fit multiple times datasets fit memory answer keras documentation faq section can batch training usingyy see models documentation alternatively can write generator yields batches training data use method data generator samples per epochepoch can see batch training action cifar example want iterate dataset way probably use however can approximate canthink seems like obvious limitation neural networks can potentially limit can example limitation neural networks probably canproperly approximate many functions used statistics like exponential moving average even variance speaking moving average can recurrent neural networks properly approximate understand feedforward neural network even single linear neuron can output moving average using sliding window technique recurrent neural networks withoutamount hidden layersmoving average size also letassume donknow original functionhappens get average last inputs outputhighersecond pretend donknowblack box recurrent neural network approximate first need know many timesteps donperhaps lstm network evensimple moving averageexponential moving average donthink even lstm can even worse stillxtrying learn simply seems simple straightforward can neural network learn donsee missing something huge machine learning algorithms extremely limited learning techniques besides neural networks can actually key point understand compact neural networks approximation structure like polynomials splines radial basis functions can approximate continuous function within compact set words theory states given exists neural network approximatesx approximation error less everywhere withinregarding examplexyes can approximate neural network within finite range etc visualise imagine approximatex within step function can paper note make steps narrow enough can achieve desired accuracy way neural networks approximatex much different neural network approximation structure finite number parameters can approximatexx question legitimate unfortunately many answers show little practitioners seem know theory neural networks rigorous theorem exists ability neural networks approximate different kinds functions universal approximation theorem uat states continuous function compact domain can approximated neural network one hidden layer provided activation functions used bounded continuous monotonically increasing now finite sum bounded functions bounded definition polynomial bounded best can provide neural network approximation polynomial compact subsetn outside compact subset approximation will fail miserably polynomial will grow without bound words neural network will work training set will generalize question neither topic represents opinion sure visceral reaction think legitimate question hard find googling even though think widely appreciated repeated outloud think case looking actually citations showing neural net can approximate function recent paper explains nicely opinion also cite original paper barron proved less general result conclusion two layer neural network can represent bounded degree polynomial certain seemingly non restrictive conditions just case link work called learning polynomials neural networks andonial understand neural networks number hidden layers can approximate nonlinear functions however can approximatexway can make sense questiontalking extrapolationcan neural network learn right valuesmean prior knowledge functionstrying approximate likely low order polynomials set functions surely build neural network can represent functions extrapolateeverywhere donprior knowledge things bit difficult infinitely many smooth functions fitrange perfectlygood reason expectgive better predictions function words prior knowledge functiontrying learn want learnx realm artificial training setsmight likely function real world probably isngive example letsay temperature mondaytuesdaywednesdayreason believe temperatures behave like low order polynomials wouldnwant infer data temperature next monday will probably around also letassume donknow original functionhappens get average last inputs outputhighersecond pretend donknowblack box recurrent neural network approximate thinktwo questions first can neural network represent function obviously depends network architecture think can come architectures can represent least closely approximate kind function question two can learn function given enough training samples learning algorithm doesnget stuck local minimum sure enough training samples set weights doesnapproximate function gives training error greater set weights fit functiontrying learn training error find global optimum network must fit function network can learnxneuron calculatesx generally node calculatesp learnsarencommonly used statement neural network can strong network relus linear output layer can learnx even unbounded rangevalues error will unbounded proportional error will bounded function learnt network piecewise linear particular asymptotically linear however risk relus relu training examples ceases learning large domain will turn possible test examples give erroneous result relus good choice test cases likely within convex hull training set easier guarantee dimensionality low one work around prefer leakyrelu one issue many neurons need achieve approximation want relu leakyrelu implements single change gradient number needed depends maximum absolute value second differential objective function divided maximum error tolerated theoretical limitations neural networks neural network can ever learn functionxx can learn infinite number functions unless assume impractical infinite number training examples infinite number units infinite amount time converge nns good learning low level pattern recognition problems signals end statistical pattern can represented continuous functions hint try buildtakesdata inputsxxn will return truerest sequence good luck infinite functions especially recursive learned just trying implement multivariate linear regression python using tensorflow run logical implementation issues code throws following error ideally weights output run depending versions clear code example list initial parameters hypothesis function list line init will fail tensorflow isnyet smart enough figure dependencies variable initialization work around change loop creates parameters use initial parameters hypothesis function initialized value adds necessary dependency another error happening related order calling initializing global variablessample code similar error failedpreconditionerror see traceback attempting use uninitialized valuechange following normally two ways initializing variables using previous answers noted load graph checkpoint can like third method use master recovering initializing model needed wait session ready want give resolution work replace line session sess hope will useful others run update better formulation issuetrying understand backpropagation algorithm xor neural network example case input neurons bias neurons hidden layer bias output neuron sourceusing stochastic backpropagation reading bit found error output unit propagated hidden get input layer neural network neuron gets error adjustment neurons hidden layer particular way error distributed difficult grasp first step calculate output instance input step calculate error output neuroncase one target valuestep use error step calculate error hidden unitweightweight hidden unitoutput unitconfusing input unit direct weight associated output unit staring formula hours started think summation meansstarting come conclusion input neuronweight connects hidden layer neurons multiplied output error summed logical conclusion formula seems little confusing since clearly says weightoutput layerhidden layerunderstanding everything correctly can anybody confirmoinput layer understanding input node two outputs one goes first node hidden layer one goes second node hidden layer two outputs pluggedhh part formula tutorial posted actually wrong double checked bishoptwo standard books two working implementations will point exactly important thing keep mind always searching derivatives error function respect unit weight former deltas latter use update weights want understand backpropagation understand chain rulechain rule donknow works exactly check wikipediahard soon understand derivations everything falls place promisew can composedow via chain rulew easily calculated sincejust derivative activation output unit respect weightso actually call deltas assumingovectors matrices output units since can calculate error mostly error function comes deltakkquadratic error function case linear outputs cross entropy case logistic outputs question now get derivatives internal units know output unit sum incoming units weighted weights application transfer function afterwardsksumkjjderivek respectj since deltaejooodeltaoogiven deltacan calculate deltaletof sumkjjoof sumkjjwfkkj case sigmoidal transfer function becomeskkkj error tutorial author sayskkkjsure question actually went tutorial can assure one obvious typo nothing incorrect will make assumption question confused backpropagation hidden delta derived indeed question please consider source probably confused author derived equation actually straightforward application multivariate chain rule namely follows taken wikipedia suppose argumentfv two variable functionhygy functions differentiable chain rule look like now imagine extending chain rule induction argumentzzzoutput kth output layer pre activationk wji sayfunctionz function wji doesnmake sense first think carefullysetup applying chain rule directly extendedvariableszzwjiekk wji important step author applies chain rule time within sum expandk wji termk wjikojzj wji difficulties understanding chain rule may need take course multivariate calculus read section textbook good luck read stepequation unit one output link output next layer weighted output receiving end unit will receive different value weight links differenth always refers value neuron last iteration error apply input layer definition input error pererror needs calculated layer layer starting output side since need error values layercalculate layerright direct connection input output backpropagation believe equation correct counterintuitive probably confusing forward propagation unit consider units links left unit input values error propagation backpropagation consider units right output value unit correspondingdata following meaning values storedform time series valuescorresponding time dependent factors known influence valuesexample temperature humidity atmospheric pressure now course can use fitys get model future valuesdepend factors dependend previousvalues least directly limitation model like modeln depends alsonn example might want use exponential moving average model elegant way scikit learn added mentioned comments can extendaddingway limitations example add last valuesnew columnsinformation time orderinglost example indicationvaluescolumn follows valuecolumn model might want linear fit last fiveuse found linear function make prediction values columns trivial added make problem even clear like give one concrete example like linear modelnkkkk emovemovjust exponential moving average can implement simple model scikit learn according wikipedia ewma works stationary data work expected presence trends seasonality cases use second third order ewma method respectively decided look pandas ewma function see handled trends came can see ewma bucks trend uphill downhill can correct without implement second order scheme taking ewma directions averaging hope data stationary mightlooking regard exponentially weighted moving average com parameter can read can combine emovxs using something like can look various linear models something like best luck using dbscan cluster data using scikit learn python however found built function aside fit predict assign new data pointsclusters identified original datak means method predict function want able dbscan something like density can inferredreturn values cluster assignments labelscan tell capability availableassume also somehow available python just canseem find documentation also tried searching reasons dbscan may used labeling new data havenfound justifications anony mousse good points clustering indeed classifying think ability assigning new pointsusefulness based original paper dbscan robertlaytons ideas suggest running core points assigning cluster first core point within eps new point guaranteed point will least border point assigned cluster according definitions used clustering aware point might deemed noise assigned clusterdone quick implementation labels obtained clustering dbscan model dbscan fitlabels obtained model data dbscan predict dbscan modelsometimes differquite certain bug somewhere result randomness edit think problem differing prediction outcomes stem possibility border point can close multiple clusters please update test find answer ambiguity might solved shuffling core points every time picking closest instead first core point case handlike evaluate clusters obtained subset data makes sense subset simply special case generalises supports validity clusters earlier steps pre processing applied clustering classification clustering unlabeled want squeeze prediction mindset best idea essentially predicts without learning labeled training data available clustering make new labels data based sees cansingle instance can bulk predict something wrong scipys dbscan random state optional generator used initialize centers defaults initialize centers centers dbscan pretty much clustering algorithm can assign new points old clustersmeans many variations performsclassification using previous iterations cluster centers updates centers algorithms donwork likemeans cancopyversion maybe usingclassificator prediction maybe extra rule points assigned noise labeldistance larger epsilon mabye also using core points maybe get dbscan paper discuss prediction iirc slightly different efficient implementation also instead taking first best core point within eps radius core point closest sample taken althoughexact algorithm can preform approximate predictions new points sklearn hdbscan see works like great answers already posted question suggestion give hdbscan try provides approximate predict method might need letfirst try understand basic things dbscan density based clustering following figure summarizes basic concepts letfirst create sampledataset will clustered dbscan following figure shows dataset looks now letuse scikit learnimplementation dbscan cluster notice results letvisualize clusters using following code snippet finally letimplement predict method predict cluster new data point implementation based following order new pointbelongs cluster must directly density reachable core point cluster shall compute nearest core point clusterwithin distanceshall return label core point otherwise pointwill declared noise point outlier notice differs training algorithm since longer allow point become new core point number core points fixed next code snippet implements predict function based idea next animation shows new test points labeled using predict function definedmeans algo doesnprediction just tries best placeclusterscluster centers one core instances per cluster therefore prediction options using dbscan aside help avoid confusionseen answers say wrong things true dbscan non parametric sklearnimplementation predict function counter examplenearest neighbors non parametric capable making predictions non parametric clustering models like dbscan spectral clustering hierarchical clustering directly predict labels new points non parametric means get set parameters predict label new point based parameters comparisonmeans gaussian mixture model parametric clustering models clustering neural network index cnni model another parametric clustering model predict labels new points analysis dbscan answers suggestion may need train supervised model clustering result predict label supervised model just using knn classifier min max jump distance provides alternative method predicting labels new points just compare pointmin max jump distance center one scom cluster mechanism similarmeans following example using min max jump distance predict labels new points three toy data sets predicting labels new points example illustrating difference knn min max jump distance predict labels new points clusters separated read information prevent overfitting use regularization include lambda parameter cost function lambda used update theta parameters gradient descent algorithm question calculate lambda regularization parameter regularization parameter lambda input model probably want know select value lambda regularization parameter reduces overfitting reduces variance estimated regression parameters however expense adding bias estimate increasing lambda results less overfitting also greater bias real question much bias willing tolerate estimate one approach can take randomly subsample data number times look variation estimate repeat process slightly larger value lambda see affects variability estimate keep mind whatever value lambda decide appropriate subsampled data can likely use smaller value achieve comparable regularization full data setnice explanations intuitive top notch mathematical approaches just wanted add specificities problem solving may definitely help speed give consistency process finding good regularization hyperparameter assume talkingweight decay regularization linearly weighted lambda term optimizing weights model either closed form tikhonov equation highly recommended low dimensional linear regression models variant gradient descent backpropagation context want choose value lambda provides best generalization ability abletikhonov way model andrewsaysdimensions suggestion least years old wikipedia determination tikhonov factor offers interesting closed form solution proven provide optimal value solution probably raises kind implementation issues time complexity numerical stabilityaware mainstream algorithm perform paper looks promising though may worth try really optimize linear model best new innovative method derived iterative approach solving general tikhonov regularization problem converges noiseless solution depend strongly choice lambda yet still avoids inversion problem github readme projectl will invert matrix noisyiterations lambda dampening effect best set links part michael nielsenamazing online book neural networks deep learning recommended reading approach seems even less said cost function usually non convex optimization performed numerically performance model measured form cross validation see overfitting regularization regularization help reduce overfitting havenenough even cross validating nielsen suggests something may want take look detailed explanationregularization provide weight decaying effect summary inversely proportional number samplescalculating gradient descent equationterm just use backpropagation usual addw partial derivative weight terms conclusion wanting similar regularization effect different number samples lambda changed proportionally need modify regularization parameter reason sizetraining set changedn changes weight decay factor learning ratecontinued use mean much less weight decay thus much less regularization effect compensate changing useful applying model different amounts data think opens door intuition work importantly speed hyperparametrization process allowing finetune lambda smaller subsets scale choosing exact values suggests conclusions choose neural networkhyperparameters purely empirical approach start progressively multiply divide find proper order magnitude local search within region commentsrelated question user brian borchers suggests also known method may useful local search hope helps cheers andres cross validation described method used often machine learning however choosing reliable safe regularization parameter still hot topic research mathematics need ideas access decent university library can look papertrying use sgd classify large dataset data large fit memorylike use partial fit method train classifier selected sample dataset rows fits memory test fitpartial fit test classifiers identical test set first case get accuracy understand sgd default passes times training dataiter second case pass times data reach accuracy differencesomething wrong finally found answer need shuffle training data iteration setting shuffle true instantiating model will shuffle data using partial fit applies fit note helpful find information exploring scikit learn making decision trees entropy gini splitting criteria exploring differences question can open hood find exactly attributes trees splitting level along associated information values can see two criterion make different choices far explored methods outlined documentation donappear allow access information surely information accessibleenvisioning list dict entries node gain thanks help apologiesmissed something completely obvious directly documentation stringio module longer supported python instead importmodule also tree attribute decision tree object allows direct access whole structure can simply read details look source code export method general can use inspect module get objectelements just want quick look going tree trydata frame independent variables clf decision tree object notice one correspond arrow graphviz visualization scikit learn introduced delicious new method called export text version may view rules tree documentationfit model just need two lines code first import export text second create object will contain rules make rules look readable use feature names argument pass list feature names example model called model features named dataframe calledtrain create object called tree rules just print save tree rules output will look like working countvectorizer class scikit learn understand used manner shown final output will consist array containing counts features tokens tokens extracted set keywords get fine situation just little bit different want extract features way donwant rows data documents features extracted words can get counts another set documents say get read documentation countvectorizer class came across vocabulary argument mapping terms feature indices canseem get argument help however advice appreciatedcredit due matthias friedrichblog example usedright vocabulary want works like pass dict desired features keys used countvectorizer one set documents want use set features documents new set use vocabulary attribute original countvectorizer pass new one example create new tokenizer using vocabulary first one call fit transform just fit original vocabulary source vectorizer learns vocab can use fit vectorizer new data source via transform method can obtain vocabulary produced fit via assuming name countvectorizer name vectorizer verify countvectorizer using vocabulary learned tags new docs printusing random forest model samples attributes samples categories classifier recognizes know far ideal conditionstrying figure attributes important feature predictions parameters best tweak optimizing feature importance tried differentestimators noticed amount significant features increased dramaticallyread documentation anyone experience like know parameters best tune brief explanation experience three features worth exploring sklearn randomforestclassifier order importanceestimators max features criterionestimators really worth optimizing estimators give better will usually sufficient max features worth exploring many different values may large impact behaviordecides many features treeconsiders split criterion may small impact usually default fine time try make sure use sklearngridsearch preferably gridsearchcv data set size small trying parameters understand question correctly though samples classes presumably samples per classlikelygoing overfit little amount data unless good representative records crucial parts usually three elements wonderful article detailed explanation tunable parameters track performancespeed trade practical tips perform grid searchestimators good one others said also good dealing overfitting increasing think min sample split also helpful dealing overfitting occurred small sample big features dataset new field neural networks like know difference deep belief networks convolutional networks also deep convolutional network combination deep belief convolutional neural nets gathered till now please correct wrong image classification problem deep belief networks many layers trained using greedy layer wise strategy example image sizewant deep network layers namely input layer willneuronsneurons sayneurons say output layer neurons order train weightsinput layeruse autoencoder learnsizeunsupervised learning feed forward images first hidden layers obtain set features use another autoencoder get next set features finally use softmax layer classification learning weights last layeroutput softmax layer supervised learning use rbm instead autoencoder problem solved using convolutional neural networksinput images develop network usingpatches say layers learning weights takepatches images sizefeed forward convolutional layer will different feature maps sizex use window saypooling hand hence get feature maps sizeoutput pooling layer use feature maps classification learning weights donuse layer wise strategy deep belief networks unsupervised learning instead use supervised learning learn weights layers simultaneously correct way learn weights understood correct want use dbnimage classification resize images particular size saymany neurons input layer whereas case cnntrain smaller patch input sayimage sizeconvolve learnt weights entire image dbns provide better results cnns purely dependent dataset thank generally speaking dbns generative neural networks stack restricted boltzmann machines rbms can think rbms generative autoencoders want deep belief net stacking rbms plain autoencoders hinton student yeh proved stacking rbms results sigmoid belief nets convolutional neural networks performed better dbns current literature benchmark computer vision datasets mnist dataset computer vision one dbns can definitely perform better theory dbns best models hard estimate joint probabilities accurately moment may interested leealwork convolutional deep belief networks looks combine two will try explain situation learning shoes use dbn learn images bad thing will happen learning algorithm will shoes different places neurons will try learn shoes also place shoes images will concept local image patch inside weights dbn makes sense images aligned means size translation rotation idea convolutional networks concept called weight sharing try extend weight sharing concept first lookedpatches according example example neurons first layer can say learned shoes front back bottom back upper parts look alikepatch shoes normally idea multiple convolution layers one another learn can think different things told different neurons areas neurons images will fire shoes part image pooling will protect higher activations sub sampling images creating lower dimensional space make things computationally easier feasible last layer lookx words dimensional vector shoe somewhere picture shoe neuronwill active whereas non shoe neurons will close zero understand neurons shoes ones will put dimensional vector another supervised classifier can anything like multi class svm said soft max layer can advise glance fukushima paper understand try say translation invariance line arc semicircle shoe front shoe idea even just looking images paper will give idea using sklearn multi classification task need split alldata train set test set want take randomly sample number class actually amusing function gives unbalanced dataset suggestion although christiansuggestion correct technically train test split give stratified results using stratify param trick starts version sklearn documentation parameter stratify stratify array like none default none none data split stratified fashion using labels array new version stratify splitting can use stratifiedshufflesplit create datasets featuring percentage classes original one classes balanced want split balanced stratifying isngoing help doesnseem method balanced sampling sklearnkind easy using basic numpy example function like might help note use sample points per class input data will upsampled sample replacement result data points will appear multiple times may effect accuracy measures etc class one data point will error can easily check numbers points per class example target return counts true another approach sample stratified test train split imbalanced learn library quite handy specially useful online learning want guarantee balanced train data within pipelines implementation use get train test data indexes function using can adapt optimizeallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed year ago best way perform hyperparameter optimization pytorch model implement use skicit learn anything else aware many researchers use raytunescalable hyperparameter tuning framework specifically deep learning can easily use deep learning framework lines code provides state art algorithms including hyperband population based training bayesian optimization bohb disclaimer contribute actively project found following young projects update something newadaptive experimentation platform facebook botorch bayesian optimization pytorch also found useful table post richard liaw can use bayesian optimization full disclosurecontributed package hyperband methods attempt automate hyperparameter tuning stage hyperband supposedly state art space hyperband parameter free methodheard random search can also look using reinforcement learning learn optimal hyperparameters prefer simplest parameter free way black box optimisation random search will explore high dimensional spaces faster grid search papersdr random search get different values every dimension time grid search donbayesian optimisation good theoretical guarantees despite approximations implementations like spearmint can wrap script hyperparameters users donsee practice hyperband got lot attention showing faster convergence naive bayesian optimisation able running different networks different numbers iterations bayesian optimisation doesnsupport naively possible better bayesian optimisation algorithm can take account fabolas practice hyperband simpleprobably better using watching tune search space intervals found scaling svm support vector machine problems really improve performance read explanation main advantage scaling avoid attributes greater numeric ranges dominating smaller numeric ranges unfortunately didnhelp can somebody provide better explanation feature scaling general trick applied optimization problems just svm underline algorithm solve optimization problem svm gradient descend andrewgreat explanation coursera videos will illustrate core ideas borrow andrewslides suppose two parameters one parameters can take relatively large range values contour cost function can look like tall skinny ovals see blue ovals gradients path gradient drawn red take long timeback forth find optimal solution instead scaled feature contour cost function might look like circles gradient can take much straight path achieve optimal point much faster true reason behind scaling features svm fact classifier affine transformation invariant words multiply one feature solution given svm will completely different nearly nothing underlying optimization techniques although affected scales problems still converge global optimum consider example man woman encoded sex height two features letassume simple case data man woman letsomething silly train predict sex person trying learnxx ignoring second parameter easy see data largest margin classifier will cut plane horizontally somewhere around height get new sample womanheight get classification man however scale everything get sth like now largest margin classifier cuts plane nearly vertically expected given new sample also scaled around get woman correct general scaling ensures just features big wonlead using main predictor just personal thoughts another perspective feature scaling influenceword applying machine learning algorithm garbage garbage real reflection features accuracy algorithm will get applies machine learning algorithms treat relationship features different humanbrain machine learning algorithms classify example features expressed calculated coordinate system sense establish priori assumption features really reflection data also nature algorithms find appropriate weight percentage features fittest data algorithms input unscaled features large scale data influence weight actuallyreflection data iteself usually feature scaling improve accuracy common practice unsupervised machine learning algorithms hyper parameters hyper hyper parameters selection example hierachical dirichlet process hlda add personal subjective assumption data best way just assume equality probability appear think applies feature scaling just try make assumption features equality opportunity influence weight really reflects information knowledge know data commonly also result better accuracy btw affine transformation invariant converge fasterinterest link will oscillate inefficiently optimum variables uneven andrewscoursera course done something like standardizing data sometimes researchers want know specific observation common exceptional express score terms number standard deviations removed mean number callscore recode original scoresscores say standardize variable learnt andrewcourse coursera feature scaling helpsachieve gradient decent quickly data spread means higher standerd deviation will relatively take time calculate gradient decent compared situation scale data via feature scaling idea scaling remove exess computes particular variable standardising variable scale tend calculate slope lot easiermxnormalizingparameter converge quickly possible yes normalisation contour will skinny thus normalisationusingpackage randomforest regression biological data training data sizejust wondered good value number trees ntree number variable per level mtry approximate formula find parameter values row input data character representing amino acid sequence want build regression model use sequence order predict distances proteins default mtry quite sensible really need muck function tunerf optimizing parameter however aware may cause bias optimization number bootstrap replicates often start ntree plot random forest object will show error convergence based oob error want enough trees stabilize error many correlate ensemble leads overfit caveat variable interactions stabilize slower rate error large number independent variables need replicates keep ntree odd number ties can broken dimensions problem start ntree also recommended looking onto one published variable selection approaches reduce number independent variables short answer randomforest function course default values ntree mtry default mtry often always sensible generally people will want increase ntreedefault quite bit correct value ntree generally isnmuch concern will quite apparent little tinkering predictions model wonchange much certain number trees can spend read waste lot time tinkering things like mtry sampsize maxnodes nodesize etc probably benefit experience lot however every data set will different sometimes may see big difference sometimes none caret package general function train allows simple grid search parameter values like mtry wide variety models caution fairly large data sets likely get time consuming fairly quickly watch also somehow forgot ranfomforest package tunerf function specifically searching optimal value mtry paper help limiting number trees random forests abstract aim paper propose simple procedure priori determines minimum number classifiers combine order obtain prediction accuracy level similar one obtained combination larger ensembles procedure based mcnemar non parametric test significance knowing priori minimum size classifier ensemble giving best prediction accuracy constitutes gain time memory costs especially huge data bases real time applications applied procedure four multiple classifier systemsdecision tree breimanbaggings random subspaces combination labeled bagfs breimanrandom forests five large benchmark data bases worth noticing proposed procedure may easily extended base learning algorithms decision tree experimental results showed possible limit significantly number trees also showed minimum number trees required obtaining best prediction accuracy may vary one classifier combination method another never use trees one nice trick use initially start first taking square root number predictors plug value mtry usually around value tunerf funtion random forest pick use code check accuracy play around ntree mtry change parameters restore original text kerasimdb dataset want restore imdboriginal text kerasimdb dataset first load kerasimdb dataset returned sequence word index found returns word index dictionary like create make converting create index word dictionary tried restore original text like followinggood english know sentence something strange happened can restore original text example coming gibberishmuch worse just missing stop wordsread docs start char oov char index parameters imdb movie reviews sentiment classification method explain happening start char int start sequence will marked character set usually padding character oov char int words cut num words skip top limit will replaced character index int index actual words index higher dictionary inverted assumes word indices start indices returned keras start unknown indexes assumes will use padding works punctuation missingcan get original dataset without stop words removed using get file credit jeremy howardsbrowser api encoding will work along labels upvote helps indices offset reserved indices padding start sequence unknown following work works get equivalent array reviews try code code worked get index details build key value pair using linear regression predict data getting totally contrasting results normalizestandardize variables normalizationxmin xmax xmin zero score standardizationxmean xstd thanks santosh note results might necessarily different might simply need different hyperparameters two options give similar results ideal thing test works best problem canafford reason algorithms will probably benefit standardization normalization see examples one preferred example clustering analyses standardization may especially crucial order compare similarities features based certain distance measures another prominent example principal component analysis usually prefer standardization min max scaling since interested components maximize variance depending question pca computes components via correlation matrix instead covariance matrix pca previous article however doesnmean min max scaling useful popular application image processing pixel intensities normalized fit within certain range rgb color range also typical neural network algorithm require data scale one disadvantage normalization standardization loses information data especially outliers also linked page picture can see scaling clusters data close together may want might cause algorithms gradient descent take longer converge solution standardized data set might even make impossible normalizing variables doesnreally make sense correct terminology normalizing scaling featuresgoing normalize scale one feature rest makes sense normalization standardization different things normalization transforms data range standardization transforms data resulting distribution mean standard deviation normalization standardization designed achieve similar goal create features similar ranges want can sure capturing true information feature weigh particular feature just values much larger features features within similar range real need standardize normalize however features naturally take values much larger smaller others normalization standardization calledgoing normalizing least one variable feature thing others first question need normalisation standardisation take example dataset salary variable age variable age can take range salary can thousand lakh compare difference person age difference will range salary difference will range thousands donwant one variable dominate use either normalisation standardization now age salary will scale use standardiztion normalisation lose original values transformed values loss interpretation extremely important want draw inference data normalization rescales values range also called min max scaled standardization rescales data mean standard deviation another example image can see actual data green spreadw standardised data red spread around whereas normalised data blue spread around normally many algorithm required first standardise normalise data passing parameter like pca dimension reduction plottingdatasay required standardisation image processing required normalise pixels processing normalisation lose outliers extreme datapoints either low high slight disadvantage depends preference chose standardisation recommended gives normal curve none mentioned transformations shall matter linear regression affine transformations found coefficients change explained variance will ultimately remain linear regression perspective outliers remain outliers leverage points transformations also will change distribution shape distribution remains lot people use normalisation standardisation interchangeably purpose remains bring features scale approach subtract value min value mean divide max value minus min valuerespectively difference can observe using min valuewill get valuemean valuewill get botve values also one factors decide approach use got kerasfile need convert tflite researched first needviapb tflitetflite sometimes results issue can use tfliteconverter directly convertfiles tflite file work windows windows use google colab notebook convert uploadfile will convert tflite file follow want try create code cell insert code run cell will get download option worked windows using tensorflow keras just colab using code notebook difficulty uploadingmodel via colab mounted google drive uploaded moved notebook content folder using google colab notebook try works using keras tensorflow cpu version information can visitrequires load keras model instance returns converted instance check link details one factor must consider need change learning phase convertingsuper important dropout batch normalization can take look keras model tflite problem converting keras model tensorflowdiscussions specific version tensorflow keras works properlyeven tried toco command line issues use tensorflowkeras will work tensorflow gpu keras exactly example get result like calculations using sigmoid function know second column probabilities documentation says first columnsamples cansamples reviews texts numbers documentation also says second columnclasses certainly cansince two classes namely function supposed calculating probabilities samples really class classes first column really first column probability entry label second column probability entry label note classes ordered can use logistic data will yielderesult currently reading machine learning book tom mitchell talking neural networks mitchell states although perceptron rule finds successful weight vector training examples linearly separable can fail converge examples linearly separable problems understanding means linearly separable wikipedia tells two sets points two dimensional space linearly separable can completely separated single line apply training set neural networks can inputs action units linearly separablebest geometry maths anybody explain though thanks suppose want write algorithm decides based two parameters size price house will sell year put sale inputs size price one output will sell will sell now receive training sets happen output accumulated make prediction easy can tell based first graphwills second graph can see first graph canreally separate two possible outputs sold sold straight line matter try will alwaysn sides line means algorithm will lot possible lines ultimate correct line split outputs course predict new ones goal beginninglinearly separable second graph data sets much easier predict means hyperplane splits input space two half spaces points first class one half space second class half space two dimensions means line separates points one class points class edit example image blue circles represent points one class red circles represent points class points linearly separable three dimensions means plane separates points one class points class higher dimensionssimilar must exist hyperplane separates two sets points mentiongood mathwriting formal definition let know comments help look following two data sets left data set linearly separable without using kernel right one separable two parts andb indicated lineone sidecalled linearly separable exist linear manifold separating two classes now famous kernel trick will certainly discussed book next actually allows many linear methods used non linear problems virtually adding additional dimensions make non linear problem linearly specially netflix contest always come across blog leaderboard forum mention applying simple svd step data helped reducing sparsity data general improved performance algorithm hand trying think since long time able guess general data hand get noisy also fun part bigdata know basic feature scaling stuff like log transformation stuff mean normalization something like svd helps say huge matrix user rating implement version recommendation system say collaborative filtering helps svd used normalize data get rid redundant data dimensionality reduction example two variables one humidity index another one probability rain correlation high second one contribute additional information useful classification regression task eigenvalues svd help determine variables informative ones can without way works simple perform svd training data call matrix obtainsset zero valuesless certain arbitrary threshold call new matrixobtainv use new training data features now set zero can removed sometimes without performance penalty depending data threshold chosen calledtruncated svd svd doesnhelp sparsity though helps features redundant two features can sparse informative relevant prediction task canremove either one using svdn featuresfeatures one will linear combination originals dimensionality reduction step just like feature selection redundant features present though feature selection algorithm may lead better classification performance svd depending data set example maximum entropy feature selection weka comes bunch see matrixlr best approximation rankmatrixfrobenius norm equivalentnorm matrices computationally efficient use representation matrixnkcan store low rank approximationk coefficients storingdoften used matrix completion problems collaborative filtering true matrix user ratings assumed low rank approximated low rank matrix wish recover true matrix computing best low rank approximation data matrix however now better ways recover low rank matrices noisy missing observations namely nuclear norm minimization see example paper power convex relaxation near optimal matrix completioncandestao note algorithms derived technique also store svd estimated matrix computed differently pca svd used dimensionality reduction reduce number inputs besides saving computational cost learning predicting can sometimes produce robust models optimal statistical sense better performance noisy conditions mathematically simpler models less variance course can problem known bias variance dilemma said plain words einstein things made simple possible formulae seem similar essentially usually use term log loss binary classification problems general cross entropy loss general case multi class classification even distinction consistentoften find terms used interchangeably synonyms wikipedia entry cross entropy logistic loss sometimes called cross entropy loss also known log loss link now dead log loss cross entropy slightly different depending context machine learning calculating error rates resolve thingcheatsheet cross entropy loss log loss measures performance classification model whose output probability value infinite stream possible events event event event event events come completely random order will assume complex patterns order events come rest events just random know patterns ahead time though event received want predict next event will based order events come past question machine learning algorithm use predictor predictor will told next event actually question arises long history predictor maintain since maintaining infinite history will possibleleave answer answer caninfinte though practicality believe predictions will done kind rolling history adding new event expiring old event therefore rather efficient require rebuilding entire predictor model example specific code instead research papers add immense value responses pythonlibraries nice anything will update one event can happen simultaneously round change solution essentially sequence prediction problem want recurrent neural networks hidden markov models fixed time look back time window approaches might suffice take sequence data split overlapping windows lengtheg split sequence abcdefg abc bcd cde def efg train function approximator map firstparts window onto nth part predictor will able look back time longer size window rnns hmms can theory hard tune sometimes just donwork state art rnn implementations can found pybrain update pybrain code problem haventested might typos stuff overall structure work will train recurrent network epochs print error every epochs afterwards can check correct predictions like will print array booleans every event rather keeping full history one can keep aggregated information past along relatively short sliding history used input predictor logic tentative implementationlike nutshell managing set markov chains increasing order grading averaging predictions can several variations general logic described particular choice particular metric used grade quality prediction individualgram lengths considerations put regards detecting adapting possible shifts events distribution assumes generally ergodic event source one possible approach use two sets tables combining probabilities accordingly periodically dropping contents tables one sets choosing right period resets tricky business essentially balancing need statistically significant volumes history need short enough period lest miss shorter depends depends accurate needs donbelieve strategy ever accurate even infinite history try historygetaccuracy trygetaccuracy etc increased memory usage processing time point either job done need find new strategy worth think looking simple soft neural net might better plan just studied branch predictors computer architecture processor take long actually evaluate condition expression tries guess save time way sure research done areacan think moment havenseen unique setup like think might need preliminary experimentation try running solutionnumber seconds historyslots correctness ratio compare fixedvaryinghistory slots try find best memory history ratio graphing one event can happenlittle mind bending constraints infinite number events happen time uhohcomputationally impossibletry approach just one event time except predictor enabled predict multiple events time processors use really lightweight tricks predict whether branch statement will branch helps efficient pipe lining may general markov models instance interesting simplicity wikipedia article branch prediction see saturating counter two level adaptive predictormy machine following spec cpu xeonv gpu titanpascal ubuntu nvidia driver cuda tookit cudnnbenchmarked following keras examples tensorflow backed reference gpu clearly performing cpu non lstm models anyone else experienced use keras use cudnnlstm place lstm cudnngru place gru case teslaseeingboost performance way using batch size suggested alexey golyshev small batch size try increase results gtxs just tip using gpu powerful neural network model big batch size bigfound googling got similar issues cpu intelxeoncpuv ghz ubuntu imdb bidirectionalgpu gtxnvidia driver cuda toolkitcudnnimdb bidirectionalobserve gpu load curve found one interesting thing gpu load mainly due sequential computation lstm layer remember lstm requires sequential input calculate hidden layer weights iteratively words must wait hidden state timecalculate hidden state times good idea gpu cores since many small cores like computations parallel sequential compuatation canfully utilize computing powersseeing gpu load around time phase backpropagation gpu run derivative computation parallel can see gpu load peak around network want train dataset example say cifar can create data loader object via question follows suppose want make several different training iterations letsay want first train network images odd positions images even positions order need able access images unfortunately seems trainset allow access trying trainset generally trainset mask will throw error instead however will force create new copy full dataset iteration already changed way avoid ideally like something equivalent supports shuffle doesnrequire writing sampler can define custom sampler dataset loader avoiding recreating dataset just creating new loader different samplingcan find info samplerin scikit learn estimators fit method depending whether supervised unsupervised also predict transform method process writing transformer unsupervised learning task wondering rule thumb put kind learning logic official documentation helpful regard fit transformy none fit params fit data transform context meant fitting data transforming data fitting finds internal parameters model will used transform data transforming applies parameters data may fit model one set data transform completely different set example fit linear model data get slope intercept use parameters transform map new existing valuesy fit transform just steps data scikit example fit data find principal components transform data see maps onto components answers explain fit need anything except returning transformer object transformers interface work nicely stuff like pipelines course transformers need fit method thinkidf actually things transform method needs return transformed data fit transform convenience method chains fit transform operations can get free deriving custom transformer class transformermixin implementing fit transform case calling fit method anything can see example transformers need actually something fit transform methods guess every class scikit learn implement fit transform predict order consistent rest package guess indeed quite overkillworking multivariate variables multi stept forecasting problem time series frequency every minute problem requires forecast one variables targetinterested knowpossible usingprophetpython api able univariate fashion using target variable datetime variable help direction appreciated please let know input clarity needed question can add additional variables prophet using add regressor method example want predict variableusing also values additional variables add add letfirst create samplesplit train test training forecaster can add regressors use additional variables argument add regressor column name additional variable trainingpredict method will use additional variables forecast note additional variables values future test data donstart predicting add add univariate timeseries predictadd regressor predicted add add future values additional variables documentation understand forecastt will use values add addvaluestnimportant create new additional variables lags see also notebook example using weather factors extra regressors forecast bicycle usage forecasting one dependent variable need implement time series using vector auto regression var model variable linear function past values past values variables information varseems like agreement prophet works multivariate way see github issues judging comments queiseanswer nice youtube tutorial can somehow make work around multivariate functionality see videoxzhpo lqu might late however reading can implement multivariate time series using lstm keras can one line using timemachines package wraps prophet functional form see prophet skaters preciseexample use note can setwhatever want number steps ahead use now careful prophet says multivariate really referring variables known advance argument doesnreally address multivariate prediction can use facebook skater called recursive use prophet predict exogenous variables predicts one really care said strongly advise read critique prophet also check position elo ratings using anger answer original question yes link specific neural prophet documentation several examples use multivariate inputs neuralprophet referred lagged regressors solution bobrupakroy yes favorite fbprophet back multivariate forecasting fbe var pure econometric model reading lot literature forecasting see var also suffers able capture trend good forecast still var workhorse model multivariate analysis think prophet multivariate rather usemodels likexgboost nnet keep mind want capture trend sure model better elsedeep learningi copying example wouldnrun gave following errors additional configuration variable needs set get example running can add begining code define sparksession work answer good will work first time second time try will throw following exception two ways avoid using instead sparkcontext using end start another sparkcontext since calling createdataframe need instead spark stands sqlcontext general peopledidnwork try import spark following using python will create spark session remember old method though will work errors regarding open sessionelectronic products want match products one database however product names always identicaltried using levenshtein distance measuring string similarity however hasnworked example items yet product names vary quite lot first thought try parse names description features companysize inch resolutiontype lcd hdtv can match descriptions compatibilityokay omit product number bad different sizes simple common attributes compatible might enough might write learn rules much different attributes allowed differ depending many different kinds products different listed names might actually start manually defining set attributes possibly even just adding specific words regexes match iteratively seeing isnparsed far adding rulesimaginelot ambiguity terms one vocabulary item possibly belonging multiple attributes though without seeing database guess donknowgoing feasible extraction kind analogous semi supervised part speech taggingsomewhat different though imagine vocabulary much limited typical parsing space product names heirarchical resolution tag applies certain kinds productsfamiliar literature might ideas use use large set training examples possible pair example set now get pair strings want decide extract features like training set create tuple numbers distance various components string feed tuple trained svm classify advantage using learning approach like donkeep modifying rules also system learns differences large pair products different use libsvm package weka donknow much machine learning know levenshtein distance best approach type problem working extremely similar problem currently found much accurate matches using largest consecutive sub sequence may also find longest common substring helpful maybe even combination levenshtein great allows substitutions can easily discount similar strings extra characters example hello aaaaaa hello bbbbb hello bbbbb closer levenshtein distance even though probably like hello match hello aaaaaa lcs lss allow substitutions methods hello match hello aaaaaa trained modelexported weights want partially load another model model built keras using tensorflow backend right nowfollowssureterrible way although works load just first layers first layers consistently named original trained model new model can use name true will update weights layers new model identically named layer found original trained model name layer can specified name keyword example call will return list weight tensors model numpy arrays next iterate list apply reload weights first layers information available showing sure classifier prediction correct want something like sure classifier prediction class class class class class samples code suspect use score function seem keep implementing correctly donknowright function one get confidence percentage classifierprediction per svc documentation looks like need change construct svc use predict proba method estimators implementing predict proba method like justin peel suggested can just use predict proba produce probability prediction estimators implement predict proba method can construct confidence interval using bootstrap concept repeatedly calculate point estimates many sub samples let know need detailed examples demonstrate either two cases ran pca data frame features using simple code result believe means firstexplains variance second component explains get data frame bellow line principal componentlike understand interpret table know square features component sum getmean dos tell something featuresince highest magnitude component explains variance thanks terminology first results pca usually discussed terms component scores sometimes called factor scores transformed variable values corresponding particular data point loadings weight standardized original variable multiplied get component score part explain check importance features plot biplot part explain check importance features save pandas dataframe using feature names summary article python compact guide source friends linkbfc aff fedfbcase value featurescore featurevalue tellsmuch feature influencescasehigher value absolute value higher influence principal component performing pca analysis people usually plot known biplot see transformed featuresdimensions case original variables features wrote function plot example using iris data results important features ones influence components thus large absolute value component get important features pcs names save pandas dataframe use printsfeature namedimportantd summary article python compact guide source friends linkbfc aff fedfbbasic idea principle component breakdown features basically tells direction principle component points terms direction features principle component features greater absolute weight pull principle component featuredirection example can saysince feature featurefeature featurerelatively low weights absolute valuemuch pointing direction features feature spacewill pointing direction featurerelative directions visualization lower dimensions visualization look following figures taken following shows example running pca correlated data can visually see eigenvectors derived pca pulled feature feature directions thus make principle component breakdown table like made expect see weightage feature feature explainingpc next example uncorrelated data letcall green principle componentpink ones clearpulled direction featureisnpc direction featurethus table must weightage featurepc weightage featurepc hope gives ideaseeing tablegotdocuments stored postgres database tagged topic categories categories total anotherdocuments donyet categoriestrying find best way programmaticly categorizeexploring nltk naive bayes classifier seems like good starting point can suggest better classification algorithm taskears problem donenough ram train naivebayesclassifier categoiesdocuments training categories usedfurthermore accuracy classifier seems drop train categories accuracy categories just train classifier categories time rundocuments classifier see matches seems like work except lot false positives documents donreally match categories get shoe horned classifier justbest match none option classifier just case document doesnfit categories test class idf vectors term frequencies sparse use python dict term keys count values divide total count get global frequencies another solution use abs hash term instance positive integer keys use can compute cosine similarity document vector category vector choose similar category label document good enough try train logistic regression model usingpenalty explained example scikit learn wrapper liblinear explained ephes vectors used train logistic regression model previously introducedlog idf vectors get good performance precision recall scikit learn lib offers try vowpal wabbit probably fastest rabbit earth large scale document classification problems easy use python wrappers afaik big number words documents memory consumptiontrainingdocs issue naive bayes good choice especially many categories training examples noisy trainingdata general linear support vector machines perform much better problem multiclass document belongs one category exclusivly multilabel document belongs one categories accuracy poor choice judge classifier performance rather use precisionrecall precision recall breakeven point prbpauc look precisionrecall curve recallplotted precisionbased value confidence threshold wether document belongs category usually build one binary classifier per category positive training examples one categorytrainingexamples donbelong current categorychoose optimal confidence threshold per category want combine single measures per category global performance measuremicro sum true positives false positives false negatives true negatives calc combined scores macro calc score per category average scores categories average corpus tens million documents millions training examples thousands categories multilabel since face serious training time problems number documents new updated deleted per day quite high use modified version liblinear smaller problems using one python wrappers around liblinear liblinear scipy scikit learn work fine way none option classifier just case document doesnfit categories might get effect simply none pseudo category trained time max can train categories thoughsureeating quite much ram train actual categories actualdocs none onedocuments taken randomly categories want stratified sampling approach may sounder still feels like bit kludge might better completely different approach find multi dimensional doc measure definespre tagged docs reasonably separable clusters just assign yet untagged docs appropriate cluster thus determined donthink nltk anything directly available support kind thing hey nltkgrowing fast may missed difference minmaxscaler standardscaler mms minmaxscaler feature range used machine learning modelstandardscaler another machine learning model used standard scaler min max scaler minmaxscaler feature range will transform value column proportionally within range use first scaler choice transform feature will preserve shape dataset distortion standardscaler will transform value column range mean standard deviationvalue will normalised subtracting mean dividing standard deviation use standardscaler know data distribution normal outliers use robustscaler alternatively remove outliers use either scalers choice depends whether data normally distributed additional note scaler used train test split data leakage will happen use scaler train test split scikitlearn site standardscaler removes mean scales data unit variance however outliers influence computing empirical mean standard deviation shrink range feature values shown left figure note particular outliers feature different magnitudes spread transformed data feature different data lie range transformed median income feature data squeezed smaller range transformed number households standardscaler therefore guarantee balanced feature scales presence outliers minmaxscaler rescales data set feature values range shown right panel however scaling compress inliers narrow range transformed number households many machine learning algorithms perform better numerical input variables scaled standard range scaling data means helps normalize data within particular range minmaxscaler used also known normalization transform values range formulavalue min max min standardscaler comes standardization value ranges formulax std deviation implementing minmaxscaler standard scaler know distribution dataset standardscaler rescales dataset mean standard deviation standardization useful data varying scales algorithm assumption data gaussian distribution normalization minmaxscaler rescale dataset value fall useful data varying scales algorithm make assumptions distribution good technique know distribution data know distribution gaussian fairly new tensorflowgeneral hereby apologize likely trivial question use dropout technique improve learning rates network seems work just fine like test network data see works like obviously yields different results time dropout still place one solution can think create two separate models one training one actual later use network however solution seems impracticalcommon approach solving problem easiest way change keep prob parameter using placeholder default way train can set parameter like evaluate default value used new returns different models based whether training testing still allows reuse model code model function something similar mode argument automatically passed depending whether call set keep prob tensorflow dropout layer probability keep weight think set variable values testing network must simply feed keep prob define something like change values session donwant use estimator api can create dropout way feed sessiontraining false evaluation instead changing dropout rate update tensorflow class rely feed dict manage external parameter allows better refactored code info computing accuracy using cross validation can report confusion matrix instead accuracy use cross val predict see scikit learn docs instead cross val score instead can short answer need understand difference cross val score cross validation model selection method cross val score name suggests works scores confusion matrix score kind summary happened evaluation major distinction score supposed return orderable object particular scikit learn float based score can tell whether methodbetter simply comparingbigger score confusion matrix name suggests matrix want obtain confusion matrices multiple evaluation runs cross validation hand bad scikit learn actually lines code think really want average confusion matrices obtained cross validation run lejlot already nicely explainedjust upgrade answer calculation mean confusion matrices calculate confusion matrix run cross validation can use something like end can calculate mean list numpy arrays confusion matrices can though define scorer uses certain values confusion matrix see link just citing code will perform cross validation four scorers return scoring dictionaryresults keys testtestetc containing confusion matrices values cross validation split reconstruct average confusion matrix cross val predict xema seems elegant note will actually work cross val scoreneed cross validate introduced scikit learnside note use one scorers hyper parameter optimization via grid search new machine learning understand correctly confusion matrix can obtain valuefntn value obtain directly scoring implied accuracy precision recall now unknownfntntpfpeqtprtptpfpassuming one unknown becomes unknown equations relative value can solved using system equationr can obtain scoring cross validate can get source one timei wrote vanilla autoencoder using dense layer code softmax provides probability distribution understood means vector values probability example summing elements provides donunderstand binary crossentropy works values binary cross entropy two values output right context autoencoders input output model input values range acceptable use sigmoid activation function last layer otherwise need use appropriate activation function last layer loss function comes back values input data input data zeros ones values binary crossentropy acceptable loss function otherwise need use loss functions mse mae note case input values range can use binary crossentropy usually used however donexpect loss value becomes zero since binary crossentropy return zero prediction label either zero one matter equal video hugo larochelle explains loss functions used autoencoders part using binary crossentropy inputs range starts concretely example using mnist dataset default values mnist integers range usually need normalize first now values range sigmoid can used activation function either binary crossentropy mse loss function binary crossentropy can used even true label values range note trying minimize loss function training loss function used reaches minimum value may necessarily equal zero prediction equal true label acceptable choice letverify case binray cross entropy defined followstrue labelpredicted value letconsiderfixed see valueminimizes function need take derivative respectassumed log natural logarithm function simplicity calculations can see binary cross entropy minimum valuep smote object attribute fit sample error donthink code cause error thanks import like need fit resample post edited submitted review months ago failed reopen post original close reasonresolved just read keras weight initializers documentation different initializers introduced want know default weight donspecify kernel initializer argument way access layer default value initializing weights layers dense convolution rnn layers default kernel initializer glorot uniform default bias intializer zeros can find going related section layer documentation example dense layer doc can find definition glorot uniform initializer keras documentation accessing weights layer already answered know xgboost need first gradient second gradient anybody else used mae obj function little bit theory first sorry asked grad hessian mae however mae continuously twice differentiable trying calculate first second derivatives becomes tricky can see kinkprevents mae continuously differentiable moreover second derivative zero points behaved xgboost second derivative used denominator leaf weights zero creates serious math errors given complexities best bet try approximate mae using nicely behaved function lettake look can see several functions approximate absolute value clearly small values squared error mse fairly good approximation mae however assume sufficient use case huber loss documented loss function however smooth guarantee smooth derivatives can approximate using psuedo huber function can implemented python xgboost follows function can used replacing obj huber approx obj fair loss documented seems work rather fair loss function can implemented code taken adapted second place solution kaggle allstate challenge log cosh loss function finally can create custom loss functions using functions templates warning due api changes newer versions xgboost may require loss functions form huber loss think gradient missing negative sign upfront running huber fair metric normally distributedreason alpha time fair result prediction will equal know pretty meta right classifiers parameter combinations quite fast take long eventually just kill processlike way estimate advance long will take alternativelyaccept pointers set common parameters reduce run time specific classes classifier regressors directly report remaining time progress algorithm number iterations etc can turned passing verbose high number option constructor individual models note behavior according sklearn earlier versions bit different verbose output still useful though best example print number trees built far remaining time progress information fairly useful estimate total time models like svms print number optimization iterations completed directly report remaining time models like linear models donprovide diagnostic information far know check thread know verbosity levels mean scikit learn fit remaining time using ipython can consider use built magic commands time timeit time time execution python statement expression cpu wall clock times printed value expression returned note win system time always reported since can measured timeit time execution python statement expression using timeit module example referencesactually working package gives runtime estimates scikit learn fits basically run right runningy get runtime estimationsimple use case feel free take look tldr scikitroc curve function returning points certain dataset control many points get backtrying draw roc curve consistently get roc triangle just make sure lengthsreturns running returns call threasholds get array always points therefore surprise roc curve looks like triangle understand scikitroc curve returning points help hugely appreciated number points depend number unique values input since input vector unique values function gives correct output problem different example mistake made input outcomes given threshold probabilities argumentscore roc curve also gives plot three points mistake ran problem reading documentaion carefully realized mistake although hints pointed others checking uniqueness insteadnecessary get point exceptusing mushrooms dataset kaggle binary classification problem procuring fpr tpr roc curvegetting points though value less fpr tprsure can consider point plotting curve using looks like one shown noticed one just implemented matlab classify entire net toolbox explain answer one likely provide better accuracy grateful pre requisite short answerinterested solving prediction task use naive bayes bayesian network good wikipedia page models relationships features general way know relationships enough data derive may appropriate use bayesian network naive bayes classifier simple model describes particular class bayesian network features class conditionally independent certain problems naive bayes solve example however simplicity also makes easier apply requires less data get good result many cases learning problem binary featuresx target variablex xornaive bayes classifierx must treated independently compute things like probabilitygivenhopefully can see isnhelpfuldoesnmakeless likely since bayesian network assume independence able solve problem naive bayes just restricted constrained form general bayesian network enforce constraint class node parents nodes corresponding attribute variables edges nothing prevents general bayesian network used classification predicted class one maximum probability conditioned variables set prediction instance values usual bayesian inference fashion good paper read bayesian network classifiers machine learning particular interest section though naive bayes constrained form general bayesian network paper also talks naive bayes can outperform general bayesian network classification tasks bayesian network classifier features selected based scoring functions like bayesian scoring function minimal description length two equivalent theory given enough training data scoring functions mainly restrict structure connections directions parameters likelihood using data structure learned class determined nodes markov blanket parents children parents children variables given markov blanket discarded naive bayesian network known nowadays features considered attributes independent given class bayesian networks naive bayesian network advantages disadvantages can see performance comparison done data sets mainly uci repository depicted can see points diagonal line representing naive bayes performs better bayesian network datasets points diagonal line representing reverse datasets bayesian network complicated naive bayes almost perform equally reason datasets bayesian network performs worse naive bayes attributesstructure learning crucial attributes discarded can combine two add connections features naive bayes becomes tree augmented naive bayesdependence bayesian classifier references bayesian network classifiersichecked source code functions seems lstm makes lstm network general lstmcell returns one cell however cases people use one lstm cell program mean one lstm cellsimple seq seq calling lstmcell lstm make difference recurrent layer contains cell object cell contains core code calculations step recurrent layer commands cell performs actual recurrent calculations usually people use lstm layers code use rnn layers containing lstmcell things almost lstm layer rnn layer using lstmcell can check source code number cells alghout seems name lstmcell single cell actually object manages units cells may think code mentioned can see units argument used creating instancedifference differences make liblinear faster libsvm practice complexity smo algorithm works kernel linear svm implemented libsvmnn whereas liblinearn support kernel svmsnumber samples training dataset hence medium large scale forget kernels use liblinear maybe look approximate kernel svm solvers lasvm edit practice libsvm becomes painfully slowsamples svm support vector machine basically linear classifier using many kernel transforms turn non linear problem linear problem beforehand link seems like liblinear much thing without kernel transforms say cases kernel transforms needed mention document classification will faster cjlin papersl lossloss linear support vector machines svms boseral inherits many features popular svm library libsvm might also see useful information one creators tid main idea say liblinear optimized deal linear classification whereas linear classification one many capabilities libsvm logically may match liblinear terms classification accuracy obviouslymaking broad generalizations exact details differences probably covered paper linked corresponding userguide libsvm libsvm also per class accuracy keras logoverall accuracyhard calculate separate class accuracy anybody knows output per class accuracy keras precision recall useful measures multi class classification see definitions following keras mnist cnn example class classification can get per class measures using classification report result probably looking use callback can easily add call example can define class using function since will format nicely inside training summary decide print verbosity setting please note particular code block set use classes can course change desired number going want configure new callback model fit assuming validation data val data tuple pair can use following please note indicates values likely change based configuration train per class accuracy implement training dataset training dataset example update solution provided solution desertnaut now keras will get error attributeerror sequential object attribute predict classes fix error use following code possible use xgboost multi label classification now use onevsrestclassifier gradientboostingclassifier sklearn works use one core cpu data features task predict columns binary boolean data metric mean average precision map short example code share great one possible approach instead using onevsrestclassifier multi class tasks use multioutputclassifier one one already suggested clf multilabel will fit one binary classifier per class will use however many cores specify params fyi can also specifyjobs onevsrestclassifier eats memory first massage data little makingcopies every data pointcorrect labels can hack way simpler multiclass problem point just get classification margins probabilities class decide threshold want predicting label note solution exact product tags artificially introduce two negative samples class can add label class want predict example data can simply reshape data adding label input according output xgboost learn treat accordingly like way will dimensionalcan still predict many labels model trained using keras tensorflow backend now need turn model tensorflow graph certain application attempted make predictions insure working correctly comparing results gathered get different values instance returns values keras predict correctgraph results helps know final intended application creating jacobian matrix function currently return correct results comparing theanojacobian function gives correct jacobian tensorflow jacobian code edit model code frankyjuang linked call create function loadmodel graph create function make model predictions usinggraph make predictions jacobian function compute jacobian matrix moduleparameters get changed training learnt training neural network buffer learnt neural network training pytorch doc register buffer method reads typically used register buffer considered model parameter example batchnormrunning mean parameter part persistent state already observed model parameters learned updated using sgd training process however sometimes quantities part modelstate saved part state dict moved cuda cpu rest modelparameters cast float half double rest modelparameters registering arguments modelbuffer allows pytorch track save like regular parameters prevents pytorch updating using sgd mechanism example buffer can found batchnorm module running mean running var num batches tracked registered buffers updated accumulating statistics data forwarded layer contrast weight bias parameters learns affine transformation data using regular sgd optimization parameters buffers create module say linear layer register new named parameter tensor register new parameter will appear inside iterator register buffer will difference buffers named tensors update gradients every step like parameters buffers create custom logic fully good thing save model params buffers saved move model cuda params buffers willtrying detect outliers dataset find sklearnisolation forest canunderstand work fit training data gives back vector values can anyone explain works provide example can know outliers real outliers tuning parameters code seems many questions let try answer one one best knowledge works works due fact nature outliers data set outliers different quite different typical clustering based distance based algorithm top level works logic outliers take fewer steps isolate compare normal point data set suppose training data setn data pointsfeatures training creates isolation trees binary search trees different features training parameters tuning train phase max samples number random samples will pick original data set creating isolation trees test phase sklearn finds path length data point test trained isolation trees finds average path length higher path length normal point vice versa based average path length calculates anomaly score decision function sklearn can used get sklearn lower score anomalous sample based anomaly score can decide whether given sample anomalous setting proper value contamination sklearn object default value contamination can tune deciding threshold amount contamination data set proportion outliers data set tuning parameters trainingestimators max samples max features testing contamination represents outliers according fitted model see isolationforest example nice depiction process prior knowledge provide parameters get accurate fitting example know contamination proportion outliers data set provide input default assumed see description parameters let add something got stucked read question time using binary classification assume majority class outlier class exmaple want detect fraud major class non fraud fraud now train test splittraintesttraintest train test splity test size random state run output normal classifier scoring can quite confusiong already mentionedpred testwill consists majority class minor class can recommend convert can use normal scoring funtions etc trying run pca matrix dimensionsxm number featuresnumber samples suppose want preservefeatures maximum variance scikit learn able way now get new matrixnew shapexpossible know features discarded retained ones thanks features pca object determined fitting discard retain pre defined features encoded columns specify mixes weighted sums find orthogonal directions maximum variance behaviour looking pca dimensionality reduction waysimple general feature selection methods can take look axes maximum variances drop axes small variances behavior like compression discardproj better namenew projectiononto principal components can reconstructrecrec closeless important information dropped pca can sayrec denoised opinion can say noise discard answer marked incorrect sklearn site clearly states components array sorted canused identify important features components arraycomponentsfeatures principal axes feature space representing directions maximum variance data components sorted explained variance class weight options option recommended way handling class imbalancesimilar concepts sample weights can force estimator pay attention samples class weights can force estimator learn attention particular class sample weight class weight basically means estimator doesnneed take consideration samples classes learning process thus classifier example will never predict class class weight class sample weight class weight bigger sample weight class weight samples classes estimator will try minimize error samples classes first place can use user defined sample weights class weights simultaneously want undersample oversample training set simple cloning removing will equal increasing decreasing corresponding sample weights class weights complex cases can also try artificially generate samples techniques like smote sample weight class weight similar function make estimator pay attention samples actual sample weights will sample weight weights class weight serves purpose oversampling behavior likely different say algorithm randomly picks samples like random forests matters whether oversampled sum class weight sample weight option one way handle class imbalance donknow universally recommended way try specific problem see works best traininglogistic classifier classify two classes using python scikit learn extremely imbalanced datagetting almost accuracy roc auc precision recallscore understand accuracy usually useful imbalanced data roc auc measure close perfect using logistic regression using decision tree decision matrix looks almost identical auc lot different one must understand crucial difference auc roc point wise metrics like accuracy precision etc roc function threshold given model classifier outputs probability belonging class predict class highest probability support however sometimes can get better scores changing rule requiring one support times bigger actually classify given class often true imbalanced datasets way actually modifying learned prior classes better fit data roc looks happen change threshold possible values auc roc computes integral curve consequentlysetting new tensorflow object detection api find small objects large areas satellite imagery works quite finds objects want also get false positives things look little like target object arenm using sample config pets tutorial fine tune faster rcnn resnet coco model offerstarted small training examples objects just class examples validation set examplepixel image labeled objectcenter train precision loss curves plateaurelatively new using deep learning object detection best strategy increase precision increase training dataset sizeyet try accurate model offer faster rcnn inception resnetatrous cocolike maintain speed will needed hard negative mining seems logical step agree implement letsay makeimages false positivesrevisited topic recently work thoughtupdate current learnings visit future topic appeared tensorflowmodels repo issue tracker ssd allows set ratio many negative postive examples mine max negatives per positive can also set minimum number images postives min negatives per image defined model ssd loss config section said donsee option faster rcnnmodel configurationmentioned issue models research object detection core balanced positive negative model will attempt learn class differences help serve purpose lastly came across article filter amplifier networks fan may informative work aerial imagery following paper describes hard negative mining purpose describe training region based object detectors online hard example mining section describe using foreground background class background rois region labeled backgroundmaximum iou ground truth intervallo lower thresholdlo used frcn sppnet hypothesized crudely approximate hard negative mining assumption regions overlap ground truth likely confusing hard ones show section although heuristic helps convergence detection accuracy suboptimal ignores infrequent important difficult background regions method removeslo threshold fact paper referenced ideas used tensorflowobject detection based model config file hardminerobject returned losses returned model seems simply generating true positive labels tool like labelimg rectlabel enough train algorithm find hard negatives within images related question gives excellent walkthrough event want feed data true positives just add negative image tfrecord bounding boxes think passing close scenarioworth share managed solve passing images without annotations trainer scenariobuilding project detect assembly failures clientproducts real time successfully achieved robust results production env using detection classification components explicity negative pattern just hole detection things doesnnegative pattens systemmandatory user record videos one containing positive scenario another containing negativevideos containingpatterns positive negative algorithm can generalize testing found register detected tape detector giving confident false positive detections tape learning pattern tape inserted instead tape another component like screwnegative format passing negative pattern tape without explicitly aware fps didnhappen found scenario necessarily pass images without tape differentiate tape tape considered two alternatives experiment try solve behavior concluded alternatives worked perfectly scenario training loss got little messy predictions work robustness controlled scenario systemcamera box illumination decrease variables make two little modifications first alternative work part traning progress currentlyusing tensorflow object detection along tensorflow using faster rcnn resnetproblem didnfound solution internet read lot people telling faster rcnn adapted negative training fps reduction tests proved algorithm recognize hand written letter one help greatly appreciated advance thank can use genetic algorithm fateman msw line line handwriting recognition comprehensive survey ocr might good starting pointdollar family recognizers can use recognize single multistroke gestures potentially map alphabet lastest member familyrecognizerstarting point python binding hope helps one seems win major competitions lately maxpool maxpooling surprised couldnfind difference two google wondering difference two basically thing future readers might want know determineddocumentation page layer can use list click view aliases accompanied blue plus sign examplemaxpooldocumentation will find maxpoolinglist aliases layer followd avg global pooling ther library soo many times updatedfunctions different names tasks can use dire need classification task example using libsvm python donknow input look like function responsible training one testing thanks code examples listed donwork libsvmless ported example mossplix example demonstrates one class svm classifiersimple possible still showing complete libsvm workflow step import numpy libsvm step generate synthetic data example points within given boundary note quite real data sets provided libsvm website step now choose non linear decision boundary one class classifier step next arbitrarily partition datardecision boundary class lie within arbitrary circle classpoints outside decision boundary circle svm model building begins steps one just prepare synthetic data step construct problem description calling svm problem passing decision boundary function data bind result variable step select kernel function non linear mapping exmaple chose rbf radial basis function kernel function step train classifier calling svm model passing problem descriptionkernelstep finally test trained classifier calling predict trained model objectexample used version libsvm current stable release time answer posted finallyrpart question regarding choice kernel function support vector machines specific particular kernel chosen different kernel gaussian polynomial etc libsvm includes commonly used kernel functions big help can see plausible alternatives select one use model just matter calling svm parameter passing value kernel type three letter abbreviation chosen kernel finally kernel function choose training must match kernel function used testing data libsvm reads data tuple containing two lists first list contains classes second list contains input data create simple dataset two possible classes also need specify kernel want use creating svm parameter might consider using shinnonoir linear polynomial rbf sigmoid also mind svm problemxclass labelsclass instancesy can lists tuples dictionaries numpy array svm via scikit learn details svm dummy example mashed donknow earlier versions libsvm options will takes just one argument casegnu dynamic values make changes according code options source documentation cjlin libsvm always amazed akinator app guess character asking just several questions wonder kind algorithm method let name class algorithms can read yes name class algorithms called classification algorithms field machine learning decision trees one example classification algorithm classification problem features algorithm answers question deciding question asked next can done various ways example trying maximize predicted mean entropy next question game sometimes known questions questions main characteristics algorithm akinator game algorithm model called expert system based fuzzy logic decision trees decision trees mistakes indulgence wrote one time agocan find linkknow exactly algorithm akinator uses put open source algorithm achieves effect questions timesanswer options timestargets see see may hard read may easier read cuda codetree structure small project build dynamic quiz find taste want share akinator uses binary trees root node first question goes inner inner probably akinator also gets location links questions developed akinator named ankusha used pattern matching algorithmquite complicated say way ankusha works can get source code github link ankusha mind reader ankusha finishes guess within five questions confirms movie guessed click next five questions asked iteration continues twenty one questions python program requires pil pygame module installed compulsorily please try note make sure read file gnu general public licence version trying plot train test learning curve keras however following code produces keyerror val acc error official document states order use val acc need enable validation accuracy monitoring understand know use code help much appreciated thanks looks like keras tensorflow val acc renamed val accuracyprint keys history dict will get like dict keys loss acc val loss val acc edit code like keys error may need enable validation split trainset usually validation happens trainset code make change given works main point everyone misses mention key error related naming metrics need consistent way name accuracy metric inside metrics metric name history callback object will receive dictionary containing key value pairs defined metrics metric metrics acc can access history object acc define metric metrics accuracy need change accuracy access value order avoid key error hope helpslink metrics can use keras upgrade keras older version newer compatible tensorflow might error acc acc val acc renamed accuracy val accuracy respectively renaming script will solve issue get val data val acc val loss need first set validation first method will validate give second method will validate part training data changed acc accuracy problem solved tensorflowtesttesttesttest empty check print shapetesttest respectively case validation datatesttest method ran validation set empty didncreate dictionary key val loss val accuracy objective val accuracy tensorflowlittle bit confused initial epoch value fit fit generator methods doc initial epoch integer epoch start training useful resuming previous training run understand useful start training scratch useful trained dataset want improve accuracy values correctwrongsure really questions since optimizers internal values set using current epoch value even may custom callbacks depend current value epoch initial epoch argument let specify initial value epoch start training stated documentation mostly useful trained model epochs say saved now want load resume training another epochs without disrupting state epoch dependent objects set initial epoch epochs since total number epochs reach everything resume initially trained model epochs one single training session however note using built optimizers keras donneed use initial epoch since store update state internally without considering value current epoch also saving model state optimizer will stored answer correct however important note trained epochs set initial epoch epochs train epochs reach total epochs example trained epochs set initial epoch epochs result trains epochs new data history object starts epoch returned history object start epoch might expect another words state history object preserved initial training epochs set initial epoch train epochs rerun fit generator epochs will train epochs starting state preserved end second epoch provided use built optimizers history object state preserved initial training contains data last epochs noticed plot validation loss versus epochs example integrate initial epoch code also donforget specify particular random state value splitting data train test encounters set training data time reinitiate training process data leakage test data entering traininggoal build scalable machine learning libraries equivalent libraries python scikits learn highly recommended can read data hdfs course runs top spark can access via pyspark see programming guidepython examples orange supposedly pretty decentheardnever used personally pyml might worth taking look also monte pysuggest python wrapper suggest toprecommendation engine implements variety recommendation algorithms collaborative filtering interesting library crab post library stable implementations collaborative filtering algorithms user based item based svd implementation includedexperimental content based algorithms roadmap check learning neural network want write function cross entropy python definednumber samplesnumber classes log natural logarithmj sample classotherwisej predicted probability sample classavoid numerical issues logarithm clip predictions range according description wrote codes clipping predictions epsilon epsilon range computing cross entropy based formula following code will used check function cross entropy correct output codes false say codes defining function cross entropy correct print result cross entropy predictions targets gave correct result ans anybody help check problem codesfar remember taking average valuesumscase code read thinklittle clearer stick also addedavoid possibility log computation hope helps note per petercomment offsetindeed redundant epsilon value greater wanted write program asking questions weather algorithms techniques start lookingwill sunny weekend chicago wanted know intent weather query date weekend location chicago user can express query many forms like solve constrained form looking ideas get started solution needs just good enough since input natural language form best way start looking first parsing sentence structure running sentence ner named entity recognizer parsing sentence come rules certain types dependencies always give intent running ner will let identify places datessimple come rules classify intent can use classifier using feature vector formulated input sentence fact parser put canformulating feature vector exists softwarestanford nlp group may can look parse sentence intent information require answer questiontook sentence will sunny weekend chicago ran online stanford ner tagger gave following now identified date location hope helps know answer quite generic may helpful just getting started think api exactly lookingeasy awesome useusing awhile now cheaper options looked will sunny weekend chicago map luis intent called weatherquery date map pre built luis datetime entity location chicago map pre built luis entity geography addressdata mining noticed lot overlap people experience fields exactly draws line just view one person formally trainedothers might see things quite differently machine learning probably homogeneous three terms consistently appliedlimited pattern extraction pattern matching algorithms terms mentioned machine learning one used academic departments describe curricula academic departments research programs term used academic journals conferences proceedingsclearly least context dependent terms mentioned information retrieval data mining much closer describing complete commercial user query retrieval delivery relevant resultsalgorithms might somewhere process flow sophisticated applications oftenformal requirement addition term data mining seems usually refer application process flow big databg therefore usually includes distributed processing map reduce component near front workflow information retrievaldata miningrelated machine learninginfrastructure algorithm kind way words machine learning one source tools used solve problems information retrievalone source toolsdoesndependinstance particularproject might storage rapid retrieval fully indexed data responsive usersearch querycrux optimizing performance data flow round trip query delivering search results user prediction pattern matching might useful likewiseproject might usealgorithm predictive engine yetproject likely also concerned entire processing flow instance parallel computation techniques efficient input enormous data volumeperhaps delivers proto result processing engine computation descriptive statistics mean standard deviation distribution etc variables columns lastly consider netflix prize competition directed solely machine learning focus prediction algorithm evidenced fact single success criterion accuracy predictions returned algorithm imagine netflix prize rebranded data mining competition success criteria almost certainly expanded accurately access algorithmperformance actual commercial setting instance overall execution speed quickly recommendations delivered user probably considered along accuracy terms information retrieval data mining now mainstream use though saw terms job description vendor literature usually next word solution employer recently hired data mining analyst donknow exactly wears tie work every daytry draw line follows information retrieval finding something already part data fast possible machine learning techniques generalize existing knowledge new data accurate possible data mining primarly discovering something hidden data know new possible intersect often use techniques one anotherir use index structures accelerate processesuses lottechniques example pattern data set useful generalization might new knowledge often hard separate favor donjustbuzzwords opinion best way distinguishing intention given find data generalize new data find new properties existing data can also add pattern recognition computational statistics another couple areas overlap three mentionedsay defined line separates history emphases statistics emphasizes mathematical rigor data mining emphasizes scaling large datasetssomewhere data mining discovering hidden patterns unknown knowledge can used decision making people machine learning learning model classify new add details clarify problem editing post closed years ago four functions seem really similar situations might give result help will thankfully appreciated now know assume internally factorize labelencoder work way big differences terms results sure whether will take similar time large magnitudes data get dummies onehotencoder will yield result onehotencoder can handle numbers get dummies will take kinds input get dummies will generate new column names automatically column input onehotencoder will rather will assign new column names get dummies better respectives please correct wrong thank four encoders can split two categories main difference pandas scikit learn encoders scikit learn encoders made used scikit learn pipelines fit transform methods pandas factorize scikit learn labelencoder belong first category can used create categorical variables example transform characters numbers pandas get dummies scikit learn onehotencoder belong second category can used create binary variables onehotencoder can used categorical integers get dummies can used type variablesalso written detailed post based answer currently training data using neural network using fit function now used validation split understood training data will testing data will confused data dealt back end like top samples will taken training percent testing samples randomly picked inbetween want give separate training testing data will using fit moreover second concern check data fitting model can see results training accuracy around validation accuracy around mean case fitting fitting last question evaluate returns document says returns loss already getting loss accuracy epoch return fit history accuracy score returned evaluate shows accuracy returned evaluate returns can say data fitting regardless individual accuracy loss epoch code keras documentation says validation data selected last samplesy data provided shuffling means shuffle occurs split also boolean parameter called shuffle set true default donwant data shuffled just set false getting good results training data getting bad good results evaluation data usually means model overfitting overfit model learns specific scenario canachieve good results new data evaluation test model new data never seen usually divide data training test sometimes might also want create third group data just adjust model obtain better better results test data way like cheating way telling model data going use evaluation cause overfitting also want split data without using keras recommend use sklearn train test split functioneasy use looks like order access modelparameters pytorch saw two methods using state dict using parameters wonderdifference one good practice bad practice thanks parameters gives module parameters hand state dict returns dictionary containing whole state module check source code contains just call parameters also buffers etc parameters persistent buffers included keys corresponding parameter buffer names check keys state dict contains using example state dictfind entries like present parameters want access parameters can simply use parameters purposes like saving loading model transfer learningneed save state dict just parameters besides differences kharshitanswer attribute requires grad trainable tensors true false question appear programming within scope defined help center closed years agogathering results image detector algorithm basically set images sizerun sliding windowthru also number predefined scales understand true negatives true negatives windows classifier gives negative results sounds weird sincesliding small windowpixels timearound different scales used detectionlots true negatives per image prepare set pure negative images objects human just slide thruone positive detections imagescount false negative vice versaexample image green rects ground truthalways seen four terms following case understand correctly trying detect objects image false negative therefore mean object result positive algorithm detect therefore returned negative true negative simply algorithm correctly stating area checked hold object can choose ignore negative values used train algorithmusing algorithm looks instead setting everything recognised false possible rectanglesfptn therefore amount true negativesvast exhaustive context generally object detection metrics containignored manymakes metric difficult use true negativeskind background prediction ground truth boxes location present predictions also false negatives ground truth boxes prediction contain box location generally object detection task look true negativecases algorithm telllike detect object non object candidate contrary classification tasks aim decide instance consider negative positive thus naturally will true negativecases classification tasks besides better compatible measures object detection tasks can refer mean average precision map evaluate object detection algorithm note map different simple averaging precision can find info topic jonathan hui map mean average precision object detectionnice explanationscore explained wiki helpful measuring success attempt write function calculatesscore afaik true negative scenario object present image marked either ground truth annotation model prediction usuallyobject detection systems use two dataground truth annotations model predictions however find true negative cases require sought superset ground truth annotations contains information class instances present image just specific model example taking given image interested object detection autonomous driving purposes can consider two ground truth annotations super setannotations autonomous drivingannotations two ground truth annotations possible calculate true negatives burger window however doubt true negatives can calculated without superset add details clarify problem editing post closed years ago four functions seem really similar situations might give result help will thankfully appreciated now know assume internally factorize labelencoder work way big differences terms results sure whether will take similar time large magnitudes data get dummies onehotencoder will yield result onehotencoder can handle numbers get dummies will take kinds input get dummies will generate new column names automatically column input onehotencoder will rather will assign new column names get dummies better respectives please correct wrong thank four encoders can split two categories main difference pandas scikit learn encoders scikit learn encoders made used scikit learn pipelines fit transform methods pandas factorize scikit learn labelencoder belong first category can used create categorical variables example transform characters numbers pandas get dummies scikit learn onehotencoder belong second category can used create binary variables onehotencoder can used categorical integers get dummies can used type variablesalso written detailed post based place computation preserve memory consumption currently know can safely use place batchnorm scale relu layers please let knowwrong seems issues layers issue seems example use place layers caffe work back propagation noted place layers donusually work box layers quite trivial relu neuron activation layers however others requires special handling code example implementation prelu layer specific cache bottom memory member variable stores information needed backprop can see similar code layers specifically test top bottom see layer used place case moreover makes little sense place layer input output different shapes thus layers convolution innerproduct pool considered candidates place layers came across problem comparing predictions model labels training set arraysusing shapes training set validation set test set however checking accuracy functiongivingusers arslan anaconda lib site packages ipykernel deprecationwarning elementwise comparison failed will raise error future gives accuracy datasets think compare arrays using compare arrays right way instead assume error occurs expression can tellsomething arrays predictions labels usual stuff dtype shape sample values maybeextra step show numpy can compare arrays size become pickier comparing arrays donmatch size error telling comparissonperforming doesnreally make sense since arrays different shapes hence canperform elementwise comparissonexample attemptingy will yield deprecationwarning elementwise comparison failed will raise error futurey right way use checks equality shape elements case floats since allows control relative absolute tolerance comparisson resultexample solved upgrading python latest using scikit learn gaussian process regression gpr operation predict data training data follows test pointsmean variance standard deviation need predicted now running gpr gausianprocessregressor fit product constantkernel rbf used kernel gaussianprocessregressor mean variance standard deviation can predicted following line code printing predicted meanpred test variance sigma get following output printed console predicted values mean nested array three objects inside inner array printed can presumed inner arrays predicted mean values data sourcetest point locations however printed variance contains single array objects perhaps test location points know variance provides indication uncertainty estimation hence expecting predicted variance data source test point expectation wrong can get predicted variance data source test points due wrong code inadvertently hit iceberg letmake clear concepts variance standard deviation defined scalar variables vector variables likeoutput concept variance longer meaningful covariance matrix used instead wikipedia wolfram continuing prelude shape sigma indeed expected according scikit learn docs predict method returnsmean array shapesamplesoutput dims mean predictive distribution query pointsstd array shapesamples optional standard deviation predictive distribution query points returned return std truecov array shapesamplessamples optional covariance joint predictive distribution query points returned return cov true combined previous remark covariance matrix first choice try predict function argument return cov true instead since asking variance vector variable meaningless will leadmatrix insteadone expected shape covariance matrix output variables clarified details letproceed essence issue heart issue lies something rarely mentioned even hinted practice relevant tutorials gaussian process regression multiple outputs highly non trivial still field active research arguably scikit learn really handle case despite fact will superficially appear without issuing least relevant warning letlook corroboration claim recent scientific literature gaussian process regression multiple response variables quoting emphasis mine gpr implementations model single response variable due difficulty formulation covariance function correlated multiple response variables describes correlation data points also correlation responses paper propose direct formulation covariance function multi response gpr based idea despite high uptake gpr various modelling tasks still exists outstanding issues gpr method particular interest paper need model multiple response variables traditionally one response variable treated gaussian process multiple responses modelled independently without considering correlation pragmatic straightforward approach taken many applications though ideal key modelling multi response gaussian processes formulation covariance function describes correlation data points also correlation responses remarks multi output gaussian process regression quoting emphasis original typical gps usually designed single output scenarios wherein output scalar however multi output problems arisen various fields suppose attempt approximateoutputstt one intuitive idea use single outputsogp approximate individually using associated training datattt see fig considering outputs correlated way modeling individually may result loss valuable information hence increasing diversity engineering applications embarking use multi outputmogp conceptually depicted figsurrogate modeling study mogp long history known multivariate krigingkriging geostatistic community mogp handles problems basic assumption outputs correlated way hence key issue mogp exploit output correlations outputs can leverage information one another order provide accurate predictions comparison modeling individually physics based covariance models gaussian processes multiple outputs quoting gaussian process analysis processes multiple outputs limited fact far fewer good classes covariance functions exist compared scalar single output case difficulty finding good covariance models multiple outputs can important practical consequences incorrect structure covariance matrix can significantly reduce efficiency uncertainty quantification process forecast efficiency kriging inferences therefore argue covariance model may play even profound rolekriging argument applies covariance structure inferred data typically case hence understanding said sckit learn really capable handling cases despite fact something like mentioned hinted documentation may interesting open relevant issue project page seems conclusion relevant thread crossvalidated thread regarding gpml matlab toolbox said apart reverting choice simply modeling output separately invalid choice long keep mind may throwing away useful information correlationoutput elements least one python toolbox seems capable modeling multiple output gps namely runlmc paper code documentation first parameter used sigmareferring standard deviation variance recall variance just standard deviation squaredeasier conceptualize using variance since variance defined euclidean distance data point mean set case setpoints think pointsplane variance just distance point mean standard deviation positive root variance case test points values standard deviation makes perfect sense since test point defined distance mean set want compute variance set points can summing variance point individually dividing number points subtracting mean squared positive root number will yield standard deviation set aside also means change set insertion deletion substitution standard deviation every point will change mean will recomputed accommodate new data iterative process fundamental force behindmeans clustering using word vec dataset roughly tokens looking word similarity part synonym extraction downstream task dongood sense many dimensions use word vec anyone good heuristic range dimensions consider based number tokens sentences typical interval say need leastachieve lowest accuracy pick lesser number dimensions will start lose properties high dimensional spaces training time big deal application stickdimensions gives nice features extreme accuracy can obtainedd word features wonimprove dramatically training will extremely slow know theoretical explanation strict bounds dimension selection high dimensional spaces might application independent explanation refer penningtonal figureaxis shows vector dimensionaxis shows accuracy obtained provide empirical justification argument think number dimensions word vec depends application empirical value can perform number dimensions reflects fitting dimensions common knowledge start one number check accuracy testing set versus training set bigger dimension size easier will overfit training set bad performance test tuning parameter required case high accuracy training set low accuracy testing set means dimension size big reducing might solve overfitting problem model categorical features data along continuous ones good absolutely bad idea hot encode category features find correlation labels along continuous creatures way calculate correlation coefficient without one hot encoding category variable cramersstatistic one method calculating correlation categorical variables can calculated follows following link helpful using pandas calculate crams coefficient matrix variables continuous values can categorize using cut pandas please note matrix deprecated pandas since verison use values instead found phik library quite useful calculating correlation categorical interval features also useful binning numerical features try phik documentation looking thing bigquery numeric features can use built corry function categorical features can calculate cardinality catcat max cardinality cat cardinality cat translates following sql higher number means lower correlation used following python script generate sql straightforward thing numpy new tensorflow deep leaning trying see loss decreases epochs rnn model created read dataset kaggle contains credit card fraud data trying classify transactions fraud fraud try run code keep getting error can anyone point wrong code also problem code possible thank advance shown code make sure number labels final classification layer equal number classes dataset invalidargumenterror see traceback logits labels must broadcastable logits size labels size shown question might suggest just two classes final classification layer actually need case classes dataset mistakenly used labels final classification layer therefore change activation softmax activation softmax say prediction labels incompatible shapes need change predictions computed get one per example minibatch error occurs mismatch count predicted class input copied code encountered error original code output classes case classes correcting classes count fixed little late party error cnn messed around different types cross entropy error resolved using sparce softmax cross entropy logits met similar problems using cnn problem occurs changed labels data type fine tune network decoder thing can see summary decoder parameters tied weights implementation nothing fine tuned returns question change implementation tied weights tied layer can still hold weights transposed weights encoder yes just way summary autoencoder model class tied dense layer slightly modifiedyears since question asked answer might still relevant function retrieves see custom layer weights selfselfadded collectionslayer parameters tweak implementation follows note excluding regularizers constraints simplicity want please refer got following error looked around something chosing input output layer script label input output set default architectureusing inceptionchanged scripts label use input layer name placeholder will work placeholder everyone getting errorguessing used architecture apart mobilenet error turns label change values solve mimii celio mentioned change scripts label line input layer input input layer mul change input dimensions input height input width use make changes label change input height input width change input width input mean input std input layer mul change input layer mul input output layer final result output evaluation time imagedaisy score sunflowers score dandelion score tulips score roses score info refer page add output layer final result parameter sorry late answer run python script retrained model can try one requirements retrained model directory python scipt save code call python codesee argument called final tensor name donpass argument will keep final result mul depending version using default way view input output names without actual training output files view graph tensorboard frozen case retrained file nice way outputting required files view tensorboard can start tensorboard view chrome viewing graph helps alot sincenoob area can run command lines options without changing codes setting input layer mul works however seems ignoring input size settings doesnmagic resize imageguess mul expecting got ohhh looking code input width input height normalize normalizegood also needed add labels write programs play board game variants sometimes basic strategy standard alpha beta pruning similar searches sometimes augmented usual approaches endgames openingsmostly played around chess variants comes time pick evaluation function use basic chess evaluation function however now writing program play completely new board game choose good even decent evaluation function main challenges pieces always board usual material function wonchange based position game played less thousand times humans donnecessarily play enough yet give insightconsidered mogo approach random games arenlikely terminate game details game played board fixed six pieces per side pieces certain movement rules interact certain ways piece ever captured goal game enough pieces certain special squares board goal computer program provide player competitive better current human players will start basics move harder stuff later basic agent testing framework matter approach take need start something really simple dumb best approach dumb agent random one generate possible moves select one random will serve starting point compare agents need strong framework comparison something takes various agents allows play number games returns matrix performance based results calculate fitness agent example function tournament agent agent agent will play games pair agent playing first second returns something like example use points win point draw scoring function end just summing everything find fitness table immediately tells agent best agent really different agent two important things set ready experiment evaluation functions letstart selecting features first need create terrible evaluation function mean function correctly identify important aspects win draw loss sounds obvious seen significant amount bots creators able correctly set aspects use human ingenuity find features game state first thing speak game expert ask access position expert even just created rules game minutes ago underestimate humanability search patters even playing couple games smart person can give ideas played mean can implement ideas use ideas features point really need know features affect game example features value pieces pieces mobility control important positions safety total number possible moves closeness finish coded features used separately see works best hurry discard features perform reasonable might helpful conjunction others ready experiment combinations building better evaluations combining weighting simple features couple standard approaches create uber function based various combinations features can linear evalfnfeatures coefficients can anything instantiate many agents absolutely random weights evaluation function use genetic algorithm play agains compare results using testing framework discard couple clear losers mutate couple winners continue process rough outline readuse back propagation idea neural networks back propagate error end game update weights network can read done backgammon written anything similar sorry shortness can work without evaluation function might sound insane person heard minimax alpha beta methods require evaluation one called monte carlo tree search monte carlo name suggests uses lot random random can use previous good agents game plays generate tree huge topic will give mine really high level explanation start root create frontier try expand expand something just randomlyleaf getting result leaf backpropagate result many many times collect statistics child current frontier select best one significant theory relates balance exploration exploitation good thing read uct upper confidence bound algorithm find candidates evaluation function like mobility possible moves minus opponentmobility try find optimal weight metric genetic algorithms seem work pretty optimizing weights evaluation function create population random weights fight limited depth turns replace losers random combinations winners shuffle repeat printing population average every generation let runsatisfied result see need adjust range metrics try appears optimal value one metric might outside initial range late edit accepted studied understood approach didnknow time something called differential evolution offspring created parents instead way avoids problem premature convergence towards average look supervised machine learning algorithm reinforcement learning check reinforcement learning board games think will give good directions look also check strategy acquisition game othello based reinforcement learning pdf link given rules game good payoff function can learned closely relatedgammon training neural network used select moves sides rather surprising finding substantial amount learning actually took place even zero initial knowledge experiments utilizing raw board encoding nobody understands game yetway can get decent evaluation function dontell standard alpha beta material count good even decent chess variants maybe losers chess exception try neural networks feedback similar machine learning algorithms usually suck tons training case probably available even donsuck cangain knowledge thinkway short understanding game best can starters leave unknowns random evaluation function just picture unknowns become better known courseshare info game get better ideas community understand want good static evaluation function use leaves min max tree best remember purpose static evaluation function provide rating good board computer playerboardboard must true board better computer likely eventually win board course static function ever completely correct boards say goal game enough pieces certain special squares board first stabboard simply count number pieces computer special squares can finesse without knowing specifics game impossible give better guesses gavegame rules sure stackoverflow users able come tons original ideas functions use various machine learning methods come evaluation functionlearning used projects gnubackgammon one example results definitely dependent game backgammon works really stochastic nature game rolling dice forces learner explore territory may want without crucial component will probably end evaluation function good others since material difference may applicable concept mobility important controlling certain area board usually better talk people play game find cluespreferable good evaluation function can also need tune search algorithm can search deeply possible sometimes actually concern since deep searcher medicore evaluation function can outplay shallow searches good evaluation function depends domain gnubackgammon plays expert game ply search example techniques can use improve quality search importantly transposition table cache search results sound forward pruning highly recommend looking slides also need careful choice algorithm known relation actual value standardfunctions will work properly valid evaluation function heuristic actual value consistently will guide decisions odd way one argue chess even though think standard points fine typically find capable required games like sokoban used minimum number box moves required get one box isolation current location goal locations accurate answer number required moves think pretty good heuristic since can never overestimate can pre calculated entire board summing score board just sum values current box location artificial life simulation wrote evolve pack hunting pack defense scoring system used guide evolution perform pruning gave creature one point born point energy consumed life gave one additional point used sum points generation determine likely reproduce case simply used proportion total points generation acquired wanted evolve creatures great evading scored getting points eaten also careful function hard goal hit trying evolve something want make sure solution space decent slope want guide evolution direction just declare victory happens randomly hit without knowing game hard pressed tell build function clear values something indicate win loss way estimating minimum cost close gap provide information happy try provide insight lots excellent books topic jacob take mindnescessarily true decent evaluation function even exists statement assume evaluation function low complexitym tryin use scikit learn cluster text documents whole find way around problems specific issues examples found illustrate clustering using scikit learnmeans clustering algorithm adopting examplemeans setting works principle howevermeans suitable since donknow number clusters read far please correct needed dbscan meanshift seem appropriate case scikit learn website provides examples cluster algorithm problem now dbscan meanshift get errors comprehend let alone solve minimal code follows documents already processed stopwords removed porter stemmer applied run code get following error instatiating dbscan calling fit clicking line dbscanthrows error noticed following line use lines directly code testing get error donreally knowcommand hence bombs correctly refers number documents curiosity removedx dbscansomething computing heavily seconds get another error short clue get dbscan working might missed general looks like sparse representations dbscan supported jan upgraded sklearn worked text implementation sklearn seems assume dealing finite vector space wants find dimensionality data set text data commonly represented sparse vectors now dimensionality input data probably isndata matrix sklearn implementations needs oneneed find different implementation maybe try implementation elki fast limitationneed spend time understanding similarity first dbscan must choose epsilon way makes sense data rule thumb domain specific therefore first need figure similarity threshold means two documents similar mean shift may actually need data vector space fixed dimensionalitytoxic comment text classification kaggle challenge classes threat severe toxic obscene insult identity hate toxic comment can multiple classesmulti label classification problem built basic neural network keras follows run line get accuracy epochs however accuracy good bit higher best kaggle submission makes thinkeither possibly overfittingmisusing kerasaccuracy seems bit hard overfitusing data validation split epochs accuracy just percentage time model gets class correct output correct output accuracy bit thought sort think accuracy metric just looking class model predicts highest confidence comparingground truth model outputs will compare class index obscene true value thinkhappening thanks help can offer multi label classification think correct use sigmoid activation binary crossentropy loss output sparse multi label meaning positive labels majority negative labels keras accuracy metric will overflatted correctly predicted negative labels remember correctly keras choose label highest probability instead binary classification threshold prediction actual labels accuracy can test hypothesis creating model always predicts negative label look accuracyindeed case may try different metric topcategorical accuracy another remote possibility can think training data labelssomehow leakedjust wild guess can refer keras metrics documentation see metrics available can also create custom metric make sure exactly expect wanted make sure neurite right accuracy computed note activation sigmoid running training will see custom acc always equal binary accuracy therefore custom acc now can refer keras code github see computed confirm neurite said actual labels accuracy see imagedatagenerator allows specify different styles data normalization samplewise center etc see examples specify one options need call fit method generator order allow generator compute statistics like mean image generator question prediction work specified data normalization training cansee framework even pass knowledge training set mean std deviation along predict allow normalize test data also donsee training code information stored image statistics needed normalization stored model can used prediction yes really huge downsideprovide standarization statistics easy method overcome issue assuming function normalizenormalizing image batch remember generator providing simple image array images batch shapeexamples batch image dims make generator normalization using might simply use gen norm normalize instead use standardize method generator element complete example cifar also issue solved using functionality imagedatagenerator used note possible reasonable small dataset like cifar otherwise solution proposed marcin sounds good reasonable using test datagen fitted training dataset will learn training datasets statistics will use statistics normalize testing keeping dataset tensorsqueue runners snippet works needs following improvements snippet several todo lines indicating needed question relevant starter information semantic segmentation problem example donuse tfrecord dataset format wonargue pros cons got interested extending keras supportmetadata needed keras internally turns tensor can easily turned tensor keras metadata calling input layer tensor param takes care initialization nowtrain inp keras model can developed training simple say train output tensor keras model can easily write custom training loop lines training keras style one features keras makes lucrative generalized training mechanism callback functions support tfrecords type training several changes need fit function can easily supported another flag parameter makes things messing keras features sample weight class weight used weigh sample weigh class compile keras creates placeholders placeholders also implicitly created targets needed case labels already fed tfrecord readers placeholders needs fed session run unnecessary cae taking account changes compile tfrecord fit tfrecord extension compile fit shares say code can used following way welcome improve code pull requests update now directly supported keras see following example tfrecords supported using external loss key lines constructing external loss example keras works applying small patchalso working improve support tfrecords following issue pull request finally possible use debugging information training data validation data shape follows think input shape first layer setup right set update using input shape got following error message even though model summary runs either change input shape use batch input shape discussion explains difference two keras detail issue found expanding dimensions input data fixed using feature map gives expected ndim found ndim full shape received none however need tell convfeature map add extra dimension input vector worked trying cluster multiple datasets urls around million find original typos url decided use levenshtein distance similarity metric along dbscan clustering algorithmmeans algorithms wonwork know number clusters facing problems using scikit learnimplementation dbscan snippet works small datasets format using since precomputing entire distance matrix takesn space time way much large datasets run many hours just ends taking memoryfigured needed way compute similarity fly hence tried method method ends giving error realize means trying convert inputs similarity function floats donwant far understand just needs function can take two arguments return float value can compare eps levenshtein distance stuck point know implementation details sklearndbscan find trying convert float neither better idea avoidn matrix computation please let know better faster way cluster many strings may overlooked scikit learn faq can making custom metric try elki instead sklearn tool know allows index accelerated dbscan metric includes levenshtein distance need add index database need choose distance index algorithm course use pyfunc distances ball trees sklearn performance really bad interpreter also dbscan sklearn much memory intensiveusing python scikit learn simple linear regression data obtained csv min max values showed yetgetting error valueerror input contains nan infinity value large dtype float remove error result true doesncontain infinites nan valuessolution editsneaked data easily checked following code snippet try imputing missing values like regression will run smoothly without problem short missing values data error message said edit perhaps easier straightforward approach check missing data right read data pandas impute data two lines oribuilt pipeline scikit learn two steps one construct features second randomforestclassifier can save pipeline look various steps various parameters set stepslike able examine feature importances resulting model possibleyes list identify step want check estimator instance returns can access model step directly wrote article general can find general pipeline can access named steps parameter will give transformer pipeline example pipeline access individual feature steps transformer get feature names will return list feature names tfidftransformer fine good doesnreally cover many use cases since normally want combine features take model example combine features using feature union subpipeline access featuresneed explicitly call named step order example gettingidf features internal pipelines kind headache doable usually use variation following snippet get code just treats sets pipelines feature unions tree performs dfs combining feature names goesalso need method operates individual transformations things like tfidfvectorizer get names scikit learn isnuniversal get feature names kind fudge different case attempt something reasonable useyhhx sinceyyworst casey independent thusyhanother way think observing random variabletaking value either gain informationdonlose edit let clarify information gain context decision trees actually mind first place came machine learning background assume classification problem given set instances labels discrete classes idea choosing attribute split node tree select feature splits class attribute two purest possible groups instances turn equivalent picking feature highest information gain since entropy split sum entropies branch weighted number instances branch now exist possible split class values will generate case even worse purity higher entropy splitting take simple example binary classification problem certain node positive instances negative ones total therefore entropy split now consider cases splits best case scenario current attribute splits instances perfectly negative imagine second attribute worst case possible one branches created doesnget instances rather instancesbranch happen example attribute constant across instances thus useless now somewhere two cases will see number cases like matter split instances always get positive gain information realize mathematical proofmathoverflow just thought actual example help note calculations according google first answer negative absolute worst possibility changezero want prooflook full proof mathoverflow like amro pointed now advice first level decision tree seems obvious never come negative however building first tree using information gain found negative gain third branching didnseem useful possible scrambled check math math fine part wrong first part base formula using answer level starting entropy wrong includes information datasets need make sure starting entropy determine entropy branch alone means starting entropy actually higher level one words calculatingmake sure using current dataset sure can information gain just change information entropy one state anotherexexex state change caneither direction can positive negative easy see example decision tree algorithms works like given node calculate information entropy independent variable can think like information entropy categorical discrete variables variance continuous variables variance course just square standard deviation instance looking predicting price based various criteria arbitrarily group data set two groups prices group prices groupgrouplowest close together course variance negative sum distances point mean square difference variance certainly can see relates information entropy information gain suppose arenpredicting price something else like whether visitor site will become registered user premium subscriber neither indepdendent variable discrete continuous like price cancalculate variance meaningful way information entropy used instead doubt close analogy varianceknow decision tree algorithms capable handling discrete continuous variables latter case algorithm will use variance splitting criterion rather usingevent calculate information entropy given node split data node entire data set root node every value every variable split calculategroups take weighted averagenext take split results lowest weighted averagecompare nodeobviously just single group weighted averagesplit lower nodesplit data node form branch stop node cansplit bottom sum heart decision tree algorithm criterion determine whether split nodeconstructed criterion whetherpositive negative geometric margin simply euclidean distance certaindata point hyperlane intuitive explanation functional margin note realize similar question asked understand functional margin svm however answer given explains equation meaning understood geometric margin simply euclidean distance certaindata point hyperlane donthink proper definition geometric margin believe confusing geometric margin just scaled version functional margin can think functional margin just testing function will tell whether particular point properly classified geometric margin functional margin scaledcheck formula can notice independently label result positive properly classified pointsg sig sig negative otherwise scalewill geometric margin geometric margin exists maximize margin need just sign need notion magnitude functional margin give number without reference cantell point actually far away close decision plane geometric margin telling point properly classified magnitude distance term unitsfunctional margin represents correctness confidence prediction magnitude vectort orthogonal hyperplane constant value time correctness functional margin always positive sinceb negativewxpositivefunctional margin negative sample divided wrong group confidence functional margin can change due two reasons samplex changes vectort orthogonal hyperplane scaled scalingb vectort orthogonal hyperplane remains time matter large magnitude can determine confident point grouped right side larger functional margin confident can say point classified correctly functional margin defined without keeping magnitude vectort orthogonal hyperplane define geometric margin mentioned functional margin normalized magnitudeget geometric margin training example constraint value geometric margin results samples scaling vectort orthogonal hyperplane geometric margin invariant rescaling parameter difference geometric margin functional margin edit introduction functional margin plays two roles intuit maximization geometric margin transform geometric margin maximization issue minimization magnitude vector orthogonal hyperplane since scaling parametersb can result nothing meaningful parameters scaled way functional margin can arbitrarily makeresults maximizing geometric margin can also rescale parameters make subject functional margin minimizecheck andrews lecture notes lecture svms notation changed make easier type without mathjax tex site letformalize notions functional geometric margins given training exampley define functional marginb respect training example gammawxnotefunctional margin large prediction confident correct needtb large positive number converselyfunctional margin large needtb large negative number moreoverwxprediction example correct check hence large functional margin represents confident correct prediction page lecture pdf linked materials page linked going unnecessary complications concept simple terms one can think relate functional geometric margin scikit learn pipline kerasregressor training pipline trying save disk using runtimeerror maximum recursion depth exceeded save pipeline disk struggled problem direct ways hack worked saved pipeline two files first file stored pickled object sklearn pipeline second one used store keras model model loaded back keras compatible pickle box can fix willing monkey patch issuecomment can also use scikeras library drop replacement kerasclassifier author scikerasrun clustering algorithm want evaluate result using silhouette score scikit learn scikit learn needs calculate distance matrix distances pairwise distancesmetric metric kwds due fact data ordermemoryresult memory can evaluate clustering result anyone know overcome problem set sample size parameter call silhouette score value smallerusing parameter will sample datapointscalculate silhouette score instead entire svm libraries tried libsvm cjlin libsvm farflabbergasted also heard svmlight tinysvm tried new players thanks comprehensive list svm libraries can foundused svmlight found stable fast good experience using recommend however think probably less documentation svmlight libsvm just papers thorsten joachims comments source code didnfind source hard follow general need read papers beforehand understand backgroundalso written purec matters new players new research mostly making svm optimisation algorithms efficient example using stochastic gradient descent svmsgd pegasos havenlooked implementations algorithmsresearch code wouldnexpect particularly easy followprimary concernanother monster list svm packages libraries svm applications best way get started read libsvm guide provided website also good starting video tutorial install libsvmfirst trainig classification task can foundgepwtnaqck good luck also just starting days pretty good results got still tuning also dlib quiet complete particular algorithms performing classification regression clustering sequence labeling anomaly detection feature ranking algorithms specialized computations shark shark modularlibrary design optimization adaptive systems provides methods linear nonlinear optimization particular evolutionary gradient based algorithms kernel based learning algorithms neural networks various machine learning techniques shark serves toolbox support real world applications research different domains computational intelligence machine learning sources compatible following platforms windows solaris macostensorflow machine learning cookbook author pre processing data uses fit transform function scikit learn get tfidf features text training author gives text data function separating train test true action must separate data first perform fit transform train transform test according documentation scikit learn fit used order learn vocabulary idf training set hand fit transform used order learn vocabulary idf return term document matrix transform transforms documents document term matrix training set need apply fit transform just fit transform essentially joins operations however testing set need transform testing instances remember training sets used learning purposes learning achieved fit testing set used order evaluate whether trained model can generalise new unseen data points details can refer article fittransformfit transform author gives text data separating train test function true action must separate data first perform tfidf fit transform train transform test consider already leaking information test set training set tend always follow rule pre processing first thing separate data create hold set talking text data make sure model trained vocabulary training set will deploy model real life will encounter words never seen validation test set keeping mind make sure new words test set part vocabulary model hence use fit transform training data transform test data think cross validation can use logic across folds thinking training word vec huge large scale datasize web crawl dump personally trainedimplementation googlenews dumpimac took hours train generate vectors impressed speed try python implementation though read somewhere generating vectors wiki dumpvector length takes days generate speed word vec need use distributed models type hardware need within days imacram one faster gensim pythonimplemention see word vec implementation support gpu training number opportunities create word vec models scale pointed candidate solutions distributed multi threaded gpu exhaustive list hopefully get ideas proceed distributed multi threading options number word vec gpu implementations exist given large dataset size limited gpu memory may consider clustering strategy number cuda implementations word vec varying degrees maturity support believe sparkml team recently got going prototype cublas based word vec implementation may want investigatetrained dataset using xgb classifier got error local worked colab also friends donproblem code donknow error got code guessreason happens class column start required since version easy way solve using labelencoder works version try run code try adding stratify train test split code downgrading worked also got warning message execution userwarning use label encoder xgbclassifier deprecated will removed future release using label encoder returns error multiclassevaluation label must num class num class found label erros comes new version xgboost uninstall current xgboost install xgboosty train must encoded newer update xgboost model training must use categorical transformation like label encoders apply xgboost model training training find confusion matrix must inverse transform predictedvalues shown use python version used colab helps just rolled back version example using standardscaler correct way apply test set yes right way small mistake code let break use standardscaler step inside pipeline scikit learn will internally job happens can described follows note usingytraintrain gridsearchcv will automatically split data training testing data happen internally use something like run code cally can access outcome grid search result object returned best score member provides access best score observed optimization procedure best params describes combination parameters achieved best results important edit want keep validation dataset original dataset use use quick answer methodology correct although answer good just like point subtleties best score best cross validation metric generalization performance model evaluate best found parameters generalize call score test setdone therefore needed start splitting data training test set fit grid searchtraintrain scoretesttest deep dive threefold split data training set validation set test set one way prevent overfitting parameters grid search hand gridsearchcv uses cross validation training set instead training validation set replace test set can verified references gridsearchcv introduction machine learning python cross validation evaluating estimator performancemy problem conceptually similar solving anagrams except canjust use dictionary lookup trying find plausible words rather real words createdgram model nowbased letters bunch text now given random sequence letters like permute likely sequence according transition probabilities thought need viterbi algorithm started look deeper viterbi algorithm optimizes sequence hidden random variables based observed output trying optimize output sequence known algorithm can read right track viterbijust seeing apply update added bounty ask insight problem analysis explaining efficient approach isnpossible heuristics approximations besides simulated annealing etc exercise wrote simple implementation markov chains matlab basically letter based probabilistic model generating words will need text train model use wonderful wizardproject gutenberg finally use model either sample random words sample words set lettersbunch examples generated letters markovchains along log probability word given model can see although none correct words still better just random sequence letters obviously using previous character generate next one enough still can easily extended sophisticated casesgram nice thing approach restricted one language can adapted simply feeding documents language choice consider setletters vertices graph add directed edges represent grams letter others weights correspond probabilities word path complete directed graph looking best least weighted word path uses letters visits vertices asymmetric traveling salesman problemnp complete donthinkgoing get easier usegrams biggerre likely find efficient algorithm letknow simulated annealing something like probably wayunderstand problem correctly searching permutations letters word one lowest product gram probabilities word long simply brute force combinationsfound stochastic optimization algorithms produce good results short time mathematical background done work algorithm simulated annealing think fit nicely problem pretty easy implement also stochastically markov chain starters make suregram table includes beginning word symbol find available transitions state filter include available letters pool choose randomly among using weighted probabilities find transitions next state filtering still available letters end letters pool reach state cantransitionback beginning try may actually find useful random available optionsrandom option massaging probabilities simply generating numbersay random words sorting likelihood choosing randomly among topperhaps gives relatively fine control whether words generate bag letters consistent seem geared determining correlation inputs outputs potentially noisy set training historical data qualitative perspective problem domains better targets neural networks opposed evolutionary algorithmsskimmed articles suggest using complementary fashion decent example use case deal machine learning problems typically two components model function class etcmethods fitting model optimizaiton algorithms neural networks model given layout setting weights neural net produces output exist canonical methods fitting neural nets backpropagation contrastive divergence etc however big point neural networks someone gave right weightsproblem evolutionary algorithms address second part fitting model canonical modelsevolutionary algorithms example evolutionary programming typically tries optimize programs particular type however eas essentially way finding right parameter values particular model usually write model parameters way crossover operation reasonable thing turncrank get reasonable setting parameters now example use evolutionary algorithms train neural networksuredone however critical bitrequire work crossover operation must reasonable thing taking part parameters one reasonable setting rest another reasonable settingoften end even better parameter setting timesused case ends something like simulated annealing confusing inefficient problems require intuition better suited anns example hand writing recognition train neural network huge amount input ratedone takes long time afterwards blackbox algorithm system can guess hand writing keep little brain use module many years something training quality ann complex problem can take monthsworst case luck evolutionary algorithms calculate adhoc solution spot sort hill climbing pattern also pointed another answer runtime ann can guess faster evolutionary algorithms can calculate however one must careful since ann just guessing might wrong evolutionary generically genetic algorithms neural networks can used similar objectives answers describe difference however one specific case evolutionary algorithms indicated neural networks solution space non differentiable indeed neural networks use gradient descent learn backpropagation similar algorithm calculation gradient relies derivatives needs continuous derivative space words can shift gradually progressively one solution next solution space non differentiableeither can choose solutionc nothing middle likesolutions impossible trying fit non differentiable function neural networks work side note discrete state space partially share issue common issue algorithms usually work done workaround issues example decision trees can work easily categorical variables models like svm difficulties generally require encoding categorical variables continuous values case evolutionary genetic algorithms perfect one even say god send since can jump one solution next without issue doncare solutions impossible gaps big small subset possible state space evolutionary algorithms can jump randomly far away close find appropriate solutions also worth mentioning evolutionary algorithms subject curse dimensionality much machine learning algorithm including neural networks might seem bit counter intuitive since convergence global maximum guaranteed procedure might seem slow evolve good solution practice selection procedure works fast converges good local maximum makes evolutionary algorithms versatile generic tool approach naively problem one tools deal either non differentiable functions discrete functions astronomically high dimensional datasets look neuro evolutioncurrent best methods neat hyperneat kenneth stanley genetic algorithms find genome sortgreat create genome neural network get reactive nature neural network rather just bunch static genesmany limits can learn takes time course neural topology evolved usual mutation crossover weights updated can back propagation also can train fitness function thus superior back propagation know output perfect learning complex behaviour systems know optimal strategies problemlearn behaviour didnanticipate often behaviour can alien although exactly rewarded fitness function thususing much time deriving fitness functions creating output sets backpropagationevolutionary algorithms eas slow rely unsupervised learning eas told solutions better others improve neural networks generally faster instance supervised learning know make solution better using gradient descent within function space certain parameters allows reach valid solution faster neural networks often used isnenough knowledge problem methods work terms problem domains compare artificial neural networks trained backpropagation evolutionary algorithm evolutionary algorithm deploys randomized beamsearch means evolutionary operators develop candidates tested compared fitness operators usually non deterministic can design can find candidates close proximity candidates away parameter space overcome problem getting stuck local optima however successapproach greatly depends model develop tradeoff high expression potential might overfit generality model might able express target function neural networks usually multilayered parameter space convex contains local optima gradient descent algorithms might get stuck gradient descent deterministic algorithm searches close proximityneural networks usually randomly initialised train many one model moreover know hidden node neural network defines hyperplane can design neural network fits problem techniques prevent neural networks overfitting neural networks might trained fast get reasonable results efford just try parameters theory neural network large enough able approximate every target function side makes prone overfitting evolutionary algorithms require make lot design choices get good results hardest probably model optimiseable search complex problem spaces manner define get good results quickly aes even can stay successful problem target function changing time tom mitchellmachine learning book tomrepresent manner training model neuronal netsmodel commonly throughout literature will find nns trained using backpropagation algorithm method attractive mathematicians requires can express error rate model using mathematical formula case situations know lots input output values function trying approximate problem can modeled mathematically minimization loss function can achieved thanks calculus mathematicians love neuronal nets also useful modeling systems try maximize minimize outcome formula difficult model mathematically instance neuronal net control muscles cyborg achieve running different time frame model establish much tension present muscle cyborgbody based input various sensors impossible provide training data eas allow training providing manner evaluation model example punish falling reward traveled distance across surface fixed timeframejust select models best sense first generations suck surprisingly hundred generations individuals achieve natural movements manage run without falling models may also capable dealing obstacles external physical forces data differing weights sample application important weights accounted estimating model comparing alternative modelsusing sklearn estimate models compare alternative hyperparameter choices unit test shows gridsearchcv apply sample weights estimate scores way sklearn use sample weight score models unit test produces output explanation since manually computing loss without weighting produces scoring gridsearchcv know sample weights used gridsearchcv takes scoring input can callable can see details change scoring function also pass scoring functionrelevant piece code page sake completeness edit fit params passed fit functions score functions parameters supposed passed scorer passed make scorer still doesnsolve issue since mean whole sample weight parameter passed log loss whereas part correspondstest time calculating loss passed sklearn support thing can hack way using sklearn understands dataframe keeps way means can exploit index dataframe see code see scoreuses indextrue find parts sample weight use sake completenesswhole code output code edit comment bellow says difference score sklearn score using solution originates way computing weighted average scores omit weighted average portion code two outputs match machine precision currently sklearn gridsearchcv classes inherit basesearchcv allow sample weight fit params using scoring correct sincepick best estimator via unweighted score notesy sample weightuse sample weights fit score two ways solve problems just pointing ongoing effort support important feature ways train word embedding yes can use yesways train word embedding provide core output one vector per word vectors useful arrangement vectors relative distances directions roughly correspond human ideas overall word relatedness even relatedness along certain salient semantic dimensions word vec incremental sparse training neural network repeatedly iterating training corpus glove works fit vectors model giant wordoccurrence matrix built corpus working corpus creating word vectors dimensionality devoting attention meta optimizations quality resulting word vectors will roughly similarseen someone confidently claim one definitely betteroften compared tweaked best case use one algorithm rough arbitrary defaultsfamiliar word vec impression word vectraining better scales larger vocabularies tweakable settings time might allow tuning trained word vectors specific application example using small versus large window parameter can strong effect whether wordnearest neighbors drop replacement words generally words used topics different downstream applications may prefer word vectors skew one way conversely proponents glove tout fairly without needing metaparameter optimization probably wouldnuse unless comparing play role downstream applications word vectors word vec predictive model trains trying predict target word given context cbow method context words target skip gram method uses trainable embedding weights map words corresponding embeddings used help model make predictions loss function training model related good modelpredictions model trains make better predictions will result better embeddings glove based matrix factorization techniques word context matrix first constructs large matrix wordscontextoccurrence information word rows count frequently matrix values see word context columns large corpus number contexts large since essentially combinatorial size factorize matrix yield lower dimensional wordfeatures matrix row now yields vector representation word general done minimizing reconstruction loss loss tries find lower dimensional representations can explain variance high dimensional data glove algorithms word representations can divided two main streams statistic based lda learning based word vec lda produces low dimensional word vectors singular value decomposition svdoccurrence matrix word vec employs three layer neural network center context word pair classification task word vectors just product amazing point word vec similar words located together vector space arithmetic operations word vectors can pose semantic syntactic relationships king man woman queen better good bad worse however lda maintain linear relationship vector space motivation glove force model learn linear relationship basedoccurreence matrix explicitly essentially glove log bilinear model weighted least squares objective obviously hybrid method uses machine learning based statistic matrix general difference glove word vec dive deduction procedure equations glove will find difference inherent intuition glove observes ratios word wordoccurrence probabilities potential encoding form meaning take example stanfordnlp global vectors word representation consideroccurrence probabilities target words ice steam various probe words vocabulary however word vec works pureoccurrence probabilities probability words surrounding target word context maximized practice speed training process word vec employs negative sampling substitute softmax fucntion sigmoid function operating real data noise data emplicitly results clustering words cone vector space gloveword vectors located discretely trying use hidden markov model hmm problemdifferent observed variables yti single hidden variabletime pointclarity letassume observed variables yti categorical yti conveys different information may different cardinalities illustrative example given figuregoal train transition emission prior probabilities hmm using baum welch algorithm observed variable sequences yti letsaywill initially hidden states read tutorials including famous rabiner paper went codes hmm software packages namely hmm toolbox matlab hmmpytk package python overall extensive web search resources find cover case single observed variabletime point increasingly makes think hmmsuitable situations multiple observed variables thanks edit paper situation depicted figure described dynamic naive bayes terms training estimation algorithms requires slight extension baum welch viterbi algorithms single variable hmm simplest way model remain generative makeconditionally independent givenleads trivial estimators relatively parameters fairly restrictive assumption casesbasically hmm form naive bayes classifier edit means timestep multivariate observationy treatij conditionally independent givenre effectively learning naive bayes classifier possible value hidden variableconditionally independent important dependencies unconditional distributioncan learned standardhmm also one commenter said treat concatenationijs single observation dimensionalityvariables beyond trivial will lead lot parametersneed way training data specifically need model generativelooking inferenced probably much better served conditional random field feature functions can far complex observations without restrictive assumptions independence found can achieved modelling system dynamic naive bayes classifier dnb slight extension ordinary single variable hmm can cater multi observation scenarios shown figure caution advised dnb still hidden state therefore regarded direct sequential expansion original naive bayes classifier naive algorithmname originates fact observed variables independent given hidden state variable similar hmm parameter estimations model can achieved via baum welchwhichever prefer name algorithm since emission distribution time step now productytiobserved variable yti forward backward joint variable equations need slightly modified described section paper aviles arriagaal thing looking called structured perceptron take look following slid page structure tensor using two time series identify hmm parameters hidden markov model identifiability via tensors good reference matlab provides tensor toolbox fyi working related problem feel free email want discuss private manner can try hidden semi markov model extension hmm allows state lasting multiple time periods paper proposed algorithm solve problemi currently two numpy arrays code written attempt build linear classification model features first adapted arrays tensorflow dataset tried fit svm model just returns error wrongsvm usage example throw error examples passed svm estimator need string ids can probably substitute back infer real valued columns input need pass dictionary picks right name column caseconceptually simpler just construct feature column error saysx pass dictionary input input sdcafprinttype int match expected type string working memory demanding cnn model task classification poses big limit batch size can use training one solution accumulate gradients training meaning weights model updated every single batch instead weights used several batches gradients batch accumulated averaged single weight update actionusing tensorflow backend keraspretty sure keras shelf function method achieve can done keras tensorflow model mentioned question shelf function method achieve keras tensorflow however can done writing custom optimizer keras main idea use flag determine whether update weights batch following implementation based github post alexeydevederkin accumulating adam optimizer can used following way example model processes samples every iteration batch size update weights happens accumulating batches accum iters actual batch size updating weights published open source tool automatically add gradient accumulation support keras models implemented runhelpbatch sizing issues using gradient accumulation models alloweduse large batch sizes limited gpu memory specifically allowedrunning neural networks large batch sizes using single gpu project available add single line code python script can add gradient accumulation support optimizer python package available pypi can installed using command pip install runai adding gradient accumulation support keras models extremely easy first import package code import create gradient accumulation optimizer two ways wrap existing keras optimizer can take keras optimizer whetherbuilt one sgd adam custom optimizer algorithm implementation add gradient accumulation support using next line optimizer optimizer steps number steps want accumulate gradients create gradient accumulation version built ins optimizers gradient accumulation versions built optimizers sgd adam available package can created using line create gradient accumulation version adam optimizer accumulate gradients steps steps information explanations examples available github addition open source tool published series articles towards data science medium explained issues using large batch sizes gradient accumulation can help solving issues works implemented links articles problem batch sizing limited gpu memory gradient accumulation help guide using gradient accumulation mechanism implemented letknow tool helped using gradient accumulation keras models give support help problems encounter using models convenient way inject changes existing optimizer usage reference training will faster rule applicable applications can provide reference paper notion comes aligning computationsonto physical processorsgpu since numberoften power using numberdifferent power leads poor performance can see mappingontopile slices size numbersaygotcan mapc mapped ontocan mapslicespp will responsibledue simd paradigm used gpus often called data parallelismthing time different data algorithmically speaking using larger mini batches allows reduce variance stochastic gradient updates taking average gradients mini batch turn allows take bigger step sizes means optimization algorithm will make progress faster however amount work done terms number gradient computations reach certain accuracy objective will mini batch sizevariance update direction will reduced factortheory allows take step sizestimes larger single step will take roughly accuracysteps sgd mini batch size tensorflow found evidence affirmation question closed github pooling generally donewindowsdifferent thing altogetherheardwhite paper training cifar intel researchers make claim general performance processors better batch size power see howeverunclear just big advantage may authors donprovide training duration datatrying convert old code using sklearn keras implementation since crucial maintain way operation want understandcorrectlyconverted code already howevertrouble super easy right however couldnfind analog svc classifier kerastried think correct means please help find alternative svc classifier sklearn keras thank making classifier need squared hinge regularizer get complete svm loss function can seen will also need break last layer add regularization parameter performing activation added code changes give output also hinge implemented keras binary classification working binary classification model use code understand article issues code feel free comment issue back github thread helped understand maybeideas directlyanswerregularizer kernel regularizer github link can use follow can use svm keras implementation suing scikeras scikit learn api wrapper keras first release may attached official documentation link hope will find answer descriptioni want color clusters color map made form dictionary leaf colortried following just want assign colors differently saw link color func tried using color mapleaf color dictionary got errorc wasnfunctioncreatedleaf color customize colors leaves associated particular clusters actual dataset colors mean somethingsteering away arbitrary color assignments donwant use color thresholdc actual data way clusters scipy repeats colors hence question can use leaf color dictionary customize color dendrogram clusters made github issuehierarchical clustering dendrogram maybe found still canfigure actually either use dendrogram output reconstruct dendrogram specified color dictionaryreformatleaf color dictionary link color func parameter also tried get subtrees dendrogram made described early little hidden docs link color func output two liner applying custom colormap cluster branches can replace rainbow cmap change number cluster want found hackish solution require use color threshold need use order obtain original coloring otherwise colors presentedlead solution however may enough information know set color palette order result main goals follows apply standardscaler continuous variables apply labelencoder onehotencoder categorical variables continuous variables need scaled time couple categorical variables also integer type applying standardscaler result undesired effects flip side standardscaler scale integer based categorical variables also want since continuous variables categorical ones mixed single pandas dataframerecommended workflow approach kind problem best example illustrate point kaggle bike sharing demand dataset season weather integer categorical variables check sklearn also using labelencoder onehotencoder checkout columntransformer scikit learnletsay access email account history received emails last yearsemails classified groups approach task creating neural network solution used spam detection basically classifying email either spam spam letassume email fetching already place need focus classification part main points hope get answered also resource recommendations existing implementations preferablywelcome thank edit insist word based vocabulary features count also add features based formatting colors fonts sizes used measures can found online papers even wikipediasimple calculations probably based features features need inputs number nodes hidden layer one output node inputs need normalized according current pre classified corpussplit two groups use one training group testing group never mixing maybe ratio train test groups similar spam nonspam ratios set neural network sounds likeset pretty use bayesian classification outlined couple essays paul graham classified history access make strong corpora feed bayesian algorithmprobably end quite effective result generally experience led believe neural networks will show mediocre performance best taskdefinitely recommend something bayesian chad birch suggests something toy problem exploring neural nets chad answersgotten far reasonablerespond update set using neural networks main aspect project testapproach work spam detection problem empirical test like canprove unsuitabilityprobably best learning bitactually donsee particularly good idea sort classification problem probably helpful way think universal function approximators idea fits together area classification spam filtering problem browsing intro text like pattern classification might helpful failing dead set seeing run just use generallibrary network issue going represent input data anyway best structure non obvious probably doesnmatter much inputs going number normalized measurements features corpus obvious counts spam words etc much less part can really play around expect poorly compared bayesian filters problems due nature problem like understand rational behind sparkonehotencoder dropping last category default example default onehotencoder will drop last category course behavior can changed question last category included default configurable via droplast makes vector entries sum one hence linearly dependent according doc keep column independents one hot encoder maps column category indices column binary vectors single one value per row indicates input category index example categories input value map output vector last category included default configurable via onehotencoder droplast makes vector entries sum one hence linearly dependent input value maps note different scikit learnonehotencoder keeps categories output vectors sparse update question focuses one problem editing post closed years agolooked around web seem find way use react native tensorflow donthinksupports react native least officially integration hope someone community found way can one use tensorflow react native project thanks contributor update now possible article explains using tensorflow native android development look native provides gpu accelerated execution supporting major modes tfjs usage also library react native tensorflow bridging tensorflow react native tensorflow inference library react native recently added support iosavailable android ios platforms get started perform library link ios will also need use cocoapods content performance limitations due nature react native bridge transferring large data native sideknown issues usage check librarydocumentation running sketch upon loading environment load trained dataset returned error object arrays loaded allow pickle false code already used google developers developing sketch rnn algorithm even run google colab past ran google colab worked seems working jupyter notebook expected output gave use allow pickle true one arguments code solved problem side just downgrade numpy problem due internal conflict believe just surfaced due change numpy load observe line error occurs references something like keras source code example line path becomes path boolean brief reading addition pickles security since pickles can contain arbitrary python code run something loaded possibly similar way sql injections performed updatingworking projecti interested test svm performance classify several individuals four groups classes using svmtrain libsvm function matlab able get three equations used classify individuals among groups based values equation scheme follows way get equations using svm functionr package svmuses one one strategy multiclass classification followed voting handle hierarchical setup probably need series binary classifiers manually like groupgroupwhatever left etc additionally basic svm function tune hyperparameters will typically want use wrapper like tunetrain excellent caret package anyway classify new individualsdonplug numbers equation manually rather use predict generic function methods different models like svm model objects like can also usually use generic functions plot summary example basic idea using linear svm tabulate actual class labelsmodel predictions extract feature weights svm model object feature selection etc can calculate manually dot product feature weights preprocessed feature vectors minus intercept offset rho preprocessed means possibly centered scaled kernel transformed using rbf svm etc equal calculated internallyworking classification problem need add different levels gaussian noise dataset classification experimentsalgorithms canclassify dataset unfortunately idea advise coding tips add gaussian noise can follow stepsreproducible example overall code without comments print statements save file back csvi looking nlp tag past couple hours confident miss anything please point question mean time though will describe trying common notion observed many posts semantic similarity difficult instance post accepted solution suggests following high level requirement utilizemeans clustering categorize text based semantic similarity need know whether approximate match instance exampleclassifying one category another course will backed similar sentences something like find related articles donrelated thinking need ultimately construct vector representations sentence sort like fingerprint exactly vector contain still open questiongrams something wordnet just individual stemmed words something else altogether thread fantastic job enumerating related techniques unfortunately stopped just post got wanted suggestions latest state art area latent semantic modeling usefulbasically just yet another application singular value decomposition svdlibc pretty niceimplementation approach oldie goodie even python binding form sparsesvd suggest try topic modelling framework latent dirichlet allocation lda idea documents case sentences might prove problem generated set latent hidden topics lda retrieves topics representing word clusters implementation lda python available part free gensim package try apply sentences runmeans output mnist dataset trying visualise using pyplot dataset cvs format row one image pixels want visualise pyplot opencv image format trying directly using working ideas approach assuming csv file format format mnist dataset availablecan visulize python matplotlib opencv can take pixels numpy array dtype uint unsigned bits integer shapeplot importing necessary packages reading mnist train dataset csv formatted pandas dataframe converting pandas dataframe numpy matrix first column contains label store separate array delete first column data matrix first row represents first imageimage stored pixels like want quick dirty solution simply get rough idea given input console without fancy libraries expects input shaped like float values either case can easily convert pixels output bit distorted get idea written tensorflow cnn already trained wish restore run samples unfortunately spitting valueerror variables save eval code can found save additionally must created graph variables assuming also creates variables model adding saver creation line work addition must pass newneed move creation sess inside block resulting function will something like simply least one note sincelong time ago yet currently accepted answer typically just finilizeing classfier problem output informative feature class returning label words happening can print words labels guys happening since using pandas read data another thing tried following form question get traceback traceback recent call last idea solve order get features highest coefficient values solve specifically linear svm first understand formulation svm sklearn differences multinomialnb reason informative feature class works multinomialnb output coef essentially log probability features given class hence size nclassfeatures due formulation naive bayes problem check documentation svm coef simple instead coef linear svmclassesclassesfeatures binary models fitted every possible class possess knowledge particular coefficientinterested alter function look like following work intended print labels topfeatures according coefficient vectorgetting correct output particular class depend assumptions aim output suggest reading multi class documentation within svm documentation get feelusing can get kind output though situation isnparticularly descriptive helpful interpret hopefully helps output project large amounts dataspread npy files holdingcontainingrecords labels record float labels float read tensorflow dataset documentation queues threads documentation canfigure best handle input training save model weights future predicting model pretty straight forward looks like way training neural net reading files one time random order using shuffled numpy array index file manually creating batch feed trainusing feed dict everything read inefficient somehow replace datasets queue threads said documentation help best way handle large amounts data tensorflow also reference data saved numpy file operation step utilities npy files indeed allocate whole array memoryrecommend convert numpy arrays tfrecords format use files training one efficient ways read large dataset tensorflow convert tfrecords complete example deals images can found read tfrecorddataset data manual can found use loc recommended methodsmay return view slices data frame may return copy can confuse pandas donuse loc end calling conditions series leads problem called chained indexing use loc however access conditions one step pandas longer confused can read along examples using loc will cause operation fail pandas documentation simple answer can often get away using loc simply typing examplealways get settingwithcopy warning code will little messier experience loc taken get head aroundbit annoying updating codereally super simple intuitive row index col indexer information see pandas documentation indexing selecting data want predict next frame greyscale video givenprevious frames using cnns rnns keras tutorials information regarding time series prediction keras use dimensional input network minen framesrowscolscurrently really unsure good approach problem ideas include using one lstm layers problemsure whethersuited take series images instead series scalars input wouldnmemory consumption explode okay use can use keras higher dimensions usingconvolution input stack previous video frames raises questions helpclassification prediction can stack layers way input network dimensionsx colsrows outputcolsrowspretty new cnns rnns keras appreciate hint right direction basically every approach advantages disadvantages letgo throught ones provided find best approach lstm among biggest advantages ability learn long term dependiencies patterns data designed order able analyse long sequences like sequential implementationinfeasible fit video data reason dense layers bad imagery data loads time spatial invariances must learnt topology completely suited catching efficient manner shifting video pixel right might completely change output network thing worth mention training lstm belived similiar finding equilibrium two rivalry processes finding good weights dense like output computations finding good inner memory dynamic processing sequences finding equilibrium might last really long time findedusually quite stable produces really good results convamong biggest advantages one may easily find ability catch spatial temporal invariances manner convimagery case make curse dimensionality much less harmful hand way convmight produce good results longer sequences way lack memory might make learning long sequence harder course one may use different approaches like timedistributed convusing timedistributed wrapper one may use pretrained convnet like architecture yet supported newest version keras marchone may see provided future mixture lstm convs belived better stacking convlstm course way solve problemmention one might usefullone thing also worth mention shape video data actuallyframes width height channelscase data actuallyframes width hieght actually use classic convchanging channels frames analyse data actually might computationally effective case transfer learning add additional dimension cnn models trained data shape width height one may notice data doesnchannels case technique usually used repeating spatial matrix three timesexampleapproach lots research finally stumbled upon keras example convlstmlayer already mentioned marcinejko exactly need current version keraslayer already included can imported using use layer video data formatted follows instance created operations fed batch data operation run operation ask next batch automatically fed tutorial codes rather confused load single batch get literally single batch size shape batch size height width num channels documentation says creates batches tensors tensors also read tutorial codeslim walkthrough tutorial function called load batch tensors returned images images raw labels batches data explained documentation thank help nothing happens automatically must call load new batch mean even without loop next batch automatically fed will always load batch size tensors example images batch size will batches can call batch three times input queue will start beginning stop epoch means miss samples training case want miss can allow smaller final batch true now willsample batchessample batch input queue will restart let also elaborate code sample need call made modification code eval image datasetdataprovider line way images accessed inference problem loading previously saved model save can see auditor model saved model directory now like load model get valueerror unable restore custom object typekeras metric currently please make sure layer implements get configand config saving addition please use custom objects arg calling load model read custom objects tensorflow docs donunderstand implement use custom layers predefined ones anyone give hint make work use tensorflow python example missing definitionprecision recall functions builtin metricsnote string fit usecase can pass custom objects follows custom metricwant evaluate model test data saving needscore test data can tryran brown clustering algorithm binary integer mean first link binary known bit string see understand correctly algorithm gives tree need truncate level get clusters case bit strings just take firstcharacters example cutting second character gives two clusters third character get cutting strategy different subject though percy liangimplementationparameter allows specify number word clusters output contains words corpus together bit string annotating cluster word frequency following format bit string word word frequency number distinct bit strings output equals number desired clusters words bit string belong cluster change running wcluster text default candistinguish different cluster words default input three sentences change clusters clusters can tell difference enter three tweets input give cluster parameter integers counts many times word seen document tested python implementation comments top python implementation instead using window brownal sec code computed pmi using probability two randomly selected clusters document willc also since total numbers cluster tokens pairs constant across pairs code use counts instead probabilities code python implementation see outputs word bit string word counts guess according figure brownal clustering hierarchical get root word leaf make decision can represent word bit string project large amounts dataspread npy files holdingcontainingrecords labels record float labels float read tensorflow dataset documentation queues threads documentation canfigure best handle input training save model weights future predicting model pretty straight forward looks like way training neural net reading files one time random order using shuffled numpy array index file manually creating batch feed trainusing feed dict everything read inefficient somehow replace datasets queue threads said documentation help best way handle large amounts data tensorflow also reference data saved numpy file operation step utilities npy files indeed allocate whole array memoryrecommend convert numpy arrays tfrecords format use files training one efficient ways read large dataset tensorflow convert tfrecords complete example deals images can found read tfrecorddataset data manual can found looking example spark site word vec interesting vector king man woman queen can use sure proceed example pyspark guess straightforward port scala key use train model exampledimensionality word vectors higher better default value will need memory highest numbermachine edit typical values relevant publications trained model can define simple function follows now examples countries capitals results always correctleave experiment get better training data increased vector dimensionalityloop function removes entries belong input query noticed frequently correct answer second one returned list first usually one input terms running result pseudo code full implementation read documentation findsynonyms int look nmf implementation python interface handles missing data zeros donwant impute missing values starting factorization want ignored minimized function seems neither scikit learn nimfa graphlab mahout propose option thanks using matlab python code conversion sheet able rewrite nmf matlab toolbox library decomposexmatrix sparsity using latent features machine took minutes iteration method using scipy sparse matrix input missing values converted using toarray method therefore mask created using function however nan values get results using function scipy method solve non negative least squares problem nnls answer reproducing blogpost using scipynnls non negative matrix factorisation may also interested blog posts use autograd tensorflow cvxpy nnmf solution consists two steps first fixlearngiven next fixlearngiven repeat procedure iteratively fixing one variable learning setting popularly known alternating least squares problem reduced least squares problem however important thing note since want constrainth non negativennls instead least squares using illustration can learn columnusing corresponding column matrixproblem collaborative filtering usually user item matrix lot missing entries missing entries correspond user rated items can modify formulation account missing entries considerm entries observed data now modify equation mask found consideringentries however since missing entries define cost terms entries present letjust try see cost initial set valuesh randomly assigned letview values masked entries decently fast simple solution based gradient descent quasi newton method right way use tensorflow real time predictions high traffic application ideally server cluster running tensorflow listening portcan connect app servers get predictions similar way databases used training done cron jobs feeding training data network server cluster one actually use tensorflow production build setup python running server use python scripts get predictionsstill new feel script will need open sessions etc scalabletalkingpredictions sec pointer relevant information will highly appreciated find morning colleagues released tensorflow serving github addresses use cases mentioned distributed wrapper tensorflow designed support high performance serving multiple models supports bulk processing interactive requests app servers information see basic advanced use loc recommended methodsmay return view slices data frame may return copy can confuse pandas donuse loc end calling conditions series leads problem called chained indexing use loc however access conditions one step pandas longer confused can read along examples using loc will cause operation fail pandas documentation simple answer can often get away using loc simply typing examplealways get settingwithcopy warning code will little messier experience loc taken get head aroundbit annoying updating codereally super simple intuitive row index col indexer information see pandas documentation indexing selecting classfier problem output informative feature class returning label words happening can print words labels guys happening since using pandas read data another thing tried following form question get traceback traceback recent call last idea solve order get features highest coefficient values solve specifically linear svm first understand formulation svm sklearn differences multinomialnb reason informative feature class works multinomialnb output coef essentially log probability features given class hence size nclassfeatures due formulation naive bayes problem check documentation svm coef simple instead coef linear svmclassesclassesfeatures binary models fitted every possible class possess knowledge particular coefficientinterested alter function look like following work intended print labels topfeatures according coefficient vectorgetting correct output particular class depend assumptions aim output suggest reading multi class documentation within svm documentation get feelusing can get kind output though situation isnparticularly descriptive helpful interpret hopefully helps output written tensorflow cnn already trained wish restore run samples unfortunately spitting valueerror variables save eval code can found save additionally must created graph variables assuming also creates variables model adding saver creation line work addition must pass newneed move creation sess inside block resulting function will something like simply least one note sincelong time ago yet currently accepted answer typically just finilizeingallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years agolooking implementations hidden markov modelslately wondering use existing hmm libraries writtenuse action recognition opencvtying avoidinventing wheel possible use torch vision even though looks like designed work speech recognition idea can convert feature vectors symbols observations using vector quantization kmeans clustering can use symbols decoding inference parameter learning baum welch algorithm way work torch vision opencv help will truly appreciated can take look hmmhard implement algorithmsbased version can take look implementationdone google summer code project also implementation wrote several days ago class discrete hmm using opencv may take look can convert feature vector one label use sequence labels train discrete places colors names objective train model take new input string predict category belongs example new input purple able predict colors correct category new input calgary predict places correct category approach research came across word vec library similarity mostsimilarity function can use one brute force approach thought following instance input pink can calculate similarity words vector names take average vectors also vector gives highest similarity average correct vector input belong issue given limited knowledge nlp machine learning sure best approach hence looking help suggestions better approaches solve problem open suggestions also please point mistakes may made new machine learning nlp worldlooking simplest fastest solutionsuggest take pre trained word embeddings word vec glove just build simple query system top vectors trained huge corpus likely contain good enough approximation domain datasolution order rundownload unpack pre trained glove data carefulupon running produce something like looks pretty reasonabledonneed big model can filter words glove accordingidf score remember model size depends data words might want able query also worth pytorch good faster implementation glove adding new classes model example trained coco dataset model classes like add classes existing one get one class object detection model result running locally provided repository completely replacing pre trained classes newly trained classes train eval mentioned way retrain model get classes result question add classes already trained network specifically want keep network output new classes means something like resnet want keep everything last layer frozen somehow expand last layer new classes answer combine existing last layer new one train specifically will replace last layer fully connected layer large enough new classes old ones initialize random weights train classes just others training copy original weights original last fully connected layer new trained fully connected layer example previous last layermatrix new last layermatrix copycorresponding space newwill destructively replace training old classes pre trained values leave training new classes good probably didntrain number old classes thing bias final network willnew weight values plus bias corresponding new classes word caution although will train fast provide quick results will perform retraining full comprehensive data set saidstill work reference replace last layer remove last layer trained model tensorflow someone else answeredi csv file contains average temperature almost years decomposition using seasonal decompose function got following results indeed results show seasonal however see clear sin trend wondering can correct thank looks like freq according question stackoverflow dataframes better newer rdds used whenever possible problem want use common machine learning algorithmsg frequent pattern mining naive bayes etc dataframes donprovide methods rdds provides algorithms dataframes better rdds referred guide recommends use arencommon machine learning methods implemented lib spark currently spark moves strongly towards dataframe api ongoing deprecation rdd api number nativealgorithms growing main points highlighted still valid internally many stages implemented directly using rdds see also switch rdd based mllib apis maintenance mode spark spark guess main missing pointoperate dataframes practice matterwrapper anything else even nativeimplementation like implement everything scratch top dataframes likely small subset machine learning algorithms can actually benefit optimizations currently implemented catalyst mention efficiently naturally implemented using dataframe api sql one problem dataframes really related machine learning decide use dataframe code give away almost benefits static typing type inference highly subjective consider problem one thing sure doesnfeel natural scala world regarding better newer faster take look deep dive spark sqlcatalyst optimizer particular part related quasiquotes following figure shows quasiquotes letgenerate code performance similar hand tuned programs changed spark still limited default hashpartitioningi curious tensorflow implementation call one simply runs howevergoing rabbit hole trying see executed code follows arrow indicates function ultimately calls familiar tensorflowimplementation lstms ability easily manipulate one deems fit function performs convcalculation written python can see strides executeddr implementation writteninvokes optimized code using either eigen cpu cudnn library gpu can find implementation chain functions mentioned question python functions building tensorflow graph invoke implementation recall tensorflow first build symbolic graph execute implementation executed happens call passing tensor whose value depends result convolution example invoking tells tensorflow run ops neeeded compute value conv including convolution path implementation somewhat complicated goes following steps convopkernel implemented compute methodperformance critical many workloads implementation quite complicated basic idea computation offloaded either eigen tensor library running cpu cudnnoptimized gpu implementation tensorflow programs consisting two discrete sectionsdef convregistergraph sess target convmaster prune full graph client graph master split client graph task graph partition register graph partition worker worker split subgraph device graph partition master notify workers run graph partitions worker notify devices run graph partitions executor will run ops topological sort device oneexecutor will invoke kernel implement computekernel implement writteninvokes optimized code using either eigen cpu cudnn library gpu currently working small binary classification project using new keras api tensorflow problem simplified version higgs boson challenge posted first elements row form input vectorelement corresponding label sample said dataset relatively new machine learning tensorflow familiar higher level concepts loss functions optimizers activation functions tried building various models inspired examples binary classification problems found online difficulties training model training loss somethimes increases within epoch leading unstable learning accuracy hits plateau around tried changing learning rate hyperparameters avail comparison hardcoded fully connected feed forward neural net reaches around accuracy problem current model mentionned epochs start higher accuracy finish leading unstable learning cause oscillations learning simple model thanks edit followed suggestions comments modified model accordingly now looks like definitely connected size network batch coming changes neural network considerably enough neurons represent relationships works fine one batch updates weights another changes previously learned connections effectively unlearningloss also jumpy network tries accommodate task given sigmoid activationsaturation may causing troubles gradient squashed small region gradient updates zero quick fix use relu activation described additionally neural network care accuracy minimizing loss value tries time say predicts probabilities classesaccuracypretty uncertain now letsay next update pushes network probabilities predictions case loss drop accuracy btw may want check scores logistic regression see performs task single layer outputalways good start simple model grow bigger needed wouldnadvise way around may want check really small subsample data say two three batches elements whether model can learn relationship input output case doubt model will able learn relationships size layers providing try increasing size especially earlier layers maybe starters see behaves sigmoid easily saturates small region changes occur values almost rarely used nowadays activation bottleneck final layer common nowadays relu prone saturation least input positivevariations might help dataset neural network model optimal choice learning rate different defaults usually work learning rate small might get stuck local minimageneralization will worse value big will make network unstable loss will highly oscillate may want read cyclical learning rate original research paper lesliesmith can find info choose good learning rate heuristically setup simple learning rate schedulers techniques used based work aforementioned researcher get started realm think sure normalization looks pretty non standard never seen done like good normalization basis neural network convergence unless data already pretty close normal distribution usually one subtracts mean divides standard deviation feature can check schemes scikit learn library example shouldnissue input complicated consider adding layers neural network right nowalmost definitely thin allow learn abstract features transform input space network overfits data may employ regularization techniques hard tell might help test include plus tons techniques may find check makes intuitive sense one like test performs trained siamese network realised use higher learning rates training loss going smooth expected since neural network learning saw huge ups downs val loss never happened using lower learning rate orderbelieve train loss actually false since recent papers proved large neural networks mean neural networks complexity can learn random data flawlessly training set though performed extremely worse validating attached paper reference clearly explains phenomena related overfitting one canconclude overall modelperformance just observing training data though parameters mentioned also matter guess one start tweaking learning rates initially case tweaking model link paperpoints great another possible cause shuffling dataset data contains ordered bias model may tuning one end dataset poorly end trying use keras make neural network data using hydrodynamics code follows tried usingy accuracy model appears remain new keras probably easy solution apologies advance question best way add regression model accuracy increases thanks advance first split dataset training set test set using train test split class scale values using standardscaler class add layers order get better results note usuallygood practice apply following formula order find total number hidden layers needed classifier becomes metric use metrics accuracy corresponds classification problem want regression remove metrics accuracy just use list keras metrics regression classification also define batch size epochs values fit method trained network can predict resultstest using can comparepred obtained neural network predictiontest real data can create plot using matplotlib library seems neural network learns good plot looks full codeilike use silhouette score script automatically compute number clustersmeans clustering sklearn someone can help question marks donunderstand put instead question marks taken code example commented part previous versionemeans clustering fixed number clusters set code way correct project need automatically chose number clusters assuming going silhouette score get optimal clusters first declare seperate object kmeans callfit predict functions datalike see official example clarity data set data frame applyingmeans thank using multi dimensional svm classifier wrapper libsvm classify set features given svm model possible incorporate new training data without recalculate previous data guess another way putting svm mutable actuallyusually called incremental learning question come pretty answered implementation details support vector machine svm briefpossible easy change library using implement training algorithm found two possible solutions svmheavy lasvm supports incremental training havenused either donknow anything online incremental although similar differ slightly online generally single pass epoch number epochs configured incremental mean already model matter built model can mutable new examples also combination online incremental often required list tools remarks online incremental svmusing example ones parallel join output code right now looks follows results following want able specify pipeline looks follows implemented recently master branch scikit learn name featureunion feature unionkeraskilled bunch useful metrics need use copied functions old included follows results wrong cansee anythingwrong according keras documentation edit full traceback traceback seems problem occurs try load saved model take look issue suggestion implement metrics keras callback can achieve thing metrics can also provide model saving strategy can add callback tested code python tensorflow keras worked think error due python usage output background reference manual gbm package statesh statistic assess strength variable interactionsstatistic scale reference manual dismo package reference literature boosted regression trees ecological modeling states dismo package extends functions gbm package question dismo asking question gbm package reference manual says possible checked difference two approaches boils partial dependence function two predictors estimated dismo package based code originally given elithal can find original source supplementary material paper briefly describes procedure basically model predictions obtained grid two predictors setting predictors means model predictions regressed onto grid mean squared errors model multiplied statistic indicates departures model predictions linear combination predictors indicating possible interaction dismo package can also obtain relevant source code copied directly source prediction prediction original gbm fitted model two predictors consideration set means different friedmanh statistic friedman popescue estimated via formula pair predictors essentially departure additivity two predictors averaging values variables setting variables means expressed percent total variance partial dependence function two variables model implied predictions will always looking library learning inference bayesian networks already found hoping recommendation requirements quick overview one recommend look wekakind popular neckopen source written java will tell bayesian networks weka abstract give subjective answer experience everything related statistics best solvedseen often fields related statisticslibraries often state art algorithms methods implemented programmers like like stay languages know learning something new trade mainlytime consuming learning new language viable optiongood choice opinion best take brief looklibraries related bayesian networks bayesian interference baysian easy install library rweka help format style libraries knows easy switch one library nexteasy test available libraries use one fits best never used perhaps mallet library fits bill can someone please tell use ensembles sklearn using partial fit donwant retrain model alternatively can pass pre trained models ensembling seen voting classifier example support training using partial fit mlxtend library implementation votingensemble allows pass pre fitted models example three pre trained models clf clf clf following code work set false fit base estimators argument ensemblevoteclassifier ensures classifiers refit general looking advanced technical features sci kit learn provide look mlxtend first point reference workaround votingclassifier checks estimators set order understand whether fitted using estimators estimators list prediction pre trained classifiers can put estimators directly like code however also using labelenconder assumes labels like also need setclasses see unfortunately currently possible scikit votingclassifier can use votingclassifer implemented try implement voting classifier can take pre fitted models also can look source code modify usehard implement votingimplementation mlxtend library implementation works still need call fit function ensemblevoteclassifier seems fit function doesnreally modify parameters rather checking possible label values example give array contains possible values appear originalcasematter totally upto will achieve results less way write code differs instance using code official documentation hand using subclassing will create class like example code take blog post can see transformermixin gives flexibility compared functiontransformer regard transform function can apply multiple trasnformations partial transformation depending value etc example can like first values want log next values wish take inverse log can easily define transform method deal data selectively just want directly use function use else want modification say complex transformations suggest subclassing take look following links get better idea key difference functiontransformer subclass transformermixin latter possibility custom transformer can learn applying fit method transform method attributes used transformation achieved simple functiontransformer least canonical way pass train set somehow possibility learn fact reason use custom transformers pipelines just apply ordinary function usage functiontransformer nothing gained cross validation process makes difference whether transform cross validation step cross validation except latter will take time doubt looking answers question use will train test modelfeatureslabel get accuracy score now doubt happens predict label new set data say normalize column valueswill changed according new data data model will trained now data data preparation step will valueswill change respect max min valueb data prepb respect min maxb can data preparation valid respect different numbers relate donunderstand prediction will correct summary example using data example using iris data hope helps see also postrequired saving model loading saved model going book familiar following training instance backpropagation algorithm first makes prediction forward pass measures error goes layer reverse measure error contribution connection reverse pass finally slightly tweaks connection weights reduce error however sure differs reverse mode autodiff implementation tensorflow far know reverse mode autodiff first goes graph forward direction second pass computes partial derivatives outputs respect inputs similar propagation algorithm backpropagation differ reverse mode autodiff thanks answer david parks valid contribution useful links however found answer question author book may provide concise answer bakpropagation refers whole process training artificial neural network using multiple backpropagation steps computes gradients uses perform gradient descent step contrast reverse mode auto diff simply technique used compute gradients efficiently happens used backpropagation important distinction backpropagation reverse modereverse modecomputes vector jacobian product vector valued functionnm backpropagation computes gradient scalar valued functionnbackpropagation therefore subset reverse modetrain neural networks always scalar valued loss function always using backpropagation since backprop subset reverse modealso using reverse modetrain neural network whether backpropagation takes general definition reverse modeapplied scalar loss function specific definition reverse modeapplied scalar loss function training neural networks matter personal tasteword slightly different meaning different contexts commonly used machine learning community talk computing gradients neural network parameters using scalar loss function completeness sometimes reverse modecan compute full jacobian single reverse pass just vector jacobian product also vector jacobian product scalar function vector vector gradient automatic differentiation differs method taught standard calculus classes gradients computed features native ability take gradient data structure just defined mathematical functionexpert enoughdetail great reference explains much depthanother guide looks quite nice just found now leastoriginally derivedtaught classes subject practice backprop used quite interchangeably automatic differentiation approach described guides splitting two terms probably much effort linguistics mathematics also noted nice article backpropagation algorithm compare guides automatic differentiation set trajectories may different lengths wish cluster actually path just seem different due noise addition lengths maybe although trajectory trajectoryyet part trajectorywish present property clustering bit knowledgemeans clustering fuzzymeans clustering may choose two adopt methods method takes belongness consideration clustersc one particular trajectorybelongs cluster shorter trajectoryalthough clustered identified part trajectoryupdate aforementioned trajectories pedestrians trajectories can either presented seriesy points series step vectors length direction presentation form control might little late also working problem suggest take look traclus algorithm created jae gil lee jiawei han kyu young wang published sigmod hanj pdf sigmod basically phase approach phase one partition divide trajectories segments done using mdl optimization complexitynnumbers points given trajectory input set trajectories output set segments phase two group phase discovers clusters using version density based clustering like dbscan input phase set segments obtained phase one parameters constitutes neighborhood minimum amount lines can constitute cluster output set clusters clustering done segments define distance measure made components parallel distance perpendicular distance angular distance phase complexityn logn number segments finally calculate cluster representative trajectory nothing else discovered common sub trajectory cluster pretty cool examples paper explained algorithm donforget cite researchmade slides based work just educational purposes especially trajectories can different lengths define metric can use clustering algorithm allows custom metric probably know correct number clusters beforehand hierarchical clustering good optionmeans doesnallow custom metric modificationsmeans likemedoids hard part defining distance two trajectories time series common approach dtw dynamic time warping improve performance can approximate trajectory smaller amount points many algorithms neither will work proper mean look distance based clustering methods hierarchical clustering small data sets probably donthousands trajectories dbscan need choose appropriate distance function allows dtw distance can accomodate good concept possibility real time applications view one can adopt clustering need select appropriate dissimilarity measure later need think computational complexity paper used hausdorff suggest technique reducing complexity paper described use trajectory clustering technique based multi view similarity compare column names different pandas data frame want compare train test data frames columns missing test data frames including dataframe columns useful set like methods intersection difference example given dataframes train test wanted save multiple models experiment noticed constructor save models simple code ran code saw models desktop can save models constructor constructor takes optional argument called max keep defaults keeping recent checkpoints model save models simply specify value argument keep checkpoints pass argument max keep none saver constructor order keep intermediate checkpoints last need change parameters following will store checkpoint every hours total number saved checkpoints reaches oldest checkpoint will deleted new one will replace use saving checkpoint done estimatorneed pass following parameters following will store checkpoint every iterations total number saved checkpoints reaches oldest checkpoint will deleted new one will replace default method variable initialization used called without specification initializer docs just says none documentation initializer none default default initializer passed variable scope will used one none glorot uniform initializer will used glorot uniform initializer function initializes values uniform distribution function documented glorot uniform initializer also called xavier uniform initializer draws samples uniform distribution within limit limit limit sqrt fan fan fan number input units weight tensor fan number output units weight tensor referenceusing opencvhar cascade face detector python example will print list detections form line represent detection first numbersy location top left point height width bounding box last number quoting opencv documentation number neighbors guess two questions last number mean couldnfind reference googling important way get confidence score detection much face classifier certain detection corresponds real face thanks detection code produces one detection object slightly shifted etc detections grouped number neighbours group number returned see also viola jones paper paragraph opencv source can possibly use number neighbours measure confidence thanks lot question answer looking opencv face detection confidence scores day question answer give guidance solve problem like palmstrom said last number means number object positions cluster can use confidence score far know kind api old python api new api number object cluster value put code case will help people old python api whose tutorial hard findtrying learn baum welch algorithm used hidden markov model understand basic theory forward backward models nice someone help explain code find easier read code can play around understand checked github bitbucket didnfind anything easily understandable many hmm tutorials net probabilities either already provided case spell checkers add occurrences words make models cool someone examples creating baum welch model observations example concrete example just example think example explains can play good understand better great specific problem trying solve thinking maybe valuable show code people can learn apply problems acceptable can post problem possible though nice python java thanks advancecode wrote several years ago class based presentation jurafsky martinedition chapter access bookreally good code doesnuse numpy absolutely crap arrays indexed instead just tweaking formulae indexed maybehelp baum welch referred forward backward code example test data based jason eisnerspreadsheet implements hmm related algorithms note implemented version model uses absorbing end state states transition probabilities rather assuming pre existing fixed sequence length also available gist prefer half testing code based following files sequence observations testing model used generate datai trying make prediction using tensorflow object detection api google colab already successfully completed training process export inference graph task problem going make new predictionthrowing error log connectserver now unable make new prediction portion error log can figure reason problemserver programwindow system runs local machines handles access graphics cards display screens input devices typically keyboard mouse computers said colab runs terminal instance server using gpu runtime problemserver accessing graphics card neither input devices generally occurs try parse data displayed separate window desktop commands like can similar functions can cause problem use graphical ouput might want look matplotlib notebook displaying data interactable matplot plots issue just post link modified code might able help problem colab simple opencv program track tennis ball tennis match video comment lines mentioned anand note lines clustered spread apart fix issue using python code google colab noteilooked algorithms intelligent web describes page interesting algorithm called docrank creating pagerank like score business documentsword documents short analyzes term frequency intersection document collection can anyone else identify interesting algorithms described elsewhere wants share something novel apply types documents improve search results please forgo answers involving things like click tracking actions analyzing actual documents first technique step wise similarity can offer one exampleactually tested validated real data gather number techniques rank along two axes inherent complexity ease implementation performance resolution predictive accuracy technique high first axis somewhere near middle second simple effective technique might underperform state art techniques found combination low frequency keyword intersection combined similarity among readers viewers document fairly strong predictor documentcontent put another way two documents similar set low frequency terms domain specific terms like decision manifold etc similar inbound traffic profiles combination strongly probative similarity documents relevant details first filter low frequency terms parsed large set documents get term frequency used word frequency spectrum fingerprint common applied inverse weighting common terms counted little similarity measure whereas rare terms counted lot quite common probably know trying determine whether two documents similar based along problematic instance two documents might share list rare terms relating mmos still documents werensimilar one directed playing mmos designing second filter readers obviously donknow read documents inferred readership traffic sources can see helped example inbound traffic mmo player site document reflected content likewise document directed mmo design second technique kernel principal component analysis kpca kpca unsupervised technique class labels removed data data passed heart technique just eigenvector based decomposition matrix case covariance matrix technique handles non linearity via kernel trick just maps data higher dimensional features space performs pca space python numpy scipy lines code data collected simple text parsing literary works particular published works four authors shakespeare jane austen jack london milton believe thoughcertain normal college students take course assigned read novels authors dataset widely usedavailable number places web works divided pieces corresponding roughly chapters novels words different substantial pieces text four authors next word frequency scan performed combined corpus text common words selected study remainder results frequency scan discarded words became field column names finally one data row corresponding texts prepared truncated word frequency scanone data points sum data comprised dimensions dimension frequency total count particular word given text one four authors although data primarily used supervised classification class labels reason technique used unsupervised put another way never showed class labels algorithm kpca algorithm absolutely idea four different clusters shown plot correspond differs algorithm even know many groups classes data comprised just gave data partitioned neatly four distinct groups based inherent ordering results algorithm used kpca using python numpy matplotlib script produced results lines codedata processing applying kpca plotting result much much post event anyone wants code can get repo time also complete documented kpca algorithm coded python numpy python packages available shogun large scale machine learning toolbox sdpy set modules directed computer vision machine learning mlpy machine learning python another interesting algorithm textrank sounds similar docrank referenced original question graph based unsupervised iterate convergence java implementationdone additional research topic found wikipedia entry okapialgorithm also successorf takes document structure account appears relevant html xmlincorporates finally wikipedia entry links lucene implementation compared douganswers appears complex algorithm implement algorithms ranking though havenseen implementations yetable trainnet labeled images binary classificationhard time figuring configure final layers keras theano multi class classification classes images corresponding masks unitpixels masks instead black white color labeled objects categories plus background follows training runs array containing masks one hot encoded follows makes mask model closely follows unet architecture however final layers seem problematicunable flatten structure match one hot encoded array suggestions modify final portions model trains successfully get variety shape mismatch errors times managed make run loss change throughout epochs targetusing channels first channels last channel target one class channel images means pixel class means pixel class target groups group containing four images imagepixels pixels indicate presence desired featuresure result will ordered correctly can try ordering doesnwork properly can manually bit late try will result mask one hot encoded last conv layer activation loss looks good multiclass segmentation trying implement application uses adaboost algorithm know adaboost uses set weak classifiers donknow weak classifiers can explain example tell create weak classifierssuppoused use kind algorithm weak classifiers weak learners classifiers perform slightly better random classifier thus classifiers clue predict right labels much strong classifiers like naive bayes neurel networks svm one simplest weak classifiers decision stump one level decision tree selects threshold one feature splits data threshold adaboost will train army decision stumps focus one part characteristics data used adaboost weak classifiers basically thresholds data attribute thresholds need performance totally random good presentation adaboost calculate weak classifiers tcan cengschedule roc auc roc auc score can just import call directly documentation scoring parameter indicates specifying scoring roc auc will use implement gridsearchcv cross val score scoring roc auc receive different numbers call roc auc score directly code help demonstrate see feel like missing something simple likely mistake implementing interpreting one scoring metrics can anyone light reason discrepancy two scoring metrics supplied predicteds instead probability roc auc score function takes score classified label try instead give similar result previous result cross val score refer post info just ran similar issue key takeaway cross val score uses kfold strategy default parameters making train test splits means splits consecutive chunks rather shuffling train test split hand shuffled split solution make split strategy explicit specify shuffling like ran problem digging bit found answer sharing love actually two half problemsfull example using two estimators split train test set keep variable can reuse feed gridsearchcv save scores note passing fourfold feed cross val score save scores sometimes want loop compute several different scores use scores across board data var var aggregated percentage values state levelnumber participants state like run linear regression var var considerationweight sklearn python general line say data loadedusing pandasbecomesn simply fit data following line need processsomehow using sample weight command weights enable training model accurate certain values input cost error higher internally weightsmultiplied residuals loss function therefore relative scale weights matterscan passed already reflects priorities uniform scaling change outcome example weighted version emphasize region around last two samples model becomes accurate scaling affect outcome expected transformation also seems necessary passing var var fit dataset number continuous dummy variables analysis glmnet want continuous variables standardized dummy variables currently manually first defining dummy vector columns values using scale command non dummy columns problem isnelegant glmnet built standardize argument default will standardize dummies elegant way tell glmnetstandardize argument skip dummies short yes will standardize dummy variablesreason glmnet function takes matrix inputparameter data frame doesnmake distinction factor columns may parameter glmnet codes standardize parameter internally convertsboolean integer feed internal fortran functions elnet lognetaleven examining fortran code fixed width old schoolsee following block take look lines marked basically applying standardization formulamatrix now statistically speaking one generally standardize categorical variables retain interpretability estimated regressors however pointed tibshirani lasso method requires initial standardization regressors penalization scheme fair regressors categorical regressors one codes regressor dummy variables standardizes dummy variables causes arbitrary scaling continuous categorical variablesdone equal penalization treatment glmnet doesnknow anything dummy variables doesnformula interface hence doesntouch want treated speciallydatalooks like tried convert classification columns vehicletype dummies one hot encoding original data missing replace given column dummies can use compact way line will drop old column vehicletype automatically join created columns datasetrf mod forest doesnseem information docs donmentions randomforest package average variable importance entire forest cart models given importancemod can also extract individual tree structure gettreefirst tree one workaround grow many carts get variable importance tree average resulting incmse extraction averaging comparison steplike able extract variable importance tree directly randomforest object without roundabout method involves completelyrunningorder facilitate reproducible cumulative variable importance plots like one one shown mtcars minimal exampleaware single treevariable importance statistically meaningfulintention interpret trees isolation want purpose visualization communicating trees increase forest variable importance measures jump around stabilizing training randomforest model importance scores computed entire forest stored directly inside object tree specific scores kept directly retrieved randomforest object unfortunately correct incrementally construct forest good news randomforest object self contained donneed implement runinstead can use stats updatefit random forest model single tree randomforest grow add additional trees one time data frame shows feature importance changes additional tree right panel plot example trees left panel can retrieved final forest given dplyr last rfs disclaimer really answer long post comment will remove deemed appropriate think understand question honest unsure whether question makes sense statisticspoint view following based obviously limited understandingcart perhaps comment post will lead insights letstart general random foresttheory variable importance hastie tibshirani friedman elements statistical learningbold face mine split tree improvement split criterion importance measure attributed splitting variable accumulated trees forest separately variable random forests also use oob samples construct different variable importance measure apparently measure prediction strength variable variable importance measuredefined measure accumulated trees traditional single classification trees carts variable importance characterised gini index measures node impurity see variable importance using cart specifically using rpartcarolin stroblphd thesis complex measures characterise variable importance cart like models exist example rpart overall measure variable importance sum goodness split measures split primary variable plus goodness adjusted agreement splits surrogate printout scaled sum rounded values shown omitting variable whose proportion less bottom line following least woneasy worst case wonmake sense compare variable measures single classifaction trees variable importance measures applied ensemble based methods likeleads ask want extract variable importance measures individual treesmodel even came method calculate variable importances individual trees believe wouldnmeaningful wouldnconverge ensemble accumulated values can simplify byi try apply code error update scikit learnresults introduced earlier called grid scores slightly different structure uninstall install conda scikit learn upgrade scikit learn package anaconda import gridsearch first update sklearn using check include wrong module change new path right way online learning work keras using adaptive optimizer learning rate schedule resets calling fit want see can just manually set however order need find learning rate last epoch said can print learning rate epoch think can callback seems recalculate timesure adam found another thread works sgd using following approach based jorijnsmit answer works adam found question helpful minimal workable example answers question everyone still confused topic solution andrey works set decay learning rate schedule learning rate lowerepoch otherwise will always print number starting learning rate number change training cansee learning rates adapts every parameter adam different learning rate adapts training variablenever changes follow thread piece code might help based keras implementation adam optimizer beta values keras defaults like use yolo architecture object detection training network custom data followed steps train pascal voc data final step darknet detector train cfgused darknet detect command weights one test images data dog nothing found donuse pretrained weights network trainedited cfg can use pretrained weights correctly without training just breaking setting create checkpoints get idea progress adding clear end training command will clear stats many images model seen previous training can fine tune model new data set can find info usage function signature void train detector char datacfg char cfgfile char weightfile int gpus int ngpus int clear learning rates usually associated current iteration usually increase max iterations want resume previous training task ended reaching max iterations believe iterations will give better results fyi small dataset training scratch classification network may great idea may still wantuse weights detection network trained large dataset like coco imagenet old question hope answer now mine just case helps working darknet monthrun roadblocks people asked posted forums casepretty certainweights trained max number batches already pre trained weights read darknet assumed training done relevant personal experience used one pretrained weights files started iteration ran cutting stick training scratch custom data want try pre trained weights might find changing max batches cfg file helps also using alexeyab darknet might problem clear option detectorreally otherwise training loop will exit immediately modify opencv number darknet makefile opencv donallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago anyone aware nearest neighbor algorithm implemented python can updated incrementally onesfound one appear batch processes possible implement incrementalalgorithm way late posterity actually technique converting batch processed algorithms liketree incremental algorithmscalled static dynamic transformation generate incremental varianttree store set trees instead just one treeelements nearest neighbor structure structure will tree bit binary representationmoreover treecorrespondsbittreecontains elements elements structurebinary therefore three treestelements elements element respectively now letinsert elementstructure insertionelements binary comparing new previous binary string seedoesnchange new treeelements treest get deleted construct new treebatch insertionalong elements treestway create incremental point query structure static base structure however asymptotic slowdown incrementalizing static structures like form extra logfactor think problem incremental constructiontree knn treealluded comment tree will eventually become unbalanced cansimple tree rotation fix balance problems keep consistency minimumbalancing task trivial one definitely want insertion often one will choose build tree batch method insert bunch new points allow tree become unbalanced pointbalance similar thing build data structure batchpoints usepointsbuild data structure batchm points sincebalancing normal fast algorithm familiar trees rebuilding necessarily slow comparison cases can faster depending sequence points entering incremental algorithm said amount code write debugging difficulty ease others understanding code can significantly smaller take rebuild approach can use batch method keep external list points yet inserted tree brute force approach can used ensure none closer ones tree links python implementations discussions havenfound explicitly claim incremental good luck compgeom pycgalvisual comments apply high dimensional spacesworkingdsaid may appropriate working high dimensional spaces use brute force approximate nearest neighbor scipy cookbook website includes complete implementation knn algorithm can updated incrementally maybe lines background helpful anyone interested familiar terminology knn engine powered either two data representations pairwise distances points dataset stored multi dimensional array distance matrixtree just stores data points multi dimensional binary tree two operationstree based knn algorithm needs create tree dataset analogous training step performed batch modealgorithms search tree find nearest neighbors analogous testing step online incremental training context knn algorithm providedbasedtree means insert nodes already builttree backtree implementation scipy cookbook specific lines code responsible node insertion appear comment line insert nodetree fact code comment directed node insertion finallytree implementation spatial module scipy library called kdtree donbelieve supports node insertion least function docs havenlooked source possible get classification report cross val score workaroundusing nested cross validation can get various scores model however like see classification report outer loop recommendations like see classification report along side score values now just call cross val score new scoring function using make scorer will print classification report text time return nested score number last lines output will follows just addition sandipananswer couldnedit want calculate average classification report complete run cross validation instead individual folds can use following code now result example sandipananswer look like choose easiest pathinput output batch normalization testing one calculate mean variance activation input layer input dimension one record means variances training calculate means variances entire training set calculate means variances entire test set many people say precalculate means variances use method calculating means variances entire test set wouldnneed calculate means variances entire test set performing forward propagation pre thank much help predicting test always use trainstatistics simple transformation batch normalizationrecommend tryingn course know coded batch normalization code github link test statistics significantly differ train means test different general model wonwork caseneed find different training data anyway precise train model data processed certain way wonwork data processed different way letimagine test samplewant make prediction one client whatever simply cancalculate test statistics case secondly lettake batch normalization data normalized values now show many standard deviations original data differes certain average model will use information training normalize test data using test statistics values will show deviation different average record empirical mean variance taken training time running average later used test set instead calculating means variances test batchinterested incorporating tensorflowserver application built visual studio windows need knowpossible google recently announced windows support tensorflow can tell just pip install commonly used python package useapi need build repo source build use google tensorflowapi tried building project using bazel ran issues trying configure build way get tensorflowwork native windows using docker new windows linux subsystemseen others post thanks ian certainly possible use tensorflowc api windows currently easy right now easiest way buildapi windows build cmake adapt cmake rulestutorials example trainer project see source code building cmake will give visual studio project can implementtensorflow program notetutorials example trainer project builds console application statically links tensorflow runtime program present written necessary rules create reusable tensorflow dll although technially possible example python extension dll includes runtime export necessary symbols use tensorflowcapis directly detailed guide joe antognini similar tensorflow readme github explaining building tensorflow source via cmake also need swig installed machine allows connectingc source python scripting language use visual cmake cmake gui screen capture shown cmake configuration used visual studio compiler stage successfully completes can click generate buttonahead actual build process however visual studio attempted building via build project setup gave build toolsfound erroraway even attempted retarget solution finally solution got built successfully visual studio also need manually set swig executable path cmake successfully configures indicated antognini link build took half hourram core machine done might want validate build attempting runtutorials example latest work building tensorflowapi windows please look github page works windows currently without cuda support cpubazel build method works cmake supported maintained anymore resulting cmake configuration errors use downgraded version visual studio addingversiontoolset installer individual components tab cmake command worked build open check graphics card compute capability remember install packages cuda toolkit cudnn python swig git add paths environment variable beginning made readme detailing built tensorflow dll lib fileapi windows gpu support building source bazel tensorflow version tutorial step step starts beginning may scroll past steps already done like checking hardware installing bazel etc url step build dll shows pass command create lib dll test lib linkproject will show identify fix missing symbols usingexport macro actively working making tutorial better feel free leave comments answerusing nested cross validation can get various scores model however like see classification report outer loop recommendations like see classification report along side score values now just call cross val score new scoring function using make scorer will print classification report text time return nested score number last lines output will follows just addition sandipananswer couldnedit want calculate average classification report complete run cross validation instead individual folds can use following code now result example sandipananswer look like choose easiest pathinput outputmod forest doesnseem information docs donmentions randomforest package average variable importance entire forest cart models given importancemod can also extract individual tree structure gettreefirst tree one workaround grow many carts get variable importance tree average resulting incmse extraction averaging comparison steplike able extract variable importance tree directly randomforest object without roundabout method involves completelyrunningorder facilitate reproducible cumulative variable importance plots like one one shown mtcars minimal exampleaware single treevariable importance statistically meaningfulintention interpret trees isolation want purpose visualization communicating trees increase forest variable importance measures jump around stabilizing training randomforest model importance scores computed entire forest stored directly inside object tree specific scores kept directly retrieved randomforest object unfortunately correct incrementally construct forest good news randomforest object self contained donneed implement runinstead can use stats updatefit random forest model single tree randomforest grow add additional trees one time data frame shows feature importance changes additional tree right panel plot example trees left panel can retrieved final forest given dplyr last rfs disclaimer really answer long post comment will remove deemed appropriate think understand question honest unsure whether question makes sense statisticspoint view following based obviously limited understandingcart perhaps comment post will lead insights letstart general random foresttheory variable importance hastie tibshirani friedman elements statistical learningbold face mine split tree improvement split criterion importance measure attributed splitting variable accumulated trees forest separately variable random forests also use oob samples construct different variable importance measure apparently measure prediction strength variable variable importance measuredefined measure accumulated trees traditional single classification trees carts variable importance characterised gini index measures node impurity see variable importance using cart specifically using rpartcarolin stroblphd thesis complex measures characterise variable importance cart like models exist example rpart overall measure variable importance sum goodness split measures split primary variable plus goodness adjusted agreement splits surrogate printout scaled sum rounded values shown omitting variable whose proportion less bottom line following least woneasy worst case wonmake sense compare variable measures single classifaction trees variable importance measures applied ensemble based methods likeleads ask want extract variable importance measures individual treesmodel even came method calculate variable importances individual trees believe wouldnmeaningful wouldnconverge ensemble accumulated values can simplify byi running following error trying train dataset since configuration published paper assuming something incredibly wrong error arrives different image every time try run training ideas kind error generally occurs using nllloss crossentropyloss dataset negative labels labels greater number classes also exact error getting assertiontclasses failed wonoccur mselossmentions crossentropyloss somewhere thus error occurs program crashes asynchronously line solution clean dataset ensuretclasses satisfiedrepresents label also ensure network output range case use nllloss bceloss require softmax sigmoid activation respectively note required crossentropyloss bcewithlogitsloss implement activation function inside loss function thanks pouyab pointing online learning work keras using adaptive optimizer learning rate schedule resets calling fit want see can just manually set however order need find learning rate last epoch said can print learning rate epoch think can callback seems recalculate timesure adam found another thread works sgd using following approach based jorijnsmit answer works adam found question helpful minimal workable example answers question everyone still confused topic solution andrey works set decay learning rate schedule learning rate lowerepoch otherwise will always print number starting learning rate number change training cansee learning rates adapts every parameter adam different learning rate adapts training variablenever changes follow thread piece code might help based keras implementation adam optimizer beta values keras defaults datalooks like tried convert classification columns vehicletype dummies one hot encoding original data missing replace given column dummies can use compact way line will drop old column vehicletype automatically join created columns dataseti try apply code error update scikit learnresults introduced earlier called grid scores slightly different structure uninstall install conda scikit learn upgrade scikit learn package anaconda import gridsearch first update sklearn using check include wrong module change new path right way quick answer fact really easycode donwant read text setup decode model will use decode layer model train model decode model will trained actual questiontrying create simple autoencoder mnist keras code fartraining learn identity function reconstruction quite interesting also like look representations cluster output passing decoding layer cluster mean one class mnist order created second model decode model reuses decoder layer try use model complains exception error checking expected dense input shape none got array shape seemed strangesimply dense layer matrix wouldneven able process dim input decided look model summary connected densedifficult keep track names layers looks like encoder layer sure enough model summary whole model apparently layers permanently connected strangely input layer decode model can reuse layer keraslooked functional api layers fused togethernevermind read entire functional api shared layersone predictions maybe still lacking trainingguessing least works now similar problemsupdated code compiled one models training need compile model prediction necessary shared layers can directly accessed one model second list surerecommended use either instead saw recently donassign simple can access inputs classify news fake real created two sets features bigram term frequency inverse document frequencyapproximately features associated document obtained using subjectivity text polarity stopwords verbs subject relations grammaticals etc best way combine tfidf features features single prediction thanks lot everyone sure asking technically combine two objects code theoretically will try answer technically tfidf just matrix rows records columns features combine can append new features columns end matrix probably matrix sparse matrix scipy sklearn will make sure new features sparse matrix make dense gives training data terms little tricky features bigram frequency matrix will sparse talking data structures just mean will lotwill binary whilst data dense continuous will run machine learning algorithms although prediction will probably dominated dense variables however bit feature engineering built several classifiers past using tree ensambles take combination term frequency variables enriched dense variables give boosted results example classifier looks twitter profiles classifies companies people usually found better results least bin dense variables binary categorical hot encoded binary didndominate use classifier tfidf use pred add new feature say tfidf probabilities give better result pic autoblueprint show results percentpercent currenttwo separate classifier onesi trying freeze weights certain layer prediction model keras mnist dataset work code like program outputs weights changed understand weights layer named dense changes setting name name trainable false can using need compile graph setting trainable info let keep layers freezed uptolayer rest will keep trainable simple efficient codehere code want made multi classification using keras vcl acc better training predict value always value confused please help month looking solution tried everything lowering learning rate changing optimizer using bigger dataset increasing decreasing model complexity changing input shape smaller larger images changin imports keras import changing activation function every layer combining trying others datasets yesterday reading book deep learning keras antonio gulli sujit pal realized autors use imports like like conv using autors use changed imports everything started work finally donknow bug something like cause now models always works even datasets predicting class nowusing imports like example try doesnwork look dataset balanced example problem classify images cats dogs cat images dog images try use number images different cause can cause problem model can think say images dogs get accuracy want can use class weight donimages balance dataset everything willcan use data augmentation can use callbacks like reducelronplateau reduce learning rate loss getting lower can increase batch size donforget shuffle data imagedatagenerator normalize images like things important nothing really helped thing worked importing may help seems problem caused huge class inbalance dataset one can see assigning class example gives accuracy order deal may use following strategies rebalance dataset either upsampling less frequent class downsampling frequent one adjust class weights setting higher class weight less frequent classpromoting network training putting attention downsampled class issue tried worked simply divide image training testing data also divided didnuse test want implement custom loss function scikit learn use following code snippet arguments passed custom loss func label matrix called labm want calculate difference actual predicted output model multiplied true output use labm placetrue use placepred okaythings going loss function training used tune models parameters scoring function used judge quality model hyper parameter tuning uses scoring function optimize hyperparameters right track defining loss fxn purpose however trying tune whole model perform say recall test need recall optimizer part training processtricky can open classifier letuse rfc example click source seeinheriting forestclassifier right class definition click word jumpparent definition see new object inheriting classifiermixin click see bottom classifiermixin class saysmodel trained accuracy need inject point want train model recall model precision model whatever model accuracy metric baked sklearn day better man will make parameter models accept however mean time gottasklearn installation tweak accuracy score whatever want best luck documentation make scorer goes like dosenneed pass arguments calling function asking arguments custom func loss connection true labels labm can keep way now internally gridsearchcv will call scoring function hence true labels conflictpred predicted values generated modeloutputtrue will assigned values labmtrying build neural net neuralnet packagetroublesuccessful nnet package luck neuralnet one read whole documentation package canfind solution maybeable spot training commandusing prediction training takes whole lot longer nnet training tried using algorithm nnet backpropagation instead resilent backpropagation nothing changed activation functionpretty much everything else result didnimproved predicted values donunderstand nnet works neuralnet one doesnreally use help lack understanding things neural netss probably cause canfind dataset uci want use neural network binary classification sample data converted matrix factors numerical values summary predicted values value wilcoxon mann whitney test area curve shows prediction performance virtualy random first reason consider get weird results neural networks normalization data must normalized otherwise yes training will result skewedwill produce outcome time common symptom looking data set values means treatedessentially reason traditionally used response functions almost constant outside range around always normalize data feeding neural network similar answer sashkello faced similar issue earlier data properly normalized normalized data everything ran correctly recently faced issue debugging found can another reason neural networks giving output neural network weight decay term rsnns package make sure decay term large weightsessentially using caret packageinitially using decay hyperparameter looked diagnostics saw rmse calculated fold cross validation rsquared alwayscase predictions coming value reduced decay much lower valuelower got expected results hope helpsadding anyone might problem didnworkusing tensorflow custom training loop make sure set training true anyone problem solved using parameter rep defining neural network seems training network done donset parameter leads network returning vector identical values values similar believe problem also default value setbinary classification code led normal results output maximum probability minimum probability usage rep leads weird behavior rstudio plotting multiple models different training iterations therefore donwant make environment crash much plotting use additional parameterbinary classification using keras tensorflow backendgot precision recall now want try play decision threshold far know keras uses decision threshold way keras use custom threshold decision precision recall thank time create custom metrics like edited thanks marcin create functions returns desired metrics threshold value argument now can use hope helps employingregularization neural network parameters keras obtain sparse model finding many coefficients close zero actually zero upon looking source code regularization suggests keras simply addsnorm parameters loss function incorrect parameters almost certainly neverzero within floating point error intendedregularizationnorm differentiable parameter zero subgradient methods need used parameters set zero close enough zero optimization routine see soft threshold operator max tensorflow keras impractical stochastic gradient descent edit also superb blog post explaining soft thresholding operatorregularization despite joshua answer three things worth mention problem values set might arise due computational reasons due nature gradient descent based algorithm setting highvalue oscillations might occur due gradient discontinuity understand imagine given weightlearning rate equal gradient main loss equal second update may see absolute valuehasndecreased even though appliedregularization happened due nature gradient based algorithm course simplified situation experience oscillating behavior really often usingnorm regularizer keras correctly implementsregularization context neural networksregularization simply addsnorm parameters loss function seel regularization encourages sparsity guarantee output will sparse parameter updates stochastic gradient descent inherently noisy thus probability given parameter exactly vanishingly small however many parametersregularized network often close rudimentary approach threshold small values research explore advanced methods generating sparse neural network paper authors simultaneously prune train neural network achieve sparsity number known network architecturesdr formulation deep learning frameworks correct currently donpowerful solver optimizer solve exactly sgd variants use proximal optimizers can obtain sparse solution observation right subgradient descent poor convergence properties non smooth functions lasso objective since ignores problem structure completely doesndistinguish least squares fit regularization term just looking subgradients entire objective intuitively taking small steps direction sub gradient usually wonlead coordinates equal zero exactly another simple work around zero small weights absolute valuetraining gradient descent step force sparsity just handy heuristic approach theoretically rigorous keras implementsregularization properly lasso lasso one need soft thresholding function correctly pointed original post useful function similar thetaxx thetaxx thetax otherwise lasso theta equal learning rate times regularization factorfunctionusing keras problem identical one implement mean pooling layer keras answer seem sufficient want implement network following code work donset return sequences true get error call averagepoolingotherwise get error call dense just attempted implement model original posterusing keras mean pooling lstm worked used globalaveragepoolingjust make sure return sequences true lstm layer give try adding timedistributed dense helped think accepted answer basically wrong solution found however works theano backend modified code supports theano tensorflow thanks also meet question think timedistributed layer working want can try luke guyetemporalmeanpooling layer works example quite late party output points consider trained ibk classifier training data created manually following build classifier want create new instance unlabeled class classify instance tried following luck just get following errors looks like something wrong creating new instance can create unlabeled instance exactly thanks advance will see error classify new instance associated dataset associate every new instance create instances object using setdataset can classify newly created instance ablumer weka doc try classify newinst weka throws exception newinst instances object dataset associated thus know anything class attribute first create new instances object similar dataraw add unlabeled instance set class index try classifying see pages weka documentation helped lot weka manual pdf file located weka installation folder just open copy pasting snippets code listings chapter using weka api creating datasets memory help solve prediction best weights calculated training model using last weights may best ones safe approach load best weightsmodel even predictions done right training training stops earlystopping callback current model may best model highest lowest monitored quantity result new argument restore best weights introduced keras release earlystopping callback like restore best weights restore best weights whether restore model weights epoch best value monitored quantity false model weights obtained last step training used earlystopping callback doesnsave anything can double check looking source codethus code saves last model achieved best result dev set training stopped early stopping callback say saving best model according dev useful also early stopping callback unless donwant save time sure enough going find better model continue training say model uses latest weights find evidence docs fortunately can check behavior model first run can load best weightsrun prediction test set model contains latest weights get improved result loading best weightsresults can sure model automatically uses best achieved results always load weights saved disk case best weightsvalidationget error part code error memoryerror unable allocate mib array shape data type float also get error try scale data using standardscalerfit transfrom works fine decrease size training set something liketraintrain link code book error get line book aur lienron hands machine learning scikit learn keras tensorflowed page anything ram unable allocate mean memory size just case specs cpu ryzenramgb free using jupyter notebook message straight forward yes available memory mib bytes bytes mib mebibyte bytesdimensions array bytes size float maybefree memory fragmented possible allocate mib one piece reboot may helpful case upgrading python bit seems solved memory error problem try converting smaller sized data types float float possible pred train pred train astype errors ignore just restartclosing tabsbuilding modelnn etc model uses function includes randomness donfix seedgoing get different accuracy results every time run algorithm training data however fix setting might give better results averaging set accuracies enough say accuracy modelm sure right place ask question open discussion simple answer yes randomize use statistics show accuracy howeversufficient just average handful runs need minimum notion variabilityimportant know whether accurate means accurate runs accurate accuratejust trying play around bit convince algorithm works can just run times look mean standard deviation call daygoing convince anyone else works need look formal hypothesis testing models naturally dependent randomness random forests models use randomness part exploring space initialisation values neural networks actually defined deterministic objective function first case will want use multiple seeds report average accuracy std deviation minimum obtained often good way reproduce just use multiple fixed seeds second case can always tell just training data run best although might actually one gives best test accuracy thus time good say runs evaluate one best training error validation error just never evaluate testing decision canlevel multiple multiple runs get standard deviation however find significant probably means werentrying enough initialisations using right model data stochastic techniques typically used search large solution spaces exhaustive search feasiblealmost inevitable will trying iterate large number sample points even distribution possible mentioned elsewhere basic statistical techniques will help determine sample big enough representative space whole test accuracy good idea set aside portion input patterns avoid training patterns assuming learning data set can use set test whether algorithm learning underlying pattern correctly whethersimply memorizing examples another thing think randomness random number generator standard random number generators rand stdlibmay make grade many cases look around robust algorithm generalize answer get question suppose accuracy always average accuracy multiple runs standard deviation considering accuracy get using different seeds random generator actually considering greater range input good thing consider standard deviation consider accuracy get question totally wrong believe cross validation may give ask averaged therefore reliable estimate classification performance contains randomness except permuting data set initially variation comes choosing different train test human activity recognition two types feedback one evaluative used reinforcement learning method second instructive used supervised learning mostly used classification problems supervised learning used weights neural network adjusted based information correct labels provided training dataset selecting wrong class loss increases weights adjusted input kind wrong class chosen however reinforcement learning system explores possible actions class labels various inputs case evaluating reward decides right wrong may case gets correct class label may giving wrong class name best possible output found till now doesnmake use specific knowledge class labels hence slows convergence rate significantly compared supervised learning can use reinforcement learning classification problems wongiving added benefit instead slow convergence rate short answer yes detailed answer yesoverkill reinforcement learning useful donlabeled dataset learn correct policy need develop correct strategy based rewards also allows backpropagate non differentiable blocks suppose case biggest drawback reinforcement learning methods thay typically took large amount time converge possess labels lot faster easier use regular supervised learning may able developmodel chooses classifier uselabels used train classifiers change performance classifiers rewardmodel others said probably take long time converge ever idea may also require many tricks tweaks make work recommend searching research papers topicrunning supervised experiments binary prediction problemusing fold cross validation evaluate performance terms mean average precision average precision fold divided number folds cross validation case like plotcurves result mean average precision folds howeversure best way previous question cross validated stack exchange site raised problem comment recommended working example plotting roc curves across folds cross validation scikit learn site tailoring average precision relevant section codemodified try idea code runs however case mean average precision curve incorrect reason array assigned store mean precision scores mean tpr variable roc example computes first element near zero elements dividing number folds visualization mean precision scores plotted mean recall scores can see plot jumps inaccurate hunch something going awry update mean precision mean precision interp mean recall recall precision fold cross validationunclear fix guidance help appreciated problem solution instead averaging across folds compute precision recall curve across results folds loop according discussion dietmaranswer agreemostly correct except instead using think using examplespace incorrect linearly interpolate points provide evidence favor computing aucpr using lower trapezoid average precision interpolated median estimators sklearndocumentation average precision score implementation interpolated different computing area precision recall curve trapezoidal rule uses linear interpolation can optimisticfully reproducible example hope can help others cross thread couldnfind answer posted discussions hopefully can help main thing reverse recall precision using interp making sure reverse back plotting full code codegetting error last linepredtest errorgetting attributeerror kerasclassifier object attribute model havenfitted classifier yet classifier model variable available need call although used cross val score classifier found accuracies main point note cross val score will clone supplied model use cross validation folds original estimator classifier untouched untrained can see working cross val score answer put mentioned line justpredtest line set hope makes clear get error didnactually train returned model kerasclassifier scikit learn wrapper make use scikit learn functions example gridsearch might know since code seems udemydl course donneed scikit learn functionality suggest avoid wrapper simply build model train playing demos recurrent neural network noticed scale data column differs lot considering preprocess work throw data batches rnn close column target want predict future question preprocessing data say standardscaler sklearn necessary case welcome edit question will beneficial normalize training data different features widely different scales fed model will cause network weight features equally can cause falsely prioritisation features others representation despite whole discussion data preprocessing controversial either exactly necessary correctly normalize data given model application domain general consensus machine learning running mean subtraction general normalization preprocessing step helpful case mean subtraction mean every individual feature subtracted data can interpreted centering data around origin geometric point view true every dimensionality normalizing data mean subtraction step results normalization data dimensionality approximately scale note different features will loose prioritization step mentioned good reasons think different scales features bear important information network may need truly understand underlying patterns dataset normalization will harmful standard approach scale inputs mean variance preprocessing operations may helpful specific cases performing pca whitening data look awesome notesn setting data model reference topics detailed explenation topics definetly yes neural networks work best data beetwen depends output function also inputs higher others network will think important can make learning long network must first lower weights inputs found normalize may improve convergence will get lower trainingallow questions seeking recommendations books tools software libraries can edit question can answered facts citations closed years ago community reviewed whether reopen question months ago left closed original close reasonresolved support vector machine library already implemented useprojects google searchhes found links interesting libsvm svm support vector machine libsvm implement someone wants write svm desire use toolkit canuse toolkit implemented modified version caffeexample works reallyincredibly slow accepts images one one ideallylike pass caffe vector images return best prediction one received great help fanglin wang implemented recommendations still trouble working retrieve best result image classify method now passed vectormat objects variable input channels vector grayscale floating point imageseliminated preprocessing method code donneed convert images floating point subtract mean imagealso trying get ridvariable want return top prediction probability image update thank much help shai made changes recommended seem getting strange compilation issues canwork managed sort issues changes made header file class file understand problem correctly inputimages expectingpairs label prob getting one pair believe modifications trick classifier predict return vector vector float vector probabilities per input image vector sizevectors size output layer channels classifier classify need process vector float argmax independantly unfortunately donbelieve parallelization network forward passes implemented howeverlike simply implement wrapper repeatedly run data copies network parallel look many images can pass caffe time linked prototxt define existing implementation evaluates batch images necessarily parallel however running gpu processing batch will faster single image batchestrying use car evaluation dataset uci repository wonder whether convenient way binarize categorical variables sklearn one approach use dictvectorizer labelbinarizergettingdifferent features whereas justorder avoid collinearization guess write function drop one column bookkeeping tedious easy way perform transformations get result sparse matrix data pandas dataframe can simply call get dummies assume data framewant one binary variable per level variable key can simply call delete one dummy variables avoid multi colinearity problem hope helps basic method sparse format dictvectorizer recommended way generate one hot encoding categorical variables can use sparse argument create sparse csr matrix instead dense numpy array usually doncare multicollinearity havennoticed problem approaches tend use sgdclassifier tree based methods shouldnproblem patch dictvectorizer drop one column per categorical feature simple need remove one term pull requests always welcome csv filecolumn column nan rows can except rows editcolumnsbdlike want convert mask nan values using isnull another way use takes care nans automatically assigns numerous occasionsgetting error trying fit gbm rpart model finally able reproduce consistently using publicly available data noticed error happens usingrepeateddonuse fit control donget error can light one keep getting error consistently typo trcontrol instead tccontrol argument provided tccontrol caret passes rpart throws error option never available guess answers question get error try cross validation training work formal background natural language processing wondering someone nlp side can light playing around nltk library specifically looking stopwords function provided package english yourselvest can will just don now donunderstand word present isnnecessary determine sentiment inside sentence instance sentence like sure problem totally different stopword removed changing meaning sentence opposite sure problem case set rules missing use stopwords concept stop word list universal meaning depends want task need understand polarity sentiment similar characteristic phrase method depends detecting negation like example obviously shouldnremove stop word note may still want remove common unrelated words constitute new stop word list however answer question sentiment analysis methods superficial look emotion sentiment laden words time attempt deep analysis sentence another example like keep stop words trying classify documents according authors authorship attribution carrying stylometrics definitely keep functional words characterize big part style discourse however many kinds analyses document similarity search etc removing common functional words makes sense computationally process fewer words cases practically may even get better results stop words removedtrying understand context specific word used oftenlike see content words functional wordstrying run lda latent dirichlet allocation non english text dataset sklearntutorialpart count term frequency words feed lda built stop words feature available english think use stop words list may just assign list words stop words saw sample code big paste author used instead official documentation keras says single gradient update one batch samples donget fit instead many feed forward backprop steps wrong yes train batch trains using single batch fit trains many batches many epochs batch causes update weights idea using train batch probably things batch used want understand custom changes batch training precide use case gans update discriminator update gan network keep discriminator untrainable first train discriminator train gan keeping discriminator untrainable see understanding however limitations memory especially gpu memory cantrain big number samples need divide data small piece called mini batches just batchs methode fit keras models will data dividing pass data gave however sometimes need complicated training procedure want example randomly select new samples put batch buffer epoch cases donuse fancy simple fit method instead use train batch method use methode generate batch inputs batch outputs labels iteration pass method will train model whole samples batch givesloss metrics calculated respect batch samples need find optimal discount productc can maximize total sales existing random forest models product map discount season sales combine models feed optimiser find optimum discount per product reason model selection input data sample data used build model product level glance data idea steps followed sudo sample code unable find way pass product models optimizer dear experts request guidance struggling find guidance since couple weeks use pso optimizer optimizer following right oneadding functions used model edit updated dataset simplified version can find complete solution fundamental differences approach following additional modifications original code include code therefore givesgot series modelled class labels knn functiongot data frame basic numeric training data another data frame test datadrawing decision boundary returned values knn functionreplicate findings locked machine please limit useparty libraries possible two class labels orange blueplotted simpleplot training data just want draw boundary around results knn function code classes just vector class labels determined earlier bit code need complete code work get class probability predictions grid draw contour linewhatever want cutoff point also method used classic mass textbook venables ripley elements statistical learning hastie tibshirani friedman see also basically question crossvalidated keep getting error importing top vec python version bit installed msbuild errors pip installing package anyone know solution problem experienced similar problem new release ver hdbscan oct fix issue see original answer details original answer looks like using latest sept versions hdbscan joblib packages available pypi cachedir removed sept hdbscan release pypi ver released feb still updated still use memory memory cachedir none verbose one possible solution force using joblib version cachedir removed ver oct however note edits open issues hdbscan repo note vulnerability cve using joblib new release ver hdbscan oct thank worked downgraded joblib package using pip install upgrade joblib however please advised version joblib known vulnerability arbitrary code execution via pre dispatch flag parallel class due eval statement please use caution production happy coding possible minimise loss function changing elements variable words variablelength can minimise loss function changingkeepingconstant hopefully code attempted will describe problem outputs like find optimal valuethusedit motivation like import trained graph model tweak various elements variables depending new data can use trick restrict gradient calculation one index partbecomes value want change one hot vector shapepartpartxforward pass since partparthowever backward passsure possible scipy optimizer interface using one regular masking gradients calling apply gradients instead calling minimize docs say basically calls previous ones output pretty easy using var list parameter minimize function note convention trainable variables added tensorflow default collection can get list trainable variables using just list variables can manipulate see fit use var list parameter tangent question ever want take customizing optimization process step can also compute gradients manually using grads loss var list manipulate gradients see fit call apply gradients grads vars list tuples hood minimize just two steps also note perfectly free create different optimizers different collections variables create sgd optimizer learning ratevariables another adam optimizer learning rateanother set variablesspecific use casejust pointing flexibility now answer oren second link calls function defined first link takes boolean hot matrix parameters optimize tensor parameters uses stop gradient works like charm neural network developed update part word embedding matrix tensorflow columns sometimes task made extensive frame try create vector vectorassembler cached trained kmeans took minutes assembling minutes kmeans different count clustersstandalone mode frameanother side processing pandas pivotiterate clusters takes less one minute obviously understand overhead performance decreasing standalone mode cachingreally discourages somebody explain can avoid overhead peoples work wideinstead using vectorassembler getting performance decreasing formal question sof rules sound like can speed code config vectorassemblertransform function processes columns stores metadata column addition original data takes time also takes ram put exact figure much things increased can dump data frame transformation parquet files compare experience feature vector built hand feature extraction methods compared one built vectorassembler can cause size increaselogistic regression parameters things will get lot worse data set many columns suggestions actually solution found map rdd advantages example code scala implementation trying load two datasets use training package versions python pytorch possible create data loaders seperately train sequentially note mydataset custom dataset class def len self def getitem self index implemented configuration works seems implementationideally like combine single dataloader object attempted per pytorch documentation however random batches get following expected tensor elementargument got tuple instead type error help much appreciated got question right train dev sets corresponding loaders follows want concatenate order use train dev training data right just simply call train dev loader loader containing data sets now sure data shapes types number features categories numbers etcguess two datasets sometimes returning different types data tensors torch stacks better shapesomething like strings torch will make tuple sounds like one datasets sometimes returning somethingtensorput asserts output dataset checkwant dive pdb adding leopdanswer can use collatefunction provided pytorch idea collatewill define examples stacked make batch since torch make sure looking correct version documentation let know helps followup questions practically possible decreasing loss decreasing accuracy epoch training cnn model getting result training can someone explain possible reasons happening least reasons might cause behavior outliers imagine exactly images belong class one belongs classcase model will start assign high probability class example majority examples signal outlier might destabilize model make accuracy decreasing theory model stabilize assigning score class might last many epochs solutions order deal examples advise use gradient clipping may add option optimizer want check phenomenon occurs may check losses distributions losses individual examples training set look outliers bias now imagine exactly images assigned class classcase model will try assign approximately distribution classes now model can achieve accuracy choosing one class two valid solution try increase model capacity often set really similar images adding expressive power might help discriminate similar examples beware overfitting though another solution try strategy training want check phenomenon occurs check distribution losses individual examples distribution skewed toward higher values probably suffering bias class inbalance now imagine images belong class early stage training model mainly concentrating assigning class almost examples might make individual losses achieve really high values destabilize model making predicted distribution unstable solution gradient clipping second thing patience try simply leaving model epochs model learn subtle phase training course try class balancing either assigning sample weights class weights want check phenomenon occurs check class distribution strong regularization set regularization strict training process mainly concentrated making weights smaller norm actually learning interesting insights solution add categorical crossentropy metric observealso decreasing means regularization strict try assign less weight penalty bad model design behavior might caused wrong model design several good practices one might apply order improve model batch normalization thanks technique preventing model radical changes inner network activations makes training much stable efficient small batch size might also genuine way regularizing model gradient clipping makes model training much stable efficient reduce bottleneck effect read fantastic paper check model might suffer bottleneck problem add auxiliary classifiers training network scratch make features much meaningful training faster efficient yes possible provide intuitive example might happen suppose classifier outputs roughly probability classesclass highest density overall within setting changing modelparameters minimally might turnprobable class effect make cross entropy loss vary minimally since depends directly probability distribution change clearly noticed accuracy depends argmax output probability distribution conclusion minimizing cross entropy loss always imply improving accuracy mainly cross entropy smooth function accuracy non smooth possible get decreasing loss decreasing accuracy far called good model problem can resolve extinct using batch normalization every conv layer model possible loss function also accounts confidence prediction accuracy accounts correctness following excel sheet shows example left side loss accuracy low right side accuracy increases time loss also increased check spreadsheet try multi class classification using softmax function softmax cross entropy loss function loss will low probability positive class high hope makes clear possible intuition someone correct feedback welcomediusing caret package analyse random forest models built using ranger canfigure call train function using tunegrid argument tune model parameters thinkcalling tunegrid argument wrong canfigurewrong help appreciated syntax ranger caret add prior tuning parameters three supported caret number trees train can specify get variable importance check works set number trees fit will much slower changing importance impurity work recommend installing latest ranger cran caret git hub train number trees can use lapply fixed folds created createmultifolds createfolds edit example works caret package version using names hyper parameters without dots works personal implementationalgorithm generates performance metrics everytime steps metric simply scalar array scalars want display simple graph want display real time tensorboard like example thanks advance really want use tensorboard can start looking tensorflow site datacamp tutorial tensorboard tensorflow can use example need particular format summary taking care condition data real numeric scalar value convertible float tensor said planning using tensorflow implementation suggest just use matplotlib library also enables plot data real timeve searching net hours couldnfind solution yet want give precomputed kernel libsvm classify dataset can generate precomputed kernel example basic precomputed kernel iris data libsvm documentation stated precomputed kernels first element instance must exampledetails can assignsequentially libsvm help example precomputed kernels really appreciated first background kernels dimension need calculate kernel function pair examples kernel function takes two vectors gives scalar can think precomputed kernel nxn matrix scalarsusually called kernel matrix sometimes gram matrix many different kernels simplest linear kernel also known dot product sumyxyn vectors secondly trying answerxx second value kernel function first vector secondx follows like rest example can see kernel matrix symmetricxkxworth pointing first set vectors represented sparse format kernel matrix isnshouldnsparse donknow just seems libsvm thing scikit learn hides details libsvm handling custom kernels can either just pass arbitrary function kernel will compute gram matrix pass precomputed gram matrix kernel first one syntax kernel kernel function can cally will compute kernel matrix second case syntax callymust matrixxk kernel see also example details though also see stompchickenanswer first number line category belongs next entry line formmust sequential first entry second entry thrid entry possible reason libsvm returns values alphavectors output file precomputed kernels vectors displayed truly huge rather indexwent vector shown make output easier match input especially since output order put grouped category thus useful reading input file able match libsvmoutputs inputsvalues can see output svm typesvc kernel type precomputedclass totalrho labelsvimportant note precomputed kernels omit zero entries like can kernels must explicitly included believe scikit learnpython binding libsvm address problem see documentation kernel functions informationsample tiny cnn implemented keras pytorch print summary networks total number trainable parameters total number parameters number parameters batch normalization donmatch cnn implementation keras summary printed modelimplementation model architecture pytorch following output summary model can see results batch normalization keras number parameters pytorchexactdifference cnn architectures equivalent missing keras treats parameters weights many things will saved loaded layer implementations naturally accumulated mean variance batches values trainable backpropagation nevertheless values updated every batch keras treats non trainable weights pytorch simply hides term non trainable means trainable backpropagation doesnmean values frozen total groups weights batchnormalization layer considering selected axis default size layer advantage like keras save layer also save mean variance values way save weights layer automatically load layer weights loaded think main problem tensorflow version used somes commandbellow also used command donworks please help solve error need update version tensorflow solved problem also checked higher versions workedneed update tensorflow can try use gpu version doesnsolve issue can also try version details issue follow answeri need perform clustering without knowing advance number clusters number cluster may since may find cases samples belong instance limited number group thought affinity propagation choice since control number clusters setting preference parameter however single cluster artificially generated set preference minimal euclidean distance among nodes minimize number clusters get terrible clustering flaw approach using affinity propagation conversely affinity propagation unsuited task use something else flawuse distances requires specify similarity donknow scikit implementation according read uses negative squared euclidean distances default compute similarity matrix set input preference minimal euclidean distance get positive value similarities negative will typically result many clusters samples note higher input preference clustersrather suggest set input preference minimal negative squared distance necessarily one single cluster donknow whether preferencerange function exists also scikit implementation matlab codehomepage also implementedpackage apcluster maintaining function allows determining meaningful bounds input preference parameter hope helps can control specifying minimum preferencessure will found single cluster also suggest donwanna make single cluster generate errors data must similarity examplers provide minimum preferenceswill commit error can also merge clusters together essentially running algorithm second time using center samples manually merging similar ones iteratively merge closest clusters till get number making choice preference easier since can just choose anything will result decent number clusters worked decently tried machine learning results donquite understand using python sciki learn million data features classificationlooks pretty bad precision recall curve roclooks just good groups classification can explain class imbalance unlike roc curvecurves sensitive imbalance optimize classifier good auc unbalanced data likely obtain poor precision recall results newday tasked building forest random forests individual random forest will built using different training set will combine forests end make predictions implementingdifficulty combining two forests built using set attempt follows course produces error browsing web time looking clue havensuccess yet help appreciatedeither oversight combinetrying nonsensical depending point view votes matrix records number votes forest case training data response category naturally will number rows number rows training data combine assuming ran random forests twice set data dimensions matrices willwants provide overall error estimates combined forest two data sets different combining votes matrices becomes simply nonsensical get combine run simply removing one row larger training data set resulting votes matrix combined forest gibberish since row combination votes two different training cases maybe simply something option can turned combine still make sense combine actual trees predict resulting object combined error estimates output combine will meaningless long story short make training data set size will run wouldnuse resulting object anything making new predictions anything combined summarizing performance forests will nonsense however think intended way use combine fit multiple random forests full data set reduced number trees combine forests edit went ahead modified combine handle unequal training set sizes means really removed large chunk code trying stitch things together werengoing match kept portion combines forests can still use predict can test like obviously comes absolutely warranty need write file result data test convolutional neural network trained data include speech data collection file format needs file name prediction hard time extract file name load data like trying write file follows problem testh data path synchronized loaded files order test loader can depends dataset implemented instance case retrieve filename simply thing filename single sample mnist samples loaded different way show dataset implementationtell done can see path file retrieved getitem self index especifically implemented dataset perhaps like support shuffle batch size return sample fname getitem call something like way wouldnneed care shuffle batch size greater need change content loop something generic general case dataloader provide batches datasetinside barriel mentioned case single multi label classification problems dataloader doesnimage file name just tensors representing images classes labels however dataloader constructor loading objects can take small things together dataset may pack targets labels file names like even dataframe way dataloader may somehow grab need using pycharm ide debug tool let use take look inside data loader hope can see list filenames like case case data loader created mmsegmentation working application processing document images mainly invoices basicallylike convert certain regions interest xml structure classify document based data currently using imagej analyzing document image asprise tesseract ocr now looking something make developing easier specifically looking something automatically deskew document image analyze document structure although prefer java imagej interested libraries code papers regardless programming languagewritten system working far possible process data automatically user oversee results necessary correct classification suggested system therefore interested using machine learning techniques achieve reliable results similar documents processed structure usually user previously corrected data documents company corrections considered future limited knowledge machine learning techniques like know realize idea following prototype mathematica finds coordinates blocks text performs ocr within block may need adapt parameters values fit dimensions actual images address machine learning part question perhaps even need application import picture create binary mask printed parts enlarge parts using horizontal closing dilation erosion query bloborientation cluster orientations determine overall rotation averaging orientations largest cluster use previous angle straighten image time ocr possible lose spatial information blocks text will make post processing much difficult needs instead find blobs text horizontal closing connected component query bounding box position centroid position use bounding box positions extract corresponding image patch perform ocr patch point list strings spatial positionsxml yet sounds like good starting point tailored straightforwardly needs code parameters structuring elements morphological functions may need change based scale actual images also invoice tilted may need rotate roughly structuring elements order still achieve goodskewing paper use skew angle detection skew detection text line position determination digitized documents gatosal limitation paper can detect skew upto degrees need something slap user message case primarily invoice scans may beautifully use multiresolution analysis extraction reference lines documents gray level background tagal wrote code matlab need help let know worked similar project long time user opencv ended using opencv popular cross platform computer vision library offers programming interfacesc found interesting blog post detect skew angle text using opencv another deskew retrieve text document able pass smaller image tesseract suggest taking look bounding box technique donknow image acquisition procedure responsibility might want take look camera calibration opencv fix distortion image caused camera precision recallscore measures system quality machine learning systems depends confusion matrix true false positives negatives given binary classification task tried following get function returns accuracy precision recallscore seems like redundantly looped dataset times get true false positives negatives also multiple try excepts catch zerodivisionerror little redundant pythonic way get counts true false positives negatives without multiple loops dataset pythonically catch zerodivisionerror without multiple try excepts also following count true false positives negatives one loop alternative way without multiple pythonic way get counts true false positives negatives without multiple loops dataset use roughlyifs using elifs conditions mutually exclusive end counts pythonically catch zerodivisionerror without multiple try excepts start almost never use bare exceptcatching zerodivisionerrors write except zerodivisionerror also consider look leap approach checking whether denominator trying divisiontype conversion overhead bitwise operations much faster instances timeitgives method using bitarray passes instances goes get idea scales pretty using loops doesnstore large intermediate representation building temporary list tuples zip depending needs several libraries will calculate precision recallscore etc one used scikit learn assuming aligned lists actual predicted values simple micro averaging macro averaging weighted binary etc come free box